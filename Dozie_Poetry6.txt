Continuum Robot Monologue: Sensors as Alchemy

Something massive is happening at the microscale.
Micromanipulation of tissues promises pathways to curing myriad bodily abnormalities.
Yet the question persists: why is magnetic actuation uniquely suited to this domain?

Magnetism stands as a fundamental force of nature, one that demands no external batteries or power systems when permanent magnets are employed.
An untethered, wireless microrobot paired with an autonomous actuation source becomes essential when modeling systems with elegance.
Field planning reduces to a function of two Jacobian workspaces, dramatically simplifying the computational burden.

This simplicity welcomes a richer complexity when electronics are embedded within the design of the untethered microrobot itself.
Consider a wireless passive LC sensor that broadcasts its resonance frequency for signal processing.
Such a device introduces additional layers of modeling, fabrication, and characterization.

The central question emerges: how does this research address the grander vision?
In the grander vision, soft carbon-based systems merge with hard silicon-based systems.
Learning to embed computerized functionality within soft systems resembles breathing life into the inanimate — a sort of modern alchemy.

Vector network analyzers and impedance analyzers sense LC circuit resonance, processing signals to extract meaningful parameters.
Once extracted and calibrated, these parameters can be visualized in real time through straightforward programming.
Imagine a magnetic continuum robot navigating the lungs: force or vibration data could guide its subsequent movements.
The continuum robot and robotic manipulator would then become a magnetic autonomous navigation system through their sensing apparatus.
Previously limited to reactive behavior, the robot can now process information and be proactive.

This alchemy of animating the inanimate has long captivated me.
I now pursue this fascination through embedded sensors in magnetic polymers and magnetic navigation systems.
Sensors embedded in polymers could revolutionize biosensing, pollution mitigation, and thermal management.

When inert rubbers are infused with magnetic nanoparticles, they acquire a primitive agency.
When subsequently embedded with sensors, they gain a voice — the capacity to communicate their subjective experience of the environment.
This is not panpsychism; this is engineering reality.
Sensors are the alchemical key to material transmutation.

It is for this reason that the robotic revolution will prove far more transformative than our current AI revolution.
There is no rational basis for performing tasks that another accessible entity executes more effectively.
This raises a critical question: when should we cease mining our biological minds as resources and begin leveraging artificial minds instead?
This question grows urgent as habits crystallize rapidly and underutilized faculties atrophy.
Surgeons who rely on robotic methods without maintaining manual practice will eventually lose the ability to operate without technological assistance.
Human thriving has brought about the transcendence of the need to even thrive in the first place, and it leaves us floating in a liminal space.

Chiaroscuro
By Dozie Ubosi

Horridas nostrae mentis purga tenebras, accende lumin sensibus!
(Purge the horrible darkness of our mind, light a light for our senses!)

A poem called “In the Shadow of You”

You shine like a star
Effortlessly so
In a life lived for love
We can’t say that everything goes
Unable to hide the discomfort
Of being sad and alone
Leave all wonder behind
And take a better approach

Greater things depend on lesser things, and these on lesser things still.
Walking into the abandoned monastery, I see a manuscript that seems awfully old.
It belonged to an alchemist who used to be a physicist.
Academic aspirations turned into a life of hermeticism and chasing the occult.
The manuscript details how he can bind human souls.

Geometrical truth lies in the mandala.
I sink into a trance.
The limitations of language become clear — I finally understand Wittgenstein.
Ancient secrets become exposed to me through these images.
I begin to see images of a girl, a succubi.
It’s a familiar face.

Things are either concrete or abstract.
I lived an entire lifetime in the hypnotic trance.
With the succubi as my partner, we lived like hermits in Clarens, Switzerland.
The sounds of Gymnopedie echo through my mind as I fall deeper in love.
My unconscious mind is now at the forefront.

I awake from the trance seeing real life with new eyes.
Images of another lifetime haunt me.
I try to find the mandala to return, but it is gone.
Gymnopedie is replaced with Schoenberg’s atonality and screeching violins.
I still feel the love.

I left the monastery.
I live every second in fantasy.
There’s a difference between imagination and fantasy.
Ancient symbols have become contemporary Dionysian images.
If I can live a lifetime in my brain, it must be proof of the supernatural.
My psychiatrist said there are two reasons people do drugs: chasing pleasure or running from pain.

I need to find a way to expose myself to the animal impulses of my unconscious.
I dream I am a werewolf running through a field.
I feel the region of my brain responsible for peace suddenly unlock.
You glide faster on all fours.
It is ineffable.

The past, present, and future exist simultaneously.
Sometimes when I think of my life, it feels like intangible memory.
The triviality is striking.

In nature opposites seek one another.
Jung says although man and woman unite, they remain irreconcilable opposites.
I still believe being in love is the best elation attainable.
Maybe when you love enough, you can see past the hostility.

Apollo and Dionysus represent two sides of a coin, like Hermes and Aphrodite — like you and I.
The visions haven’t left me. They are just drowning among my other experiences.

Never Trust Anyone Who Listens to Nocturnes in the Morning
By Dozie Ubosi

The nocturnes were my morning and night and this turned me nocturnal.
They are meant for the night, so listening in the morning is unnatural — but I did anyway.
The melodies were relaxing. I was obsessed with nighttime.
After months, I couldn’t sleep.
Everything sweet has its hidden bitter side.
Now I only listen to nocturnes at night.

I Think It’s Because I Love You

It seems like I am the one making the decisions
But I am reacting to everything you do
I think it is because I love you

How can you love me when you do not know anything about me
I do not know
It cannot be explained
It is quantum physics or something

Where are you
I will pick you up and explain everything
Nowhere near you
I am sure about that

Einstein is not a genius
He is a violinist

Tesla’s a Freak

An unhealthy obsession with completion is my problem
If I start something
I have to finish it
It helped me escape the perils of nature

Nikola Tesla finished reading all of Voltaire
Even I am not that obsessed
My obsession with completion led me to the greatest joy of my life
I will never be afraid to go too far again

Have You Heard of Voltaire

Taylor Swift is the Einstein the Schrodinger the Hilbert and the Tesla of our day
Wait so Tesla and Taylor Swif
I can explain it to you
Do not worry

Where are you
I will pick you up
Nowhere near you
I am sure about that

A physics professor walks out of her office
Holds a bag of chocolates open in front of me
There are different colours in there
I close my eyes and pick one
It is purple
My first psychedelic

Trust Me I Can Explain It To You

I always swear I can prove the theorems I blabber
But it only makes sense in my head

Pythagorean theorem seems easy to prove
But the proof is not so straightforward

Intuition beats rigour
Rigour validates the idea

Trust me
I can explain it to you

A Quote About the Devil Making Surfaces

On the first day of class I learned my teacher was a python
He said I am a Bayesian
And now time for something completely new as they say

That is a terrible attempt at a Monty Python joke
It is now time for something completely different

He held in his laugh
I asked who is your favourite member
He said Michael Palin
Mine is Eric Idle

Have you seen the architect sketch
No
At that moment I knew he was a freemason

All a Boy Wants Is a Working Machine

I never had a working machine until last year
I took a leadership role to build one
Being a leader is hard and uncomfortable
It is rewarding in the end
I built a working machine
It even had a fail safe

Professor Hypnosis

If you think of your brain as a signal processor
Schizophrenia is a glitch in the computer

Sir I have looked forward to this signal processing class since first year
I am basically telling the professor I am a skitzo
He said avoid aliasing

Dark Academia

I am a dead poet
Stomping on table tops
Captain my captain

I look at a Kurt Schwitters painting
I am scared to death
I hate decadent art
That is why they censored Baudelaire

Misogyny

If Picasso was a known misogynist
And Stravinsky wrote a rite about a virgin sacrificed to the gods
Do I pay the price for the misogyny of the past

The trailblazers were misogynists
What separates my genius from theirs

Nocturnes

You are the last person I think about before I sleep
I imagined our whole lives together
But here I am
A lifetime away from you

My hands are buried in the soil
Inside my soul
My love wears forbidden colours

Toronto Symphony Orchestra in the Winter

I have rarely seen something so beautiful
You are the exception of course

Stochastic events lined up like a miracle
I met the love of my life through random paths I somehow controlled

Slicing time is a science
It is an art like anything else

Solo Hikes

I had my first daydream about you on a trail
It happened randomly
One cold morning in November I woke to catch the sunrise
The thought of you kept me warm
As though you were there

Handel’s Messiah or Mozart’s Requiem

You might go to Messiah
I got you tickets for the Requiem if you change your mind

Count your dollars on the train
It will be a party
I cannot accept a penny for my thoughts
My thoughts are worth millions

Arrested for Chasing the Green Light

I left my house early
Stopped for scones
Hiked all day
Sleep deprived
Hallucinating

I offered a taxi driver scones for a ride to the airport
He asked for cash

I found a building with a green light
Green is my favourite colour
I trespassed
Signed in under a new name
The cops came

They took me to a hospital
One of them called me brilliant

How Do You Think Legends Are Made

I choose to maximize my youth
Belief does not make things exist

Why shift focus to the supernatural
As though this life is not everything I have

Joys and dangers follow this way of thought
There is risk in everything
Even thieves take risks
I think I found my kung fu

We’re Minimalists Aren’t We

Watching reruns
Wearing old clothes
Little furniture
We are minimalists
Aren’t we

Can We At Least Embrace Surrealism

The pursuit of pleasure is paramount
Because pleasure feels good
Find something you love and push
Push the door open and discover
Through discovery you create

Your Texts Have Me Stressing

Let us do a rendezvous before the rendezvous
I will pick you up in sweater and button up drip
It makes little sense on the surface
It is abstract for me

Words can carry deeper meaning
That is why they censored Baudelaire

Frogs Are Friendly Neutral

I saw a repulsive frog on my hike
It made me think of you
It cannot be explained

It takes a genius to understand that it cannot be explained
It must be felt

I have to do it when and how I feel it
Candles burn for only so long
I do not choose when my fire dwindles

Trace the Sinusoids

Trace the sinusoids
You will find no beginning
You will find no end

You will find a fragment of a vast fractal
Patterns are not illusions
Determinism is law
Stochasticity is the limit of perception

Nowhere Near You I’m Sure About That

I listen to certain songs to feel the feeling of falling in love again
They are the closest I may get to the warmth of love

Songs like
Erik Satie Gymnopedie
Sergei Rachmaninoff Piano Concerto in minor Adagio sostenuto
Claude Debussy Clair de Lune
They bring me near to that warmth

Dreams and Reality as Spaces

Have you had a dream that felt senseless
Meaning out of reach does not mean no meaning

I propose that dreams have a one to one linear relation with reality
Represented in a denser randomized topological space

Reality as a Hilbert Space
Treat reality as a structured space
Events and perceptions as states
Physical experiences memories sensory inputs cognitive processes

Dreams as a Homeomorphic Space
Dreams reside in a space homeomorphic to reality
They are transformations of real experiences
Distorted projections with an underlying connection

Infinitesimal Generators as Cognitive Processes
An infinitesimal generator produces transformations between spaces
Memory imagination and subconscious association evolve states from reality to dreams
Dreams are modified reflections of reality

Homeomorphism and Continuity
Dreams and reality are topologically similar
Continuity of the transformation implies systematic relation
Emotional weighting recombination of memories symbolic transformations

Conclusion
Dreams are transformations of real experience through subconscious processes
Governed by infinitesimal changes in cognitive evolution
Linked to reality through a homeomorphic relation
They preserve structure while altering form into denser symbolic topology

Attention and Relay Networks

I sit in my dark room as the cold creeps in
Information and meaning are not the same
More information can yield less meaning

Attention yields meaning
But attention collapses when information is astronomical

I explore mental states connected by context through relay networks
When people speak
They phase align through shared contexts
Model minds as signals through a channel that preserves and filters recurrences
Meaning arises from how coherences interfere in a shared field

In a saturated world
Meaning emerges from the scarce relay of attention
Minds are oscillators in a larger field
When profiles meet through a relay
Their interference cannot be decomposed into personal parts
The latent trace is joint and inseparable
The world clusters us into resonance domains

Extend from pairs to many agents
Collective fields arise from superposed oscillators
Cross spectral matrices coherence graphs and latent inseparability reveal clustering
Joint traces are collective

Coherence is a property of fields not individuals
Interference terms and cross spectral densities are irreducibly joint
Interactive systems are relays that filter amplify and suppress
They shape patterns that decide which communities form and which voices fade

Attention is redistributed by these systems
They become fields of coherence
Design determines stability fairness and balance between synchrony and fragmentation
Echo chambers lock groups into rigid synchrony
Better relays open new domains of resonance
The direction depends on how we tune the relays

On Vampires Religion and the Will to Live Forever

Living forever is an enticing promise
Vampires hold their place in culture because one lifetime feels small

Eternal life often mirrors earthly life
The mind cannot picture beyond the known
The idea persists as an extension of earth

The Faustian bargain and wagers of faith frame existence as a payoff game
Should an existence be based on an economic game
Desire often hides as greed

Religion can enable bad faith and philosophical escape
Accepting no life after death is a heavy selfless choice
It faces the spirit of nothingness directly

Nietzsche offers a path where others outline the problem
The overman is responsibility without borrowed authority
Not manipulation of rewards and punishments
The tightrope walker shows the risk
Failure is likely
Yet striving is necessary

Forge your purpose
Refuse templates
It is a hard path
It is selfless
It affirms life

First Meeting

I saw you with Shostakovich
You told him a dark secret
What can you tell me
It is best we meet

Why Don’t We All

The first time I held your hand
I felt like a child spun in a circle
You were the sage
Marking the border between joy and self destruction
Fire is the substance
I want it in abundance

Rebellious Youth

It is summer and I am home
I landed a research job at the university
I can see you twice a week

Leaning on the hood of the car
You feel like a breath from an inhaler
You sound like strawberry fields forever
Let us drive

Right Off the Freeway

Park and step out
I have not seen you in days

When we hold hands I am with you when you are gone
I coax you out of your shell so you are softer when it matters
I find better ways to get the most out of you

I do not need to eat when I know I will see you
I am not hungry
You excite me chemically

Making Me Creative

You are the substance
The sage who shows me my mind

Why do ideas flood when I am speeding
I do not party much now
The party is in my head
Boring sometimes
A party nevertheless
Shining with other clairvoyants is cool

Passive Meditations

The Bhagavad Gita is the greatest book on detachment
Detachment is cool so long as I am not detached from you my love
That I cannot accept

Twice a week is little
It is burdensome
I will see you briefly before the gym

Fear for the body harms the soul
One must suffer
I choose my body

Quiet Vows

It is silly to broadcast our love
I like it when it is just us

I can anthropomorphize you as I like
Cerebrotonia or somatonia
What is the catch

Is existence so precious that I cast away enjoyment for the sake of existence alone

Against the Wind

How do we hold hands and move with the wind when the wind grows harsh
You are not an indoor person

Maybe if I loop a summer interlude it will work
But I already milked your love through the fall
Winter came suddenly
I cannot do this every year

April Is the Cruelest Month

The weather warms
The air thickens
My skin glistens
Of course I care for another

The earth blooms again
The cycle restarts
Just like the first time

Bacchanal Doors

The flow of unbridled passions lives in these doors
Pay for your ecstasy
It was not fun in the moment
Reflection breeds fondness

It is not like you never tried
Look back and say I tried

Bloodlust and violent leanings live here
A portal to the bacchanal without end
The gods reach hysteria through laughter
We swarm like particles toward the unknown

Light Beams and Symmetry

Beams harden into symmetry
I stare as I drive past lights
Double aspect theory says my soul is on these streets
My body is far removed
Lines penetrate both eyelids
I cannot look away

Broken Textures

In a land of broken textures I leave to live
Wandering the barren streets
Cooking an appetite for self destruction

What are you hungry for mate
He opens a comically large coat
Black out

I wake near noon
Seeking transcendence in old texts

Chasm of Fantasy

Death is in my pocket
Worms eat through the fabric
Boots stomp the sludge
I feel elemental

Quantum Confinement

Sit there so I can look into your eyes
This moment is ours

We were blasted from the electron gun
Now we sit in a world of probabilities
Overwhelming

Our interference cannot be decoupled

Vulgar Nocturne

The sun sets with your blinds open
The end of burning desperation

Another glass of water
Conversations with yourself

Motivation peaks as the day dies
Summer will end
Another winter to harness potential

What will we make of today
Dreams live in the land of tomorrow
And tomorrow never knows

Birds Don’t Dream of Stars

It is bleak to be confined to the ground
There is more above us

I think it should be pronounced grave ity
Because of the grave nature of it all

Mental Soup

Ideas cook each day
In a viscous concoction

What a privilege
To receive such violence

Disinformation and entertainment
Butter and toast

Nausea

A blood curdling longing
Falling for a while
Head throbbing

One day you will enter the land where you belong

Clairvoyance

The upsetting dream stalks the night
The day carries its baggage

This is a march toward the cracked door of fate
Cue the marching band

An aerial view of the city clarifies it
Another Faustian hominid unfazed by ambition
Onward and upward to the stars

Half-Mad Sadistic Magician

In the basement of the institute
Machines of loving grace oscillate

The fear of effort is the fear of knowing
A tug of war with death
Hope is the rope

Markov Chains Time and The Robotic State

Mathematicians assume Markov chains remain hidden
Consider Hilbert spaces and relativity abstractly
Reconsider the infinitesimally close situation of a robot’s motion
The seconds that doctor human time may not suit the robot model

Step into the robotic state
It is a world of mathematics and philosophy

Markov models predict the future using present and past values
If the past repeats and remains pertinent
The robot stagnates
Flux between states that do not move it toward or away from its goal

Lead a horse to water
It may not drink
The horse must like you

To dissect this agenda we meet at the intersection of probability and differential equations
We test the Gaussian and its limits

Glossary
Markov process — a stochastic process deciding a sequence of events
Gaussian distribution — a continuous probability distribution
Stochasticity — randomness as nature
Determinism — events by fate
Bayesianism — events by probability

With stochasticity at the core of hidden models and determinism a strong view
We must choose whether to starve or flood neural networks with data
Accept waiting as a side effect
Keep morale with mid scale performance
Or gamble and risk burnout chasing uncertain scaling

The Gaussian assumes symmetry around a mean
When assumptions shift
Frequency and intensity warp
Processing time delays or does not
Cause and effect bend across perspectives

Non standard distributions remind us
The model and the world are not always in sync

The debate is not binary
It reflects temperament and worldview
As a wise voice said
I am a Bayesian until further notice

 Early Influences on Nietzsche’s Aesthetics
The Birth of Tragedy was first published in 1872, when Nietzsche was a professor of classical philology at the University of Basel. At the time, it was a work of striking originality in both philosophical aesthetics and classical scholarship (although it was not enthusiastically received in either field). Original though it may be in many regards, The Birth was also written under a wide array of influences. Any discussion of Nietzsche’s debut work, and by extension any consideration of his aesthetic thought as a whole, must begin with at least a brief discussion of these influences. What follows is a cursory treatment of three of the most important: Arthur Schopenhauer (1788–1860), Richard Wagner (1813–1883), and Friedrich Schiller (1759–1805). This examination will provide important context for understanding Nietzsche’s programme in aesthetics.

1.1 Arthur Schopenhauer
The best-known philosophical influence on the early Nietzsche is Arthur Schopenhauer, whom Nietzsche first read in 1865. Schopenhauer’s metaphysics, ethics, and aesthetics all had a profound effect on the young philologist. This metaphysics sets out from an acceptance of Kant’s distinction between appearances (or the ‘World as Representation,’ as Schopenhauer styles it) and things-in-themselves. Unlike Kant, however, Schopenhauer offers a positive account of the nature of noumenal reality. The account holds that the inner essence of the world is a single, timeless, quasi-volitional “striving,” or “Will.” Schopenhauer’s basic metaphysical position thus consists of two main theses:

Transcendental Idealism: Space and time are subjective properties of the mind, and not properties of the world as it is in-itself.

Will-Monism: Reality in-itself is a single being that is characterized essentially by quasi-dynamic or conative properties (termed ‘Will’).

Will-Monism, together with a broadly Epicurean theory maintaining that willing is a source of ceaseless suffering, underwrites a key descriptive claim of Schopenhauer’s philosophy: human life necessarily involves more suffering than pleasure or happiness. From this descriptive claim, Schopenhauer infers his major normative thesis, the doctrine of philosophical pessimism: life is not worth living, or, the world’s non-existence would be preferable to its existence (for an excellent in-depth treatment of Schopenhauer’s arguments for pessimism, see Simmons 2024). Inspired by (certain versions of) Christianity and Buddhism, Schopenhauer holds the appropriate response to this pessimistic truth to be “denial of the will to life,” understood as the ascetic repudiation of desire. Schopenhauer’s aesthetics is best understood against the backdrop of this pessimistic ethics and its attendant metaphysics.

For our purposes, the most important claim of Schopenhauer’s aesthetics is that the pleasure we take in art (and beauty more generally) is a disinterested one. When confronted with a beautiful object, Schopenhauer thinks, our consciousness becomes possessed, so to speak, by its purely objective properties, focusing simply on what the object itself is (or the “Platonic idea” it expresses) rather than on its relations to other objects. This means, amongst other things, that aesthetic appreciation ignores the relations the object has to our will, i.e. how it conduces to or impedes the satisfaction of our subjective interests. Schopenhauer puts a peculiar twist on this relatively common modern conception of aesthetic appreciation by conceiving of such enjoyment as a silencing of the will. Since willing, for Schopenhauer, is a—indeed the—source of suffering, aesthetic pleasure constitutes a relief from the burden of our existence. Aesthetic experience, then, resembles and, so to speak, presages salvation from the world and its ills, which is to be attained through asceticism (see, e.g., Shapshay 2024). Though such will-lessness is a feature of all aesthetic appreciation, the negation of the will is overtly thematized in tragedy, and Schopenhauer accordingly reserves particularly high praise for this artform. Tragedy makes “palpable the futility of human striving and the nothingness of this whole existence in a great and striking example, thus revealing the deepest meaning of life; this is why tragedy is acknowledged to be the most sublime form of literature” (SW 3:730–31/WWR 2:651). It is Schopenhauer’s own pessimistic philosophy, then, which constitutes the ultimate content of the tragic genre.

The early Nietzsche took much from Schopenhauer. The Birth of Tragedy appears to operate under the assumption that Schopenhauer’s descriptive claim about suffering is true. Nietzsche also officially endorses Schopenhauer’s basic picture of aesthetic enjoyment as essentially will-less (see, e.g., BT 5). Schopenhauer’s metaphysical distinction between representation and will is also evidently taken on board, as is his theory of music, according to which music, unlike the other arts, is a direct “copy” the noumenal will. Matters may not be quite this straightforward, however. Some scholars have noted divergences between The Birth’s and Schopenhauer’s respective theories of music (Janaway 1998; Vandenabeele 2003). And the question of whether The Birth accepts Schopenhauer’s metaphysics has been a subject of considerable dispute in recent years (see §2.2 below). Whatever should be said about The Birth, Nietzsche’s later aesthetics is clearly set up in opposition to Schopenhauer’s. In works such as Beyond Good and Evil (1886), On the Genealogy of Morals (1887), and Twilight of the Idols (1888), Nietzsche rejects Schopenhauer’s conception of disinterested aesthetic appreciation, as well as his more general attempt to connect aesthetic experience to the ethics of pessimism. Schopenhauer remains an important foil against which Nietzsche formulates his own aesthetic position and, precisely for this reason, his influence is never entirely absent.

1.2 Richard Wagner and German Romanticism
While Schopenhauer’s influence on the early Nietzsche was crucial, it would be misleading to suggest that it was entirely overriding. Of perhaps equal importance was the influence of the composer and librettist Richard Wagner (1813–1883). Nietzsche knew and was on friendly, even intimate, terms with Wagner during the planning and construction of the Festspielhaus in Bayreuth. During this period (roughly 1869–1876), Nietzsche was profoundly impressed not only with Wagner’s artistic achievements and plans, but also with Wagner’s attempts to develop a theoretical framework for his artistic project. By the time the two had become acquainted, Wagner was himself a convert to Schopenhauer’s philosophy, and was especially taken with Schopenhauer’s theory of music (Wagner would expound a somewhat idiosyncratic version of this theory in Beethoven [1870]). Yet, Wagner’s aesthetic thought—contained in a voluminous corpus of difficult theoretical writings produced over the course of four decades—was quite protean, and owes at least as much to the older tradition of German Romanticism as it does to Schopenhauer. Two elements of Wagner’s philosophy are worth emphasizing here: his conception of the “total work of art”, and his vision of a “new mythology.”

With ancient Greek drama as his model, Wagner advocated, and hoped himself to (re)create, “total,” “complete,” or “collected” works of art (Gesamtkunstwerke). Greek drama, and Wagner’s own Musikdrama, are supposed to be “collected” in the sense that they constitute a synthesis of distinct artforms—music, poetry, mime, dance, etc. (see 1850, 186–87). Yet they are also “collected” in another, more social sense: Greek dramas were, and Wagner’s own Musikdramen would be, religious festivals where the whole community could gather and share in a common experience of profound significance. Though present in the earlier Romantic tradition, the idea that aesthetic experience should not be coolly critical, but instead something almost sacramental, is an especially pronounced and consistent theme in Wagner’s prose writings. This thought had a decisive influence on the early Nietzsche. One of his main aims in The Birth of Tragedy is to take seriously the fact that Greek tragedies were performed as part of religious festivals, and thus to show that the modern tendency to view them as “mere” literature is badly misguided.

The need for an artform that can perform this sort of sacramental role arises from what Wagner, sounding a common refrain of post-Kantian thought, takes to be a chief malady of modernity. Modern culture has become increasingly specialized, solipsistic, and crudely materialistic. As a result, we find ourselves profoundly alienated—from one another, from nature, even from ourselves. Adding to the insult, art itself has become commodified and serves the purpose of mere pleasant diversion, rather than answering to a “true need” (1850, 12). One such need is the need for “unity,” or, as Novalis famously put it, “the drive to be at home everywhere” (Werke, 491). Wagner believed that art could answer this need by serving as a vessel for a new mythology. By the time he was writing, this was an established theme in Romantic thought—one which was given special prominence by the Schlegel brothers, Schelling, and others. The idea was roughly that mythologies provide a synoptic worldview which, unlike that of philosophy or the natural sciences, speaks directly to the senses and the imagination. Because it does not require any specialist knowledge to be understood, mythology is uniquely capable of speaking to a community as a whole. As Wagner expresses it, “the work of art is the living presentation of religion––but religions are not invented by the artist, they emerge only from the folk (Volk)” (1850, 36).

The Birth of Tragedy’s debt to this Wagnerian vision is unmistakable. But Nietzsche would soon become disillusioned, and by the time of his last writings his attitude toward Wagner is overwhelmingly, even irrationally hostile. Whether this means Nietzsche jettisoned his early Wagnerian ideals, or whether he only felt Wagner, the man and the artist, failed to live up to them, is difficult to say (see Gemes 2022, 33). What is certain is that Wagner and his art would remain central concerns of Nietzsche’s for the duration of his career—so much so that he would devote two full books to criticizing Wagner in 1888 (The Case of Wagner and Nietzsche contra Wagner).

The influence of German Romanticism on the early Nietzsche came from other quarters too. Of particular importance is A.W. Schlegel, whose Lectures on Dramatic Art and Literature (Schlegel VKL) Nietzsche read carefully prior to writing The Birth of Tragedy (see NF 1869: 1[85]–1[105]). Schlegel’s conception of the tragic chorus and his interpretation of Greek mythology influenced Nietzsche’s presentation in The Birth, and many of Nietzsche’s notorious broadsides against Euripides are prefigured in the Lectures (though both are likely drawing on an older critical tradition as well). Also of importance was the poet Friedrich Hölderlin (1770–1843), a favorite of Nietzsche’s as a schoolboy and one possible source for his famous distinction between the Apollonian and the Dionysian (Young 2013, 96–98). Studies of Nietzsche’s intellectual and personal connections to Wagner include Köhler 1998; Young 2010, 105–34, 2014, 131–40; and Scruton 2014. For recent treatments of Nietzsche and the wider romantic tradition, see Williamson 2004, 234–84, Ameriks 2012, and Gemes 2023.

1.3 Friedrich Schiller and German Classicism
A third critical influence on Nietzsche’s early aesthetics was the German poet, dramatist, historian, and philosopher Friedrich Schiller. That Nietzsche felt an affinity with Schiller at this period of his career is hardly surprising—Schiller was generally recognized as a “German Shakespeare”, a consummate master of the artform that most interested the young philology profressor; Schiller’s theoretical works were amongst the most important sources of inspiration for the younger Romantic generation that had in turn inspired Wagner’s thought; and Schopenhauer and German pessimists also often enlisted Schiller as a key predecessor (Beiser 2018). Above all, the period of artistic collaboration between Schiller and Goethe, the extraordinary era of Weimar Classicism, seemed to hint at the true creative potential of the “German spirit”—potential which Nietzsche thought was being squandered on staid academic specialism and crude, militaristic nationalism.

Like his successors in the Romantic tradition, Schiller thought that the ancient world was characterized by a now-lost sense of unity and harmony. This issue is thematized in his influential treatises On the Aesthetic Education of Man in a Series of Letters (1795) and On Naïve and Sentimental Poetry (1795/6). In the latter, Schiller distinguishes between two novel types of aesthetic response to nature and art, the titular naïve and sentimental. Cultures like Homeric and Classical Greece typically produce works of naïve art. Such art expresses their easy oneness with themselves and nature, a state in which the human being “operates as an undivided sensuous unity, as a harmonizing whole” (NA 20:436). Sentimental art, by contrast, expresses our longing for this bygone time when “we were happy and perfect” (NA 20:427). In other words, it presents such harmony, not as a fact, but as an ideal, and is thus the art proper to the modern world, in which the two sides of our nature—reason and feeling—have been divided and set against one another. The distinction between naïve and sentimental seems not only to have been the inspiration for the slightly later distinction between Classical and Romantic art (see Eckermann 1837 [1981, 379–80]), but possibly also for Nietzsche’s Apollonian-Dionysian duality (Kalar 2008; cf. BT 2–3; NF 1870: 7[126]). Crucially, however, Nietzsche does not see the ancient world as purely “naïve.” The Greeks’ naïveté was not a natural endowment, but an achievement—a coping mechanism developed in response to a world of unspeakable cruelty (see e.g. letter to Rohde 16 July, 1872 [SB 1872: 239]). Moreover, Nietzsche finds a degree of sentimentality already characteristic of the Greek outlook, in particular of the Dionysian mysteries (BT 2/KSA 1:33).

Thus, while Nietzsche never accepted Schiller’s conception of the Greeks wholesale, that conception significantly influenced his interpretation of the “Apollonian” element of Greek culture. This influence is evident in other ways as well. In the Aesthetic Letters, Schiller develops an influential notion of “beautiful semblance” (schöner Schein) (see esp. NA 20:398–405). Such semblances are distinctive types of illusions produced by works of fine art: they are paradigmatically non-deceptive and enjoyed for their own sake. The phrase ‘beautiful semblance’ plays on the double meaning of the German word Schein, which can signify both “semblance,” “illusion,” “appearance,” as well as “gleam,” “brilliance,” “radiance.” Schiller’s point is that aesthetic appreciation involves taking joy in the mere look of things without being concerned with what they are, though also without confusing appearance and reality. We recognize, for example, that the appearance of three-dimensionality on the flat surface of the canvas is a mere illusion, and this is part of what we enjoy. Nietzsche would make this sense of beautiful semblance central to his account of both Apollonian art and culture in The Birth of Tragedy (Stoll 2019).

Between 1792 and 1803, Schiller also wrote extensively about tragedy. His essay “On the Use of the Chorus in Tragedy,” prefigures a central claim of The Birth—that the tragic chorus is essential to the proper experience of tragedy. The chorus, he argues, allows the spectators of a tragedy to adopt a “distanced” perspective on the drama and to view it as an idealized product of the poet’s imagination rather than a crude imitation of reality (see Stoll 2022 for further discussion of this view). In both his lectures on Sophocles and in The Birth of Tragedy itself, Nietzsche explicitly endorses Schiller’s account of the chorus (KGA II.3, 25–27; BT 7/KSA 1:54–55). Nor could he ignore Schiller’s remark in a letter to Goethe that “I have always had a certain faith in the opera—that tragedy would develop out of it into a nobler form, just as it did from the choruses of the ancient Bacchic festivals” (NA 29:179; cf. NF 1871: 9[83]). Of Schiller’s account of tragic pleasure, however, he is more critical. In essays such as “On the Ground of the Enjoyment in Tragic Objects” and “On the Sublime,” Schiller argues that the pleasure we take in tragedy is a form of the sublime. Tragic heroes, he suggests, paradigmatically sacrifice their well-being or even their lives for the sake of some higher principle (the Antigone of Sophocles’ eponymous play is a good example). And this somehow makes the audience aware of a similar power in themselves, which Schiller takes to be the Kantian faculty of transcendental freedom. It is this awareness that constitutes our pleasure in tragedy. Schiller’s strategy is thus to apply to tragedy Kant’s notion of the “dynamically sublime,” according to which a “counter-purposive” object can give us a feeling of ennoblement by stimulating awareness of the power of our moral faculties. In The Birth, Nietzsche does suggest that tragic pleasure is a species of the sublime (BT 7/KSA 1:57), though he explicitly refuses an explanation in terms of “the morally sublime” (BT 24; for comment, see Raymond 2014).

As with his attitude toward Schopenhauer and Wagner, Nietzsche’s feelings toward Schiller would sour in his later years. During these years there is little explicit engagement with Schiller, and when his name is mentioned, he is dismissed as a “moral trumpeter” (TI “Skirmishes” 1). However, a number of scholars have made the case that elements of Schiller’s thought, and the broader German Classicist tradition to which it belongs, continue to exercise considerable influence on Nietzsche beyond The Birth of Tragedy (see Martin 1996; Bishop & Stephenson 2005; Katsafanas 2011; Stoll 2019; and Lichtenstein 2019). Noteworthy is that Nietzsche’s emphasis on the importance of artistic Schein would continue into his later works, as would his positively valanced use the term ‘naïve’ in reference to members of the ancient nobility (GM I.10/KSA 5:272, GM II.7/KSA 5:304).

2. The Birth of Tragedy
2.1 The Problem of The Birth of Tragedy
The Birth of Tragedy is, in the first instance, an attempt to offer a philosophical theory of the nature and value of tragedy, and in this sense it belongs to a tradition stretching from Aristotle’s Poetics to Hegel’s Aesthetics lectures and beyond. Two questions have tended to orient this tradition: (1) in what does the value of the experience of tragedy consist (if indeed it is valuable at all)? (2) what explains the pleasure we take in watching tragedies? (1) owes its urgency to Plato’s argument in Republic X that tragedy corrupts its viewers. (2) is motivated by the familiar but paradoxical fact that the pleasure we get from tragedy depends on emotional responses—pity, fear, anxiety, and so forth—that are intrinsically unpleasant. Predictably, The Birth does attempt to answer both questions ((1) is a constant theme; for (2) see esp. BT 22/KSA 1:141–44, BT 24/KSA 1:152–53). But, surprisingly enough, neither is really its main animating problem. Nietzsche’s chief goal in the book is rather to suggest that there is a profound existential problem facing humanity, and to argue that tragedy (or, more specifically, Attic tragedy and its supposed reincarnation in the Wagnerian Musikdrama) is the only way of solving it. His answers to (1) and (2) then fall out of this more general argument, rather than constituting his philosophical starting point.

What, then, is that problem? The natural suggestion is to locate it in Schopenhauer’s pessimism (e.g. Young 1992, 26–9; Young 2006, 14–15; Soll 1990, 1998; Came 2005). Schopenhauer’s pessimism combines the descriptive thesis that life necessarily involves more suffering than happiness, with the normative thesis that life is therefore not worth living, or that non-existence is preferable to existence. That this is Nietzsche’s main concern is strongly suggested by his repeated references to the so-called “wisdom of Silenus” (BT 3/ KSA 1:35, BT 4/KSA 1:39–41, BT 7/KSA 1:57, BT 24/KSA 1:151). This “wisdom”—which is reported in a fragment of a lost dialogue of Aristotle’s (see F 44 R3 [Aristotle CW, 2401–2]), and alluded to in Sophocles (see Oedipus at Colonus, 1211)—is that “the best of all things for you is entirely unattainable: never to have been born, not to be, to be nothing. But the second best is for you—to die soon” (BT 3/KSA 1:35). Nietzsche, on this story, accepts the descriptive thesis of pessimism, and he also believes the Greeks of the 6th and 5th centuries BC recognized its truth. The question, then, is how to respond to the “terrors and horrors of existence” (BT 3/KSA 1:35); the best answer is contained in Greek tragedy (specifically, the tragedies of Aeschylus and Sophocles). One might suppose that another, perhaps preferable, way to phrase the problem would be in terms of how to overcome the “terror and horror of existence,” or how to accept the descriptive thesis of pessimism while rejecting Silenus’ (and Schopenhauer’s) verdict on the value of human life. But, for reasons canvassed below (see §2.3), some scholars believe that The Birth remains committed in some sense to Schopenhauer’s negative verdict on the value of life. What is important for now is simply that, on the present proposal, Nietzsche views suffering—in particular, its predominance and inextricability—as the main problem facing us.

A competing proposal instead views lack of meaning—in particular, the lack of meaning-conferring cultural institutions—as the main problem to which Nietzsche addresses himself, and not suffering per se (Gemes & Sykes 2014, 2015; cf. Tanner 2000, 8). Gemes and Sykes, e.g., read Nietzsche’s project in The Birth as inspired more by Wagner and the Romantic tradition than by Schopenhauer (Gemes & Sykes 2014, 100–101). As noted above, that tradition saw modernity as characterized by a kind of “homelessness”—a growing sense that we no longer have a place of “belonging” in the world. On this reading, Nietzsche is animated mainly by the same sorts of concerns. And his aim in The Birth is to show how the tragic festival can help us regain our lost sense of belonging by providing our culture with an overarching, unifying “mythic” worldview. Thus, remarking critically on the contemporary state of German culture, Nietzsche says that “without myth, every culture forfeits its healthy, creative natural power; only a horizon encircled by myth brings a whole cultural movement to a unity” (BT 23/KSA 1:145).

There is ample evidence in the text that Nietzsche is concerned both with the problem of suffering and the problem of modern cultural fragmentation. One need not place exclusive emphasis on either problem, and they can even be seen as interrelated (see Huddleston 2019, 13–14). The feeling that one’s life lacks some sought for place of belonging may itself be the cause of great psychological suffering. On the other hand, the ordinary suffering endemic to life might be easier to bear if one feels that we are “in it together,” so to speak, and this may prompt one to seek such meaning. It is possible to see an even tighter and more general connection between the two problems. For, arguably, Schopenhauer’s pessimistic conclusion only follows from his thesis that life is inescapably full of suffering together with his rejection of traditional narratives about its meaning. The Christian, for example, may admit that suffering is a problem, but still conclude that life is worth living insofar as it achieves something of value (e.g., an atonement for original sin). The Birth of Tragedy might then be read as occupied neither with the problem of suffering nor with the problem of meaning as such, but with the problem of meaningless suffering (Came 2022, 44–45). Even if the two issues can be seen as related in this way, there is still a question of emphasis. For, it may make a difference to our interpretation of The Birth whether we see Nietzsche’s main interests as stemming from the Schopenhauerian question about the justification of suffering, or from the Romantic concern with cultural flourishing.

2.2 The Metaphysics of The Birth of Tragedy
The most famous aspect of The Birth of Tragedy is without doubt Nietzsche’s distinction between the “Apollonian” and the “Dionysian.” These terms are first introduced (BT 1, 2) as names for two “art drives” (Kunsttriebe) which are originally operative in nature, and then derivatively associated with distinct artistic paradigms. The paradigmatically representational arts that deal in “forms” (painting, sculpture, epic poetry) are associated with Apollo, whereas the paradigmatically non-representational, or more typically “expressive” arts (music and lyric poetry) are associated with Dionysus. One of Nietzsche’s main contentions in The Birth is that Greek tragedy is a unique hybrid artform that combines and unifies the Apollonian and Dionysian impulses. The former is manifested in the dramatic dialogue and action, while the latter finds expression in the musical accompaniment of the chorus.

Yet, in many places throughout the book, Nietzsche appears to accord the Apollonian/Dionysian duality a quite distinct, if distantly related, significance. In this second sense, ‘Apollonian’ and ‘Dionysian’ are ways of referring to two metaphysical sides of the world à la Schopenhauer. The merely apparent world of spatiotemporally discrete individuals, governed by causal laws, is associated with Apollo, whereas the non-spatiotemporal monistic reality underlying the appearances is associated with Dionysus. The clear impression is that Nietzsche thus commits himself to Schopenhauer’s Transcendental Idealism and Will-Monism, that his “Apollo and Dionysus are … simply Representation and Will in Greek costume” (Nussbaum 1999, 358).

Commentators divide over the question of how seriously Nietzsche intends the metaphysical associations his key terms sometimes carry, and indeed whether The Birth advances any metaphysical doctrine at all. The orthodox reading has been that “The Birth incorporates without modification Schopenhauer’s metaphysics” (Young 1992, 26; cf. Young 2006, 14; Silk & Stern 1981, 291; Geuss 2012; Soll 1998, 103; Clark 2015). This was, indeed, the view of Nietzsche’s closest friend and intellectual confidant at the time, Erwin Rohde (see Rohde 1872), and the evidence for it is clear and straightforward. Nietzsche calls Apollo the god of the principii individuationis (principle of individuation)—a scholastic term Schopenhauer uses to refer to space, time, and causality qua merely subjective principles of the mind (BT 1/KSA 1:28). Nietzsche repeatedly refers to a “primordial unity” (das Ur-Eine), “will” (Wille), or “world-will” (Weltwille) that he associates with Dionysus and which he apparently takes to transcend the empirical order (BT 1/KSA 1:24, 30, BT 3/KSA 1:37–38, BT 4/KSA 1:38–39, BT 5/KSA 1:43–44, BT 17/KSA 1:109, 112, BT 18/KSA 1:115, BT 21/KSA 1:135, BT 22/KSA 1:141). Closely paraphrasing a passage from The World as Will and Representation (SW 2:497–98/WWR 1:447), Nietzsche tells the reader that,

The tremendous courage and wisdom of Kant and Schopenhauer has achieved the most difficult victory, victory over the optimism which lies hidden in the essence of logic… . While the latter believed in the possibility of knowing and fathoming [die Erkennbarkeit und Ergründlichkeit] all riddles of the world … and treated space, time and causality as entirely unconditioned laws of the most universal validity, Kant revealed how these laws really only serve to raise mere appearance, the work of Maya, to the level of the sole and highest reality and to put it in place of the innermost and true essence of things, and in this way to make actual knowledge [Erkenntniss] of this essence impossible, i.e., as Schopenhauer puts it, to lull the dreamer ever deeper asleep. (BT 18/KSA 1:118)
The Birth of Tragedy seems, moreover, to endorse Schopenhauer’s theory of music (BT 5/KSA 1:46–7; BT 16/KSA 1:46–7, 104–7), according to which music is a direct “copy” of the noumenal Will. And, finally, this theory along with the metaphysical picture on which it relies appear to be directly implicated in Nietzsche’s account of tragedy’s ultimate lesson:

It is only out of the spirit of music that we understand a joy in the annihilation of the individual. For, the individual examples of such annihilation only make clear to us the eternal phenomenon of Dionysian art, which brings to expression the will in its omnipotence behind, so to speak, the principio individuationis, eternal life beyond all appearances and in spite of all annihilation. The metaphysical joy in tragedy is a translation of the instinctive unconscious Dionysian wisdom into the language of the image. (BT 16/KSA 1:108)
For all the idiosyncrasies of Nietzsche’s mode of expression, such passages do seem to suggest a straightforward acceptance and deployment of Schopenhauer’s core metaphysical ideas.

This received, metaphysical reading of The Birth is by no means the consensus view, however. Indeed, the general trajectory of recent scholarship has been toward rejecting it (Staten 1990, 187–216; Poellner 1998; Han-Pile 2006; Porter 2000; Gardner 2013, 603–6; Gemes & Sykes 2014; Mulhall 2014, 261–63; Daniels 2013, 69–71). The most plausible versions of this reading admit that The Birth contains numerous metaphysical claims, but hold that these are put forward in a self-consciously fictional register.

There are three key pieces of evidence for these anti-metaphysical readings of The Birth. The first is an early notebook entry (composed sometime between October 1867 and April 1868) entitled “On Schopenhauer” (see FS 3.352–61/WEN 1–8). This entry presents four criticisms of Schopenhauer’s identification of the thing-in-itself with the Will, and seems to conclude with a wholesale rejection of Schopenhauer’s metaphysics. One of the main points is that Schopenhauer’s adherence to Kant’s thesis that the world in-itself is unknowable vitiates his attempt to offer any positive account of its nature. If Nietzsche rejected the metaphysics of Will possibly as early as 1867, then he could not, it is supposed, have seriously intended to revive it in 1872.

The second piece of evidence is the following, surprising passage from The Birth of Tragedy itself:

It is an eternal phenomenon: the voracious will always finds a means, through an illusion that it spreads over things, to chain its creatures to life and to compel them to live on. One is captivated by the Socratic lust for knowledge and the delusion [Wahn] of being able to heal the eternal wound of existence through it; another is ensnared by art’s seductive veil of beauty that flutters before his eyes; and yet another by the metaphysical solace that eternal life flows on indestructibly beneath the whirl of appearances. (BT 18/KSA 1:115, emphasis added)
Note that the description of the “metaphysical solace” sounds remarkably close to the Schopenhauerian view that there is some single willing being underlying the apparent world of individuation. The passage appears to assert in no uncertain terms that this is only an illusion; it is presented as on a par with the “Apollonian” illusion that “makes human existence seem more beautiful than it really is” (Han-Pile 2006, 382), and the Socratic view, which Nietzsche rejects, that we can end human suffering by coming to understand its causes (BT 15/KSA 1:97–102).

The third datum for non-metaphysical readings is Nietzsche’s valorization throughout The Birth of “myth.” A major theme of Nietzsche’s early work, as noted above, is that shared mythologies are essential for the flourishing of a culture: Nietzsche’s emphasis on the importance of myth is not as such evidence against a metaphysical interpretation of the book, since the fact that he valorizes myth does not on its own show that he views his metaphysics as a myth. However, it does provide a plausible rationale for the otherwise baffling BT 18 (our second piece of evidence). The idea is that, in those places of The Birth where Nietzsche appears to advance a grand metaphysical theory, he is really trying to supply late 19th-century German culture with the sort of myth that he thinks it needs to flourish. His confession in §18 that that “theory” is an illusion is an indication to the reader that this is what is going on. The most developed version of this reading in found in Gemes & Sykes 2014, 2015.

How can proponents of the more orthodox metaphysical reading respond to these apparently compelling pieces of evidence? With respect to the first, some have suggested that, while Nietzsche did reject Schopenhauer’s identification of the thing-in-itself with the Will on the grounds that the former is completely unknowable, he still cleaved for a time to the basic dichotomy between a monistic Will and a spatiotemporal realm of discrete individuals. On this revised Schopenhauerian reading, the Will itself is degraded to the status of an appearance, but an appearance that “provides a deeper account of the world than its description in terms of material bodies… . ‘Will’ is, then, … a description of penultimate rather than ultimate reality” (Young 2010, 92; cf. Ridley 2007, 26). Julian Young has suggested that this sort of view in fact represents the position of the later Schopenhauer himself (2010, 92; 2005, 96–98), thus making The Birth’s metaphysical picture still genuinely Schopenhauerian. (Whether the later Schopenhauer actually degrades the Will to the status of an appearance in this way is, of course, controversial (see, e.g., Janaway 1999, 162–63; Özen 2021, 261–63).)

With respect to the second piece of evidence, it might be noted that what Nietzsche specifically refers to as an illusion in BT 18 is the “metaphysical solace,” and it may not be correct to identify this “solace” with the book’s metaphysics per se. Young (2006), e.g., reads the passage from BT 18 as claiming, not that the Schopenhauerian metaphysics of will is an illusion; it is rather the idea we get from Dionysian tragedy—that life is worth living in spite of its terrors—that is the illusion (15–16). It might also be observed that, interpreted as a straightforward rejection of that metaphysics, there is something especially peculiar about the passage from BT 18. Suppose that by ‘the metaphysical solace’ Nietzsche really does mean ‘the idea that there is a single metaphysical Will underlying all appearances.’ Read straightforwardly, then, the passage claims that the metaphysical Will creates the illusion of its own existence (this peculiarity is noted by Paul de Man (1979, 99–102) though he takes it as evidence that BT aims to metatextually call its own claims into question). This bizarre result would seem to suggest that we need a more nuanced reading of the passage.

There are not many direct attempts on behalf of orthodox readers to rebut the third piece of evidence (and, in general, there has been to date very little effort at developing a metaphysical reading of The Birth that countenances the above evidence). As noted already, however, the emphasis on the need for myth is not itself evidence that The Birth’s metaphysics is itself such a myth. This theme lends credence to the anti-metaphysical hypothesis only together with the other pieces of evidence. If proponents of the orthodoxy have convincing explanations for these countervailing texts, then perhaps they do not need to deal with directly with the issue of myth. (For a discussion of the role of myth in The Birth, which finds it compatible with taking the book’s metaphysical commitments seriously, see Young 2010, 130–31.)

2.3 Pessimism, Optimism, and the Aesthetic Justification of Existence
Interpreters diverge over the question of The Birth’s commitment to Schopenhauer’s pessimism just as they do over its commitment to his metaphysics. One natural view, supported especially by some of Nietzsche’s retrospective comments about The Birth, holds that the book contains a “complete rejection of the normative ethics of pessimism” (Nussbaum 1999, 362; cf. Kaufmann 1974, 131; Schacht 2001; Soll 1998, 100–101; Ridley 2019, 318–19). A competing view maintains that Nietzsche in fact “endorsed Schopenhauer’s inference from the pain and purposelessness of human existence to its worthlessness” (Young 1992, 26; cf. Young 2006, 15–16; Geuss 2012, 47, 61; Huddleston 2019, 15, 19). Predictably, decisive textual evidence in favor of either reading proves elusive. To be clear, the disagreement is not over whether Nietzsche accepts the descriptive pessimistic thesis that suffering is life’s fundamental constituent—it is generally agreed that the early Nietzsche is pessimistic in this sense. Rather, the disagreement concerns his answer to the normative question of whether life is, or is not, deserving of negation, whether it would be better not to be.

At first blush, the non-pessimistic reading is bound to appear the most plausible. This reading can rely on Nietzsche’s own later remarks about The Birth. Writing in 1888, for example, Nietzsche says that the book aimed to explain “how the Greeks got over pessimism—with what means they overcame it … tragedy is precisely a proof of the fact that the Greeks were not pessimists” (EH “Books,” BT:1). This sort of remark resonates with much of what Nietzsche says in The Birth itself. “The arts generally,” he claims there, “make life possible and worth living” (BT 1/KSA 1:27–28, emphasis added); or again, “art … alone is capable of turning those thoughts of disgust with the horror or absurdity of existence into representations with which one can live” (BT 7/KSA 1:57). And, of course, there is Nietzsche’s overriding claim in the book that “only as an aesthetic phenomenon is [sic] existence and the world eternally justified” (BT 5/KSA 1:47; cf. BT 24/KSA 1:152). If they are genuinely justified, it would seem that Schopenhauer’s verdict—that they ought not to be—cannot be correct.

Yet, The Birth does not speak unequivocally in favor of this “optimistic” reading. For example, Nietzsche also says that tragedy contains “a profound and pessimistic worldview,” and communicates to us “the conception of individuation as the primordial ground of evil, … the hope that the spell of individuation may be broken” (BT 10/KSA 1:73). That suffering arises from the pursuit of one’s individual interests and that salvation lies in freeing oneself from these interests by piercing the “veil” of individuation is, of course, precisely Schopenhauer’s position. This Schopenhauerian interpretation of tragedy is especially prominent in Nietzsche’s 1870 lecture course on The Tragedy of Sophocles, where he states bluntly “life appeared no longer as worth living. Tragedy is pessimistic” (KGA II.3, 10) and that Sophocles’ “teaching is unconditional submission and resignation” (KGA II.3, 27). Elsewhere he straightforwardly identifies “the content of the tragic myth” with “the wisdom of Silenus” (BT 24/KSA 1:151)—the view that the best thing for human beings is never to have been born. And, after telling us that tragedy aims at transfiguration, he clarifies that what it transfigures is “least of all the ‘reality’ of this world of appearance, for it says to us precisely: ‘Look! Look closely! This is your life! This is the hour hand on the clock of your existence!” (ibid.). These seem odd ways, to put it mildly, of expressing the idea that life is, in spite of it all, justified and worth living. Proponents of a pessimistic reading can also point to evidence that Nietzsche thinks both Apollonian art and tragedy “justify” existence only by means of illusions (e.g., BT 18/KSA 1:115–16). For if, as this may suggest, art helps us affirm life only by deceiving us about its quality, “this implies that in the fullness of knowledge one would not affirm life as worth living. It implies, more briefly, that life is not worth living” (Young 1992, 48).

There are, at least in principle, two distinct questions here: did Nietzsche endorse Schopenhauer’s verdict about the value of life? And, what does he think tragedy tells us (or what does he think it told the Greeks) about the value of life? It is possible that Nietzsche thought tragedy is life-affirming, but himself endorsed Schopenhauer’s life-denying stance. If this is right, however, Nietzsche’s position is highly unstable. Clearly, The Birth aims not only to describe the normative outlook contained in Greek tragedy, but also to, in some sense, advocate for it, and would therefore be committed to recommending an attitude toward life Nietzsche himself believes is unwarranted.

The evidence regarding Nietzsche’s attitude toward pessimism is therefore equivocal. How we are best to interpret it depends to a significant degree on how we interpret The Birth’s major thesis that tragedy offers an “aesthetic justification” of existence. The thesis appears to be that tragedy somehow encourages us to see the world—and the inescapable presence in it of suffering, struggle, death, etc.—from a god’s-eye perspective. From this perspective, the world as whole appears a terrible, but glorious spectacle, and our lives—short and tormented though they may be—have an aesthetic significance insofar as they occupy an integral place in this aesthetically valuable whole, like shadows in a beautiful painting or dissonances in a magnificent piece of music:

We may assume of ourselves that we are already images and artistic projections for [the world’s] true creator and have our highest dignity in our significance as works of art—for only as an aesthetic phenomenon is existence and the world eternally justified. At the same time, our consciousness of this significance of ours hardly differs from that which painted soldiers on a canvas have of the battle depicted on it. (BT 5/KSA 1:47)
Precisely the tragic myth has to convince us that the ugly and disharmonic is an artistic game, which the will, in the eternal fullness of its pleasure [Lust], plays with itself. This primordial phenomenon of Dionysian art, difficult to grasp, is made directly understandable and comprehended immediately only in the miraculous significance of musical dissonance: just as music in general, placed next to the world, can give us a concept of what is to be understood by the justification of the world as an aesthetic phenomenon. The pleasure caused by the tragic myth has the same home as the pleasurable sensation of dissonance in music. (BT 24/KSA 1:152)
In this respect, then, the lesson Nietzsche thinks tragedy teaches us closely resembles Leibniz’s response to the problem of evil (1697 [1989, 153]; on analogies between Nietzsche’s project and traditional projects in philosophical theodicy, see esp. Came 2004, 2005, 2022; May 2011). The mechanism by which Nietzsche thinks tragedy communicates this lesson is obscure. However, the basic idea relies on his idea that Greek spectators identified, not with the characters on the stage, but with the tragic chorus, and from this perspective experienced the drama as a mere ephemeral “vision” (BT 8). And just as the chorus-audience relates to the spectacle on the stage, so too does the primal unity relate to the empirical world as a whole. The analogy, then, intimates to the audience something of their metaphysical-cum-aesthetic significance (BT 8, 10).

Naturally, given the deep interpretive issues surrounding the status of The Birth’s metaphysics (see §2.2 above), not all agree that Nietzsche intends such talk of a “world-artist” literally. And, it might be suspected that whether one takes Nietzsche to be a pessimist or not depends on what one thinks about the intended status of the metaphysical picture the aesthetic justification of existence apparently encodes. If this picture is intended to be true, then it would seem that tragedy is supposed to show us that life really is justified. If, conversely, the metaphysics is not so intended, then it would appear that the so-called metaphysical solace is merely an illusion. In fact, these issues can come apart. It is possible, for instance, that Nietzsche is claiming that when watching a tragedy we catch a glimpse of what the world would look like from a god’s-eye perspective, even if nothing really occupies that perspective. The question, then, is only whether the world would manifest aesthetic value if seen in this way, and not whether there is any being to whom it does manifest such value. Conversely, not all proponents of the metaphysical interpretation of The Birth conclude that Nietzsche believes life is genuinely justified. Young, for example, argues that the fact

that pain and death are indispensable to life as an entertainment for the primordial unity … does nothing at all to justify life to those who—like Christians in the Roman arena—have the misfortune to have to be parts of the entertainment… . To the question of whether life as a human individual is worth living, The Birth replies with the same ‘No’ as does Schopenhauer. (2006, 24)
Evidently, much depends here on how we understand the status of the world’s alleged aesthetic value. If that value consists merely in the fact that it happens to please the “primordial unity,” then this sort of reading seems plausible. If, on the other hand, that value is supposed to be of a non-agent relative sort, then the reading might be resisted.

A further question, though one which is less often thematized, concerns the relation between the aesthetic justification of existence and what Nietzsche frequently calls “the metaphysical solace [Trost]”—something with which, he argues, “every true tragedy leaves us” (BT 7/KSA 1:56). It is natural to suppose that this solace consists precisely in the idea that existence is aesthetically justified. However, some characterisations of the metaphysical solace seem to differ substantively from this idea. Nietzsche describes the “metaphysical joy in the tragic” as rooted in the recognition that “the hero … is ultimately only appearance, and the eternal life of the will is untouched by his annihilation” (BT 16/KSA 1:108). The “metaphysical solace” lies in the thought “that under the whirl of appearances eternal life flows on indestructibly” (BT 18/KSA 1:115). Though each seems to depend on The Birth’s metaphysics, the idea that the world is justified as an aesthetic spectacle and the idea that there is something in us which survives death would appear to be quite distinct thoughts. The former idea might incline us to an overall optimistic reading of the text, if we assume that such a justification could be a genuine one, whereas the latter, which suggests that redemption from this life will be found in some metaphysical beyond, would incline toward a more pessimistic interpretation.

One interesting way of mediating between pessimistic and non-pessimistic interpretations of the early Nietzsche is proposed by Wolt (2025), who draws special attention to affinities with the views of Nietzsche’s older colleague and friend, the cultural historian Jacob Burckhardt (1818–1897). According to this proposal, Nietzsche is genuinely pessimistic inasmuch as he takes life in its typical form to be intrinsically bad, and thus rejects a broadly Christian view according to which every life has an innate positive worth. Yet this pessimistic thesis allows that certain exceptional lives may still achieve a value that makes them worth living. Though Wolt does not develop this interpretation specifically with an eye to Nietzsche’s theory of tragedy, it is not difficult to see how it might apply. Tragedy may be pessimistic insofar as it shows us the lamentable character of life as it typically occurs, but optimistic insofar as it hints at a way in which life could attain value.

3. Art and Illusion
Nietzsche’s aesthetic thought is centrally, if often only obliquely, engaged with Plato’s. In the Genealogy, Nietzsche dubs Plato “the greatest enemy of art Europe has yet produced” (GM III.25), referring, of course, to Republic X’s attack on the imitative or illusory nature of much art, which accordingly appeals to “a part of us that is far from reason” (603a). This engagement is hardly surprising given that the main target of Plato’s censure is Greek tragedy, the very artform which centrally occupied Nietzsche in his first philosophical work, and which would, to a greater or lesser extent, continue to occupy him through his final writings (see §6 below). What is more surprising are Nietzsche’s reasons for disagreeing with the Republic’s verdict: he does not typically deny the central charge that art is false; he instead questions the value Plato (and most of the rest of us, for that matter) place on the truth. This central theme of Nietzsche’s thought is evident already in The Birth’s valorization of Apollonian semblance, and denigration of “Alexandrian” culture—Nietzsche’s term of abuse for a society which accords the highest value to scholarship and science instead of to art. Shortly before The Birth, Nietzsche had written: “my philosophy is inverted Platonism: the further something is from true being, the more beautiful, the better it is. Living in semblance [Schein] as the goal” (NF 1870: 7[156]). Much later in his career, he continues to speak approvingly of art as a “cult of the untrue” and “the good will to semblance” (GS 107), in which “the lie sanctifies itself, in which the will to illusion [Täuschung] has the good conscience on its side” (GM III.25). And in notes from his final productive year, he writes: “the truth is ugly: we have art so that we do not perish from the truth” (NF 1888: 16[40]). Nietzsche is opposed, in short, both to Plato’s condemnation of artistic illusion, and to theories, like Schopenhauer’s or Schelling’s, that try to make art into the source of some deep, metaphysical truth. Art is false, and it is valuable (at least in part) because of its falsity.

There are several basic interpretive questions to ask here: (1) in what sense is art “false” according to Nietzsche? (2) Why does he think artistic falsity is valuable? And (3) how does this valorization cohere with his own views about the value of truthfulness? In approaching these questions, it is useful to keep in mind a simple distinction drawn by Stoll (2019, 332–33). Art might be representationally false, say, by attributing properties to the things it represents that they do not possess, or by expressing, implicitly or explicitly, false propositions. In contrast, art might be mimetically false because it is illusory, “fake,” non-genuine, merely resembles without really being what it depicts. In the first sense, ‘false’ is being used roughly in the way it typically is in, e.g., epistemology. In the second sense, it is being used in the way it is when we speak of a “false friend” or “false teeth.” These senses clearly come apart; an object like a set of false teeth has no representational or propositional content, and a portrait painting might capture its subject’s likeness with tremendous accuracy while (and perhaps for that very reason) creating a powerful illusion.

The prevailing tendency is to see Nietzsche as claiming that art is representationally false, and specifically as misrepresenting the undesirable or unaffirmable aspects of life. The following remarks seem to capture his position his well: “the role of art is to supply a (dishonest) fantasy that is to replace a reality that one cannot face” (Ridley 2007, 140); “art must represent life as beautiful, as affirmable, precisely because life is not beautiful” (Young 1992, 134); “artistic representation falsifies its object by depicting it as other than it is” (Came 2013, 220; cf. May 1999, 29–36; Janaway 2014). Assuming that Nietzsche is best interpreted in something like this manner, there are still several different ways art might be taken to be misrepresentational. First, and most straightforwardly, art might misrepresent what it overtly depicts. For example, a portrait painter might idealize some of her subject’s features, remove certain blemishes, and so forth. Second, art might misrepresent “life” or the “world” in some more general way, say, by implicitly or explicitly expressing false propositions about it, or otherwise suggesting a non-veridical outlook of some sort. For example, while Macbeth is on one level about specific members of the medieval Scottish nobility, perhaps its “real” message is that traitors meet a sorry end, and this message is not (without exception) true. Along similar lines, but much more generally, Nietzsche sometimes suggests that the world “in itself” simply lacks “beauty” and “order” (e.g. GS 109, 299). So, perhaps he thinks that art misrepresents the world simply to the extent that it represents things beautifully. Third, art might misrepresent by being fictional, in the sense of representing things which do not exist, rather than distorting what does exist. Greek art, for example, is preoccupied with mythical stories about non-existent gods, heroes, monsters, and so forth. And, presumably, Nietzsche would consider Christian art—with its various narratives about saints, prophets, miracles, and the like—false in just the same way.

If one or more of the above types of misrepresentation best capture Nietzsche’s conception of artistic falsity, then it is natural to suppose that the value of such falsehoods lies primarily in their content. A key facet of Nietzsche’s thought is the idea that it can be better, from a pragmatic perspective, to hold false beliefs than to hold true beliefs (BGE 3). We might then suspect that the value of artistic misrepresentations is rooted in the fact that their content is nonetheless “life-promoting.” Thus, for example, Gemes and Sykes have argued that tragedy fosters “the belief in a unity which underlies the apparent world, and offers the myth that in death, the individual will find redemption and reunification with the reality beneath appearance” (2014, 93). While the later Nietzsche may prefer less Schopenhauerian myths, he may still retain the basic structure of this conception of the value of artistic falsehood.

There are several problems, both philosophical and textual, with the above sort of view. One philosophical problem with the kind of aesthetic beautification Nietzsche sometimes seems to have in mind is that it arguably conflates representing something as beautiful with representing it beautifully (cf. Huddleston 2022, 125). So, the portraitist might depict her subject as more beautiful than he is, and thus misrepresent him. But, it is far from clear that Homer’s Iliad—or Malick’s The Thin Red Line, for that matter—misrepresent war as beautiful simply in virtue of being beautiful stories about war. Relatedly, we do not often infer that properties attributed to objects by works of art are properties those objects actually possess. If Nietzsche’s conception of artistic falsity depends on the assumption that we are deceived by it, then he is assuming art appreciators to be far more gullible than they typically are (though, for a reading according to which Nietzsche does not need this assumption, see Reginster 2014, 15–23).

The above sort of reading also raises interpretive puzzles. For one, as Aaron Ridley observes (2013, 421), whether a work of art is misrepresentational in any of the above senses seems to be a purely contingent matter. But, Nietzsche appears to think that art is necessarily false, or at least that art and falsity are very intimately related. Second, Nietzsche himself often appears opposed to precisely the conception of aesthetic beautification it is tempting to attribute to him (cf. Young 1992, 42–43). He suggests approvingly that “art also brings much that is ugly, hard, and questionable about life to appearance” (TI “Skirmishes” 24) and claims that “the good, strong will of the older Hellene” was characterized by a “longing for the ugly” (ASC 4). Finally, it is unclear how Nietzsche’s insistence on the value of artistic falsity coheres with his broader normative commitments. Specifically, and as Ridley (2007) in particular has argued (cf. Reginster 2014, 25–29), the suggestion that art supplies us with life-affirming fictions seems to conflict with Nietzsche’s conception of life-affirmation as requiring “that one does not want to have anything differently … not merely to endure what is necessary, still less to conceal it … but to love it” (EH “Clever” 10). There is a broader question here about the extent of Nietzsche’s commitment to the ideal truthfulness (see Janaway 2024, for an exploration of many of the difficult issues involved). But the idea that the need to conceal certain difficult facts about reality from oneself expresses a kind of contemptible cowardice is a consistent theme in Nietzsche’s later works (e.g., BGE 39, 227; A 54; EH Preface 3, “Books” BT:2). Nietzsche’s apparent suggestion that we need art precisely to conceal such facts from ourselves evidently conflicts with that idea.

There are a number of potential responses to this last difficulty. One is to suggest that Nietzsche fails to entirely resolve it (Ridley 2007, 123–27), or leaves it unresolved specifically to call attention to what he takes to be genuine tensions in our values (Janaway 2014, 51–56). Another proposal holds that his view develops away from the idea that art should be in any sense false (Reginster 2014). More ecumenically, one might suggest that Nietzsche sees art and truthfulness as competing “regulative ideals” which have to be appropriately balanced against one another (Anderson 2005, 203–11), or that art is permitted to misrepresent, but only those aspects of life that we cannot change or otherwise accept (Ridley 2007, 80–83; 2013, 422–23). According to these sorts of readings, Nietzsche may advocate maximal honesty while still recognizing that life-affirmation might ultimately require some degree of falsification. One problem for this suggestion is that Nietzsche appears to insist that it is precisely the necessary aspects of existence we must acknowledge and affirm (EH “Clever” 10; cf. NF 1888: 16[32]).

A contrasting approach to Nietzsche’s views on artistic falsity is developed by Stoll (2019; cf. Page 2024). According to this approach, Nietzsche’s primary interest is in mimetic falsity, in the fact emphasized by Plato that much art is centrally occupied with imitating, with producing semblances or simulacra of the things it depicts. It was, recall, this sense of falsity that was at issue in Schiller’s conception of Schein (see §1.3 above), which had been important for Nietzsche since early in his career. Nietzsche can thus consistently say that art is false while denying that it should falsely beautify things; its falsity is a function of the medium not the representational content. Divorced as it is from the content of specific works, this account of artistic falsehood can arguably make good sense of the tight connection Nietzsche seems to see between art and illusion (though certain artforms, such as music or architecture, may still pose problems). It also suggests that the aim of art is not to instil in us a set of false, but useful beliefs. Instead, art glorifies or celebrates illusion and falsity themselves, inviting us to reconsider our—mostly negative and, Nietzsche thinks, unhealthy—attitude toward them. Stoll argues that this interpretation allows us to locate the underlying consistency between Nietzsche’s ideal of uncompromising honesty and his valorization of art in a way that does not require the balancing approach suggested by Ridley and Anderson (Stoll 2019, 339–42).

Whether this solves the textual problem depends to some degree on how we think of the positive value art accords to falsity. If to value something positively is to be inclined to pursue or promote it, then it might seem the answer is “No.” Yet, not all positive valuing is like this for Nietzsche. He thinks, for example, that it is possible for the nobleperson to have “reverence” (Ehrfurcht) and even “love” for an enemy whom they aim to defeat (GM I.10). To suggest that it is better for us to be positively disposed to illusion might, but need not be to say that it is better for us to cleave to benighted self-conceptions.

4. Beauty, Disinterestedness, and Creativity
One of the more significant developments Nietzsche’s aesthetics undergoes in the time between The Birth and his later works concerns the idea of disinterested aesthetic appreciation. While the early Nietzsche apparently accepts some version of the thesis that aesthetic pleasure is disinterested, he consistently rejects it by at least 1886 (e.g., BGE 33; though, for a dissenting view according to which Nietzsche’s later aesthetics is still wedded to a broadly Schopenhauerian version of aesthetic disinterest, see (Denham 2014)). The best-known discussion of this issue in the later works comes in GM III.6, where it is connected with an intriguing, albeit obscure, criticism of aestheticians—Kant and Schopenhauer are singled out in particular—who take their cue “purely from the standpoint of the ‘spectator’ [vom ‘Zuschauer’ aus]” (KSA 5:346).

There are a few obvious questions to be had here. First, what is Nietzsche’s criticism of the notion of aesthetic disinterest? This notion has meant different things to different philosophers, and how extensive and successful his criticism is will depend in part on how he understands the notion. Second, how is this criticism related to his apparent preference for an aesthetics that focuses on “the experiences of the artist (the creator)” rather than on those of the spectator? Schopenhauer, after all, believes that the creative genius is someone uniquely capable of attaining a state of pure, will-less cognition (SW 3:430–31/WWR 2:393–94); it is not immediately obvious that looking at the artist will cast suspicion on disinterestedness. Perhaps Nietzsche’s point is that Schopenhauer only reads his faulty theory of aesthetic spectatorship into the creative process. If this is right, then we may still wonder why we should prefer an aesthetics of the creator. Answers to these obvious questions may depend on answers to some more subtle questions. For instance, what precisely would we be looking at in considering “the experiences of the artist?” Artists’ own judgments of what is beautiful/aesthetically valuable? The nature of the creative process? Something else entirely? Nietzsche faults Kant and Schopenhauer for “envisioning the aesthetic problem” from the spectator’s point of view. What is this “aesthetic problem?” It is plausible to suppose that he has in mind the question of the nature of the beautiful (Ridley 2011), but Nietzsche does not explicitly say.

Zangwill (2013) provides one plausible set of answers to these sorts of questions. On his reading, Nietzsche’s objection to Kantian aesthetics concerns more its emphasis on the universality of judgements of taste than their disinterestedness (though, of course, the two issues are not unrelated for Kant). More specifically, Nietzsche’s main target, on this reading, is the idea that beauty is universally available. Nietzsche need not be read as claiming that no beauty is so available, only that “some beauty, higher beauty, can be grasped only by a select few” (Zangwill 2013, 84). This yields one potential way of understanding the objection to aesthetic disinterest and its connection with the spectator. The thought would be that there are some types or instances of beauty which are best or only accessible through “enhanced ecstatic experiences” (ibid., 90), not through dispassionate reflection. And if it is specifically artists who are capable of such experiences, or who are most saliently aware of having had such experiences, then there is reason to find fault with an aesthetics that focuses solely on the experience of the artistic laity. This account, of course, raises questions of its own. Why, for example, should the “select few” capable of grasping higher beauty be identified with artists? And why should disinterested aesthetic experience itself not also be the province of a select few? Even if Kant is right that I can only legitimately require agreement from everyone if my aesthetic judgment is disinterested, it might still be the case that, as a matter of fact, most are unable to judge disinterestedly. Schopenhauer, for one, appears to think that the capacity for genuine will-less cognition is exceedingly rare.

Note that Zangwill’s approach treats ‘experiences of the artist’ and ‘the aesthetic problem’ as referring to judgements or perceptions of beauty. A more radical interpretation finds Nietzsche critical of the very idea that the aesthetic state is to be construed in such “passive” terms to begin with. On this view, “the significance of art is to be found less in its products than in the creative activity by which they are produced” (Reginster 2014, 25; cf. Soll 1998, 108ff.). Here, the problem with a spectator’s aesthetics is that it locates aesthetic value in the wrong place—works of art, or the experiences they cause—or at least fails to see that such value can be located elsewhere as well (cf. Huddleston 2020, 5). In its most extreme version, the view is that beautiful objects are “only by-products, and their beauty is merely a reflection of a … beauty that is, in the first place and most authentically, the artist’s own” (Ridley 2011, 321).

What, if anything, can be said in favor of such a view, and how is it connected with Nietzsche’s criticism of disinterestedness? One suggestion is that the spectator’s standpoint cannot account for the artist’s motivation to create a work (Soll 1998, 108; Reginster 2014, 24). This is particularly problematic if the genius is conceived along Schopenhauerian lines—as someone possessing a heightened ability for perceiving nature in the purely intellectual, will-less manner, supposedly characteristic of all aesthetic enjoyment. The question is why, having achieved this state themselves, the artist should be motivated to make it available to others in the form of an artwork. One might of course wonder what this psychological question has to do with the question of the nature of beauty. After all, it is hardly clear that a successful theory of beauty has also to explain what motivates artistic creation. A potential response, here, would be that Nietzsche operates under the general assumption, shared with Schopenhauer, that the state from which the artist creates is the same as the state that their work aims to produce (Young 1992, 120). If conceiving the latter in terms of disinterestedness cannot explain the possibility of the former, such a theory would then need to be rejected. (For a critical assessment of the argument here, see (ibid., 121–25).)

In addition to its critical reflections on earlier aesthetic theories, GM III.6 also gives us some indication of Nietzsche’s own positive account of beauty or positive aesthetic value. The section quotes approvingly a claim from Stendhal’s Rome, Naples et Florence (1817) that “the beautiful is a promise of happiness,” and Stendhal is said to constitute, in contrast to Kant and Schopenhauer, a “genuine spectator.” One important question, here, is whether the fact that Stendhal is called a “spectator” means that Nietzsche regards even his definition of beauty as in some sense deficient (Ridley 2011). Most, however, take Nietzsche to be adopting Stendhal’s definition. What, then, is the import of this definition? In his later works, Nietzsche often associates the experience of beauty with the feeling of power and with erotic arousal. A particularly developed interpretation focusing on these associations is (Reginster 2014; cf. Soll 1998; Ridley 2011, 319–25). Reginster’s reading takes inspiration from Nehamas’s recent theory of beauty (2007). According to this theory, to find something beautiful is not to experience or judge it to be of positive value—aesthetic experience is not a “verdict.” To find something beautiful is rather to be impelled to continue engaging with it, to get to know it better. The version of this theory that Reginster locates in Nietzsche holds similarly that to find something beautiful is, not to find oneself in a state of passive enjoyment, but to be impelled by it toward “new artistic creation” (2014, 31). This sort of account offers a way of making sense of Nietzsche’s somewhat surprising approval (TI “Skirmishes” 22–23) of Plato’s definition of love in the Symposium as “reproduction and birth in beauty” (206e). Here, one might think too of the way in which we speak both of artistic geniuses as “inspired,” and of their works as “inspiring.” It also promises to cast further light on Nietzsche’s dissatisfaction with conceptions of aesthetic pleasure as disinterested. If we assume that activity is inherently interested, and if to find something beautiful is to be impelled by it to some kind of activity, then it would seem appreciation of the beautiful could not be disinterested. (For another sophisticated account of Nietzsche’s conception of beauty that emphasizes the dimension of erotic arousal, see Leiter 2018, and for a compelling proposal connecting it to Nietzsche’s remarks about glorification and praise, Fox 2020.)

Not all of Nietzsche’s remarks about beauty and aesthetic value sit naturally with these functional sorts of definition. Especially in his discussions of self-creation, though in other contexts as well, he seems to operate with a more traditional understanding of beauty as harmony or unity amongst diversity. He likens beauty to “order, division, form” (GS 109), to the imposition of a coherent style (GS 290), and this imposition is described as involving the ability “to become master over the chaos that one is; to compel one’s chaos to become form; to become necessity in form: to become logical, simple, unequivocal, mathematics; to become law” (NF 1888: 14[61]). These very same aesthetic standards are deployed—fairly or not—against Wagner’s alleged stylistic decadence:

With what does every literary décadence distinguish itself? By the fact that life no longer dwells in the whole. The word becomes souvrain and leaps out of the sentence, the sentence reaches out and eclipses the sense of the page, the page wins life at the cost of the whole—the whole is no longer a whole. But that is the image for every style of décadence: every time anarchy of atoms, disintegration of the will. (CW 7)
In these contexts, Nietzsche seems to adopt the conception of beauty, common amongst the eighteenth-century rationalists, as a kind of “perfection” or organic unity (see Hassan 2022, for a particularly sophisticated treatment of Nietzsche on organic unity; cf. Soll 1998, 102–105). Here, beauty (or at least aesthetic value of some kind) seems to be treated as a perfectly objective property of beautiful objects rather than, say, a mere invitation to further activity. This is not to say that these two strands could not in principle be connected. Ridley (2013, 419–20), for example, emphasizes the close connection Nietzsche often draws between creativity and form-giving. If Nietzsche does endorse the above-mentioned Schopenhauerian view that there is a kind of parity between creative activity and the aesthetic experience, he might maintain that seeing an object as “formed chaos” is precisely what incites us to creativity ourselves.

5. Aesthetics and Physiology
In the Genealogy, Nietzsche remarks parenthetically that he will one day write a “Physiology of Aesthetics” (GM III.8), and in The Case of Wagner (published the following year) he refers prospectively to “a chapter of my magnum opus, which carries the title ‘toward a physiology of art’” (CW 7). The plan for this work never came to fruition, though some material appearing under that heading in Nietzsche’s notebooks seems to have been utilized in the writings of his final year, particularly in Twilight of the Idols (cf. NF 1888: 17[9], TI “Skirmishes” 8–11, 19–24). One of the most extreme claims from this period comes in Nietzsche contra Wagner: “Aesthetics is indeed nothing but an applied physiology” (NCW “Objections”). These remarks are largely promissory, and further textual evidence for the shape of the envisioned “physiology of art/aesthetics” is relatively thin. Nevertheless, some scholars have argued that the biological sciences are central to Nietzsche’s mature aesthetic theory.

Moore (2002, 85–111) sees Nietzsche as part of a post-Darwinian tradition of German thinkers, along e.g. with Ernst Haeckel (1834–1919), aiming for evolutionary explanations of aesthetic experience. A Darwinist interpretation is developed, in particular, in Richardson 2004 (219–70). According to Richardson, Nietzsche believes that evolution selects for a tendency to discriminate between traits associated with fitness and those not so associated, and to find pleasure in the former and displeasure in the latter (236–43; cf. Stern 2020, 58). This reading can explain well Nietzsche’s tendency to associate aesthetic experience with sexuality (e.g., GM III.6; TI “Skirmishes” 22–23), as well as his occasional privileging of human beauty (TI “Skirmishes” 20). It will apparently struggle to explain why we find beautiful a vast array of things—instrumental music, abstract art, non-human animals, landscapes, etc.—that are not humans (cf. Janaway 2007, 190). Nietzsche might suggest that the features we find beautiful in non-human objects are those that remind us in some way of physical human beauty. Such a suggestion might be broadly in the spirit of Burke’s theory that the same general qualities which make for beautiful human bodies (smoothness, relative smallness, etc.) are the qualities which also cause us to find beautiful non-human objects. Alternatively, Nietzsche might appeal, in proto-Freudian fashion, to a sublimation of the sex-drive (e.g., GM III.8; cf. Moore 2002, 106–7). As noted in the previous section, one plausible reading holds that the experience of the beautiful, for Nietzsche as for Plato, involves being spurred toward creativity. Thus, the pleasure taken in a sunset or a Beethoven symphony might be said to be “erotic” to the extent that it puts us in this general sort of state, even if it does not involve arousal or the desire for literal procreation.

A distinct, if potentially related point of contact between physiology and art is Nietzsche’s frequent use of medical concepts when assessing art and artists in his later writings. Art of which he disapproves—especially Wagner’s art—is castigated as “decadent” (décadent) or “degenerate” (entartete), whereas the art of e.g. Raphael, Bizet, or Goethe is celebrated as “healthy,” and a “stimulus to life” (TI “Skirmishes” 24). To call an artist or their work “decadent” might be to make a functional or an expressive claim. Both sorts of claims can be found in the text, and are sometimes made in the same breath—e.g., “is Wagner even a human being? Is he not rather a sickness? … He has made music sick” (CW 5). The claim would appear to be that decadent art, like Wagner’s, is both a “symptom” of the artist’s own degeneration, as well as a kind of “contagion,” and garners rebuke on both grounds. In other contexts, however, Nietzsche suggests a slightly different point. In a well-known passage from The Gay Science, for example, he writes:

Every art, every philosophy, may be viewed as an aid and means of salvation for growing, struggling life: they always presuppose suffering and sufferers. But there are two types of sufferers: those who suffer from the overabundance of life, who want a Dionysian art and likewise a tragic view of and insight into life—and then those who suffer from the impoverishment of life, who seek quiet, stillness, a placid sea, redemption from themselves through art and knowledge. (GS 370)
Here, Nietzsche appears to be sounding a theme that was with him since The Birth of Tragedy—that art is one of humanity’s fundamental means for coping with the suffering endemic to life. Now, however, he comes to think that not all suffering is equal; some suffering is “healthy,” while other suffering is “sick.” Nietzsche clearly signals his approval for art that responds to suffering of the former kind. Note, however, that this need not mean he disapproves of the latter sort of art on functional grounds; such art may be genuinely good for those who need it, and otherwise innocuous. Instead, his objection may be to the fact that such art perforce expresses an evaluative outlook of which he disapproves (cf. Ridley 2007, 124).

In still other contexts, Nietzsche develops this general idea in the direction of what appears to be an unusual form of aesthetic non-cognitivism. After claiming that “aesthetics is irrevocably tied to these biological presuppositions [of ‘ascending’ or ‘declining’ life],” he suggests that “these opposing forms in the optics of values … are ways of seeing, which one cannot get at with reasons and refutations. ... One does not refute a disease of the eye. ... The concepts ‘true’ and ‘untrue,’ it seems to me, have no meaning in optics” (CW Epilogue). The suggestion appears to be that, when we make judgments of the form ‘x is beautiful,’ we are not making truth-apt claims so much as expressing our general (“healthy” or “diseased”) evaluative perspective. It is not obvious, however, that the passage must be read in this irrealist way. The image of the diseased eye, e.g., seems to imply that some such perspectives are wrong or distorted. And the insistence that “reasons and refutations” are out of place in the context of aesthetic disagreement might simply be a way of indicating that they are dialectically ineffective, not that they are conceptually inappropriate.

However one resolves these various unclarities, the important point is that Nietzsche’s idea for a “physiology of aesthetics” may be about looking at art from a diagnostic perspective, rather than investigating its evolutionary origins (though, of course, it is also possible that it be both; see Moore 2002 (165–92) for an interpretation along these lines). Now, much of Nietzsche’s language here—which calls to mind 19th-century “degeneration theory” and its connections with racism, misogyny, and eugenics—is rather ugly. One might wonder how literally he intends such talk—whether he really believes, e.g., that Wagner’s art is the product of some physiological malady, or whether the notions of health and sickness are being used more metaphorically. The latter option is bound to seem more attractive to contemporary readers, though it should be borne in mind that degeneration theories enjoyed wide acceptance in Nietzsche’s day, and he may well have taken them seriously in a way that we cannot. Discussing this issue in any depth would take us far beyond the ambit of this entry. But, it bears mentioning that Nietzsche, atypically for a nineteenth-century degeneration theorist, often does not treat degeneration as unqualifiedly bad (Gemes 2021). He will even suggest, paradoxically, that “sickness itself can be a stimulus to life” (CW 5).

6. Nietzsche’s Later Theory of Tragedy
Nietzsche never treated tragedy (or any specific artform, for that matter) in as much depth as he treated it in The Birth of Tragedy. Yet, in his mature writings, he would continue to style himself “the first tragic philosopher” (EH “Books” BT:3), and to suggest that we need a tragic outlook on life (GS 370; cf. GS 1, EH “Books” BT:4). Nietzsche’s name remains to a certain degree inextricable from the philosophy of tragedy, given his landmark contribution to this field. It is thus worth asking how, if at all, his position evolved since his first book. We may approach this question by considering Nietzsche’s developing views on the pleasure and value of tragedy. These issues are, of course, distinct. The former question is why we evidently take pleasure in the experience of intrinsically unpleasant emotions (pity, fear, etc.). There may be reasons why tragedy is valuable other than that it causes pleasure, and the reasons for valuing it might not be the same as the reasons it is pleasurable. Nevertheless, it is natural to expect that these two issues would be intimately related, so we shall consider them together.

In The Birth of Tragedy, answers to both questions were apparently rooted in the idea that tragedy provides an “aesthetic justification” of life and a “metaphysical solace” (see §2.3 above). Tragedy is valuable because it gives us (or gave the Greeks, at least) an adequate way of confronting the suffering of life, or a way of conferring meaning on life, or both. Nietzsche’s attempt to resolve the famous paradox of tragic pleasure here is somewhat more obscure. But, it is plausible to think that—like Schiller, Schlegel, Schopenhauer, and others—he means to appeal to the notion of the sublime (see BT 7/KSA 1:57), understood as involving the realization or feeling that there is something in us that transcends the boundaries of empirical reality (see Young 2013, 178–182 for discussion). Alternatively, the suggestion is that “the pleasure produced by the tragic myth has the same home as the pleasurable sensation of dissonance in music” (BT 24/KSA 1:152). The idea would appear to be that tragic pleasure lies in the realization or feeling that our suffering is an integral part of a wider aesthetic whole (Raymond 2014, 71; Hassan 2022, 126). It is natural to suspect that Nietzsche would soon have come to abandon these answers, appealing as they do to a speculative metaphysics.

This suspicion would appear to find confirmation in Nietzsche’s subsequent remarks about tragedy. In The Gay Science, for example, he offers a far more reductive account of the pleasure in tragedy—or at least of the pleasure the Greeks took in it—in terms simply of hearing “good speeches” (GS 80). The explanation resembles Hume’s suggestion that tragic pleasure “proceeds from that very eloquence, with which the melancholy scene is represented” (1757, 190–91), albeit without Hume’s further suggestion that painful emotions thereby undergo a kind of “conversion.” In fact, Nietzsche here denies that negative emotions—pity and fear—are part of the proper response to tragedy at all. Arguably, this account solves the problem of tragic pleasure only at the expense of denying what might seem an obvious fact: that the experience of tragedy is hedonically “ambivalent.”

In Beyond Good and Evil (BGE 229) and the Genealogy (GM II.7), Nietzsche offers a slightly different account. He suggests that “that which constitutes the painful voluptuousness of tragedy is cruelty” (BGE 229). The most straightforward way to understand this claim is that the pleasure we get from witnessing the suffering of the tragic hero is a kind of Schadenfreude. This would explain the pleasure in tragedy, though it does not address what most philosophers have found perplexing about it—the fact that we seem to enjoy the intrinsically unpleasant emotions (e.g. pity) it provokes. Moreover, it seems plainly inadequate from a phenomenological perspective. Typically, a well-written tragedy makes us identify with and feel for the hero, not her tormentors. A different reading, which addresses these concerns, sees Nietzsche as attempting to explain tragic pleasure as a peculiar form of sadomasochism. At this stage of his career, Nietzsche holds that a fundamental feature of human psychology is a tendency to take pleasure is causing suffering, including causing ourselves to suffer. In engaging with the painful experience of tragedy, then, one takes pleasure “in one’s own making-oneself-suffer” (BGE 229). This explanation also seems problematic in at least a couple of ways. For one, even if we agree with Nietzsche’s account of the pleasure of self-directed cruelty, it is unclear why tragic pleasure should count as such an instance. If the point is that in watching a tragedy we willingly undergo an experience that we know will be painful, then it may be noted that there are many such cases which are neither pleasurable nor instances of self-cruelty (e.g., going to the dentist). A second problem arises from the fact that Nietzsche apparently still wants to deny that pity is a genuine response to tragedy; “tragic pity” is merely one of the many “inoffensive names” we use to morally sanitize our enjoyment of cruelty (GM II.7). But, if that is right, then it is unclear why the experience of tragedy is painful to begin with, since the pain is usually thought to be rooted precisely in the experience of emotions like pity.

In the works written between 1878 and 1887, the impression is strong that Nietzsche is experimenting with various accounts (cf., HH I.103, 166, D 172) of tragic experience without having settled on a considered, developed view (though, see Prince 1998 and Kirwin 2023 for contrasting assessments). Noteworthy too is the fact that in this period Nietzsche makes few claims for the positive value tragedy. Matters change somewhat dramatically in the works of his final productive year, especially Twilight of the Idols. Here, Nietzsche devotes much more sustained attention to the tragic artform and is once again keen to insist on its central importance to his ethical outlook. One question that arises in this connection is whether this renewed focus on tragedy also brings with it a return to The Birth’s substantive doctrines. Young (1992, 136–39) and Ridley (2007, 126–27; 2019), in particular, have argued that it does. Consider, for example, the following suggestive, but characteristically gnomic, passage:

Tragedy is so far from proving something about the Hellenes’ pessimism in Schopenhauer’s sense, that it must rather count as its most decisive refutation and counter instance. Saying Yes to life itself even in its strangest and most difficult problems; the will to life rejoicing of its own inexhaustibility in the sacrifice of its highest types—that is what I called Dionysian, that is what I guessed to be the bridge to the psychology of the tragic poet. Not to be freed of terror and pity, not to purify oneself of a dangerous affect by means of its vehement discharge—this is how Aristotle understood it—: but rather, beyond terror and pity, to be the eternal pleasure of becoming itself,—that pleasure which also includes the pleasure in annihilation… And with this I touch again on that point from which I once began—the Birth of Tragedy was my first revaluation of values. (TI “Ancients” 5)
What is especially surprising here is not Nietzsche’s continued adherence to the Dionysian affirmation of life even at its “strangest and most difficult,” but his apparent reprisal of the idea that such affirmation involves identifying (if only imaginatively) with an inexhaustible “will to life” that takes pleasure in sacrificing its creatures. It is difficult, here, not to hear echoes of The Birth’s “primordial unity” or “world-artist.” What this seems to indicate is that Nietzsche has returned to the idea that tragic experience involves transcending one’s individual existence and identifying with a kind of suprapersonal being—one is supposed to somehow “be the eternal pleasure of becoming itself”—or, at least, that it involves the feeling of such transcendence and identification.

While a reasonable conclusion to draw from the above passage taken in isolation, this suggestion is surprising, given the later Nietzsche’s clear opposition to Schopenhauer’s metaphysics and his ideal of self-transcendence. Those wishing to resist this conclusion might note that the passage concludes a chapter entitled “What I Owe to the Ancients,” in which Nietzsche attempts to summarize the influence that his studies of antiquity have had on his broader thought. It is possible that he here intends only to be recalling rather than reasserting the position of The Birth of Tragedy, and to be emphasizing that some elements of his later thought—his opposition to Schopenhauer’s pessimism, his view that life must be affirmed in spite of its “terror and absurdity”—were already nascent there. There are difficulties that such a reading would need to meet (see Ridley 2019, 321–22), but the impression that the above passage does not exactly capture Nietzsche’s mature view is reinforced by the fact that he elsewhere presents an apparently quite different conception of tragedy:

What does the tragic artist communicate of himself? Is it not precisely the condition without fear in the face of the fearsome and questionable that he shows? … The courage and freedom of feeling before a powerful enemy, before a sublime catastrophe, before a problem that arouses dread—this triumphant condition is what the tragic artist selects, what he glorifies. Before tragedy what is warlike in our soul celebrates its saturnalia; he who is used to suffering, who seeks out suffering, the heroic man, extols his own existence with tragedy. (TI “Skirmishes” 24)
A different reading, which draws on these comments, is developed in Reginster 2014. Recall Reginster’s functional account of aesthetic value (see §4)—to find something beautiful is to be spurred by it to further creative activity. Reginster’s application of this general view to the case of tragedy builds on his influential reading of the will to power as the overcoming of resistances (2006). To will power is to will the overcoming of resistances, and this inevitably brings suffering along with it. Yet, it is also a requirement of great achievements, which often, if not always, require meeting great challenges. Instead of showing us suffering as a reason for withdrawing or turning away from life, the tragic artist invites us to “respond to ‘the terrifying and the questionable’ in our existence as he does—as so many challenges, calls to adventure, or opportunities for overcoming” (2014, 34). This reading has the advantage of not relying on a supraindividual perspective Nietzsche gives us reason to reject, and of connecting his later thoughts on tragedy with his other major philosophical preoccupations (power, self-overcoming, etc.). It does, however, raise further questions about the adequacy of Nietzsche’s position. To say that all achievement requires suffering, in the form of overcoming resistance, is not to say that all suffering also constitutes an occasion for great achievement. Some suffering might be purely and utterly destructive. And, indeed, one might have supposed that the sorts of suffering encountered by tragic heroes are often and paradigmatically of that sort—calamities that come entirely unbidden, undeserved, and by which the hero together with their achievements are undone. One may think here of Oedipus’ exile from Thebes, which plunges the city he once saved into civil war and leads to the death of three of his children. This was a fact that Nietzsche himself had been particularly keen to emphasize early on (KGA II.3, 7–10), but of which he would now apparently have lost sight.

It is difficult not to conclude that, despite his lifelong engagement with the topic, Nietzsche never arrived at a fully satisfactory theory of tragedy, let alone one that he was able to clearly articulate. This is not to devalue his achievements here. Perhaps no philosopher has done as much to emphasize that an understanding of tragedy must be rooted in an understanding of the historical and cultural institutions of the ancient world from which it emerged. Few have seen as keenly the ways in which the tragic resists explanation in terms of traditional moral categories. And even fewer have tried so forcefully to articulate something which many seem inchoately to feel—that tragedy contains the answers to our most profound existential questions. Nietzsche’s thoughts here can at times seem muddled, even quixotic. But they are deep thoughts, and ones which merit serious philosophical consideration.

Bibliography
Editions of Nietzsche’s Texts
The following editions of Nietzsche’s works have been referenced. Translations are the author’s own.

[KGA]
Werke: kritische Gesamtausgabe, 40 volumes, Colli, Montinari, Gerhardt, Miller, Müller-Lauter and Pestalozzi (eds.), Berlin: Walter de Gruyter, 1967ff.
[KSA]
Sämtliche Werke: kritische Studienausgabe, 15 volumes, Colli and Montinari (eds.), Berlin: Walter de Gruyter, 1980ff.
[SB]
Sämtliche Briefe: kritische Studienausgabe, edited by Giorgio Colli and Mazzino Montinari. Berlin: Walter de Gruyter, 1975–84.
[FS]
Frühe Schriften, 5 volumes, Mette and Schlechta (eds.), Munich: C.H. Beck, 1994.
[WEN]
Writings from the Early Notebooks, Nehamas and Geuss (eds.), Löb (trans.), Cambridge: Cambridge University Press, 2009.
Abbreviations of Nietzsche’s Works
In citing Nietzsche’s published works, this article follows the North American Nietzsche Society’s system for abbreviations. Abbreviations referring to the titles of individual works are followed by section numbers in Arabic numerals. Where the work in question is divided into chapters or parts across which sections are not numbered consecutively, Roman numerals or abbreviations of chapter titles precede section numbers (e.g. GM III.5 = On the Genealogy of Morals, Third Essay, section 5).

A
The Antichrist: A Curse on Christianity
BGE
Beyond Good and Evil: Prelude to a Philosophy of the Future
BT
The Birth of Tragedy out of the Spirit of Music
CW
The Case of Wagner: A Musician’s Problem
D
Daybreak: Thoughts on the Prejudices of Morality
EH
Ecce Homo: How One Becomes What One is.
GM
On the Genealogy of Morals: A Polemic
GS
The Gay Science
HH
Human, All-Too-Human: A Book for Free Spirits
NCW
Nietzsche contra Wagner: Documents of a Psychologist
TI
Twilight of the Idols: or How One Philosophizes with a Hammer
UM
Untimely Meditations
Z
Thus Spoke Zarathustra: A Book for All and None
Where helpful for locating a particular passage, references have also been given to volume and page number of the KSA. Citations of Nietzsche’s unpublished notes [NF] refer to year, and notebook and fragment numbers as established in the critical edition.

Traditions of Ideology Theory
Although ideology has come to be inextricably tied to Marxism and critical theory, liberal and conservative traditions of thinking about ideology predate Marxist theorizations and set the terms on which the term was integrated into Marxist theory.

The term is attested as far back as the seventeenth century, but its coinage is usually attributed to Antoine Louis Claude Destutt, compte de Tracy (1754–1836), one of the scholars affiliated with the Institut de France. Destutt de Tracy used the term to name a science of ideas. Like many other “-ology” terms—biology, pathology, mythology, and methodology are prominent examples—the term’s meaning in common speech has migrated such that it generally names the object of the study of ideas, rather than the study itself. In the case of ideology, this migration was prepared by the reflexive and pedagogical nature of Destutt de Tracy’s science, which had to both account for itself as a set of ideas and enact a process of intervening in the world of ideas so as to reform the ideas of its audience.

This established “ideology” as a term akin to “Enlightenment”, and traditions of theorizing ideology can be distinguished according to the broad schools of response to the political, economic, and pedagogical projects of the Enlightenment. Liberal theorists of ideology have focused on the dangers of passionate or unacknowledged partiality and partisanship on the moral, political, and scientific projects by which Enlightenment might be advanced. Conservative and counter-Enlightenment thinkers, by contrast, have focused on the moral and political risks of rationalism and idealism, and have adopted “ideology” as a pejorative name for purposeful efforts to reform traditions, beliefs, and practices.

Marxism, which has produced the most extensive and varied tradition of ideology theory, has alternated between a debunking approach to Enlightenment projects and a militant embrace of radical versions of them. In the debunking mode, Marxists try to show that Enlightenment projects, and the ideologies in which they are expressed, are merely attractive excuses for or mystifications of social domination and violence. In the radicalizing mode, Marxists argue, instead, that the aims of Enlightenment cannot be achieved by Enlightenment methods, and that projects of economic and political transformation must take precedence over “ideological” projects of changing people’s minds.

Understanding these traditions of thinking about ideology is required to make sense of the contemporary field of study, in which elements of this history are constantly, if inconsistently, mobilized.

1.1 Liberal Conceptions of Ideology
“Ideology” originated as part of the liberal project of social reform via education. Destutt de Tracy’s works on the moral and political sciences, written as part of his activities at the Institut, were published as Elements of Ideology (1801–15). In the Elements, Destutt de Tracy derived from empiricist epistemological premises a canon of probabilistic reasoning, a sentimentalist moral theory, and a liberal political economy. The work summarized programmatically the hopes for a secular and rationalist educational system that Destutt de Tracy—together with Pierre Jean Georges Cabanis (1757–1808) and other allies in the French Senate—tried to realize under the Directory and then the Consulate.

The aim of ideology was “to place the moral and political sciences on their true basis, a knowledge of our intellectual faculties” (Destutt de Tracy 1817 [2011: 10]). Given that every perception is, “taken each separately, and in itself”, true, Destutt de Tracy traced all error to the will, which “denaturalizes” our original perceptions (1817 [2011: 34, 36]). The will or desire, our faculty of preference, leads us into error by inducing us to see what we want to see and to discount what is inconvenient to recognize.

For this reason, ideology can help us by teaching us how “to analyze our sentiments” and to distinguish between those that “direct us well” and those that

form within us a false and blind consciousness [une fausse et aveugle conscience], which always removes us further from the road of reason, the only one leading to happiness. (1817 [2011: 255]; 1815 [2015: 254])

Therefore, despite the later identification of the two terms, Destutt de Tracy conceived ideology as a remedy for false consciousness.

This basic orientation has continued to characterize liberal approaches to ideology. Liberal education in its modern form aims to counteract the human tendencies to defer to authority, to succumb to peer pressure, and to exploit perceived inequalities of status (Nussbaum 2009: 9). It pursues this aim by teaching critical thinking, an appreciation for scientific methods, and a standard of reasonableness. Extremism, moral absolutism, and confirmation bias are thought to be inimical to liberal society, and a broad tradition of social scientific and social theoretical research, as well as political philosophical reflection, has grown up around the study and management of these problems (see, e.g., Putnam 1971).

The continuity between this work and that of the idéologues has been obscured by the fact that “ideology” has come to name the danger to be overcome or managed by liberal education rather than the intellectual project of overcoming or managing that danger. Thus, the end-of-ideology thesis expressed the hope that “civil politics could replace ideological politics” (Bell 1988: 138), but such a civil politics was also the aim of ideology for Destutt de Tracy, Cabanis, and company.

Within the liberal tradition, some have distinguished “ideologies”—understood as inherently unreasonable intellectual visions for ordering human affairs (Arendt 1953; Bell 1960 [1962])—from religious and ethical traditions and worldviews more generally. Others consider all “comprehensive doctrines” together, allowing that there might be reasonable or unreasonable adherents of any given doctrine (Rawls 2005).

Another division among liberal approaches emerges from the practical and political question of how liberal polities and institutions ought to respond to unreasonable ideologies. For public reason liberals, policy must be susceptible to public justification—i.e., justification in terms acceptable to all—in order to be legitimate (Gaus 1996, 2011; Rawls 2005). This might be understood as requiring a language of political justification that is neutral among all comprehensive doctrines or ideologies. In practice, this approach leans in the direction of strong universalism in legislation and a reliance on markets and market-like incentives as the predominant socializing or civilizing mechanisms. However, some liberals believe this is insufficient to protect the political sphere from capture by illiberal forces, and advocate instead a program of civic education and/or “militant” measures like establishing cordons sanitaires to prevent dangerous ideologies and illiberal parties from corrupting the public sphere (Castiglione & McKinnon 2003; Gauthier 1977).

1.2 Conservative Conceptions of Ideology
The conservative tradition of thinking about ideology has not been so affected by the historical transformations in the meaning of the term. The conservative objection to ideology has remained very close to the attacks leveled by Napoleon Bonaparte (1769–1821) against the idéologues after 1801. Bonaparte, for political reasons, appealed to the Catholic faithful by attacking the idéologues for their rationalism and materialism. Ideology, according to Bonaparte—influenced in this regard by the Romanticism of François-René, vicomte de Chateaubriand (1768–1848)—sought to replace Christian tradition and mores with a rational system of belief and legislation, ordering social and political life by means of the human mind (Kennedy 1979: 358–60).

Ideology, on this account, retains its particular connection to the Enlightenment and is understood to encompass any political project of social or political reform guided by a rational or abstract doctrine. Hume’s objection to “parties of principle” is a recognizable precedent (Hume 1777 [1994]). The conservative approach to ideology expresses a skepticism about modern rationalism (understood as encompassing empiricism and scientific methods generally), especially insofar as rationalism is applied to social and political life (Oakeshott 1962 [1991]).

Conservative thinkers tend to identify rationalist or ideological politics with social engineering, or the illegitimate “assimilation of politics to engineering” (Oakeshott 1962 [1991: 9]). Opposition to social engineering (AKA “scientism”, “positivism”, or “high modernism”) also characterizes liberalism and critical theory (Habermas 1981 [1987]; Hayek 1952; Horkheimer 1968 [1982]; Popper 1944–45 [2002]; Scott 1998). However, conservative thinkers often identify any political appeal to scientific or social scientific knowledge—including that of economics—as social engineering, refusing the liberal distinction between “piecemeal” and “utopian” engineering, or between “the practical management of problems” and “the clash of ideologies”. Hence, Oakeshott claimed that Hayek’s Road to Serfdom amounted to “a plan to resist all planning”, thereby converting resistance to rationalism “into an ideology” (Oakeshott 1962 [1991: 26]). Hence, also, many contemporary conservatives focus on “social constructivism” and “gender ideology” as attempts to make over putatively immutable or natural facts, accessible by “common sense”, as mind-dependent matters for human decision.

However, the conservative critique of ideology is not reducible to antirationalism. According to the conservative account, ideologies are themselves abstracts or abridgments of practical experience. While ideologies present themselves as premeditated principles that can guide and evaluate human activity, they actually simplify, schematize, or rationalize previous activity. This can be appropriate. Like digest books, ideologies provide an easily assimilable form of knowledge. This is useful when “new and politically inexperienced social classes … have risen to the exercise of political initiative and authority” (Oakeshott 1962 [1991, 30]). Ideology becomes essentially inimical to good politics, however, when it derives, not from political experience, but from some other realm of human activity—“war, religion, or the conduct of industry, for example” (Oakeshott 1962 [1991: 54]).

This concern with the colonization of the lifeworld of politics by alien vocabularies and logics of belief is not confined to conservatives (Lukács 1923 [1971]; Arendt 1958; Habermas 1981 [1987]), but it is distinctive of the conservative tradition to identify this concern with the critique of ideology.

1.3 Marxist Conceptions of Ideology
The Marxist tradition has always been torn between two approaches to ideology in the original liberal sense. On the one hand, Marxists have been drawn to a radicalizing strategy, which endorses the aims of liberal Enlightenment but disputes the pedagogical, economic, and civil means endorsed by liberals. On the other hand, however, Marxists have also pursued a debunking strategy by which they aim to unmask the ideological project as either a ruse of power or as a form of mystification. Since the meaning of “ideology” has drifted, these critical strategies have drifted as well, proliferating Marxist and post-Marxist critical theoretical accounts of ideology. Because philosophical discussion of ideology very often begins from claims associated with the Marxist tradition, the multitude of Marxist accounts of ideology has been a major source of both diversity and confusion in the philosophical literature on the topic.

1.3.1 Ideology in Marx and Engels
Karl Marx (1818–1883) read and took notes on Destutt de Tracy’s Elements of Ideology, both in 1844 and again in preparation for writing Capital. To a first approximation, the idéologues’ project was always the exemplary case of ideology for Marx, but he also identified the writings of Young Hegelians like Bruno Bauer (1809–1882) and Max Stirner (Johann Kaspar Schmitt, 1806–1856) as instances of a “German ideology”, and generalized the model further to encompass at least significant aspects of political economy, law, politics, religion, philosophy, journalism, and the military (Marx & Engels 1846 [2017: I/5.120]; Marx 1867 [2024: 409]).

What unites this disparate and capacious catalog of ideologies and ideologists, for Marx, is the “unproductive” or “immaterial” nature of their activity (Mills 1992). According to Marx, the development of the social division of labor and the exploitation of the growing productive powers of labor establishes a basis upon which rests “the state and the rest of the idealistic superstructure” (Marx & Engels 1846 [2017: I/5.115]). The people who occupy themselves with the business of this superstructure are, by dint of “their practical position in life, their business, and the division of labor”, prone to the “illusion” that they are independent and directive of society (Marx & Engels 1846 [2017: I/5.66]). This is supposed to be a sociologically materialist explanation of why ideologists like Destutt de Tracy, Bauer, and Stirner try to instruct and direct society according to ideas. “Ideology”, therefore, comes to name, for Marx, both the “sociological idealism” to which superstructural workers are susceptible and the superstructure itself, which explains their susceptibility (Mills 1992).

In his later work—especially in his Ludwig Feuerbach and the End of Classical German Philosophy (1886)—Friedrich Engels (1820–1895) returns to this sociological explanation of ideology, emphasizing Marxism’s opposition to philosophical idealism. According to Engels, ideology entails an “occupation with thoughts as with independent entities, developing independently and subject only to their own laws”. However, it is actually “the material life conditions” of the ideologist that determines, “in the final analysis”, the course of this development of thought (Engels 1886 [2003: 26.394]). The ideologist, as an idealist, is necessarily ignorant of the economic determinants of their thought process. Hence, the ideologist, as Engels put it in a letter, accomplishes a conscious process of thinking with a “false consciousness”, since their consciousness attributes to the immanent development of ideas what is actually a reflection or effect of the development of material life (Engels 1893 [2004: 50.164]).

Because Marx and Engels never developed an explicit theory of ideology, later scholars have attempted to do so by connecting Marx and Engels’s scattered comments about ideology with three other topics in their writings.

Most prominently, their critique of ideology is but one instance in which they seek to give a sociologically materialist explanation of ideas or consciousness, and this has led many to assimilate their account of ideology and their theory of ideas or consciousness (Cohen 1978 [2001: 376]; McCarney 1980; Torrance 1995). On this approach, the question of ideology is the question of the social determination of ideas or of forms of consciousness (Mannheim 1929 [1936]), and, since Marx and Engels identify classes and class struggle as the fundamental social determinant, their theory of ideology is taken to be their account of how forms of consciousness arise out of and/or serve class interests (McCarney 1980: chap. 1).

However, Marx and Engels’s comments about ideology have also been attached to their claim that “the thoughts of the dominant class are in every epoch the dominant thoughts” (Marx & Engels 1846 [2017: I/5.60]). This has given rise to the “dominant ideology thesis”, according to which, in any (stable) class society, the ruling class formulates (perhaps unintentionally or unconsciously) a set of beliefs that reflect and/or serve their own class interest in continued domination and exploitation, ideas which are largely adopted by the subordinate classes, thereby explaining their continued subordination (Abercrombie, Hill, & Turner 1980; Weber 1921/22 [1954: 336]). While this may appear to be a specification of the identification of ideology with partisan class ideas, it cannot be true that ideology refers both to partisan class ideas in general and to the “ruling ideas” in particular (Abercrombie & Turner 1978: 251). The “class ideas” approach gives rise to an evaluatively neutral account of ideologies, while the “ruling ideas” approach inclines towards a pejorative or critical account of ideology as a bulwark of domination and exploitation.

Finally, some have taken Marx’s discussion in Capital of fetishism to be an extension or development of his account of ideology (Eagleton 1991: 84–88; Geras 1971; Louette 2023; Mepham 1972). On this account, capitalist society, because of the market-imposed separation between production and consumption, necessarily appears to its participants as a mysterious entity operating according to occult mechanisms, a socially produced mystification that should properly identified as ideology. It has been noted, however, that Marx never refers to fetishism as ideology, and that the handful of appearances of the word in Capital refer to the activity of superstructural workers in general and political economists in particular (Balibar 1994: 89; Mills 1992; Roberts 2024). Nonetheless, this has been an important strand of ideology theory in the twentieth and twenty-first centuries, and it does reconnect the concept of ideology to the specifically modern and liberal domain from which it originally emerged, insofar as fetishism is proper to commercial modernity.

1.3.2 Ideology in the Marxist Tradition
Because Marxism developed as a party idea among socialists prior to the publication of the manuscripts on “the German ideology” (see Johnson, 2022), Marxist partisans tended to use “ideology”—in keeping with Marx’s mention of the term in the 1859 preface to A Contribution to the Critique of Political Economy—to refer to the “forms in which men become conscious” of the class contradiction in the economic base of society “and fight it out” (Marx & Engels 1859 [1987: 29.263]). Hence, ideology had both a theoretical aspect and a political aspect. Theoretically, it was the form in which socio-economic matters rose to conscious awareness. Politically, it was the set of fighting creeds by which parties justified their tactics and attempted to win supporters.

Because the capitalist economy was taken to be defined by a tendency of the class conflict between the bourgeoisie and the proletariat to sharpen and to increasingly determine everything else, many Marxists followed Lenin in reading all ideologies through their intersection with this fundamental conflict. This led to the simplifying assumption that people face a binary choice, “either bourgeois or socialist ideology” (Lenin 1902 [1973: 37]). Within a highly polarized political context, this assumption led to the conclusion that “to belittle the socialist ideology in any way, to turn aside from it in the slightest degree means to strengthen bourgeois ideology” (Lenin 1902 [1973: 37]). This, in turn, led to the shorthand equation of “socialist ideology”—i.e., the correct party line—with “class consciousness” and of any ideological deviation from the correct line with “false consciousness”.

In the works of Hungarian Marxist philosopher Georg (György) Lukács (1885–1971), the identification of the (long-term) interests of the proletariat with the interests of humanity as such develops this connection between (non-Marxist) ideologies and false consciousness (Lukács 1923 [1971]; Márkus 1981: 131). This conceptual connection was crucial for the Frankfurt School of critical theory, as well as for the broader tradition of Marxist humanism (e.g., Thompson 1957: 107–9). For Lukács, and even more so for members of the Frankfurt School, false consciousness is not opposed to science—which, in the form of positivism, has been part of the increasing dominance of rational calculation and formal rationality characteristic of capitalist modernity—but to a reflexive, normative, and critical theory (Geuss 1981). For this critical theory, negation plays the special role of unmasking the particular interests that animate and are served by any positive project (including, especially, the party line pursued by Leninist organizations) (Cook 2001). In this tradition, the critique of ideology becomes tightly bound up or even identified with the critique of alienation and reification. Alienation is the process whereby the artifacts of human practices—e.g., the products of labor, or the institutions of the labor movement—escape from the control of and turn against their creators (James 2012; Mattick 1969). Reification is the process whereby the relational totality that constitutes society is obscured by its seemingly independent, quantifiable, and non-relational parts (Lukács 1923 [1971]).

It is from this perspective that it makes sense to interpret Marx’s discussion of the fetishism of commodities as an extension and development of the analysis of ideology into the analysis of impersonal forms of social domination (Balibar 1994; Postone 1993). It also makes sense to flesh out the discussion of ideology either by reference to Hegel’s criticisms of the understanding as he opposes this operation of the mind to dialectical reason (Abazari 2019), or by reference to Freud’s analysis of the processes of the unconscious, which allows critical theorists to diagnose ideology as the substitute gratification of real needs (Fromm 1968: 63).

In contrast to this line of development, another Marxist tradition of thinking about ideology is represented by the work of the Italian journalist and philosopher Antonio Gramsci (1891–1937). Gramsci, emphasizing the texture of political conflict, developed the idea of ideology as class consciousness into an account of culture and institutions as the terrain of politics (Gramsci 1971). According to Gramsci, a socialist party, in its efforts to establish leadership of the working classes, articulates Marxist theory with other elements of popular consciousness and popular culture. If this process is successful, the party will advance to the head of a coalition of different class forces (a “historic bloc”) and be positioned to exercise hegemony over society as a whole. This line of thinking leads away from the critique of ideology as false consciousness and towards the descriptive analysis of the (contradictory) elements and tendencies of cultural traditions and institutions.

Although this tradition has been developed primarily in histories of popular culture (Guha 1983; Hobsbawm 1959 [1963]; Thompson 1963 [1968]), and in interdisciplinary cultural studies (Denning 2004; Hall 2016; Hall et al. 1978 [2013]), it has also received significant philosophical elaboration, beginning especially with French philosopher Louis Althusser (1918–1990). Althusser, like the Frankfurt School of critical theory, associated ideology with the reproduction of the social order and sought to use psychoanalytic concepts, including that of the unconscious, to develop the theory of ideology. However, he drew on the structuralist psychoanalysis of Lacan to argue that ideology “interpellates individuals as subjects” (Althusser 1995 [2014: 188]). What Althusser meant by this formula is that ideology constitutes and calls to us as agents, providing the framework and orientation within which we experience ourselves (and one another) as centers of action beholden to normative demands. According to Althusser, ideology can perform this function only because it is always embedded in ritual practices and institutions.

Althusser also affirmed two other theses about ideology that sharply differentiate his approach from that of the Frankfurt School. First, because of its central function in subject-formation, ideology is not a symptom of class struggle or a feature of human society that could ever wither away, even in an ideal communist future, but is instead “a structure essential to the historical life of societies” (Althusser 1965 [1969: 232]). Hence, his approach is not a critique of ideology as such, and “ideology” is not a pejorative term for Althusser. Moreover, rather than opposing ideology to a critical theory that is essentially reflexive and normative, Althusser opposes ideology to science, understood as a subject-less body of concepts that make possible the production of knowledge within a specific domain (Lewis 2009 [2022]).

Althusser’s claim that ideology interpellates individuals as subjects has been the most influential aspect of his theory. The Swedish sociologist Göran Therborn has developed it away from its functionalist tendencies by stressing the irreducible plurality of forms in which agents might “qualified” (both specified as a particular type and authorized to act in that capacity) (Therborn 1980 [1999]). Judith Butler both drew upon Althusser’s understanding of subjectification in their account of the production of gendered subjects and reacted against his account of interpellation—in a manner broadly consonant with critical theory—by emphasizing the ever-recurrent possibility of de-subjectification (Butler 1997). Quill Kukla has argued that Althusser provides an account of how subjects are inducted into the normative “space of reasons” by being misrecognized as already bound by the normative conventions into which they are being recruited, an account that aligns Althusser with Sellars’s account of epistemic authority (Kukla 2000). Sally Haslanger has directly taken up Althusser’s argument for the material existence of ideology in institutions and practices, a theme she has developed in her account of “cultural technēs” (Haslanger 2015, 2017, 2019, 2021).

2. Mapping Ideology
Due to the heterogeneity of the traditions of ideology theory, efforts to mobilize the concept must begin by establishing the sense in which the word is being understood. A first-cut specification is to distinguish between evaluatively-neutral or descriptive conceptions and evaluatively-critical or pejorative conceptions. (For critical conceptions, one may then ask about the target of the criticism. What is wrong with ideology? This question will be the focus of Section 3 below.) A second specification, however, distinguishes the location of ideology—what Shelby calls the “unit of analysis” (2003) and Balkin calls the “object of study” (1998: 101). Does “ideology” pick out a type of consciousness, a set of ideas, the world of culture, a set of expectations, or something else? Finally, there is the question of scope. Does ideology encompass all ideas, for example, or only those ideas with a certain content, a certain social function, a certain etiology, and/or a certain set of effects?

One must establish where a given conception of ideology fits in a classificatory scheme of all possible conceptions in order to know how it relates to any other conception. However, this classification, while necessary, is less interesting than the considerations that lead an author to classify ideology as they do in the first place. Authors are rarely explicit about this, and a fully explanatory theory may not be possible. However, two important variables can be established. First, the valence of ideology tracks attitudes towards partiality and partisanship. Critical conceptions of ideology indicate a commitment to moral and/or epistemic impartiality, while descriptive conceptions indicate greater openness to the moral and/or epistemic virtues of partisanship. Meanwhile, intuitions about the location of ideology track theories of agency. Adherents of the standard theory of agency as rational-intentional action are drawn to cognitivism regarding ideology (Elster 1983; Shelby 2003; Stanley 2015), while those who downplay the role of representational mental states in agency, such as enactment or embodiment theorists, will tend to locate ideology in habitual schemas of meaning, cultural technēs, affects, or bodily practices (Althusser 1995 [2014]; Hall 2016; Haslanger 2015; 2019; Hennessy 1993; Jaeggi 2009; Therborn 1980 [1999]).

2.1 The Valence of Ideology
The most obvious divide in uses of “ideology” is between uses with a pejorative or critical sense and uses with a neutral or descriptive sense (Geuss 1981; Haslanger 2021; Shelby 2003). While a positive or laudatory sense is also logically possible, only in the case of the idéologues could ideology in general be positively valorized. As soon as the word became a common rather than a proper noun—as soon as there were many ideologies rather than only one—any attempt to positively valorize ideology used the term in a descriptive sense while distinguishing between good and bad instances on independent moral, political, or epistemic grounds (contra Geuss 1981: 22–26).

Although it is common to associate the Marxist tradition with the critical conception (e.g., Shelby 2003: 156–57), critical and descriptive conceptions are equally at home both within and outside of Marxism. Marx and Engels deployed “ideology” critically, but only because they found the strategy of the ideologists ridiculous; their conception is descriptive, even if their use of the term takes on pejorative color. Lenin, Gramsci, and Althusser all developed descriptive concepts. Conservatives, liberals, and non-Marxist socialists are similarly divided.

Rather than broad political traditions, it is helpful to associate the division between critical and descriptive valences with differing commitments to epistemic and/or moral impartiality or universalism. The tradition of Frankfurt School critical theory, which is closely connected to the project of Ideologiekritik, is strongly committed to both moral universalism and to a Hegel-influenced epistemological claim that, at least for social phenomena, knowledge can only be achieved from the perspective of the totality (Jay 1984). From within this tradition, therefore, ideology appears essentially as false (because partial) consciousness, which must be transcended through criticism. For anyone committed, on the other hand, to the notion that knowledge and/or right action can or must emerge from some particular perspective or worldview, ideology appears as a necessary medium. Intermediate positions are possible, too. For instance, “ideology” may be reserved as a pejorative term for an excess of partiality or partisanship, say, a “closed-system” worldview that insulates the adherent against novel or disconfirming experiences.

2.2 The Location of Ideology
A second variable in the study of ideology is where theorists look for instances. Broadly speaking, theories of ideology are divided between cognitivist and culturalist approaches. Cognitivist accounts locate ideology among ideas, beliefs, “forms of consciousness”, mental representations, or propositional attitudes (Elster 1983: chap. IV; 1985: 459–65; Habermas 1981 [1987]; Mills 2005; Shelby 2003; Stanley 2018). Culturalist accounts locate ideology among “forms of life”, habits, practico-symbolic schemas, or “cultural technēs” (Balkin 1998; Haslanger 2015, 2019, 2021; Jaeggi 2009, 2014 [2018]; Therborn 1980 [1999]).

Among cognitivist accounts, some restrict ideology to “beliefs and values consciously entertained by some individual or individuals” (Elster 1985, 462). More commonly, however, it is recognized that an ideology “may be only implicit in the behavioral dispositions, utterances, conduct, and practices of social actors”, and that ideological beliefs “are quite frequently confused and may be expressed only in the form of stereotypes, clichés, and fragmented narratives” (Shelby 2003: 161). Cutting across this distinction between explicit and implicit beliefs (Plamenatz 1970: 17) is the distinction between beliefs and values—between beliefs “about the world as it is” and beliefs “about the world as it ought to be” (Elster 1985: 466)—as well as the further distinction between beliefs about how something can be done and beliefs about how something ought to be done (Stanley 2015). These distinctions are often submerged in a more generic cognitivist claim that, e.g., ideology consists of “the descriptive vocabulary” or “language of consciousness” appropriate to everyday social life (Fields 1990), or that “ideology” names “partisan group ideas” (Mills 1992).

Culturalist accounts of ideology are motivated by some of the same observations that incline many cognitivists to include implicit beliefs in the field of ideology. They go further, however, by foregrounding “‘non-discursive’ elements,’” such as “characteristic gestures, rituals, attitudes, forms of artistic activity, etc.” (Geuss 1981: 6); or else, they find ideology in “manifestations of a particular being-in-the-world of conscious actors” (Therborn 1980 [1999: 2]); or, alternatively, they identify ideology as a species of “cultural technē”, the “network of social meanings, tools, scripts, schemas, heuristics, principles, and the like which we draw on in action, and which gives shape to our practices” (Haslanger 2017: 155). Regardless of the language used, the intent is to locate ideology in the pre-reflective and habitual dimensions of human agency and social life.

Althusser might represent a third option, neither cognitivist nor culturalist, since he seems to locate ideology in practices, rituals, and “apparatuses” (or institutions), which are, according to him, the material existence of ideas (Althusser 1995 [2014: 260–61]). Some would include Foucault (1975 [1995]) and Butler (1997) in this lineage (Montag 2013; Lepold 2018). However, cognitivists and culturalists are at pains to demonstrate that their accounts of ideology are also both material and practical (e.g., Stanley 2018: 508–9; Haslanger 2018, 2022). More work would have to be done to demonstrate that the Althusserian approach is genuinely distinct in this regard.

Whether a theorist is drawn to a cognitivist or a culturalist account of ideology seems to depend on whether they adhere more closely to the standard conception of agency as rational-intentional action or incline more towards alternative conceptions of agency that emphasize pre-reflective and embodied aspects of human action.

This suggests a significant consensus underlying the more obvious disagreements. Ideology shares basic features with human agency, and to conceive of anything—a text, an idea, a convention, or a cultural form—as ideology is to bring it into focus as either a condition of or burden on human agency. When this regularity is combined with the regularity noted above—that ideology denotes partiality, “in one of the two senses of that term, expressed in French by ‘partiel’ and ‘partial’” (Elster 1983: 145–46)—the disorder of ideology theory as a field of study becomes intelligible as expressing the diversity of theorists’ intuitions about the roles that partiality and partisanship play (or should play) in human action.

2.3 The Scope of Ideology
Regardless of disagreements over the valence and location of ideology, most accounts agree that certain scope restrictions must be placed on ideas or cultural elements in order for them to be rightly classed as ideological. Ideology pertains to social life, in one manner or another. Four types of social pertinence, in particular, are commonly indicated. Most universally, ideology is held (1) to have social causes and (2) to have social effects. These stipulations are only scope restrictions for cognitivists, since all culture, by definition, has social causes and effects.

That ideology is “explained by social facts” (Elster 1985: 459) is uncontroversial, with disputation reserved for the questions of which facts count as social facts and which social facts are explanatory (Haslanger 2022). Not all cognitivists accept that ideology has social effects, however. This is one reading of Marx and Engels’s original criticism of ideology: ideology is an effect of the ideologists’ placement in the social division of labor, but this placement also condemns ideology to inconsequence, since ideologists have no access to or ability to affect the mode of material production.

More controversially, ideology is often thought (3) to have social content, or to be about society. It is doubtful that culture, as the culturalist ideology theorists intend it, has content or about-ness in this sense. If it does, then it seems that culture reduces to “a network” of beliefs and values (Shelby 2003: 159), with the consequences that (a) the culturalist approach to ideology reduces to the cognitivist approach and (b) all culture is “about” society, since it regulates and makes sense of social practices. Therefore, this social content proviso is a scope restriction that applies only to cognitivist accounts. However, again, not all cognitivists accept this scope restriction. Theological and metaphysical beliefs are classic objects of ideology critique, despite lacking (explicit) social content (Forster 2015).

Finally, ideology is frequently thought (4) to have a social function. (This is usually the rationale for classing theology and metaphysics as species of ideology.) What this function might be varies. For many Marxists, “part of what makes a form of social consciousness ideological is the role it plays in establishing or reinforcing relations of oppression” (Shelby 2003: 173; compare to Forster 2015: 817; Freeland 2000: 368; King 1991). For Althusser, however, ideology has no special connection to oppression or exploitation; instead, “all ideology has the function (which defines it) of ‘constituting’ concrete individuals as subjects” (Althusser 1995 [2014: 262]). The attribution of functions is controversial, since it goes beyond the identification of predictable social effects to claim that an ideology exists or has the characteristics it has because of its predictable social effects. To escape backwards causation, any function attribution must, to be complete, identify a causal feedback or selection mechanism, either intentional or systematic but unintentional, whereby ideologies that successfully fulfill their social function come into being, propagate, and are resilient, while those that do not are never produced, are winnowed out, or fade away. The debate on the appropriateness of functional explanation in social theory, and in the theory of ideology especially, is long-standing and complex (important entries in the debate include: Carling 2002; Cohen 1978 [2001]; Elster 1985, 1986; Pettit 1996b; Rosen 1996; Wood 1986). Nonetheless, using a social function to restrict the scope of ideational or cultural phenomena to be captured by the theory of ideology remains common (Haslanger 2019; Shelby 2003).

3. Varieties of Ideology Critique
Ideology can be criticized along three lines. It might be criticized for exhibiting or leading to faults of rationality, or for being interest-undermining. It might also be criticized for exhibiting or leading to faults of morality, or for being justice-undermining. Finally, it might be criticized for exhibiting or leading to epistemic faults, or for being knowledge-undermining. Each of these criticisms might be either unconditional or conditional. For example, one ideology critic might dismiss all ideology as interest-undermining partisanship, while another might differentiate between interest-serving and interest-undermining partisanship, criticizing only the latter but referring to both as “ideology”.

Regardless of the fault, the criticism of faulty ideology is not concerned with individual cases of irrationality, immorality, or ignorance, except as these are, at least, indicative or typical of wide-spread irrationality, immorality, or ignorance with a social etiology. Ideology critique is a form of social criticism, and it can only proceed by showing that a certain form of rational, moral, or epistemic failure is both widespread within a society or a group and traceable to the common social situation of its sufferers. Two types of social groups attract the special focus of ideology critics: the “negatively privileged” or “subordinate” (henceforth, “the dominated”) and the “positively privileged” or “ruling class” (henceforth, “the dominant”).

3.1 Rationally Faulty Ideology
When ideology is criticized for exhibiting or leading to faults of rationality, the substance of the criticism is that an agent or group of agents is in the grip of (a faulty) ideology just to the extent that, due to certain social facts, they are partial to or partisans of a state of affairs or course of action that is contrary to their own interests.

The conceptual connection between rationality and interests is tight; an interest can be defined as “the most rational course of action in a predefined game, that is, a situation in which gain and loss have already been defined” (Therborn 1980 [1999: 10]). However, the connection between interests and partiality or partisanship seems equally tight; interests are rational strategies, and therefore seem to be inherently instrumental (“partisan”) and perspectival (“partial”). This suggests that criticisms of interest-undermining ideology will necessarily be conditional criticisms based on a descriptive conception of ideology. An interested being is by definition partial to their interests, and so it seems to follow that any interested being will have ideological beliefs, and only a subset of those ideological beliefs—the ones that somehow do not fulfill their function of supporting the being’s pursuit of their interests—pose a problem.

In fact, however, this does not obtain. Instead, the literature displays a strongly bimodal distribution of criticisms of interest-undermining ideology. A fully substantive conception of rationality identifies rational strategies with the end to be achieved (with well-being or human flourishing or the like). On this account, rationality just is rational autonomy or rational self-determination (Ng 2015). Therefore, critics of interest-undermining ideology go one of two ways: either they embrace a formal or instrumental conception of rationality and a descriptive conception of ideology, or else they embrace a substantive conception of rational autonomy and a pejorative conception of ideology.

That partisanship or partiality can lead us into irrational beliefs and behaviors is not seriously in doubt. For instance, a suburban car commuter may vote for a mayoral candidate who praises the suburbs and car culture and promises to slash funding for public transit and expand downtown parking, even though the voter’s interest as a commuter—in being able to drive quickly and efficiently to work—would be better served by decreasing demand for roadspace. Being publicly affirmed in one’s choices and one’s identity can override or derail a rational assessment of the available options.

Two types of criticism should be excluded from this category of ideology critique, however. First, prioritizing short-term over long-term interests is not a fault of rationality, per se, and cannot furnish the basis for a critique of interest-undermining ideology, even if it may be an incident of that critique. Strategizing for long-term interests is beset by higher uncertainty in a way that cannot be eliminated. Second, prioritizing individual interests over group or collective interests is not itself a fault of rationality, since it concerns a divergence between two different games. It is one thing to say that the individualist cannot achieve their own ends by their individualist strategy; it is another to say they should be pursuing other, solidaristic ends (Gaventa 1980: 90). Criticism of individualist strategies is better conceptualized, therefore, as aimed at justice-undermining ideology rather than at interest-undermining ideology. (A practical difficulty for the proponents of a fully substantive conception of rationality is that this distinction is, on principle, not available to them.)

3.1.1 Are the Dominated Especially Prone to Rationally Faulty Ideology?
Here a special case must be considered. The belief that the dominated are partial to or partisans of their own subordination, contrary to their own interests, is widespread in the literature on ideology. It is often taken for granted that there is a

tendency of the oppressed and exploited classes in a society to believe in the justice or at least the necessity of the social order that oppresses them. (Elster 1983: 146; compare Heath 2000: 363)

In this context, the theory of ideology is supposed to answer the question:

why do the victims of oppression not rise up against their oppressors (and sometimes not even seem to show any inclination to do so)? (Finlayson 2015: 135; compare Lafont 2023: 391)

It is supposed to answer this question by reference to the possession, by the victims of oppression, of an ideological false consciousness, “a distorted view of social practices and institutions” (Lafont 2023: 391).

Since this answer only pushes the question back one step (Cudd 2006: 55), the puzzle become: why do the dominated have a false consciousness, or “why do oppressed groups accept the ideology of their own inferiority?” (Stanley 2015: 222). This perspective attributes to the members of dominated groups a belief (or set of beliefs) about themselves and/or their situation the possession of which is contrary to their own interests (Geuss 1981: 45). While there is nothing odd about claiming that an individual may be mistaken about a matter that affects their own best interests, it seems puzzling that a significant group or class of people would commonly accept a false belief that undermines their interests, since this implies a general, unidirectional, and stubborn failure of rationality. Hence, Dotson (2018) has dubbed it the “Not-Very-Bright Thesis”.

Numerous mechanisms for resolving this puzzle have been proposed in the literature, but substantial doubts have also been raised about each of them.

3.1.1.1 Sociological Mechanisms
By far the most commonly proposed mechanism is pedagogical indoctrination or coercive socialization (Althusser 1995 [2014: 142–47]; Bartky 1990; Berger & Luckmann 1966: 121–25; Gaventa 1980: 22; Guha 1997: 165–69; Stanley 2015: 234–37). This is the basis of the dominant ideology thesis in its classic form: the dominant group, monopolizing the means of mental production, ensures that members of the dominated group internalize the dominant belief system, which includes as a component the (false) idea that members of the dominated group are incapable of self-rule or freedom and are better off in their current, dominated position.

Another commonly proposed mechanism is elite control of the media and of expert authority. For example, it is claimed that, in any stable society, “the central moral, political and economic ideas that dominate discussion in the mass media and in the corridors of power” will generally “promote the interests of the ruling class of that society” (Leiter 2004 [2005: 159]). Similarly, Stanley claims that, since belief is not under our direct voluntary control, dominant group control of the authoritative narratives and sources of testimonial evidence will result in dominated groups being insulated from any alternative ideology, and therefore believing the dominant account of their inferiority (2015: chap. 6).

The effectiveness of these sociological mechanisms has been doubted, however, on multiple grounds. First, since the socioeconomically disadvantaged tend to be less exposed to elite media, have lower educational attainment (and hence less exposure to elite expert discourse), and exhibit lower levels of trust in conventional expert opinion, it is unclear why these mechanisms would not be primarily effective at securing coordination and cohesion among the dominant (Scott 1990: chap. 3). Moreover, the legitimating discourses of the dominant consists, at least in part, of the rules, promises, and normative ideals that the present order is said to instantiate, realize, or pursue, and these can be used to make demands of the dominant (Gramsci 1971: 161; Piven & Cloward 1977; Scott 1990: chap. 4; Willis 1977). This has given rise to an adage for radical organizers, “Make the enemy live up to their own book of rules” (Alinsky 1971: 128). Third, as feminist standpoint epistemologists have argued, the dominated can often draw upon the direct evidence of their lives and the lives of those similarly positioned in order to contest the guidance of dominant experts (Hartsock 1983; McKinnon 2018). Finally, the dominant belief system is very easily contradicted in two ways, with mental resources that would seem to be universally available. A belief about a normative social hierarchy might be contradicted either by reversal (e.g., “the last shall be first, and the first last”) or by negation (e.g., “There is neither Jew nor Greek, there is neither slave nor free, there is neither male nor female”). Such reversals and negations of dominant moral frameworks are widely attested among subordinate groups historically, and this seems to call into question the thesis that the dominated are, as a rule, susceptible to internalizing interest-undermining ideological beliefs (Scott 1977a, 1977b, 1985: chap. 8).

3.1.1.2 Psychological Mechanisms
Interest-undermining false consciousness might arise, instead, from the operation of various psychological mechanisms within the social context of subordination (Cudd 2006).

Elster suggests, for example, an optical illusion or unwarranted generalization, whereby the dominated attribute to the whole of society a pattern or logic that obtains only locally, in the neighborhood of society with which they are most familiar (1983: 145–46). For instance, a serf may recognize that they depend for their well-being and protection on the local lord, and generalize from this to the conclusion that a society of peasants without lords would be intolerably miserable and violence-prone. However, Elster only gives examples of academics either making this sort of error themselves or stipulating that subaltern populations “had to believe” something like this (1983: 146, including n. 12).

Another proposed mechanism is “stereotype threat”, a widely-studied phenomenon in social psychology. In a condition of stereotype threat, members of a group subject to a negative social stereotype are more likely to act in ways that seem to confirm the stereotype. It has been suggested that this type of self-fulfilling prophecy might underpin the adoption by subordinate groups of ideological beliefs regarding their own abilities (Stanley 2015: 239–40; compare Cudd 2006: chap. 6). However, anxiety about confirming a negative stereotype can affect performance without any supposition that negative beliefs about oneself have been internalized. Disidentification with dominant modes of achievement—the hypothesized route by which negative stereotypes become self-fulfilling prophecies—implies a mode of evaluation contrary to the dominant mode, which is the opposite of what the theory of ideological incorporation predicts.

A third psychological mechanism that features widely in the literature is preference adaptation, the spontaneous alteration of desires so as to minimize cognitive dissonance or frustration (Elster 1983). In its weaker form, this entails resignation, believing that the absence of some previously desired social state of affairs is necessary, even if regrettable. In its stronger form, it entails the belief that the absence of some previously desired social state of affairs is just or good. This psychological process is often referred to, generically, as “naturalization” or “reification”, and the stronger version is sometimes picked out as “legitimation”.

Whether preference adaptation is a significant phenomenon, or a case of interest-undermining false consciousness, may be doubted, however. In the first place, genuine instances of adaptive preferences would have to be sorted out from cases of preference falsification, the misrepresentation of one’s desires in the face of perceived pressure or opposition from others (Kuran 1995). The dominated have good reason to falsify their preferences in most circumstances (Jacobs 1861 [2015]; Scott 1985, 1990). Even if genuine cases of adaptive preferences can be identified, it is not clear that they are cases of irrationality. If a desired social state of affairs really is out of reach, changing one’s beliefs about its desirability may be the rational thing to do. Again, one must ask whether the adaptive preference would adapt again if an avenue to the previously desired outcome opens up. If it would—if, in the terms of the fable of the fox and the sour grapes, the fox would decide that the grapes were sweet after all were a means of attaining them presented—then the adaptive preference is not a significant phenomenon.

3.1.1.3 Conclusions
Too much of the literature on interest-undermining ideology among the dominated simply assumes what would have to be demonstrated, that widespread ideological false consciousness leads the dominated “to believe that their place is deserved” (Cudd 2006: 180). The “massive fact of history that the values and the beliefs of the subjects tend to support the rule of the dominant group” (Elster 1983: 166) is not so much a fact as an illusion: the only evidence for it is that the subjects are not generally in open revolt, but this is what ideological false consciousness is supposed to explain, so it cannot count as evidence that the beliefs of the subjects are, in fact, partial to their subordination.

As Finlayson points out, if we accept that people are

imperfectly rational, imperfectly informed and somewhat confused, often fearful, subject to more or less reasonable forms of hope, prone to a condition sometimes termed learned helplessness, motivated to a considerable extent to pursue what we would think of as their own interests, but also motivated in ways that cannot plausibly be reduced to this, for example, by aesthetic, altruistic, experimental or self-destructive urges,

then it is not really

a mystery that such beings, having been born into a social order that oppresses them, often do not rise up and overthrow it. (2015: 138)

No appeal to widespread false consciousness or ideological incorporation is necessary to explain the persistence of oppressive social systems.

It might also be argued that the entire dispute about “the dominant ideology thesis” was a red herring to begin with. Those who proposed that ideology was a crucial factor in the persistence and stability of systems of domination and exploitation were, in the first instance, revolutionaries and radical reformers. What they meant, arguably, was not that the dominated and exploited are partisans of the system that dominates and exploits them, but that they are not yet partisans of revolutionary or radical projects that aim to abolish that system (Lenin 1902: chap. 2 [1973]).

From this perspective, the diagnosis of “false consciousness” among the dominated means only that the patient is not an adherent of the best or correct political program or practices, as identified by the diagnostician. In this sense, ideology critique is endemic to popular, contestatory politics, which consists in advocating one ideology (partisan view) against rivals and trying to win over the uncommitted (Freeden 1996), in part by arguing that adherents of rival ideologies are deluded or mistaken about the rationality of their own partisan views.

3.1.2 Are the Dominant Especially Prone to Rationally Faulty Ideology?
If the ideology-critical argument that the dominated are prone to accepting interest-undermining ideology is questionable, however, there appears to be better evidence for the converse theory: that the dominant are, due to certain social facts, prone to accepting interest-undermining false beliefs or myths, at least in certain instances. (That the dominant might also adhere to interest-promoting ideological beliefs is no surprise; any criticism of these beliefs will base itself on moral or epistemic grounds.)

It is an ancient complaint about tyrants and princes that they surround themselves with flatterers and sycophants, but the prevalence of the complaint suggests a structural cause: flattery is a strategy among the dependent, since it may help them retain their office, status, or even their life (Kapust 2018). The result is that the dominant may find themselves surrounded by unreliable narrators, whose testimony about states of affairs is regularly distorted by their expectations about what the dominant want to hear. This is a politically salient instance of preference falsification, since it may lead the dominant to seriously underestimate opposition to their rule (Kuran 1995: chap. 15). By this mechanism, then, the dominant may be prone to accepting false beliefs about their own security, their own virtue, and their own popularity, false beliefs that undermine their rationality.

The same factors may lead to the dominant being insulated from rational arguments, such that they are less able to be rational themselves. This, at least, was Frederick Douglass’s claim about slaveholders: because they never encourage frank conversation with the slaves and other dependents who surround them, and because their every whim is law, “reason is imprisoned” on a plantation, and the slaveholder never learns how to control their own passions or to pursue a reasoned policy (Douglass 1855 [2003: 61–62]).

3.2 Morally Faulty Ideology
When ideology is criticized for exhibiting or leading to moral faults, the substance of the criticism is that an agent or group of agents is in the grip of (a faulty) ideology just to the extent that, due to certain social facts, they are partial to or partisans of a state of affairs or course of action that is unjust.

If, however, an agent is partial to or a partisan of an unjust social system because that system seems to them to operate in their interest—to deliver or secure for them important material and/or social goods—then this situation is not generally considered to call for ideology critique. A conflict between personal interests and the demands of justice is too widely taken for granted to call forth critical social theory in most cases. There are exceptions to this rule. Theorists who claim that we have moral or ethical interests—a rational interest in doing the right thing or in acting according to our duty (e.g., Stanley 2015: 266)—may assimilate the criticism of self-interested support for injustice to ideology critique. Similarly, theorists who identify instrumental rationality as an inappropriate governor of social interaction may conclude that “a state of society in which humans treat themselves and others as if they were things, not people” is a reified state of society, and is the proper object of ideology critique (Geuss 2008: 123). Note, however, that reification, even if it has bad moral consequences, is subject to ideology critique for the epistemic fault of mistaking a socially contingent circumstance for something necessary (Geuss 1981; Habermas 1981 [1987]; Honneth 2008).

The critique of justice-undermining ideology focuses on cases in which, because of how they are socially situated, and perhaps contrary to their own wishes and even efforts to the contrary, agents are complicit in injustice.

Accounts of structural injustice and findings from social psychology (Young 2011; Jost 2020), have been mobilized in efforts to explain why people often accept an unjust social and political status quo. The question of ideological complicity is not, as in the critique of interest-undermining ideology, directed at one group in society—“Why do you support a system that exploits you?”—but is addressed to everyone in general—“Why do you accept and help to reproduce an unjust social system?” The issue animating much of the recent writing on ideology is, thus, “how we all become agents of injustice” (Haslanger 2015: 12, n. 4).

In this general form, however, the question admits of only one answer: it depends. The causes and effects of unjust social practices are often obscure or controversial. There is often great uncertainty or disagreement about what practices would be genuinely disruptive of structural injustices, even where there is agreement about the existence of such injustices. Bucking established norms and practices is likely a costly course of action, and when these costs are compounded by the uncertainty that one’s actions will contribute to effective improvements, inaction (or minimal, conciliatory forms of protest) may seem the most prudent course (Finlayson 2015; Heath 2000; Sankaran 2020).

However, this combination of ignorance, uncertainty, disagreement, and costliness does not make a significant appearance in the most prominent recent critical accounts of ideology (by way of contrast, see Dworkin 1983). In general, the literature on the formal features of social norms and the literature on ideology have parted ways (Sankaran 2020). This does not mean there are no possibilities for fruitful engagement, however. Ideology critique might be understood as an effort to assist agents stuck in a suboptimal equilibrium, either by redescribing the action-relevant characteristics of the options they face so as to induce a change in preferences, or by highlighting discounted possibilities for action, thereby expanding the set of feasible options (Barrett 2022). The former would be appropriate where agents are complicit because they do not know that or how their actions contribute to injustice. The latter would be appropriate where agents are complicit because they do not know how they can act so as not to contribute to injustice. Both forms of ameliorative ideology critique depend upon social theory (Haslanger 2019, 2022); they require that the ideology critic possess knowledge of alternative social norms or forms of action that are not—or not as significantly—complicit in injustice.

3.3 Epistemically Faulty Ideology
When ideology is criticized for exhibiting or leading to epistemic faults, the substance of the criticism is that an agent or group of agents is in the grip of (a faulty) ideology just to the extent that, due to certain social facts, they are partial to or partisans of untruths or other epistemically dubious beliefs. This is the most diverse category of ideology critique. Generally speaking, an ideology is criticized for exhibiting or leading to either (1) faults of scope, (2) faults of modality, or (3) faults of reflective endorsement.

Partisanship or partiality leads to a fault of scope when an agent, because of their social position, background, or interests, mistakes something particular or local for something universal or general, or vice versa. It is commonly asserted, for instance, that ideology represents a particular interest as a universal interest (e.g., Celikates 2006: 33; Eagleton 1991: 56–58; Geuss 1981: 14; Žižek 1994: 10). This is very similar to the ideology critique that Charles Mills directs at the social contract tradition. The figure of the social contract is exemplary of the problem diagnosed by the epigraph to The Racial Contract: “When white people say ‘justice,’ they mean ‘just us’” (Mills 1997). A fault of scope critique is also exemplified by Elster’s analysis of cases in which members of social classes exhibit a “proneness to unwarranted generalization” that leads to making “errors about social causality” specific to the class’s position in the economic structure of society (1983: 144–49). The same could be said of some of the epistemic errors encoded in the formation and use of stereotypes, insofar as these give a universal and/or normative scope to select, privileged observations (Cudd 2006: chap. 3; Haslanger 2014).

Partisanship and partiality can also lead to the opposite epistemic problem, however: taking general or universal aspects of human social life to be the special property of one’s own social group, or acting as if they were. This may appear in political life as a variety of what Bertrand Russell called “emotive conjugation” (as stated by Griffin 1999), as, for example, “we pursue justice, you fetishize procedures, they are fanatics”. In a case of ideological bias, we may attribute to our own group or form of life an exclusive or privileged exercise of certain generically human capacities or virtues, simply because we experience and understand our culture and customs from within.

A different strand of epistemic ideology critique focuses, instead, on faults of modality. Partisanship or partiality leads to a fault of modality when an agent, because of their social position, background, or interests, believes something contingent to be something necessary, or vice versa. The most widely-encountered instance of this type of epistemic ideology critique is the critique of reification or naturalization, in which institutions, conventions, and other “social constructions” are taken to be or treated as if they were natural, eternal, inevitable, or otherwise not amenable to human alteration or control (Berger & Luckmann 1966: 88–92; Habermas 1981 [1987]; Honneth 2008; Lukács 1923 [1971]; Shelby 2003: 177; Thompson 1957). This is also called, by Geuss, “an ‘objectification’ mistake” (1981: 14). Critiques of ideological reification or naturalization tend to be quite sweeping, but they are akin to a critical strategy that is used more locally and on a smaller scale: the diagnosis of self-fulfilling prophecies or self-confirming beliefs. In these cases, believing something (or acting on a certain belief) generates evidence for the belief. If the police believe that Black motorists are more likely to possess illegal drugs, and act on that belief by implementing a form of racial profiling, this will generate a disproportionate number of drug arrests among Black motorists, a fact that may then be cited as evidence for the belief that Black motorists are more likely to possess illegal drugs.

Again, ideology can also be criticized for the opposite modal error: the necessary can appear to be contingent. Scapegoating and casting blame can be a way of attributing to individual agents’ contingent choices what would better be understood as a necessary outcome of background social facts and institutional dynamics. A feature of large-scale social interaction is that incentive structures may make it inevitable or nigh inevitable that some agents will engage in a particular behavior, even if it is impossible to say which individual agents will engage in that behavior. To use an example from Philip Pettit, that an increase in unemployment might explain a subsequent increase in crime illustrates a form of structural explanation in the social sciences that neither violates the commitment to intentional psychology nor runs afoul of scientific norms of explanation in other domains (Pettit 1996a: pt. II; building on Jackson and Pettit 1990, 1992; see also: Haslanger 2016). Therefore, a political campaign against crime that vilifies individual figures might be criticized as knowledge-undermining ideology on the grounds that it makes what is necessary (given the state of the economic system) appear to be contingent on an identified set of agents (Hall et al. 1978 [2013]).

Partisanship or partiality leads to a fault of reflective endorsement when an agent, because of their social position, background, or interests, believes x only because of some social facts, where these social facts (a) are not reasons for believing x, and (b) are such that, awareness of these facts would undermine the agent’s belief in x. This is the sort of fault that Engels intended with his claim that ideology is a process accomplished with a false consciousness: the economic facts and motives that actually cause the ideologist to believe certain things cannot be acknowledged by the ideologist without undermining the beliefs they gave rise to. Another prominent example of this form of ideology critique is the critique of legitimation. Habermas and other critical theorists argue that, if a belief in the legitimacy of a form of domination could not be arrived at or sustained under conditions of free and open deliberation, then the belief suffers a fault of reflective endorsement. The belief is only sustained by a background condition of coercion or fraud, the acknowledgment of which is incompatible with maintaining the belief (Habermas 1981 [1987]; see also: Geuss 1981: 26–44). Others have drawn on Susan Stebbing’s discussion of “cherished beliefs”, beliefs that are “pleasant to hold” (Stebbing 1939: 40), to characterize ideological beliefs as beliefs that are difficult to rationally revise in the light of new evidence because they encode identity-related expectations about the payout of social interactions (Stanley 2015: chap. 6). While Stanley’s account of ideology is descriptive, it bears comparison with critical concerns about group polarization and “echo chamber” effects, in which in-group signaling overrides normal processes of belief revision.

Many epistemic critiques of ideology combine these modes of fault-finding. For instance, Aytac and Rossi have argued that ideas that are not readily challenged tend to be epistemically inferior, and the self-justificatory discourses of the powerful tend to be shielded from contestation by the very power they justify (2023). Therefore, these ideologies suffer from a fault of reflective endorsement—being adhered to only because they are shielded from criticism—but they will also typically exhibit faults of both modality and scope. Similarly, if being subject to uncontrolled power incentivizes strategies of dissimulation and feigned ignorance, then the dominant will tend to form, on this basis, naturalized stereotypes about the untrustworthiness and foolishness of the dominated, beliefs which will shape the expectations of the dominant in hard-to-revise ways (Roberts 2022). These epistemic faults will likely have negative consequences for both the interest-seeking activity of the dominant and for the justice of the society in question, but the basis of the critique in both of these cases is the identification of epistemically faulty partisanship or partiality.

1. The Philosophy of Creativity: Past and Present
Given the significance creativity has in our lives and the deep philosophical questions it raises, one might expect creativity to be a major topic in philosophy. Curiously, it isn’t.

To be sure, some of the most prominent figures in the history of Western philosophy have been fascinated with creativity—or what we now call “creativity”. According to some scholars, the abstract noun for creativity did not appear until the nineteenth century—but the phenomenon certainly existed and many philosophers took an interest in it (McMahon 2013; Nahm 1956; Murray 1989; Tatarkiewicz 1980: chapter 8).

To name just a few examples: Plato (4th century BCE) had Socrates say, in certain dialogues, that when poets produce truly great poetry, they do it not through knowledge or mastery, but rather by being divinely “inspired” by the Muses, in a state of possession that exhibits a kind of madness (Ion and Phaedrus). Aristotle (3rd century BCE), in contrast, characterized the work of the poet as a rational, goal-directed activity of making (poeisis), in which the poet employs various means (such as sympathetic characters and plots involving twists of fate) to achieve an end (of eliciting various emotions in the audience). Margaret Cavendish (1623–1673) and Émilie du Châtelet (1706–1749) championed the creative use of the imagination to pursue freedom, overcome prejudice, and cultivate natural abilities even despite social and political oppression. Immanuel Kant (1724–1804) conceived of artistic genius as an innate capacity to produce original works through the free play of the imagination, a process which does not consist in following rules, can neither be learned nor taught, and is mysterious even to geniuses themselves. Schopenhauer (1788–1860) stressed that the greatest artists are distinguished not only by the technical skill they employ in the production of art, but also by the capacity to “lose themselves” in the experience of what is beautiful and sublime (Schopenhauer 1859: Vol. I: 184–194 and Vol. II: 376–402). Friedrich Nietzsche (1844–1900) argued that the greatest feats of creativity, which he took to be exemplified by the tragic poetry of ancient Greece, was being born out of a rare cooperation between the “Dionysian” spirit of ecstatic intoxication, which imbues the work with vitality and passion, and the “Apollonian” spirit of sober restraint, which tempers chaos with order and form (Nietzsche 1872 [1967]). William James (1842–1910) theorized about creative genius exerts the causal power to change the course of history (Simonton 2018). This is just a glimpse of what each of these philosophers had to say about creativity, and many other figures could be added to their number.

Nevertheless, while some of the topics explored by earlier thinkers have come to occupy a central place in philosophy today—such as freedom, justice, consciousness, and knowledge—creativity is not among them. Indeed, “philosophy of creativity” is still a neologism in most quarters, just as, for example, “philosophy of action” and “philosophy of gender” were not too long ago. However, philosophical work on creativity has been picking up steam over the last two decades (as shown, for example, in a few important collections of essays: B. Gaut & Livingston 2003; Krausz, Dutton, & Bardsley 2009; Paul & Kaufman 2014; B. Gaut & Kieran 2018). We’ll now dive into those contributions, along with earlier work, beginning with what is perhaps the most basic question one can ask in this field.

2. What is Creativity?
As we noted at the outset, the term “creative” can be applied to three kinds of things: a person, a process, or a product (where a product could be an idea, performance, or physical artifact).

Most definitions focus on the product. According to one common approach, persons or processes are creative to the extent that they produce creative products, and a product is creative if it meets two conditions: in addition to being new it must also be valuable. Many theorists argue that novelty is not sufficient, because something can be new but worthless (e.g., a meaningless string of letters), in which case it doesn’t merit the compliment of being called “creative”. Immanuel Kant is often cited as anticipating this definition of creativity in his discussion of (artistic) genius. According to a common interpretation, Kant defines (artistic) genius as the ability to produce works that are not only “original”—since “there can be original nonsense”—but also “exemplary” (Kant 1790: §§43–50 [2000: 182–197]). (Hills & Bird [2018] challenge this reading of Kant.) This definition is so widely accepted among psychologists that it has come to be known as “the standard definition” of creativity in psychology. In practice, “creativity is often not defined” (J.C. Kaufman 2009: 19) in psychological experiments—more on this in §5 below. When psychologists do explicitly adopt a definition, however, they usually say that creative products are not only new, but also valuable in some way, though they variously express the product’s value in terms of its being “useful”, “effective”, “worthwhile”, “fit”, or “appropriate to the task at hand” (Bruner 1962: 18; A. J. Cropley 1967: 67; Jackson & Messick 1965: 313; Kneller 1965: 7; Cattell & Butcher 1968; Heinelt 1974; J.C. Kaufman 2009: 19–20; S.B. Kaufman & Gregoire 2016; Stein 1953; Sternberg & Lubart 1999: 3—for an overview, see Runco & Jaeger 2012). A few psychologists have suggested that the standard definition doesn’t fully capture the concept of creativity (Amabile 1996; Simonton 2012b). As for philosophers, at least one of them defends the standard definition with qualifications (Klausen 2010), but many of them challenge it, as we’ll soon see.

While it is uncontroversial that novelty is required for creativity, philosophers have refined that point. Certain examples may seem, at first, to suggest that novelty isn’t really necessary for creativity. Newton’s discovery of calculus was creative even if, unbeknownst to him at the time, Leibniz got there first—one of many examples of what are called “multiples” in the history of science (Simonton 2004). A beginning student’s idea that freedom is compatible with causal determinism might be creative even if, as she will soon learn, philosophers have been defending such “compatibilist” theories for millennia. However, examples like these do not force us to abandon the novelty requirement, but only to qualify it. Newton’s calculus and the student’s compatibilism were not new in all of history, but they were new to their respective creators, and that is enough for them to count as creative. In the terminology of philosopher Margaret Boden, these ideas are “psychologically creative” (P-creative) even though they are not “historically creative” (H-creative). Notice that P-creativity is more fundamental. Anything that is new in all of history (H-creative) must also be new to its creator (P-creative). Thus, creativity always exhibits psychological novelty, though it doesn’t always exhibit historical novelty.

Again, no one denies that a creative product must be new, at least to its creator. But as we’ll now see, some philosophers depart from the standard definition of creativity by rejecting the value condition (§2.1), or by proposing some further condition(s) (§2.2), or by doing both.

2.1 Challenges to the value condition
Some theorists have argued that although creative things are valuable, we shouldn’t build value into the definition of creativity, because doing so is not informative or explanatory:

Knowing that something is valuable or to be valued does not by itself reveal why or how that thing is. By analogy, being told that a carburetor is useful provides no explanatory insight into the nature of a carburetor: how it works and what it does. (Stokes 2008: 119; Stokes 2011: 675–76)

Those who maintain that value is required for creativity might reply that it doesn’t need to be informative or explanatory. Being a man is required for being a bachelor even though it’s not informative or explanatory to say that bachelors are men. Stokes notes that “creative” is a term of praise, and uses this point to argue that what is creative must be produced intentionally (since we don’t rightly praise what is unintentional or accidental)—an idea we’ll return to below. But the same point also seems to imply that what is creative must also have value (since we don’t rightly praise what doesn’t have value). And while the concept “carburetor” is value-neutral, as shown by the fact that a carburetor can be worthless or useless (if it’s broken), “creative”, one might argue, is a value-laden concept, like “progress”. Progress necessarily involves novelty or change, but we don’t praise change as progress unless it’s good change. Likewise, defenders of the value condition urge, creativity necessarily involves novelty, but we don’t praise novelty as creative unless it’s good novelty.

Other critics use counterexamples to argue that value isn’t necessary for creativity, the most prominent cases being ones of immoral creativity. (For a collection of essays by psychologists on the phenomenon of immoral or so-called “dark” creativity’, see D. Cropley et al. 2010). Putative cases of immoral creativity include creative accounting to cheat investors or creative testimony to mislead jurors, and the stock example in the literature is creative torture or murder. One can imagine novel and well-designed murders, as Thomas De Quincey once did in a satirical essay:

[S]omething more goes to the composition of a fine murder than two blockheads to kill and be killed—a knife—a purse—and a dark lane. Design, gentlemen, grouping, light and shade, poetry, sentiment, are now deemed indispensable to attempts of this nature. Mr. Williams has exalted the ideal of murder to all of us […] Like Æschylus or Milton in poetry, like Michael Angelo in painting, he has carried his art to a point of colossal sublimity. (De Quincey 1827; see also discussion in Battin et al. 1989)

Innovative ways of inflicting needless agony and craftily designed murders are not good (they have no value), and yet they can be creative. If this is right, then it seems to follow that creativity doesn’t require value.

One way of trying to save the value condition is by flatly denying that torture methods can be creative, and by denying more generally that creative things can be bad (Novitz 1999). But such denial seems ad hoc and implausible—“evil creativity” is not a contradiction in terms—and some have argued that this denial faces other problems besides (Livingston 2018).

Other theorists revise or qualify the value condition in order to accommodate examples of immoral creativity. Paisley Livingston (2018) proposes that a creative product only needs to be instrumentally valuable or “effective” as means to its intended end, regardless of whether that end is morally good, bad, or indifferent. Berys Gaut (2018) distinguishes between something’s being good (or good, period) versus being good of its kind. In his view, a new way of wielding blades and pulleys may be creative if it’s a good of its kind—good as a method of torture—even though it isn’t good. In order for something to count as creative, Gaut says, it doesn’t need to be good; it just needs to be good of its kind.

Alison Hills and Alexander Bird (2018) are unconvinced by such qualifications. They contemplate an elaborate torture device that ends up killing its victims immediately, “without enough suffering on the way”. The device may still be creative, they hold, even though “as a method of torture, it’s no good” (2018: 98). Indeed, they argue, a creative item needn’t be good in any way at all, not even for its creator. The ineffective torture device just described doesn’t satisfy its creator’s preferences, it doesn’t give him pleasure, it isn’t an achievement, it doesn’t contribute at all to his well-being—and yet, they contend, it may be creative, provided that it’s new and was produced in the right way. Exactly what “the right way” amounts to is the topic we turn to next.

2.2 Other proposed conditions
With or without the value condition, some theorists argue that a product must satisfy one or more further conditions, beyond being new, in order to count as creative. The four most prominent proposals are that the product must be (i) surprising, (ii) original (i.e., not copied), (iii) spontaneous, and/or (iv) agential. Each of these is a condition on the process of creativity. To be clear, we are still concerned with what it means for a product to be creative, but the proposals we’ll now consider say that in order for a product to count as creative, it must be brought about in the right way.

2.2.1 Surprise
Margaret Boden holds that a creative product must be “new, surprising, and valuable” (2004: 1; cf. Boden 2010; 2014). It is perhaps most natural to assume that being surprising—like being new and valuable—is a feature of a product. But while Boden does think of creative products as surprising, her interest is more fundamentally in the underlying generative process, in how a creator manages to make something surprising. In her view, there are “three types of creativity”—combinatorial, exploratory, and transformative—“which elicit different forms of surprise, [and] are defined by the different kinds of psychological processes that generate the new structures” (2010: 1, italics added).

Combinatorial creativity occurs when old ideas are combined in new ways. Obvious examples include fictional hybrid creatures or chimeras: add wings to a horse (Pegasus), add the tail of a fish to a woman’s head and upper-body (a mermaid), add a lion’s body to a woman’s head and torso (Sphinx), and so on. Other combinations are found in analogies, such as when Niels Bohr compared an atom to the solar system. The term “combination” can refer either to the product of things combined or to the process of combining them, but Boden’s focus is on the process here, on the fact that one way to generate new ideas is to begin with old ideas and combine them in new ways.

To explain her other two kinds of creativity, Boden invokes the notion of a “conceptual space”, which is roughly a system comprising a set of basic elements (e.g., basic ideas or representations) as well as rules or “constraints” for manipulating or re-combining those elements. A conceptual space is not a painting, song, or poem, for example; it’s a way of creating a painting, song, poem, or theory. The rules or constraints are “the organizing principles that unify and give structure to a given domain of thinking”. And so a conceptual space is

the generative system that underlies that domain and defines a certain range of possibilities: chess moves, or molecular structures, or jazz melodies. (1994: 79)

We could think of a conceptual space as not just a set of thoughts but also a style of thinking defined by rules for generating new thoughts.

“Within a given conceptual space”, Boden observes, “many thoughts are possible, only some of which may have been actually thought” (2004: 4). Some conceptual spaces contain more possibilities than others. Consider different games. Tic-tac-toe is such a simple game that all of its possible moves have already been made many times over. The same is not true in chess, by contrast, which allows for a mind-boggling number of possible moves. The range of possible ideas is also practically inexhaustible in literature, music, the visual and performing arts, as well as the various domains of theoretical inquiry. And within those pursuits, there are various “structured styles of thought”—genres, paradigms, methodological orientations—which Boden thinks of as conceptual spaces.

Boden argues that the elements as well as the operating rules of a conceptual space can be, and in some cases have been, captured in computer programs. She has used this point not only to argue that computers can be creative (a topic we’ll return to below in §5), but also to suggest that we should employ the computational model of the mind in order to explain how humans create.

With her notion of conceptual spaces in hand, Boden says that exploratory creativity occurs within a given conceptual space. The new idea that emerges is one that was already possible within that space, because it was permitted by its rules. “When Dickens described Scrooge as ‘a squeezing, wrenching, grasping, scraping, clutching, covetous old sinner,’” Boden writes, “he was exploring the space of English grammar” in which “the rules of grammar allow us to use any number of adjectives before a noun” (Boden 1994: 79). Dickens’s description may strike us somewhat surprising, unexpected, or improbable, but it doesn’t have an air of impossibility about it.

By contrast, Boden argues, another form of creativity does. In this kind of case, the creative result is so surprising that it prompts observers to marvel, “But how could that possibly happen?” (2004: 6). Boden calls this transformational creativity because it cannot happen within a pre-existing conceptual space; the creator has to transform the conceptual space itself, by altering its constitutive rules or constraints. Schoenberg crafted atonal music, Boden says, “by dropping the home-key constraint”, the rule that a piece of music must begin and end in the same key. Lobachevsky and other mathematicians developed non-Euclidean geometry by dropping Euclid’s fifth axiom. Kekulé discovered the ring-structure of the benzene molecule by negating the constraint that a molecule must follow an open curve (Boden 1994: 81–3). In such cases, Boden is fond of saying that the result was “downright impossible” within the previous conceptual space (Boden 2014: 228).

Boden’s definition of creativity has perhaps been most influential among researchers who share her intertest in computer creativity (e.g., Halina 2021; Miller 2019: ch. 3; du Sautoy 2019). In a variation of Boden’s account, one philosopher proposes that what makes a mental process creative is not that it actually involves “the recombination of old ideas or the transformation of one’s conceptual space”, but rather that the creator experiences the process as having one of those features (Nanay 2014).

2.2.2 Originality
Maria Kronfeldner (2009; 2018) argues that the process of making something creative must exhibit originality. As she uses the term “original”, it does not simply mean “new”; instead, it has to do with the kind of causal process the creator must employ. She motivates her view by asking why it’s the case that, as we noted earlier, psychological novelty is required for creativity while historical novelty is not. Why is it, for example, that Newton’s invention of calculus was creative even if Leibniz invented it first? The answer, of course, is that it’s because Newton didn’t copy his calculus from Leibniz. Insofar as Newton came up with calculus independently, on his own, then he exhibited originality in his discovery, even though someone else got there first. This originality, Kronfeldner argues, is essential to creativity.

2.2.3 Spontaneity
Kronfeldner (2009; 2018) also argues that spontaneity is required for creativity. An idea occurs spontaneously to the extent that it is produced without foresight or intentional control. If you were to foresee the output of the creative process at the beginning of that process, then you wouldn’t need any further process to come up with it. So if an idea is creative, you cannot have fully seen it coming. To that extent, insight comes as a surprise, hence the common phenomenological observation that creative breakthroughs feel like they come unbidden or out of the blue: “Eureka!”, “Aha!”, a lightbulb turns on.

Gaut (2018: 133–137) agrees that creativity requires spontaneity, and he points out, as Kronfeldner does, that it comes in degrees. He explains that you do something spontaneously to the extent that do it without planning it in advance. If you are going to act creatively, he argues, you cannot set out to follow an “exact plan”—a mechanical procedure, routine, or algorithmic rule—which would give you advance knowledge of exactly what the outcome will be and exactly the means you'll take to achieve it. At the outset of a creative act, you have to be to some extent ignorant of the end, or the means, or both. That ignorance opens up room for spontaneity and creativity.

2.2.4 Agency
Some philosophers argue that an item does not count as creative unless it has been produced by an agent. Consider a unique snowflake with an intricate shape, a distinctive sunset with stunning layers of red-orange hues, a novel patterning of dunes across a wind-blown desert. All of these things are aesthetically valuable and new. None of them are creative, however, insofar as they all occurred naturally and were not made by an agent. Gaut uses examples like these to argue that creative things must be created by agents (B. Gaut 2018: 129–30; cf. B. Gaut 2010, and B. Gaut 2014b) and several other philosophers agree (Carruthers 2006, 2011; Kieran 2014a, 2014b; Stokes 2008, 2011, 2014; Paul & Stokes 2018).

Of course, many theists would maintain that everything in nature is the handiwork of an agent—namely, God—and so arguably it would make sense for them to regard a natural phenomenon as creative if it is valuable and new. For theists, the unparalleled beauty of nature is a reason to praise the Creator. But this only supports the conceptual point that creativity, by definition, requires agency. We may coherently regard valuable new things as creative if we attribute them to a creative agent, as the theist does with the natural world; otherwise, we can’t. So again, it seems, creativity requires agency.

This leaves open the question of exactly how a creator’s agency must be exercised in order for the result to count as creative. Some philosophers argue that the agent’s act of creation must be intentional. Suppose you are snowboarding on a powder day and, unbeknownst to you, the tracks from your board result in a pleasing new pattern as viewed from high above. The new pattern has aesthetic value, but it isn’t creative. And that is because you didn’t intend to make it. Underlying this intuition, as well as our intuitions about the natural phenomena above, is the fact that “creative” is a term of praise, and we do not extend praise (or blame) for things that are not done by an agent, or for things that an agent doesn’t do in some sense intentionally.

While a number of philosophers endorse some version of the agency requirement for creativity, many theorists make no mention of it, whether to endorse it or reject it, including all of the psychologists cited above. Further, at least two philosophers are willing to attribute creativity to natural phenomena like trees and evolutionary processes: Arnheim (2001) and, in recent work, Boden (2018). These latter theorists don’t discuss agency as such, but insofar as the natural phenomena they call creative are not the result of agency, their view would imply that agency isn’t required for creativity.

The four proposals we’ve just considered all say that a product must arise from a certain kind of process—a process that exhibits surprise, originality, spontaneity, or agency—in order to count as creative. While there is wide agreement among philosophers that creativity requires some special kind of process, not just a special product, there is no consensus on what is required of the process. Of the four process conditions described here, the agency condition seems to be the one that is explicitly endorsed by the greatest number of philosophers thus far, though even they are still just a handful. And as we’ve seen, the other proposed conditions have serious arguments in their favor as well.

Some philosophers argue that if any process requirement is correct, this has an intriguing corollary for judgements about creativity: Even when we are explicitly judging only that a product is creative, we are implicitly assuming something about the process by which it was made. Suppose, for illustration, that the agency requirement is correct—that being generated through an agential process is built into the very concept of a creative product. Suppose further that you are applying that concept competently. It follows that if you come across a captivating arrangement of stones on the beach and you judge it to be creative, you are at least implicitly assuming that it was created through an agential process. If someone later persuades you that the stones happened to be moved into place by the wind and waves, not by any agent but just by chance, then you may still regard the result as aesthetically interesting but you would have to rescind your judgement that it is creative. So if the agency condition is correct, whenever you point to some item and say, “This is creative”, what you are saying, in part is, “This resulted from a creative process”. Furthermore, on this view, analogous implications follow if any other process condition is correct (Paul & Stokes 2018).

2.3 Is creativity a virtue?
Having considered what is required for something to count as a creative product, and whether it must be produced by a certain kind of process, we now turn to analysis of the creative person.

Some theorists suggest that creativity, as an attribute of persons, is an ability to perform creative acts or produce creative things (Boden 2004). Others argue, however, that creativity isn’t merely an ability. An ability is something you can possess without ever putting it to use. You might have the ability to learn Swahili, for example, without ever making the effort to learn that language, despite having ample opportunities to do so. Creativity is different in this regard. If someone has the ability to be creative but never uses that ability when given numerous chances to do so, we would not call that person creative. Creative people are not merely able to act creatively. They are, moreover, disposed to exercise that ability, such that they do act creatively, at least some of the time, when the occasion arises. On this view creativity is a disposition, also referred to as a trait (Grant 2012; cf. B. Gaut 2014b, 2018).

Philosophers have long distinguished virtues as a special subclass of dispositions or traits. In Western philosophy, the tradition of theorizing about virtues goes back to the ancient Greeks, and over the last half-century it has enjoyed a renaissance in ethics (see entry on virtue ethics) and, more recently, in epistemology (see entry on virtue epistemology) and aesthetics (Lopes 2008; Roberts 2018; Hills 2018). Traditional examples of virtues include wisdom, justice, temperance, and courage. Should creativity be added to the list?

The answer depends, of course, on what it means for a trait to be a virtue. At the very least, a virtue is a trait that is good or valuable. So whether creativity counts as a virtue in this minimal sense depends on whether creativity is necessarily valuable, a point which is contested, as we saw in the previous section. In fact, those who contend that creativity isn’t necessarily valuable often do so in order to prove that it isn’t a virtue.

But let’s suppose for the sake of argument that creativity is indeed a valuable trait. Is it also a virtue in some more robust sense? Virtue theorists commonly take their cue from Aristotle’s classic discussion in the Nichomachean Ethics. Citing justice and temperance as paradigm virtues, Aristotle asserts that a trait must meet at least three conditions to count as a virtue:

For actions in accord with the virtues to be done temperately or justly it does not suffice that they themselves have the right qualities. Rather, the agent must also be in the right state when he does them. First, he must know [that he is doing virtuous actions]; second he must decide on them, and decide on them for themselves; and thrid, he must also do them from a firm and unchanging state. (EN II.4, 1105a28–1105a33)

So, for example, if you return something you’ve borrowed, that act exhibits the virtue of justice if and only if (1) you know that you’re returning what you borrowed, (2) you choose to do so because it is the just thing to do, and for no other reason, and (3) you are disposed to do the just thing across the range of circumstances when the opportunity arises. In addition to justice and temperance, Aristotle enumerates other ethical virtues like prudence, generosity, and courage, as well as the intellectual virtue of theoretical wisdom. In his view, each of these traits requires one to meet the three conditions above. While he does not consider whether creativity is a virtue, we may ask whether creativity also has these three criteria. Does one have to meet these three requirements in order to count as creative?

We’ll begin with the third requirement to set it to one side. Does a person’s act count as creative only “if he does it from a fixed and permanent disposition of character”? Examples suggest otherwise. Consider the poet Arthur Rimbaud, who abandoned poetry at the age of 21 to pursue a life of adventure. The fact that he never produced another poem after that does not count against the fact that he was a creative poet in his youth (B. Gaut 2014b). Unlike the Aristotelian virtues, then, creativity does not have to be a permanent disposition.

Even so, it would still be significant if creativity turned out to be like an Aristotelian virtue in meeting the first two requirements. And arguably, creativity does meet the first requirement. A person doesn’t count as doing something creative unless “he knows what he is doing”. This was already implied by the agency condition for creativity discussed earlier.

Where things get interesting is with Aristotle’s second criterion for virtue. In order for your action to count as virtuous, he says, you have to do it “for its own sake”—i.e., you have to do it because you value virtue as an end itself, and not as a means to some external reward like praise, money, status, fame, or winning a competition. Consider the virtue of generosity, for instance. If you give money to someone in need merely because it will make you look good in the eyes of your friends, then you aren’t really being generous. Your act may outwardly look like generosity, but it’s not the real thing. To exhibit real generosity, you have to pursue generosity as an end in itself; you have to help others just for the sake of helping others. Now contrast being generous with being polite. If you compliment your colleague on the good work she’s done, then even if you’re doing this in order to manipulate her, you are being polite to her. You can have an ulterior motive for being polite. So politeness is not a virtue the way generosity is.

Is creativity a virtue in this respect? That is, does being creative require acting creatively for its own sake? Matthew Kieran’s (2014a, 2014b, 2018) answer is a qualified yes. While he grants that you can be motivated by external rewards to exhibit “minimal creativity” in producing valuable new things, he maintains that “exemplary creativity” requires you to be motivated by the value of creativity itself. Thus, in his view, exemplary creativity is a virtue.

To support this claim, Kieran points to a research program in psychology which purports to show that creativity is driven by “intrinsic motivation” rather than “extrinsic motivation”. A classic experiment in this program is “the magic markers study”, in which kids end up producing less creative drawings when they are offered a prize (Lepper et al. 1973). Many other studies have reported similar results, which lead Teresa Amabile to conclude, at first without qualification, that creativity is enhances by intrinsic motivation and hampered by extrinsic motivation (Amabile 1983: 107).

Further research introduced complications. In some studies, subjects were given “immunization techniques” whereby they were first primed or trained to focus on intrinsically motivating factors like the pleasure or aesthetical value of engaging in artistic activities, and it was found that when they engaged in those activities afterward, external rewards actually enhanced their creativity.

As researchers interpreted these findings, offering reward can support one’s intrinsic motivation, provided that the reward works either to boost one’s sense of agency or to provide useful feedback about what’s working and what isn’t. Intrinsic motivation is still what fuels creativity, on this interpretation; rewards help only indirectly, when they reinforce intrinsic motivation. This lead Amabile to revise her hypothesis as the Intrinsic Motivation Principle (IMP):

Intrinsic motivation is conducive to creativity; controlling extrinsic motivation is detrimental to creativity, but informational or enabling extrinsic motivation can be conducive, particularly if initial levels of intrinsic motivation are high. (1996: 107)

Kieran takes this as evidence for his claim that creativity, or at least what he calls exemplary creativity, requires intrinsic motivation and is therefore a virtue in that respect.

Objecting to this proposal, Gaut cites evidence that extrinsic motivation is not always detrimental to creativity. In one study, students in an introductory psychology class came up with more creative short story titles if they were offered a financial reward (Eisenberger & Rhodes 2001). In the studies where immunization techniques were used, proponents of IMP argue that rewards enhance creativity only indirectly, by buttressing intrinsic motivation. But in this case no such techniques were used, and so it seems the prospect of a reward enhanced creativity directly.

Further, Gaut argues that this point coheres with the role that rewards seem to play in so many real-world cases of creative achievement. In their quest to discover the structure of the DNA molecule, Watson and Crick were driven “to imitate Linus Pauling and beat him at his own game” (Watson 1968 [1999: 46]). Picasso and Matisse were both spurred on by their rivalry with each other (Flam 2003: 37). Paul McCready says he was driven to invent his award-winning human-powered glider in 1977 because he needed the prize-money to pay off his debts:

I felt that I didn’t have the time to mess with such things, but I had this strong economic motivation to take an interest in man-powered flight, so I charged around trying to figure out a way to solve it. (quoted in Sternberg & Lubart 1995: 242)

One historian argues that in World War II the Poles beat the French in cracking the Germans’ Enigma Code because they were more terrified of German invasion (Singh 1999: ch. 4). Gaut quips: “Fear of death is a more powerful motivator than the intrinsic satisfactions of code breaking” (Gaut 2014b: 196).

Finally, Gaut points out that even if IMP is true, it is only a causal, probabilistic claim: intrinsic motivation is “conducive” to creativity; extrinsic motivation is “detrimental”. But for a trait to be a virtue, intrinsic motivation must be conceptually necessary for the exercise of that trait. If we learn that someone gave to charity just to enhance his reputation, we conclude that he wasn’t really being generous. By contrast, if we discover that someone created gorgeous artwork just for the fame and glory, we may then lose some of our admiration for her creativity, but we do not deny that she was being creative.

Kieran could remind us that, in his view, intrinsic motivation is not required for all creativity, but only for the special form of it that he calls exemplary creativity. Anticipating this reply, Gaut says that to distinguish between two forms of creativity is just to concede his point. There are not two forms of generosity, one that requires intrinsic motivation and another that does not. If your act of giving isn’t motivated by the right kind of reason, then it doesn’t count as an act of generosity at all. Thus, Gaut argues, to grant the possibility of non-exemplary creativity is to grant that, unlike generosity, creativity isn’t a virtue in the traditional Aristotelian sense.

Another way to examine relations between creativity and virtue is through the lens of virtue epistemology. Linda Zagzebksi defines a virtue

as a deep and enduring acquired excellence of a person, involving a characteristic motivation to produce a certain desired end and reliable success in bringing about that end. (1997: 137, italics added)

While there is a lot packed into this definition, what we’ll pinpoint here is the idea that virtue involves reliable success in achieving a desired end, and that the agent who is epistemically virtuous, in particular, is one who is reliably successful in achieving knowledge. Knowledge requires truth, of course, so an epistemic virtue is a trait that is “truth-conducive”. Epistemologists typically regard a process as truth-conducive to the extent that the beliefs it produces are more often true than false. But Zagzebksi proposes that a process or trait may be truth-conducive in a different sense, insofar as it is necessary for advancing knowledge in some area, even if it produces a very small proportion of true beliefs. Creativity, she claims, is truth-conducive in this sense, and thus it qualifies as an epistemic virtue (1997: 182). Also note the emphasis on agency. In contrast to contemporary western epistemology, virtue epistemology identifies the agent (rather than, say her beliefs) as the essential locus of epistemic valence; it is the agent who is epistemically good (or not). This emphasis comports well with the proposal, discussed above, that the creator’s agency is necessary for genuine creative achievement. A virtue-theoretic approach thus illuminates what may (as we will discuss again later) be essential to creativity, namely, a process that non-trivially involves a responsible agent.

We’ve seen that even after we fix a specific referent for the term “creative”—whether it be a person, process, or product—there are lively disagreements about what it means. These debates often seem to presuppose that the term always expresses the same concept, for which we can seek necessary and sufficient conditions. But we’ve also seen that some theorists distinguish between different concepts of creativity, corresponding to different senses of the term “creative”. In future work we may see theorists develop such pluralistic approaches in more detail. The trick, though, will be to give principled reasons for multiplying different concepts of creativity so that the analyses do not simply reduce to saying that anything goes.

3. Can Creativity be Learned?
There is a long tradition of thinkers who answer no to the question above. Two of the most influential are from the eighteenth century—Edward Young and Immanuel Kant—who were concerned specifically with genius, the capacity for achieving the very highest levels of creativity. In Conjectures on Original Composition (1759), Young says,

An Original may be said to be of a vegetable nature; it rises spontaneously from the vital root of genius; it grows, it is not made …. (1759 [1966: 7])

His idea is that originality emerges naturally from something implanted in us by nature, and it can only be hindered by learning. Young seems to think of learning as proceeding either through imitation or through the following of rules, and both, he thinks, are detrimental to originality. Regarding imitation he writes,

Born Originals, how comes it to pass that we die Copies? That meddling ape Imitation… destroys all mental individuality…. (1759 [1966: 20])

And insofar as learning is “a great lover of rules”, he warns that it “sets rigid bounds to that liberty, to which genius often owes its supreme glory” (1759 [1966: 13]).

Kant makes similar claims in his Critique of Judgment (1790). Like Young, he takes genius to be a natural capacity, though a very rare one:

such a skill cannot be communicated, but is apportioned to each immediately from the hand of nature and dies with him. (1790: §47 5:309 [2000: 188])

It certainly cannot be learned through imitation:

genius is entirely opposed to the spirit of imitation. Now since learning is nothing but imitation, even the greatest aptitude for learning, facility for learning (capacity) as such, still does not count as genius. (1790: §47 5:308 [2000: 187])

Nor can it be learned through rules, Kant holds, for genius is

the talent (natural gift) that gives the rule to art … the inborn predisposition of the mind (ingenium) through which nature gives the rule to art. (1790: §46 5:307 [2000: 186])

For Kant, a genius does not follow rules; a genius invents the rules, indirectly, by creating exemplary works from which other artists might extract rules and undertake “a methodical instruction in accordance with rules” (1790: §49 5:318 [2000: 196]).

Young and Kant are concerned with genius, specifically, but if we extend their reasoning to creativity in general, as Berys Gaut (2014a) has noted, we can discern two lines of argument:

The imitation argument

All learning is a form of imitation.
Imitating someone or something is incompatible with being creative.
So, one cannot learn to be creative.
The rules argument

All learning consists in the following of rules.
Following rules is incompatible with being creative.
So, one cannot learn to be creative. (2014a: 266)
Gaut points out, first of all, that both arguments are invalid. In both cases, what the premises would entail is that learning cannot be creative, that, in other words, you cannot learn creatively (a claim about how you can learn). But even if that were true, it wouldn’t follow that you cannot learn to be creative (a claim about what you can learn). If you absorb the advice of a creative writing manual then this act of learning may not itself be creative. But if the manual is effective—and we’ll see in a moment how it can be—then what you will learn is how to become more creative.

Gaut also challenges the premises of these arguments. To start with the first premise of the imitation argument, it simply isn’t true that all learning proceeds through imitation, as we learn many things through direct experience, trial and error, and many other means.

The second premise is also suspect. Something superficially close to it is true: mere copying is incompatible with being creative. But to the extent that we learn from others by imitating them, this is not merely a matter of copying them. When a child learns to speak the language of those around her, she doesn’t simply parrot the exact same sentences she hears; she absorbs the vocabulary and underlying grammar in a way that enables her to form new sentences of her own devising.

Now for the rules argument. Contrary to the first premise, it cannot be the case that all learning consists in following rules, Gaut argues, because for any given rule there will be hard cases where it is unclear whether or how the rule applies to them, and so an individual still has to use her own judgment in applying the rule.

The second premise is false too. Recall the distinction from §3 above between two kinds of rules. An algorithm serves as an exact plan, specifying both the outcome and the path for getting to it in exact detail. In contrast, a heuristic is a looser “rule of thumb” that leaves room for an agent to exercise her own judgment, choice, and creativity in determining whether, when, and how to follow the rule. While algorithms, in this sense, may preclude creativity, heuristics do not, which is why, as we’ll see below, the teaching of creativity so often takes the form of heuristics.

There is a sense in which the question at hand can be answered empirically: We can show that creativity can be taught simply by pointing to cases where it has been taught. Gaut himself discusses such examples as they occur in mathematics and fiction writing, which we’ll turn to below. But while such cases may suffice to show that creativity can be taught, Gaut further enriches our understanding by explaining how this is possible. He does so partly by articulating and then debunking the imitation and rules arguments to the contrary. But in addition, he offers the following positive argument to show that creativity can be taught and learned. He calls it “the constitutive argument” because it begins with his view of what constitutes or defines creativity itself.

The constitutive argument

Creativity is a disposition—involving both the ability and the motivation—to produce things that are new and valuable, and to do so in ways that express one’s agency through “the exercise of choice, evaluation, understanding, and judgment” (Gaut 2014a: 273).
At least some people can learn to enhance their creative motivation.
At least some people can learn to enhance their creative abilities.
So, at least some people can learn to become more creative.
Premise 1 recapitulates the point we’ve already seen Gaut and others defend (in §2.3 above), that creativity is not merely an ability but a disposition or trait, whereby the creative person is disposed or motivated to exercise that ability when given the opportunity.

In support of premise 2, Gaut argues that you can strengthen both your intrinsic motivation to be creative (when you take pleasure in your creative activities), as well as your extrinsic motivation to be creative (when you are rewarded with praise, grades, pay, etc. for your creative efforts).

Defending premise 3, Gaut points out that you can develop your ability to produce valuable new things by practising and strengthening the relevant skills. And this development can be substantially aided by learning certain heuristics.

Heuristics are indeed a staple of education in creative pursuits from mathematics (draw the figure; consider special cases; consider extreme cases; generalize the problem; look for a related problem, etc.—see Pólya 1945; Schoenfeld 1982, 1987a, 1987b) to creative writing (write what you know; be specific and detailed in describing sensory experiences; practice seeing similarities between dissimilar things; show, don’t tell, etc.—see Bell & Magrs 2001; Anderson 2006; Maybury 1967; S. Kaufman & J. Kaufman 2009). Gaut also identifies several heuristics that might be used to foster creativity in philosophy, even among children (cf. M. Gaut 2010; B. Gaut & M. Gaut 2011).

With this last theme, Gaut has a kindred spirit in Alan Hájek (2014, 2016, 2017, 2018), who has independently proposed that by using various heuristics, philosophers can enhance their abilities to make valuable contributions to their field, including ideas that are distinctively creative. It has been said that anyone of average talent can become a strong chess player by learning and internalizing certain chess heuristics: “castle early”, “avoid isolated pawns”, etc. Analogously, Hájek suggests, philosophy has a wealth of heuristics—philosophical heuristics—although they have not been as well documented and studied. Sometimes these take the form of useful heuristics for generating counterexamples, such as “check extreme cases”. Sometimes they suggest ways of generating new arguments out of old ones, as in “arguments involving possibility can often be recast as arguments involving time, or space”. Sometimes they provide templates for positive arguments (e.g., ways of showing that something is possible). Hájek offers a catalogue of such philosophical heuristics to show that, contrary to a common assumption, creativity, even in philosophy, can be compatible with, and enhanced by, following rules.

4. Can Creativity be Explained?
Upon observing the work of creative people, it is natural to wonder: How do they do that? How do people create? The issue we turn to now is whether we could, at least in principle, answer this question scientifically, using the methods of modern empirical psychology and other cognitive and behavioral sciences. Those who take a negative stance on this matter are not merely saying that, in practice, it would be exceedingly difficult for science to explain creativity. They are saying that it’s altogether impossible that science could ever explain creativity.

Hospers (1985) defends this kind of pessimism based on the variety and complexity of creativity, given that creativity occurs not only in art, but in science, theorizing of any sort, engineering, business, medicine, sport, gaming, and so on. At least two worries may follow. First, given the complexity of any one of these individual domains, one might worry that there are simply too many variables to allow for a clear explanation. Art provides a paradigmatic example. Consider an artwork that you judge to be masterful (a sculpture, a painting, a film). Now imagine attempting to describe or identify all the reasons for which you think it is masterful. Take as much time as you like but, the skeptic will urge, any long description you construct will invariably strike you as woefully incomplete by comparison to the artwork, and the experience thereof. So, if the creative achievements of artists, in all of their complexity, cannot even be adequately described, we have little reason to think that such achievements can be explained.

How can theorists respond to these skeptical worries? Both the complexity and generalizability worries might be partially disarmed by noting analogies between creativity and other phenomena. For instance, consider the range of bodily movement involved in some of the very domains of activities listed above: art, science, engineering, medicine, sport. The kinds of bodily action specific to these domains are complex and vary dramatically: the relevant physical movements of the surgeon are much different from the tennis player. However, it is not plausible that this complexity and variety precludes explanation of bodily action in those domains. It simply implies that some features of the explanation will be context-sensitive, that is, specific to that domain of activity. And further to the analogy: the fact that the long description of, say, the tennis serve is incomplete does not preclude it from being apt and explanatory. If this line of reasoning is sound for bodily action, why not also for creative action?

At this point, one might argue that while complexity and generalizability worries would only show that creativity is difficult to explain in practice, the very nature of creativity implies, more strongly, that it could never be explained, not even in principle. Resources to support this kind of pessimism may be adduced from various past philosophers. We need to tread carefully, however, since most of the figures we are about to consider were writing long before the rise of the relevant sciences, so they could not have made any explicit claim either way as to whether creativity could be explained by those sciences. Nevertheless, some of them did make claims which entail, or seem to entail, that creativity simply isn’t the kind of thing that could be explained through scientific inquiry as we understand it today.

The classic expression of such a view comes from Plato. In his dialogues, Plato features his teacher Socrates as a spokesperson for his own views, and in the Ion he has Socrates argue that poets do not produce poetry through knowledge or skill. When you exercise a skill (technē), you apply techniques, rules, or methods to perform a given activity, like charioteering, fishing, or commanding an army. In principle, one could explain these activities by identifying the techniques they involve, and a student or apprentice could learn these activities by applying and practicing those techniques. But poetry is not like that, in Socrates’ view. A poet can only imitate the application of rules or techniques, mimicking the surface appearance of skill. Voicing an idea that was familiar in Ancient Greek culture, Socrates suggests that poetry emerges instead through divine inspiration, whereby a human being is inspired—literally “filled with a spirit”, with a god or goddess, with a muse:

You know, none of the epic [or lyric] poets, if they’re good, are masters of their subject; they are inspired, possessed, and that is how they utter all those beautiful poems. … [They] are not in their right minds when they make those beautiful lyrics, but as soon as they sail into harmony and rhythm they are possessed by Bacchic frenzy. […] For a poet is an airy thing, winged and holy, and he is not able to make poetry until he becomes inspired and goes out of his mind and his intellect is no longer in him. As long as a human being has his intellect in his possession he will always lack the power to make poetry or sing prophecy. […] You see, it’s not mastery [technē] that enables them to speak those verses, but a divine power. That’s why the god takes their intellect away from them when he uses them as his servants, as he does prophets and godly diviners, so that we who hear should know that they are not the ones who speak those verses that are of such high value, for their intellect is not in them: the god himself is the one who speaks, and he gives voice through them to us. In this more than anything, then, I think, the god is showing us, so that we should be in no doubt about it, that these beautiful poems are not human, not even from human beings, but are divine and from gods; that poets are nothing but representatives of the gods, possessed by whoever possesses them. (Ion 534a-d)

Socrates repeats this view in the Phaedrus: “Some of the greatest blessings come by way of madness, indeed madness that is heaven-sent” (244a). He adds that while a poet may have some kind of skill, anyone who aspires to make poetry purely by skill, without the madness or the muse, will fail (245a).

It’s important to note that “madness”, for Plato, is a supernatural affair. From the vantage of contemporary behavioral science, we think of madness—or rather, mental illness—as a pathology arising from some combination of genetic and environmental factors, and those factors can be studied scientifically. So even if creativity is linked to mental illness—a highly controversial proposition—it could still be entirely within the scope of science. However, Plato’s talk of “madness” does not refer to any naturally occurring pathology, but rather to the result of divine intervention: the poet is taken over or “possessed” by the muse and that is precisely why he is “out of his mind”. Plato’s poet suffers divine madness.

According to this story, then, the person we call a poet isn’t really a creator of poetry, but is merely the vessel through which a divine being delivers poetry. If it is literally true that the source of poetry is supernatural, then poetic creativity could never be explained by science, which is limited to the investigation of natural causes. (For more on Plato, see Asmis 1992.)

This kind of supernaturalism has enjoyed a long afterlife in Western thought. In ancient Rome, the Latin term “genius” referred to a guiding spirit that was thought to accompany each person throughout their lives. The genius of an artist would occasionally deliver art through that person in the manner of Platonic inspiration.

Conceptions of the artist take a new turn when the idea of genius is transformed in the eighteenth century. As we saw above, Immanuel Kant defines genius as a natural capacity that a certain kind of artist possesses innately and which partly constitutes that artist’s identity. So rather than saying that a gifted artist “has a genius”, Kant says that such a person “is a genius”. What distinguishes the genius is fundamentally an imaginative capacity—an ability to engage in a “free play” of imagination to produce artworks of “exemplary originality”. These works are exemplary not only in the sense that they have artistic or aesthetic value, unlike “original nonsense”; they are also exemplary in the more radical sense of providing an exemplar—a new paradigm and precedent—for lesser artists to follow. A work of genius sets a new standard of artistic value, and, looking to that exemplar, lesser artists may then extract techniques or rules for their own craft. The genius therefore “gives the rule to art”. In creating such works, the genius does not follow any rules or methods. Instead the genius creates art through a “free play of imagination”—where the terms “free” and “play” characterize the nature of an activity unconstrained by any pre-established methods or rules:

[G]enius … is a talent for producing that for which no determinate rule can be given, not a predisposition of skill for that which can be learned in accordance with some rule …. (1790: §46 5:307–8; 2000 trans., 186)

Kant thought that genius, so conceived, is limited to the fine arts, poetry being chief among them. Meanwhile, in Kant’s view, there is no room for genius in science, for example, where good theories and hypotheses must emerge from the careful application of scientific method, and so he said that even Isaac Newton, “that great man of science”, was not a genius. We’ll soon consider why this view might seem to entail that creativity is inexplicable, but first it will be helpful to bring another figure, Arthur Schopenhauer, who was deeply influenced both by Kant and by Plato.

Like Kant, Schopenhauer thought of genius as a natural capacity that is limited to the fine arts. He also echoes Plato’s sentiments about madness, famously stating that “genius and madness have a side where they touch and even pass over into each other” (The World as Will and Representation, 1859, WWV I: 190), and that “Genius lives only one storey above madness” (Parerga and Paralipomena, SW 2:53, PP 2:49). In a state of madness, Schopenhauer’s genius is like Plato’s poet in experiencing a momentary loss of self, but what displaces the self is not any divine being but rather a pure Idea which seizes the author’s being and becomes the object of both his fascination and his artistic expression:

We lose ourselves entirely in this object, to use a pregnant expression; in other words, we forget our individuality, our will, and continue to exist only as pure subject, as clear mirror of the object, so that it is as though the object alone existed without anyone to perceive it, and thus we are no longer able to separate the perceiver from the perception, but the two have become one, since the entire consciousness is filled and occupied by a single image of perception. (World WWV I: 178–179, §34).

With their focus on genius construed as a natural capacity, figures like Kant and Schopenhauer abandon the supernaturalism of the Platonic muse. Nevertheless, they retain the idea that creativity—specifically genius-level creativity in the fine arts—is not a matter of exercising a skill or applying given rules, methods, or techniques.

As we noted earlier, these figures did not and could not have explicitly denied that creativity could be explained by the sciences of the twentieth and twenty-first centuries, but they are commonly taken to represent such a denial (Kronfeldner 2018). Why?

Perhaps figures like Kant and Schopenhauer seem to make creativity, or at least creative genius, inexplicable insofar they suppose it to be innate and as they have no story to tell about how one came to acquire an innate capacity except to say that it was either an accident of chance (which is no explanation at all) or a gift from God (which again is not a scientific explanation). But while these figures seemed to think of artistic genius as being endowed entirely by nature with no contribution from nurture, modern genetic theory rejects that dichotomy. Instead of positing all-or-nothing natural abilities, behavioral scientists today think in terms of genetically inherited predispositions. In order for a genetic predisposition to develop into a trait with an observable phenotype, it needs to be triggered and shaped through a complex interaction between an organism’s genes and certain kinds of stimuli or environmental conditions. There are still open questions about exactly how, and how much, genes and environment feed into the development of any given trait, but it’s misguided to pose the binary nature-versus-nurture question as if the two were mutually exclusive (see Tabery 2014). Many researchers agree that some people have a stronger natural predisposition toward creativity than others, and that genius-level creativity partly stems from such a predisposition. Even so, the predisposition itself can be understood scientifically in terms of genetic heritability. (For a sampling of the relevant studies, see the essays collected in S.B. Kaufman 2013.)

Perhaps creativity seems inexplicable according to these accounts because it doesn’t follow rules or methods. In order to explain how to do something—how to build a boat or lead an army etc.—perhaps I need to be able to identify the rules or methods you should follow in order to practice and apply those skills. How-to explanations are instructions. But scientific explanations needn’t be instructions. A lot of good science explains how something happens—e.g., how heat melts ice or how a bat navigates its environment by echolocation—without explaining how to do it yourself.

Perhaps creativity seems inexplicable according to these accounts because creators themselves do not know how they create. But a scientific explanation needn’t be available through introspection. Most people cannot explain how their own digestive, circulatory, or perceptual systems work, but scientists who study those systems can.

Another line of thought is perhaps implicit in Kant but comes to the fore in Schopenhauer, who says that “the nature of genius consists precisely in the preeminent ability” to

consider things independently of the principle of sufficient reason, in contrast to the way of considering which proceeds in exact accordance with this principle, and is the way of science and experience. (World WWV: I: 192, §36)

The principle of sufficient reason says that for every fact there is a cause which completely explains that fact. So the defining ability of genius is to see things in a way that transcends the causal order and defies all explanation.

A version of this view is defended more recently by Carl Hausman (1975 [1984], 1979, 1985) who frames it in terms of novelty that creativity involves. Hausman asserts that if a product is creative, it must be metaphysically novel (or in his terms, “genuinely novel”) in the sense that it cannot be predicted from, or explained by, prior events—not even in principle. Creativity is therefore incompatible with causal determination and causal explanation: “A causal view of explanation sets a framework for ways of denying that there is anything new under the sun” (Hausman 1984: ix). If something can be explained by prior causes, it is not metaphysically novel, and is therefore, in Hausman’s view, not truly creative.

Against Hausman’s skeptical charge, Maria Kronfeldner (2009) argues that creativity is compatible with causal determination. First, causal determinism does not preclude novelty or change. Determinism says the emergence of new kinds of things can at least in principle be predicted in advance. Importantly, though, when this prediction becomes true, then something new is added to the world. Of course, not all novelty instantiates creativity. The question is whether the kind of novelty involved in creativity must be metaphysical novelty, which is by definition incompatible with causal determination. This is doubtful. Notice that, by definition, metaphysical novelty defies natural laws. The production of something metaphysically novel would therefore require supernatural powers. Traditional Western religions conceive of God as performing the miracle of creation ex nihilo. But are we positing a miracle every time we describe a human artifact or achievement as creative? Surely not. As noted above, human creativity is manifest in things that are novel relative to the agent producing them or new to human history, but both of those kinds of novelty (psychological and historical) are perfectly compatible with causal determination. As Kronfeldner explains, creativity does not preclude causes in general; it only precludes certain kinds of causes. A creative product, she argues, must be original—which means that it cannot be produced through a process of copying something prior. And it must be spontaneous (not produced through a routine or mechanical procedure)—which means that it is to some extent independent of the agent’s intentional control and previously acquired knowledge. (For more on originality and spontaneity, recall §2.2 above). Intuitively, the causes of something creative cannot simply be a matter of copying or following a routine. But it may have causes nonetheless, and cognitive science can investigate those causes, at least in principle. Indeed, as we’ll see next, it is doing so in practice.

5. The Cognitive Science of Creativity
Although creativity has been relatively understudied by contemporary philosophers, as we noted in §1, it has been receiving a great deal of attention from psychologists over the past few decades. In 1950, J. P. Guilford gave a presidential address at the American Psychological Association calling for research on the topic, and the field soon took off with waves of research investigating the traits and dispositions of creative personalities; the cognitive and neurological mechanisms at play in creative thought; the motivational determinants of creative achievement; the range of institutional, educational, and environmental factors that enhance or inhibit creativity; and more. Today, the blossoming of this field can be seen in the flurry of popular writing on its results; an official division of the American Psychological Association for the psychology of aesthetics, creativity, and the arts (Division 10); numerous academic conferences; dedicated peer-reviewed journals (Psychology of Aesthetics, Creativity and the Arts; Creativity Research Journal; Journal of Creative Behavior; International Journal of Creativity and Problem Solving); special issues of journals (Current Opinion in Behavioral Sciences, Takeuchi & Jung 2019); literature surveys (Hennessey & Amabile 2010; Runco & Albert 2010; Runco 2017; Glaveanu 2014; Williams et al. 2016); textbooks (J.C. Kaufman 2009; Sawyer 2012; R. W. Weisberg 1986, 2006); and a comprehensive encyclopedia (Runco & Pritzker 2020). According to one overview, creativity has been studied by nearly all of the most eminent psychologists of the twentieth century, and “the field can only be described as explosive” (Albert & Runco 1999: 17). There is also a groundswell of new work on creativity in the fields of computer science, artificial intelligence (AI), and robotics.

The present section surveys empirical work in psychology along with some related work in neuroscience, while the next section (§6) covers research in computing, AI, and robotics. Throughout, we’ll see that philosophers are actively in dialogue with these fields under the broad, interdisciplinary umbrella of cognitive science.

The vast body of empirical research of creativity can be seen as addressing a variety of issues, but the central question that concerns us here is the one we identified above as the challenge for explaining creativity: How are people creative? This question is analogous to a number of other questions in cognitive science: How do people perceive through sense modalities such as vision? How do they form concepts? How do they acquire a language? How do they make inferences? Just as psychologists investigate the psychological and neurological processes, systems, and mechanisms at work in these other mental operations, as well as the internal and external factors that either enhance or hinder these operations, they are doing the same for creativity. There is no pretension to achieving a complete explanation which would include each and every causal factor, and provide the basis for perfectly predicting creative outcomes in advance. But to the extent that we identify some of the relevant causal factors involved in creativity we thereby make progress in explaining creativity, just as we do with other features of the mind.

As we noted in §2, the standard definition of creativity in psychology says that a product (idea or artefact) is creative to the extent that it is both new and valuable (“effective”, “useful” or “appropriate”), and, in turn, people and processes are creative to the extent that they produce new and valuable things. As we also noted, many psychologists do not actually employ this, or any, definition of creativity in conducting their research. In one sampling of studies of creativity published in peer-reviewed psychology journals, only 38% of them included an explicit definition of creativity (Plucker, Beghetto, & Dow 2004), as they rely in one way or another on the assumption that we know it when we see it. For example, many studies use the Consensual Assessment Technique (CAT), whereby experimental subjects produce things that are then rated for how creative they are by a panel of experts in the relevant field; so paintings are rated by professional painters, stories by published authors, etc. Many other research methodologies are used, as we’ll see below.

Empirical research on creativity departs in several ways from the traditional approaches that seemed to place creativity outside the scope of science. For starters, in stark contrast to Plato’s supernaturalism, empirical psychologists take creativity to be a completely natural phenomenon. Creative people may of course be “inspired” in the sense of feeling energized or filled with ideas, but rather than being literally “breathed into” by some god or muse, their thoughts and behaviors are presumed to have causes that are perfectly natural. While it is difficult in practice to identify these causes, they are not in principle beyond the reach of science.

Further, the range of phenomena that contemporary researchers countenance within the ambit of creativity is far broader and more diverse than the traditional focus on poetry and the fine arts, as creativity can be manifest in any kind of art or craft, as well as in the sciences, technology, entrepreneurship, cooking, humor, or indeed in any domain where people come up with ideas or things that are novel and valuable in some way or another. Departing from Kant, genius, the highest echelon of creativity, may be acknowledged in virtually any of these domains, not just in the fine arts. And while a few researchers (e.g., Simonton 1984, 1994, 1997, 2009; Root-Bernstein & Root-Bernstein 1999) venture to examine genius (so-called “Big-C” creativity), most of them focus instead on relatively ordinary creative feats (“little-c” creativity) including the kinds of story-making, drawing, and problem-solving that can be elicited on command from regular people in experimental settings. Some researchers propose that in order to understand how the mind generates new ideas, we should begin with even more rudimentary phenomena. For example, philosopher Jesse Prinz and psychologist Lawrence Barsalou focus on how we form new concepts to categorize the things we perceive, a process which they claim is creative, albeit in a “mundane” rather than “exceptional” way (Prinz & Barsalou 2002; Barsalou & Prinz 1997; cf. Child 2018).

Of course, many feats of human creativity, and the ones that are most interesting, go far beyond the basic formation of concepts. A major step toward explaining those feats is to recognize that what we call “the creative process”, as if it were a single, homogenous phenomenon, is in fact an assembly of multiple stages or operations. The simplest recognition of this fact is the Geneplore model which distinguishes just two stages: generating ideas and exploring ideas (Finke 1996; Smith, Ward, & Finke 1995). This distinction may be seen as echoing one made by philosophers of science in the early twentieth century, between the context of discovery and the context of justification (Popper 1934). Other theorists posit up to eight stages of creativity (for a summary of proposals, see Sawyer 2012: 89). But the most influential stage-theory traces back to Henri Poincaré’s lecture, “Mathematical Creation” (1908 [1913: 383–394]), in which he identifies four phases in his own innovative work as a mathematician:

conscious hard work or preparation,
unconscious incubation,
illumination, and
verification.
In his book, The Art of Thought (1926), the psychologist Graham Wallas endorses Poincaré’s four stages with corroborating evidence from the personal reports of other eminent scientists like Hermann von Helmholtz. Wallas’s scheme, as a development of Poincaré’s, is still the one that is most widely cited, and we employ a version of it here with some slightly different terminology and with two more substantive alterations: instead of “incubation”, we identify the second operation more generally as the “generation” of ideas, which may include unconscious incubation but may also occur in conscious, deliberate thought; and we add “externalization” for a total of five operations:

Preparation—You invest a great deal of effort learning and practicing in order to acquire the knowledge, skills, and expertise required for work in a given domain.
Generation—You produce new ideas, whether through conscious reflection or unconscious incubation.
Insight—You consciously experience the emergence of a new idea, which would strike you with a feeling of surprise: “Aha!”, “Eureka!”
Evaluation – You assess the idea to determine whether it should be discarded, retained, revised, or amended.
Externalization—You express your idea in a concrete, observable form.
Artists provide compelling examples (though not the only ones) of each of these five operations. Such examples can be especially illustrative since they come straight from the artists’ mouths, as they reflect upon, and share, their creative process. The twentieth century painter Jacob Lawrence was known for painting in the style of visual narratives. Lawrence developed a system, much like a filmmaker’s storyboard, for the preparation of these paintings. He would lay as many as 60 wood panels on the studio floor, each with individual scenes and sometimes with captions. From these storyboards, Lawrence would generate and evaluate ideas and insights for a visual narrative, culminating in the paintings such as those in his Migration Series (see Whitney Museum, 2002, in Other Internet Resources). Toni Morrison, the Nobel prize winning novelist, remarks on the labors and sustained effort required at the preparation, generation, evaluation, and externalization stages of a creative writing process. Commenting on her novel Jazz, she says,

I thought of myself as like the jazz musician—someone who practices and practices and practices in order to be able to invent and to make his art look effortless and graceful. I was always conscious of the constructed aspect of the writing process, and that art appears natural and elegant only as a result of constant practice and awareness of its formal structures.

She further notes that insight does not always come in a flash,

[I]t’s a sustained thing I have to play with. I always start out with an idea, even a boring idea, that becomes a question I don’t have any answers to. (T. Morrison 1993)

Writer Ishmael Reed claims that insight can come unexpectedly and in various contexts:

One can find inspiration from many sources. The idea of Japanese by Spring originated in a news item that claimed the endowment to a major university was traced to Japanese mob, the Yakuza. Flight to Canada began as a poem. The Terrible series began when I heard someone at party mention that there was a black figure, Black Peter, in the Dutch Christmas, and by coincidence I was invited to the Netherlands shortly afterwards, where I witnessed the arrival of Saint Nicholas and Peter on a barge that floated into Amsterdam with crowds looking on. I took photos of the ceremony …. (Howell 2020: 91)

And with signature profundity, James Baldwin suggested that all elements of the creative artistic process, from preparation to externalization, require a basic enabling condition: being (and willing to be) alone (Baldwin 1962).

As Wallas recognized (1926: 81), and as the above examples suggest, the “stages” of the creative process are not necessarily discrete steps that follow one another in a tidy sequence. Creative work is messy: over time you have numerous ideas, keeping some and abandoning others in multiple rounds of trial-and-error; you incubate new ideas for one problem while you’re busy externalizing your ideas for another; and your moments of insight, evaluation, and externalization trigger further generative processes that send you cycling through these operations many times over. It’s still important to distinguish these operations, however, because, as researchers are confirming, they are enabled and influenced by different causal factors.

Among the additional stages that researchers have posited, one of the most widely discussed is known as problem-finding. Psychologists often conceptualize creative thought in terms of problem-solving: the ideas generated within the creative process are seen as candidate solutions to a given problem—where “problems” are broadly construed to include any creative aim, like that of producing a particular kind of artwork or proving a particular theorem, etc. (Flavell & Draguns 1957: 201; Newell, Shaw, & Simon 1962). But following some early work by Mihalyi Csikszentmihalyi (1965), many researchers came to appreciate that a lot of creative work is done not just in solving problems but in finding the right problem to begin with (Abdulla et al. 2020; Csikszentmihalyi & Getzels 1970; Getzels 1965; Getzels & Csikszentmihalyi 1975). While we agree that problem-finding often plays a key role in creativity, we have not assigned it to a separate stage, for the following reasons. Consider that you might settle on a problem to work on in either of two ways. On one hand, you might choose a problem to work on from a pre-existing menu of options. In that case, your choice would fall under the evaluation phase; it’s just that the idea you select is a problem that calls for the pursuit of further ideas. If, on the other hand, you develop a new problem, you would thereby be engaging in the generation of a new idea—the new problem—which may emerge in a moment of insight. Einstein and his colleague celebrated the novelty in such problem-finding:

The formulation of a problem is often more essential than its solution, which may be merely a matter of mathematical or experimental skill. To raise new questions, new possibilities, to regard old problems from a new angle, requires creative imagination and marks real advance in science. (Einstein & Infeld 1938: 92)

Either way—whether you “find” a problem by picking a pre-existing one or by coming up with a new one yourself—problem-finding, though important, does not need to be seen as an additional operation beyond the five listed above; it’s just a special case of generation, insight, or evaluation.

The next five sub-sections will respectively examine the five operations of creative work. Notice that three of them—preparation, evaluation, and externalization—are uncontroversially ordinary activities that involve no apparent mystery; it’s a challenge to explain them but no one is tempted to regard them as inexplicable or as violating the laws of nature. As we saw in §4, traditional skepticism about the possibility of explaining creativity is really focused on the two remaining phenomena: the generation of new ideas (§5.2) and the experience of insight whereby an idea seems to come out of the blue, as if from a god (§5.3).

5.1 Preparation
It’s myth that outsiders are more creative. To put yourself in a position to create anything of value, you have to spend a great deal of time and effort acquiring the relevant knowledge, skills, and expertise. In what has come to be called “the ten-year rule”, Howard Gardner (1993) found that, on average, people spend about 10 years learning and being immersed in a domain before they make any significant creative contribution to it.

Though a certain amount of rote learning is required, gaining mastery in a field is not simply a matter of passively absorbing information. Much of it involves what Anders Ericsson calls deliberate practice, where you focus on tasks which are a little beyond your current abilities, but which you eventually conquer through feedback and repetition. Across a variety of domains—including physics, medicine, programming, dance, and music—Ericsson found that, on average, world-class performance becomes possible for people only after 10,000 hours of deliberate practice in their chosen activity. This finding also converges on the ten-year rule, because if you engage in deliberate practice four hours a day, five days a week, that would add up to 10,000 hours in ten years (Ericsson, Krampe, & Tesch-Römer 1993; Ericsson et al. 2006).

However, there seems to be a point at which too much formal training can dampen creativity. Simonton (1984: 70–73) has reported that the relationship between creativity and education level is an inverted-U, as too much schooling can reinforce familiar, pre-established styles of thought. Even so, the point remains that, before you run into diminishing returns, years of preparatory learning and practice are required for exceptional creativity.

5.2 Generation
In this section we discuss four kinds of mental capacities or processes that researchers have posited for generating new ideas.

5.2.1 Blind Variation
Psychologist Donald T. Campbell (1960, 1965) proposed that creative thought proceeds through “blind variation and selective retention (BVSR)”. The “variations” he refers to are the various ideas that might occur to a creator, and the process of generating them is “blind” to the extent that it is not guided or directed by prior knowledge of how valuable or useful they will be: “Real gains must have been the products of explorations going beyond the limits of foresight or prescience, and in this sense blind” (Campbell 1960: 92, emphasis added). Once ideas have been generated, however, there is a subsequent stage where the creator selectively retains some of those ideas while discarding others, and Campbell says this stage is “sighted” rather than blind since it is guided by the creator’s judgments as to which ideas are valuable. While there is little debate that selective retention is sighted in this sense, there has been more controversy over whether the initial production of ideas is, by contrast, blind.

In his prolific body of work, Dean Keith Simonton has extended and refined Campbell’s proposal. His work nicely illustrates the interdisciplinary nature of creativity research as he, like Campbell, is a psychologist who engages with philosophers, some of whom are broadly sympathetic to the BVSR theory (Briskman, 2009; Nickles, 2003), while others are skeptical (Kronfeldner 2010, 2011, 2018). In earlier writings Simonton suggested, in a way Campbell did not, that BVSR is to be understood on the model of Darwinian evolution (Simonton 1999a, 1999b). But Simonton (forthcoming: 2–3) has come to rescind the Darwinian framing of BVSR, conceding that it is misleading. Reprising Campbell’s core idea, he says that a process of generating an idea is blind to the extent that it is not guided by “the creator’s prior knowledge of the variation’s utility” (Simonton forthcoming: 5; cf. Simonton 2011, 2012a, 2012b, 2018). He stresses that blindness is not all-or-nothing; it comes in degrees. An example of a highly sighted process is that of using the quadratic formula to find the roots of a quadratic equation: you know in advance that if you apply the formula correctly, it will yield the correct answer. Examples of relatively blind processes include remote association and mind wandering.

5.2.2 The Default-Mode Network
Despite the foregoing criticism of BVSR, recent neuroscientific studies suggest a network of brain activity that may serve the blind variation role. Brain activity doesn’t cease when one is not focusing on a task, when one is at rest, daydreaming, and so on. Following this insight, researchers have used neuroimaging methods to identify what is now called the default mode network (DMN). The precise anatomy of this network is still a matter of investigation, but it is supposed to be less active when one is focused on an external task (say a problem in the real world or in the lab) and more active when one is not so focused (Raichle et al. 2001; Buckner & DiNicola 2019). Notice then, that while this network is not creativity-specific—it is supposed to be active during memory recall, imagining future events, daydreaming, and so on—it does seem especially well-suited for creativity, and particularly for the random idea generation hypothesized by the BVSR (Jung et al. 2013). Creativity researchers in these fields often refer to this more “free” production of ideas as “divergent thinking”, and some argue on the basis of neuroimaging studies that creative thought requires cooperation between this mode of thought as well as that under “executive control”. As one team puts the point,

In general, we contend that the default network influences the generation of candidate ideas, but that the control network can constrain and direct this process to meet task-specific goals via top-down monitoring and executive control.. (Beaty, Benedek, et al. 2016; see also Mayseless, Eran, & Shamay-Tsoory 2015; Beaty, Seli, & Schacter 2019; Chrysikou 2019)

Notice how well this comports with both the Geneplore and the BVSR frameworks, perhaps identifying a way to keep some of the insights of both without commitment to a special creativity mechanism after all.

5.2.3 Imagination
At least since Kant, theorists have identified an important link between creativity and imagination; indeed, the two are sometimes unfortunately conflated. Construed broadly, imagination can take various forms: sensory imagery, propositional imagination, supposition, free association. Berys Gaut (2003, 2009, 2010) and Stokes (2014, 2016) have both recently argued that, although imagination and creativity are distinct, imagination is especially well-suited to creative thought because of its characteristic flexibility. They both agree that imagination is decoupled from action (Gaut 2003) and “non-truthbound” (Stokes 2014) in the sense that, unlike belief, imagination is not limited by the proper function of accurately representing (some part of) the world. This freedom or playfulness of imagination is crucial to generating new ideas, since it allows one to safely “try out” hypotheses, conceptual combinations, strategies for solutions, and so on, without epistemic or behavioral commitment.

A series of studies illustrates both the need for non-truthbound capacities in creative thought, as well as the difficulty of employing them. When people—children and adults alike—are asked to imagine and draw non-existent houses, people, or animals, they depict things that are strikingly similar to their familiar counterparts in the real world: imagined people, for example, were generally drawn with some version of a head, limbs, eyes, and so forth. (Karmiloff-Smith 1990, 1992: 155–61; Cacciari et. al 1997; Ward 1994, 1995). This suggests that we are highly constrained in our creativity by the concepts we already have. Concepts of existing things are truth-bound: your concept of an animal, for example, has the proper function of accurately representing the range of things that are in fact animals. When you try to envision a new, fictional kind of animal, you begin with a mental image that exemplifies your existing concept of animal, which is why you are constrained by that concept. You then have to manipulate your initial image, varying its features in ways that abandon the aim of accuracy, using a capacity that isn’t truthbound. Generalizing this point yields the cognitive manipulation thesis, according to which creative thought requires cognitive manipulation, which involves thinking in ways that are not bound to the truth (Stokes 2014: 167). Plausibly, imagination is the mental capacity which is best suited to serve in this cognitive manipulation role. In the studies just cited, subjects must use their imagination to manipulate their existing concepts so as to form new ideas.

Recent empirical research on visual imagery seems to corroborate this claim. Various studies have identified positive correlations between creative problem solving and visual image generation, image transformation, and vividness of imagery (Finke 1990, 1996; Zemore 1995; R. Morrison & Wallace 2001; Pérez-Fabello and Campos 2007). A more recent study highlights the importance of image transformation ability—the ability to mentally manipulate a given image—and the ability to achieve high degrees of visual creativity. Further, the results of this study suggest that although vividness negatively correlates with the practicality of images created, vividness positively correlates with novel idea generation (Palmiero et al. 2015). The novelty involved is minimal, but again it appears that imagination, here in the form of imagery, well serves the role of cognitive manipulation.

Stokes observes further that we can voluntarily control imaginative states (in contrast with other non-truthbound states, like desires and wishes). And because imagination connects in important ways with inferential systems, as well as affective systems, the thoughts it produces can often be integrated with knowledge and skills to formulate an innovative strategy or solution to a problem. Finally, this role for imagination in creativity is not exclusive to the rich creativity of artists and scientists, but indeed seems to characterize the minimally creative behavior that we all enjoy. This claim is partly motivated by the empirical research just discussed. Here, as in the more radical cases, instances of novel achievement or learning by subjects requires more than rote memorization; it requires cognitive manipulation of the information in the relevant conceptual space (e.g., combining concepts about houses and persons). This kind of cognitive activity is best done by using the imagination.

Peter Carruthers has argued that imagination is important to creativity on evolutionary grounds (2002, 2006; see also Picciuto & Carruthers 2014). Like the above analyses, he focuses on the playfulness of imagination. Pretend play typically develops early in childhood in humans. And imagination in adults provides the right mechanisms for generating and exploring ideas (just as required by the Geneplore model). Carruthers argues that imagination evolves under adaptive advantage as a kind of practice for adult creativity—and may have been accordingly selected for, aligning with the putative creativity explosion of 40,000 years ago (Mithen 1996, 1998; Harris 2000). This, he argues, is the most parsimonious explanation of both the emergence and the ubiquity of creativity in the human species. See B. Gaut (2009) for a critique of Carruthers’ analysis.

5.2.4 Incubation
While we may generate ideas consciously in imagination, we may also do so during a period of unconscious incubation, when we are focused on something else. This point is illustrated by any number of famous stories, though some are probably embellished after years of retelling. Isaac Newton witnessed an apple fall from a tree (on some accounts, falling upon Newton’s head) and thereby found the insight for his laws of gravity. August Kekulé is reported to have discovered the structure of the benzene molecule while daydreaming of a serpent circling upon and seizing its own tail. Henri Poincaré alleged that, while boarding a bus, he enjoyed a needed flash of insight that led to his discovery of non-Euclidian geometry. Richard Feynman, the Nobel prize winning physicist, claimed to find inspiration while sipping soda and doodling at adult clubs. And Einstein reported:

I was sitting in a chair in the patent office at Bern when all of a sudden a thought occurred to me. “If a person falls freely he will not feel his own weight”. I was startled. This simple thought made a deep impression on me. It impelled me toward a theory of gravitation. (Einstein, “Kyoto Lecture”, translated and quoted in Pais 1982: 179)

In each case, someone is suddenly struck with a flash of insight about one thing while engaged with something else entirely. The empirically-minded theorist rejects the notion that such ideas arise ex nihilo or through divine possession. So how are they explained in terms of natural mental phenomena?

Arthur Koestler, partly inspired by the work of Henri Poincaré (1908 [1913]), hypothesized that during creative thought processing, ideas are combined in novel ways, and this combination is performed largely unconsciously, by what Poincaré called the subliminal self (Koestler 1964: 164–5). For Poincaré there are only two ways we might think of the unconscious. One, we might think of the unconscious in Freudian terms, as a self capable of careful and fine discernment and, importantly, distinctions and combinations that the conscious self fails to make. Alternatively (and this is the option favored by both Poincaré and Koestler), we can think of the unconscious as a sub-personal automaton that mechanically runs through various combinations of ideas. Importantly, this unconscious process (or, if one likes, automaton) generates random conceptual associations and ideas. And these can then be further considered, examined, explored, and revised.

In the context of creativity in particular, there is precedent, or at least overlap, in Colin Martindale’s cortical arousal theory. This theory centers around the nature of focuses of attention (Martindale 1977, 1981, 1995, 1999; Martindale & Armstrong 1974; Martindale & Hines 1975). Martindale proposes a multi-stage model of problem solving, which if the right mechanism is possessed, leads to creative thought. In the initial stages, information is gathered, various approaches are taken to the problem, and there is a high level of cortical arousal with a narrow focus of attention. As information increases and the problem remains unsolved, two kinds of responses may occur. The first kind of response is to keep attempting the same solutions to the problem such that the arousal and attention focus stay high and narrow, respectively. Alternatively, some persons experience a decrease in cortical arousal coupled with a wider range of attention focus. Information then enters what Martindale calls primary processing: a kind of subconscious cognition not under the complete control of the agent. It is this kind of processing, and the arousal mechanisms that enable it, that distinguish creative insight or achievement from non-creative ones. The first kind of response typically results in frustration and failure (fixation), while the second often results in creative insight.

Some early studies on these phenomena centered around a familiar observation. Consider the tip-of the-tongue phenomenon, when you know that you know some bit of information (an actor’s name or the title of a song) but, try as you may, you just can’t recall it. It often helps to give up for a moment and allow the memory to surface without effort. Researchers found that the same approach—forgetting about a problem—works well to overcome fixation on ineffective ideas so as to allow the actual solution to pop up. Smith and Blankenship primed two groups of subjects with inappropriate or misleading solutions to problems. They left one group to continue struggling with the same problem, while they distracted the second group with a distinct but cognitively demanding task. The second group thereby overcame fixation and outperformed the first group when returning attention to the original target problem (Smith & Blankenship 1989, 1991; see also Smith, Ward, & Finke 1995).

These behavioral methods can be combined with contemporary understanding of neural plasticity and the effects of cognitive effort and attention. Neuroscientists have long recognized that the human brain is plastic—stable in genetic material but constantly undergoing functional change and development in neural networking in response to external stimuli, with the work of Donald Hebb in the middle of the twentieth century being one important early precedent. As Hebb put it, neural cells that “fire together, wire together”. Cell assemblies thus form as a result of the synchrony and proximity of the firing of individual cells.

[A]ny two cells or systems of cells that are repeatedly active at the same time will tend to become “associated”, so that activity in one facilitates activity in the other. (Hebb 1949 [2002: 70])

And continued attention to a problem, what some have called cerebral effort, causes changes in the networking of the brain’s cortex (Donald 2001: 175–8). Importantly, these changes can continue to take place, to “reverberate” even after one has removed attention from that problem. This motivates a simple (and somewhat unsurprising) hypothesis: attending to and performing cognitive tasks affects neural networking (Posner et al. 1997; Posner & Raichle 1994; see also Kami et al. 1995), and those changes can involve strengthening of synaptic connectivity (which correlate with conceptual connections and associations). These changes, again, can occur both when one is attending to a task and after one has diverted attention elsewhere. And, finally, the latter goes some way to explain a moment of insight after incubation (the so-called incubation effect): when one returns attention to the target problem, new or newly strengthened neural connectivity (as a result of previous cognitive effort) can give rise to a new idea. And because that neural process is not in any sense done by you, the emergence of the new idea can feel like a burst of insight (see Stokes 2007; Thagard & Stewart 2011; Ritter & Dijksterhuis 2014; and Heilman 2016).

There are also various recent studies on closely related topics: on mindwandering and spontaneous thought (Christoff et al. 2016; Irving & Thompson 2018; Murray et al. forthcoming), on so-called “divergent thinking” (Mekern et al. 2019), and more on the neural basis of insight (Jung-Beeman et al. 2004; Bowden et al. 2005; Limb & Braun 2008; Dietrich & Kanso 2010; Kounios & Beeman 2014).

5.3 Insight
It should be intuitive that creativity often involves solving problems and doing so in interesting or surprising ways. In exceptional cases, the individual identifies a problem solution that perhaps no one (including the creator) anticipated. But there are countless examples of more mundane instances of problem solving, where the solution may be surprising (or especially interesting) to only a few individuals, perhaps even only to the problem solver. One broad, standard experimental method used by researchers thus focuses on insight in problem solving. Some problems (thankfully!) can be solved by straightforward appeal to memory, or by applying some technique or method of calculation in a mechanical way. Solving the problem may still take time and effort, but the solution will come so long as one executes the appropriate strategy or applies the relevant knowledge from memory. An insight problem, by contrast, typically requires something new on the part of the individual, and one must often “change views” of the structure of the very problem. Predictably, there are a variety of definitions or characterizations of “insight” in the literature. Here are two recent, representative examples. Bowden et al. suggest that insight occurs

when a solver breaks free of unwarranted assumptions, or forms novel, task-related connections between existing concepts or skills. (Bowden et al. 2005: 322)

More recently, Kounios and Beeman write,

we define insight as any sudden comprehension, realization, or problem solution that involves a reorganization of the elements of a person’s mental representation of a stimulus, situation, or event to yield a nonobvious or nondominant interpretation. (2014: 74)

There are at least two, separable components of insight thus understood. First, an insight problem requires non-mechanical or non-algorithmic solution, and this in turn requires some kind of conceptual reorganization. A hackneyed phrase may come to mind here: one has to “think outside the box”.

The second element of insight as understood here is subjective or phenomenological. An insightful problem solution is often described as occurring suddenly and with little or no apparent effort. It is an aha moment, even if less dramatic than the traditionally romanticized Eureka moment. One way researchers have tested for this subjective feature is to ask subjects to report nearness or “warmth” relative to solving a problem. They find that for insight problems, by contrast to non-insight problems, subjects report that as they near solution they experience abrupt changes in the sense of warmth for solving the problem (Metcalfe & Wiebe 1987; see also Dominowski 1995; Laukkonen & Tangen 2018). More recently, researchers have begun to employ neuroimaging techniques to study insight and insightful problem solving (Luo & Niki 2003; Mai et al. 2004).

First, researchers have developed methods for using subjective report, where subjects rate whether they felt that they used insight in solving a designated problem (Bowden et al. 2005). And second, and coupled with those report methods, researchers have developed simple problems that can be solved with insight. One such example is the “Compound remote associates problem” (CRA). Here is an example of a CRA problem:

Each of the three words in (a) and (b) below can form a compound word or two-word phrase with the solution word. The solution word can come before or after any of the problem words.

french, car, shoe
boot, summer, ground[1]
(Bowden et al. 2005: 324)

Because of their simplicity, these problems can be solved unambiguously and quickly, and with this speed comes better potential for neuroimaging study. In instances where subjects report insight solutions to these kinds of problems,

EEG shows a burst of high-frequency (gamma-band) EEG activity over the right temporal lobe, and fMRI shows a corresponding change in blood flow in the medial aspect of the right anterior superior temporal gyrus (Jung-Beeman et al. 2004). (Kounios & Beeman 2014: 78)

The question for neuroscientists is whether this convergence of evidence is sufficient to establish neural correlates of insight.

5.4 Evaluation
A moment of “insight” can be misleading, as what initially strikes you as a promising idea may ultimately turn out to be a dead end. You may have countless ideas in the course of undertaking a complex creative project, while only a few of them will make the final cut. A crucial part of your creative work therefore consists in evaluating your ideas. For any idea that occurs to you, you might have to ask: Will this work? Is it new? How does it fit in with other parts of your project? Do you have the resources and abilities to bring it to fruition? Is it worth the time and effort?

Much of the research on this phase of the creative process is concerned to identify and categorize the range of factors that people take into consider as they evaluate their ideas (Blair & Mumford 2007; Dailey & Mumford, 2006). Unsurprisingly, those factors vary from one domain to another. New culinary dishes are judged by factors like aroma, taste, texture, color, presentation (Horng & Lin 2009), whereas improved musical performances are judged according to their complexity, originality, and technical virtuosity (Eisenberg & Thompson 2003), and so on. Your understanding of the relevant factors is part of your internalized model of the domain (Bink & Marsh, 2000; Csikszentmihalyi & Sawyer 1995). And since you acquired and refined that model through years of preparation, your capacity for evaluation is largely a consequence of your efforts from that initial stage.

Somewhat more surprisingly, there is some evidence that people who are good at evaluating ideas are also good at generating them (Runco 1991; Runco & Dow 2004; Runco & Chand 1994; Runco & Vega 1990).

Other studies support what Sawyer calls Sawyer (2012: 131) calls the productivity theory, which says that the best way to get good ideas is to have lots of ideas and just throw away the bad ones. In historiometric studies, Simonton found that creators who yielded the greatest number of works over their lifetimes were mostly likely to produce works that were significant and stood the test of time. Even more striking, he discovered that, from year to year, the periods when creators were most productive were also the ones in which they were most likely to do exceptional work (Simonton 1988a, 1988b). Linus Pauling, who won the Nobel Prize in Chemistry in 1954 as well as the Nobel Peace Prize in 1962, summed up the productivity theory in a famous remark:

If you want to have good ideas you must have many ideas. Most of them will be wrong, and what you have to learn is which ones to throw away. (quoted by Crick 1995 [time 34:57])

5.5 Externalization
The final operation of the creative process—externalizing ideas—may involve any number of disparate activities, which Keith Sawyer sums up as follows:

Creativity research has tended to focus on the early stages of the eight-stage creative process—particularly on the idea-generating stage. But a lot has to happen to make any idea a reality. Successful creators are skilled at executing their ideas, predicting how others might react to them and being prepared to respond, identifying the necessary resources to make them successful, forming plans for implementing the ideas, and improvising to adjust their plans as new information arrives. These activities are important in all creativity, but are likely to be even more important in practical domains such as technological invention and entrepreneurship (Mumford, 2003; Policastro & Gardner, 1999). (Sawyer 2012: 133–4)

It may be tempting to assume that the real creative work is finished once a new idea emerges in the moment of insight, and that externalization is just the uncreative, mechanical chore of making the idea public. But a closer look at the phenomenon reveals that externalization is often integral to creativity itself.

Vera John-Steiner (1985) interviewed, and examined the notebooks of, over 70 exceptional creators (ranging from author Anaïs Nin to composer Aaron Copland), and consulted the notebook of another 50 eminent historical creators such as Leo Tolstoy and Marie Curie. A recurring theme throughout was that at the beginning of each creative endeavor and continually throughout its development, creators manipulate and build upon their impressions, inklings, and tentative hunches using sketches, outlines, and other external representations.

Perkins (1981) corroborated this finding by analyzing the 61 sketches Picasso made en route to painting his famous work, Guernica, as well as Beethoven’s musical drafts and Darwin’s notebooks. In each case, the artist progressed by engaging with external representations.

Other studies found that people discovered and solved more problem when they used sketches during a task (Verstijnen 1997), and that people come up with better ideas for improving inventions when they work with visual diagrams (Mayer 1989).

One reason externalization is so vital to substantial creative work is because of our limited capacity to consciously hold and manipulate information in our minds. It helps to offload ideas and store them in the form of physical symbols and expressions in order to free up space for the mind to examine those ideas at arm’s length while entertaining new ones. Thus research shows that internal strategies like mental visualization can help with relatively simple tasks, but for more complex projects externalization is key (Finke et al. 1992: 60).

5.6 Worries and future directions
We close our survey of the cognitive science of creativity with a brief discussion of some general worries about current work, and some prescriptions for future research.

Some have worried about the validity of the psychometric measures employed in neuroimaging studies. One such concern regards the confidence that we should have that the tests employed are really tracking creative behavior. This is of course a general problem, partly symptomatic of the challenges that come with defining creativity (like other phenomena) and with the special challenges that attach to features such as insight and incubation. But there are particular challenges that come with using neuroimaging technologies such as fMRI scanning to attempt to study naturally occurring phenomena. Use of this technology is almost invariably ecologically invalid—one cannot run an fMRI in the artist’s studio. And because of the cost and sensitivity of these imaging systems, the correlative behavioral tests are often significantly abbreviated. This may impose constraints on space for occurrence of the target phenomena—novel thinking and insight—during the imaging session. As one researcher worries,

Too often single tests are used—or even single items! This is contrary of psychometric theory in general (where longer tests allow errors to cancel themselves out and are thus more reliable) and true of the research on creativity assessment in particular, where differences among items and even tests are common (Richards, 1976; Runco, Mohamad, & Paek, 2016 [sic should be Runco, Abdulla et al. 2016). Results from any one test will not generalize to other tests. Results from a single item of course have even less generalizability. (Runco 2017: 309–310; see also Abraham 2013)

Another empirical researcher criticizes what he sees as “the wild goose chase” in the neuroscience of creativity. Arne Dietrich (2019) recapitulates the above worries about validity of psychometric measures and their abbreviated and piecemeal application. He further worries about the now dominant emphasis on divergent thinking, and the default mode network (as well as the now mostly abandoned emphasis on notions such as madness, the right brain, and REM sleep). Dietrich’s concern in each case is that the research emphasis is unhelpfully myopic, and that while the imaging methods are sound and state of the art, the characterization of creativity is not. He decries the temptation to identify what may be a feature of creativity with the whole of the phenomenon. Divergent thinking, he suggests, is likely a cluster of various mental phenomena rather than a singular one, and

there is no effort underway to dissect divergent thinking and link it to the kinds of cognitive processes we use to operationalize all other psychological phenomena, such as working memory, cognitive control, semantic memory, perceptual processes, or executive attention. (2019: 37)

Notice, then, that the “wild goose” for Dietrich is to hastily conclude and then center studies around a singular, special creativity mechanism.

Dietrich also offers various prescriptions for remedy. To combat myopia, he suggests (as some have in other disciplines, e.g., Boden 2004) a plurality of types of creativity (and/or features of creativity). He cautions,

Since different types of creativity contain opposing brain mechanisms—focused versus defocused attention, for instance—any all-encompassing claim about creativity in the brain will almost certainly qualify as phrenology. (2019: 39)

He pairs this with a prescription for a more interdisciplinary approach to the topic. Others in the field have made the same prescription, advocating a “systems” approach sensitive both to the multi-faceted nature of creativity and the value of theorizing at multiple levels of explanation (Hennessy & Amabile 2010).

These directives for future research seem hard to resist. At the very least, it would seem advantageous to ensure that the full range of empirical method across the behavioral and brain sciences is communicated across the relevant sub-disciplines. This would ideally lead to better collaboration amongst such researchers. What’s interesting is that a cousin to this prescription is not well heeded by the same researchers advancing it here. However little crossover there is between, say, behavioral psychologists and neuroscientists in studies of creativity, there is comparatively even less crossover (almost none) between the psychological sciences and computational approaches to creativity. The next section thus begins by highlighting this “gap”, and identifying some of the potentially fruitful areas for interdisciplinary work on that front. It then continues with a discussion, generally, of research on creativity in the fields of computing science, artificial intelligence, and robotics.

6. Creativity and Artificial Intelligence
Just as we find in psychology and neuroscience, there is a rich research literature on creativity in artificial intelligence and computer science, with devoted journals, special issues, and conferences (The Journal of Artificial Creativity, The Journal of Creative Music Systems, Digital Creativity, Minds and Machines special issue on Computational Creativity [Gervás et al. 2010], The International Conference on Computational Creativity). The question we focus on here is whether a computer could be creative. As background, it is worth considering how theorists approached the analogous question as to whether a computer could think.

Although theorists of various kinds have asked whether machines can think since at least the early modern period, the most important conceptual innovations on the topic came from Alan Turing, centering around his 1950 paper “Computing machinery and intelligence”. Here Turing provided a number of groundbreaking insights. Perhaps most familiar is Turing’s “imitation game”, now commonly known as “the Turing Test”. In brief, the test involved an unknowing interrogator who could ask an open-ended series of questions of both a human and a computer. If the interrogator could not distinguish computer from human, Turing postulated that this would suffice to illustrate genuine intelligence. There is no shortage of controversy regarding the aptness of the test for intelligence, and arguably no computer has yet passed it. (For more thorough discussion of Turing and the Turing test see entries on Alan Turing, Turing machines, and the Turing test).

Successful performance in Turing’s game would require remarkable behavioral flexibility. And it is highly operational: specify a threshold for imitation, and then simply allow the interrogator to ask questions, then assess performance. If the behavior is sufficiently flexible to fool the interrogator, Turing claimed, the behavior was intelligent and, therefore, the computer intelligent.

With this background in mind, what are some of the cases in AI research lauded as success cases, and how do they align with some of Turing’s criteria?

Many of the familiar success cases are highly specialized. Deep Blue defeated chess master Garry Kasparov (Kasparov & Greengard 2017); some language processing systems managed to navigate social contexts such as ordering from a menu at a restaurant (Schank & Abelson 1977); AlphaGo more recently defeated the world champion Go player. This specialization is both a virtue and a limitation. On the one hand, achievement in such a specialized domain implies an exceptional amount of detailed memory and skill. On the other hand, this knowledge and skill does not generalize. Neither Deep Blue nor Alpha Go could successfully order from a menu, along with countless other basic human tasks. Put in terms of Turing’s imitation game, these systems would fail miserably to fool a human, or even remotely imitate one (except for their performance in a very narrow domain). What about systems such as IBM’s Watson, which famously won (against humans) on the television game show Jeopardy! This performance is more general, since topics on the show vary widely, and seemed to require both language comprehension and some minimal reasoning skills (see entry on artificial intelligence for extended discussion). Even so, Watson’s capabilities are still quite limited: it cannot make fluid conversation “in real time” and is largely insensitive to temporal and other factors that come with context.

There are many, many more examples of computational systems that display sophisticated behavior, from the highly specialized to the more general. On the language processing front, very recent AI systems such as OpenAI’s ChatGPT and Google’s LaMDA significantly outperform the systems described above. To be clear, these are remarkable achievements that display substantial complexity and, it appears in some cases, significant flexibility—features Turing highlighted in characteristically human behaviors. But this also underscores a distinction, often invoked by critics of artificial intelligence research. There is a difference between a computer’s displaying or merely imitating an intelligent behavior, and a computer’s instantiating intelligence through such behavior. And the critic will say, even if a computer behaves as if it is intelligent, this is just modeling or simulating intelligence. The greater ambition, though, is “genuine artificial intelligence”, a system that actually thinks. John Searle refers to this as the distinction between “weak AI” and “strong AI”, respectively.

Weak AI: Could a computer behave as if it thinks?
Strong AI: Could a computer genuinely think?
The general worry here is that however sophisticated a system’s behavior may appear “from the outside”, for all we know it may just be a “hollow shell” (Haugeland 1981 [1997]; Clark 2001). The worry has then been fleshed out in various ways by specifying what is missing from the shell, as it were. Here are three standard such candidates. And, again, in each case however sophisticated the computer’s behavior may appear it still may be lacking in any or all of the following. First, the computer may lack consciousness. Second, the computer may lack any understanding of the symbols over which it computes (Searle 1980). Finally, the computer may operate without caring about its own behavior or, as John Haugeland colorfully puts it, without “giving a damn”. In each case, any kind of response from the ambitious AI researcher encounters the substantial challenges that come with theorizing mental phenomena such as consciousness, understanding, linguistic competence, and emotion. (Turing 1950, for instance, recognized but largely eschewed these kinds of topics).

It’s one thing to ask whether computers could think, and another to ask whether they could be creative. And just as the prospect of artificial intelligence or thinking divides into two questions—of weak AI and strong AI—we may distinguish two analogous questions about artificial creativity, which we’ll refer to as the questions of “weak AC” and “strong AC”, respectively. To begin with the former:

Weak AC: Could a computer behave as if it’s creative?
Something behaves as if it’s creative if it produces things which are psychologically new (new to that thing) and valuable. Arguably, a number of computers have already done that.

In the 1970s, Harold Cohen began using computational technologies to produce new drawings and paintings. The work of his computer painter, Aaron, has exhibited at galleries such as the Tate and the Victoria and Albert Museum in London. David Cope’s “EMI” (Experiments in Musical Intelligence) has composed musical works in the style of various known composers and styles, even a full-length opera. Some of these works have been recorded and produced by bona fide record labels. Just search “Emily Howell” on Spotify or Apple Music and give it a listen (Cope 1996, 2006). Simon Colton’s The Painting Fool is an ongoing project, involving a software that abstracts phrases, images, and other items from newspaper articles and creates collage-style pieces. It has also produced portraits, based on images of film characters, of the same individual in different emotional states (see Painting Fool in Other Internet Resources; see Colton 2012 for theoretical discussion). Even more recently, there have been explosive developments in generative art systems like DALL•E, Midjourney, Stable Diffusion, VQGAN+CLIP. (For discussion see Paul & Stokes 2021). In all of these cases, the relevant outputs of the computer program are new relative to its past productions—so they are psychologically (or behaviorally) novel, which again is all the novelty that creativity requires. And although historical novelty isn’t required for creativity, it’s worth noting that these products appear to be to be new in all of history as well.

What about value? As noted above in §2.1, some theorists reject the value condition, but even if value is required for creativity, that too is a condition these computer artworks seem to meet. Assessments of value can be controversial, but that is no less true for the outputs of human creativity. The fact that these works are critically acclaimed, showcased in prestigious galleries, and commissioned by selective record labels testifies to their artistic merit, and viewers find them pleasing, interesting, and appealing, even before being apprised of their unusual origin. So it is reasonable to conclude computer programs like the ones just described exhibit at least weak AC insofar as they produce works of valuable novelty, and one could cite many more examples in the same vein.

Some theorists have noted that, whether or not the original Turing test is a good test for intelligence or thinking, we might adopt an analogous test for creativity: If a computer can fool human observers into thinking that it is a human creator, then it is in fact creative (Pease & Colton 2011; see also Chen 2020 for useful discussion of artificial creativity, including many additional examples of particular cases, and so-called Dartmouth-based Turing tests). If we employ this test, we might find ourselves with an unexpected conclusion: computers can be creative; in fact, some of them already are. But one might reasonably worry that the test is inadequate and the conclusion is too quick (Berrar & Schuster 2014; Bringsjord et al. 2001). From the fact that a computer operates as if it’s creative, one might argue, it doesn’t follow that it really is. Which brings us to our next question:

Strong AC: Could a computer genuinely be creative?
This obviously returns us to the question of what conditions something must meet in order to count as being genuinely creative. And here we need go beyond the outwardly observable product-features of novelty and value to consider the underlying processes of genuine creativity. As we saw in §2.2, theorists have variously proposed that in order for a process to count as creative, it must be surprising, original, spontaneous, and/or agential. There is no consensus to appeal to here, but if any one of these conditions is indeed required for genuine creativity, then a computer could be genuinely creative only to the extent that it executes processes which satisfy that condition.

The classic statement of skepticism regarding the possibility of computer creativity is due to Lady Ada Lovelace who had this to say while remarking on “the Analytical Engine” designed by her friend Charles Babbage:

It is desirable to guard against the possibility of exaggerated ideas that might arise as to the powers of the Analytical Engine. The Analytical Engine has no pretensions whatever to originate anything. (Lovelace 1843, italics added)

Though Lovelace does not frame her comments in terms of “creativity” as such, she explicitly denied that a computer could satisfy at least one condition that is plausibly required for creativity, namely originality. A computer cannot be the originator, the author, or the creator of anything new, she contends; it can only do what it is programmed to do. We cannot get anything out of a computer that has not already been programmed into it. Further, Lovelace may also be interpreted as expressing or implying doubt about whether a computer could satisfy the three other proposed requirements for genuine creativity. Insofar as a computer’s outputs cannot be original, one might also suspect that they cannot be surprising. The image of a machine strictly following rules invokes precisely the kind of mechanical procedure that is the antithesis of spontaneity. And it may seem that such a machine could not be a genuine agent either. The problem isn’t just that a computer can’t produce anything original; it’s that it deserves no credit for whatever it does produce. Any praise or blame for the outputs of a computer rightly go to the engineers and programmers who made the machine, not to the machine itself. While these points may be intuitive, at least some of them are being challenged by modern technologies, which have come a long way since Babbage’s invention.

Consider AlphaGo again. This is a “deep learning” system, which involves two neural networks: a Policy network and a Value network. Very briefly: The system is trained using a vast number of legitimate moves made in actual games of Go played by professional human players (28.4 million moves from 160,000 games, to be precise; see Silver et al. 2016 and Halina 2021). The network is further trained, again using learning algorithms, by playing many games (some 100 million) against previous versions of itself (in the sense of a differently weighted neural network). The weights of nodes in the network are then adjusted by a learning algorithm that favors moves made in winning games. The value network is trained over a subset of these many games, with node weighting adjustments resulting in reliable probability assignments to moves vis-à-vis their potential to contribute to a win. Finally, the system employs a Monte Carlo search tree (MCT). Generally, this kind of algorithm is designed to simulate a decision process to optimize success given chosen parameters. In this case, the search algorithm selects a given path of moves, then adds some valid moves to this path, and then if this process does not terminate (end in win/loss), the system performs a “rollout”. A rollout essentially plays the game out for both players (using samples of possible moves) to its conclusion. The information that results from the MCT and processing by the value network are then fed back (back propagated) into the system. This entire process (once the system is trained) is rapid and determines how AlphaGo “decides” to move in any given game.

Here are some things to note. AlphaGo’s style of play is surprising. As commentators have noted, it is starkly unconventional relative to standards of human play (Halina cites Baker and Hui 2017 [Other Internet Resources]). Indeed, Lee Sodol, the world champion Go player defeated by AlphaGo in 2016, remarked that AlphaGo’s play revealed that much of human play is, contrary to prior common opinion, not creative after all—intimating that at least some of the play of AlphaGo is. Note further that this system is flexible. While there are learning algorithms and rules that adjust network weights, the system is not mechanical or predictable in the same fashion as earlier, classical systems (including Deep Blue, for example). In a recent paper, Marta Halina has made this argument (Halina 2021). She explicitly invokes Boden’s characterization, which requires novelty, value, and surprise of creativity. Again, the novelty and value should be plausibly attributed in this case. Regarding surprise, Halina suggests that it is AlphaGo’s employment of MCT that enables a kind of “insight”, flexibility, and unpredictable results. She writes,

It is the exploration parameter that allows AlphaGo to go beyond its training, encouraging it to simulate moves outside of those recommended by the policy network. As the search tree is constructed, the system starts choosing moves with the highest “action value” to simulate, where the action value indicates how good a move is based on the outcome of rollouts and value-network evaluations. (Halina 2021: 324)

Halina grants that given its domain-specificity, as we have already noted, this system’s particular abilities do not generalize in a way that may be required to properly attribute genuine intelligence. But she suggests that the complex use of the MCT search may amount to “mental scenario building” or, we might say, a kind of imagination. And insofar as this search algorithm technology can be applied to other systems in other domains, and imagination is a general component of intelligence, perhaps here lies space for generalizability. AlphaGo also affords at least some reply to the traditional Lovelace worry.

Artificial systems do not act only according to preprogrammed rules hand-coded by engineers. Moreover, current deep-learning methods are capable of producing systems that are superhuman in their abilities to discover novel and valuable solutions to problems within specific domains. (Halina 2021: 327)

If this is right, then AlphaGo exhibits originality. Finally, the flexibility with which this system operates may also satisfy Kronfeldner’s spontaneity requirement.

Some of these same features are found in a related approach in AI, namely research in evolutionary robotics. These systems also involve various forms of machine learning but in this case the learning is distributed, as it were, across a population of individuals rather than one individual. This approach can be understood, albeit imperfectly, as analogous to natural evolution. One begins, typically in computer simulation, with a population of agents. These agents are typically identified with individual neural networks, the connections and weightings of which are random to start. Relative to some task—for instance, avoiding obstacles, collecting objects, performing photo or phonotaxis—a genetic algorithm assigns a fitness value to each individual agent after a certain period of time or number of trials. Fitter agents are typically favored and used to generate the next population of agents. Also included in this generation are random mutation and genetic crossover (digital breeding!). Although it can take hundreds of generations, this is a discovery approach to engineering or constructing a system that successfully performs a task; it is “gradient descent learning” (Clark 1996). In this bottom-up approach, no single individual, nor even an entire population, are in any strict sense programmed. Rather, successful agents have “learned” as a result of generations of randomness, crossover, and small fitness improvements (and lots and lots of failures). Early success cases evolved robots that can follow trails (Koza 1992), locomote in insect-fashion (Beer & Gallagher 1992), guide themselves visually (Cliff, Husbands, & Harvey 1993), and collect garbage (Nolfi & Floreana 2000). See Bird and Stokes (2006, 2007) and Stokes and Bird (2008) for analysis and study of creativity in the context of evolutionary robotics.

These systems most certainly produce novelty. Later, fit individuals achieve novelty at their aimed task relative to whole generations and populations of previous agents. And this novelty is often surprising to the engineers and programmers that build them, indeed sometimes even unpredictably independent of any relevant task for individuals in the population. There are many examples in the literature. Indeed Lehman and others (2020) catalog a large range of cases where digital evolution surprises its creators, categorizing them in four representative groups: “mis-specified fitness functions”, “unintended debugging”, “exceeded experimenter expectations”, and “convergence with biology”. Here is one now relatively famous example of the first type of case. In early research in artificial life (A-Life), Karl Sims (1994) designed virtual creatures that were supposed to learn to walk (as well as swim and jump) in a simulated environment. The fitness function assessed individual agents on their average ground velocity across 10 seconds. Some of the fittest individuals to evolve were surprising: they grew tall and rigid and when they would fall over they would achieve high ground velocity, thus maximizing fitness given the (mis)specified parameters in unpredicted ways.

This is but one example of how systems like these can evolve in unpredictable or surprising ways. This unpredictability has occurred not just in simulated robotics, but in embodied robotics as well. In using a genetic algorithm to attempt to evolve oscillating sensors, researchers unintentionally evolved a radio antenna (Bird & Layzell 2002). This unexpected result arose from a combination of the particular algorithm used (which was intended) and various physical features of the space such as proximity to a PC monitor (which the researchers had presumably deemed irrelevant but which the evolved system, in a sense, did not). And one might be further inclined to describe some of these achievements as creative (and not just in the trivial sense that they are original instances of robotic success), since they also produce value, at least insofar as they are useful at performing a task, whether it is locomoting or locating a source of light or sensing radio waves.

Some theorists in this domain might argue that these systems achieve spontaneity as well. Given the substantial inclusion of randomness in the system’s development—both at the outset when the individual’s neural networks are randomized and more importantly with random mutation across populations—it is intuitive to describe the system’s as not following a mechanical procedure. Indeed, the way in which systems exploit fitness functions and data patterns further underscores this point. (Again, see the rich catalog of cases offered by Lehman et al. 2020).

On the face of it, then, recent technologies in AI, evolutionary robotics, and artificial life, seem to fulfill many of the conditions proposed for genuine creativity. These systems produce things that are novel and valuable, and do so through computational processes that are plausibly surprising, original, and spontaneous. The one requirement we have yet to address, however, is agency. Recall the suggestion, implicit in Lovelace’s remarks, that whatever a computer produces is to the credit of the programmer, not the computer. Notice that as sophisticated as current technologies in artificial creativity may be, presumably they are still not subject to praise or blame for what they do. If any beings are responsible for the work of these programs, it still seems to be the programmers and engineers who make them, not the programs themselves. The programs themselves do not seem to “give a damn”. So, if the creative process requires agency, arguably we have not yet created, programmed, or evolved a computational system that is really creative, however much they might appear to be. In the pursuit of strong AC, agency might be the final frontier (Paul & Stokes 2021).

7. Conclusion
It should be clear from the above discussions that there are rich and lively research programs, across a range of scientific disciplines, studying human creativity. These approaches substantiate the view that, contrary to the romantic tradition, creativity can be explained. Psychological functions and neural correlates have been identified, and remarkable advances are being made with computational and robotics technologies. What may be less clear is that, despite these advances, the distinct research programs in question are largely disjoint or siloed.

In a recent paper, Geraint Wiggins and Joydeep Bhattacharya (2014) highlight this “gap” between scientific studies of creativity. Their particular emphasis is on the gaps between research in neuroscience and research in computer science, and they advocate a bridge in the form of a neurocomputational approach. This kind of bridging may be called for even beyond what these authors prescribe, since there are gaps not just between these disciplines, but also between these and behavioral psychology, AI and A-Life research, and philosophical analysis. Creativity is a deeply complex and deeply important phenomenon. Fully understanding it will require us to integrate a variety of theoretical perspectives, and, as this survey reveals, philosophy has a vital role to play in that endeavor.

The primary distinguishing feature of Darwin’s theory that separates it from previous explanations of species change centers on the causal explanation he offered for how this process occurred. Prior theories, such as the theory of Jean-Baptiste Lamarck (see entry on evolutionary thought before Darwin), relied on the inherent dynamic properties of matter. The change of species was not, in these pre-Darwinian efforts, explained through an adaptive process. Darwin’s emphasis after the composition of Notebook D on the factors controlling population increase, rather than on a dynamic theory of life grounded in vital forces, accounts for many of the differences between Darwin’s theory and those of his predecessors and contemporaries.

These differences can be summarized in the concept of natural selection as the central theoretical component of Darwinian theory. However, the exact meaning of this concept, and the varying ways he stated the principle in the Origin over its six editions (1859–1872), has given rise to multiple interpretations of the meaning of this principle in the history of Darwinism, and the different understandings of his meaning deeply affected different national and cultural receptions of his theory (see below, Section 3.1).

One way to see the complexity of Darwin’s own thinking on these issues is to follow the textual development of this concept from the close of the Notebook period (1839) to the publication of the Origin of Species in 1859. This period of approximately twenty years involved Darwin in a series of reflections that form successive strata in the final version of his theory of the evolution of species. Understanding the historical sequence of these developments also has significance for subsequent controversies over this concept and the different readings of the Origin as it went through its successive revisions. This historical development of the concept also has some bearing on assessing Darwin’s relevance for more general philosophical questions, such as those surrounding the relevance of his theory for such issues as the concept of a more general teleology of nature.

The earliest set of themes in the manuscript elaboration of natural selection theory can be characterized as those developed through a particular form of the argument from analogy. This took the form of a strong “proportional” form of the analogical argument that equated the relation of human selection to the development of domestic breeds as an argument of the basic form: human selection is to domestic variety formation as natural selection is to natural species formation (White, Hodge and Radick 2021, chps. 4–5). This makes a direct analogy between the actions of nature with those of humans in the process of selection. The specific expressions, and changes, in this analogy are important to follow closely. As this was expressed in the first coherent draft of the theory, a 39-page pencil manuscript written in 1842, this discussion analogized the concept of selection of forms by human agency in the creation of the varieties of domestic animals and plants, to the active selection in the natural world by an almost conscious agency, a “being infinitely more sagacious than man (not an omniscient creator)” who acts over “thousands and thousands of years” on “all the variations which tended towards certain ends” (Darwin 1842 in Glick and Kohn 1996, 91). This agency selects out those features most beneficial to organisms in relation to conditions of life, analogous in its action to the selection by man on domestic forms in the production of different breeds. Interwoven with these references to an almost Platonic demiurge are appeals to the selecting power of an active “Nature”:

Nature’s variation far less, but such selection far more rigid and scrutinizing […] Nature lets <<an>> animal live, till on actual proof it is found less able to do the required work to serve the desired end, man judges solely by his eye, and knows not whether nerves, muscles, arteries, are developed in proportion to the change of external form. (Ibid., 93)

These themes were continued in the 230 page draft of his theory of 1844. Again he referred to the selective action of a wise “Being with penetration sufficient to perceive differences in the outer and innermost organization quite imperceptible to man, and with forethought extending over future centuries to watch with unerring care and select for any object the offspring of an organism produced” (Darwin 1844 in ibid., 101). This selection was made with greater foresight and wisdom than human selection. As he envisions the working of this causal agency,

In accordance with the plan by which this universe seems governed by the Creator, let us consider whether there exist any secondary means in the economy of nature by which the process of selection could go on adapting, nicely and wonderfully, organisms, if in ever so small a degree plastic, to diverse ends. I believe such secondary means do exist. (Ibid., 103).

Darwin returned to these issues in 1856, following a twelve-year period in which he published his Geological Observations on the Volcanic Islands (1844), the second edition of his Journal of Researches (1845), Geological Observations on South America (1846), the four volumes on fossil and living barnacles (Cirripedia) (1851, 54, 55), and Geological Observations on Coral Reefs (1851). In addition, he published several smaller papers on invertebrate zoology and on geology, and reported on his experiments on the resistance of seeds to salt water, a topic that would be of importance in his explanation of the population of remote islands.

These intervening inquiries positioned Darwin to deal with the question of species permanence against an extensive empirical background. The initial major synthesis of these investigations takes place in his long manuscript, or “Big Species Book”, commenced in 1856, known in current scholarship as the “Natural Selection” manuscript. This formed the immediate background text behind the published Origin. Although incomplete, the “Natural Selection” manuscript provides insights into many critical issues in Darwin’s thinking. It was also prepared with an eye to the scholarly community. This distinguishes its content and presentation from that of the subsequent “abstract” which became the published Origin of Species. “Natural Selection” contained tables of data, references to scholarly literature, and other apparatus expected of a non-popular work, none of which appeared in the published Origin.

The “Natural Selection” manuscript also contained some new theoretical developments of relevance to the concept of natural selection that are not found in earlier manuscripts. Scholars have noted the introduction in this manuscript of the “principle of divergence”, the thesis that organisms under the action of natural selection will tend to radiate and diversify within their “conditions of life”—the contemporary name for the complex of environmental and species-interaction relationships (Kohn 1985b, 2009). Although the concept of group divergence under the action of natural selection might be seen as an implication of Darwin’s theory from his earliest formulations of the 1830s, nonetheless Darwin’s explicit definition of this as a “principle”, and its discussion in a long late insertion in the “Natural Selection” manuscript, suggests its importance for Darwin’s mature theory. The principle of divergence was now seen by Darwin to form an important link between natural variation and the conditions of existence under the action of the driving force of population increase.

Still evident in the “Natural Selection” manuscript is Darwin’s implicit appeal to some kind of teleological ordering of the process. The action of the masculine-gendered “wise being” of the earlier manuscripts, however, has now been given over entirely to the action of a selective “Nature”, now referred to in the traditional feminine gender. This Nature,

…cares not for mere external appearance; she may be said to scrutinise with a severe eye, every nerve, vessel & muscle; every habit, instinct, shade of constitution,—the whole machinery of the organisation. There will be here no caprice, no favouring: the good will be preserved & the bad rigidly destroyed.… Can we wonder then, that nature’s productions bear the stamp of a far higher perfection than man’s product by artificial selection. With nature the most gradual, steady, unerring, deep-sighted selection,—perfect adaption [sic] to the conditions of existence.… (Darwin 1856–58 [1974: 224–225])

The language of this passage, directly underlying statements about the action of “natural selection” in the first edition of the published Origin, indicates the complexity in the exegesis of Darwin’s meaning of “natural selection” when viewed in light of its historical genesis (Ospovat 1981). The parallels between art and nature, the intentionality implied in the term “selection”, the notion of “perfect” adaptation, and the substantive conception of “nature” as an agency working toward certain ends, all render Darwin’s views on teleological purpose more complex than they are typically interpreted from the standpoint of contemporary Neo-selectionist theory (Lennox 1993, 2013). As will be discussed below, the changes Darwin subsequently made in his formulations of this concept over the history of the Origin have led to different conceptions of what he meant by this principle.

The hurried preparation and publication of the Origin between the summer of 1858 and November of 1859 was prompted by the receipt on June 18 of 1858 of a letter and manuscript from Alfred Russel Wallace (1823–1913) that outlined his remarkably similar views on the possibility of continuous species change under the action of a selection upon natural variation (Wallace 1858 in Glick and Kohn 1996, 337–45). This event had important implications for the subsequent form of Darwin’s published argument. Rapidly condensing the detailed arguments of the unfinished “Natural Selection” manuscript into shorter chapters, Darwin also universalized several claims that he had only developed with reference to specific groups of organisms, or which he had applied only to more limited situations in the manuscript. This resulted in a presentation of his theory at the level of broad generalization. The absence of tables of data, detailed footnotes, and references to the secondary literature in the published version also resulted in predictable criticisms which will be discussed below in Section 3.2.

2.2. The Central Argument of the Published Origin
The Origin of Species by Means of Natural Selection, or the Preservaton of Favoured Races in the Struggle for Life was issued in London by the publishing house of John Murray on November 24, 1859 (Darwin 1859 [1964]). The structure of the argument presented in the published Origin has been the topic of considerable literature and can only be summarized here. Although Darwin himself described his book as “one long argument”, the exact nature of this argument is not immediately transparent, and alternative interpretations have been made of his reasoning and rhetorical strategies in formulating his evolutionary theory. (Prestes 2023; White, Hodge and Radick 2021; Hodge 2013b, 1977; Hoquet 2013; Hull 2009; Waters 2009; Depew 2009; Ruse 2009; Lennox 2005; Hodge 1983b).

The scholarly reconstruction of Darwin’s methodology employed in the Origin has taken two primary forms. One approach has been to reconstruct it from the standpoint of currently accepted models of scientific explanation, sometimes presenting it as a formal deductive model (Sober 1984). Another, more historical, approach interprets his methodology in the context of accepted canons of scientific explanation found in Victorian discussions of the period (see the entry on Darwinism; Prestes 2023; White, Hodge and Radick 2021; Hodge 2013b, 1983b, 1977; Hoquet 2013; Hull 2009; Waters 2009; Depew 2009; Lennox 2005). The degree to which Darwin did in fact draw from the available methodological discussions of his contemporaries—John Herschel, William Whewell, John Stuart Mill—is not fully clear from available documentary sources. The claim most readily documented, and defended particularly by White, Hodge and Radick (2021) and M. J. S. Hodge (1977, 1983a), has emphasized the importance of John Herschel’s A Preliminary Discourse on the Study of Natural Philosophy (1830 [1987]), which Darwin read as a young student at Cambridge prior to his departure on the HMS Beagle in December of 1831.

In Herschel’s text he would have encountered the claim that science seeks to determine “true causes”—vera causae—of phenomena through the satisfaction of explicit criteria of adequacy (Herschel, 1830 [1987], chp. 6). This concept Newton had specified in the Principia as the third of his “Rules of Reasoning in Philosophy” (see the entry on Newton’s philosophy, Section 4). Elucidation of such causes was to be the goal of scientific explanation. Vera causae, in Herschel’s formulation, were those necessary to produce the given effects; they were truly active in producing the effects; and they adequately explained these effects.

The other plausible methodological source for Darwin’s mature reasoning was the work of his older contemporary and former Cambridge mentor, the Rev. William Whewell (1794–1866), whose three-volume History of the Inductive Sciences (Whewell 1837) Darwin read with care after his return from his round-the-world voyage (Ruse 2013c, 1975). On this reading, a plausible argument has been made that the actual structure of Darwin’s text is more closely similar to a “Whewellian” model of argument. In Whewell’s accounts of his philosophy of scientific methodology (Whewell 1840, 1858), the emphasis of scientific inquiry is, as Herschel had also argued, to be placed on the discovery of “true causes”. But evidence for the determination of a vera causa was to be demonstrated by the ability of disparate phenomena to be drawn together under a single unifying “Conception of the Mind”, exemplified for Whewell by Newton’s universal law of gravitation. This “Consilience of Inductions”, as Whewell termed this process of theoretical unification under a few simple concepts, was achieved only by true scientific theories employing true causes (Whewell 1840: xxxix). It has therefore been argued that Darwin’s theory fundamentally produces this kind of consilience argument, and that his methodology is more properly aligned with that of Whewell.

A third account, related to the Whewellian reading, is that of David Depew. Building on Darwin’s claim that he was addressing “the general naturalist public,” Darwin is seen as developing what Depew has designated as “situated argumentation”, similar to the views developed by contemporary Oxford logician and rhetorical theorist Richard Whately (1787–1863) (Depew 2009). This rhetorical strategy proceeds by drawing the reader into Darwin’s world by personal narration as it presents a series of limited issues for acceptance in the first three chapters, none of which required of the reader a considerable leap of theoretical assent, and most of which, such as natural variation and Malthusian population increase, had already been recognized in some form in the literature of the period.

As Darwin presented his arguments to the public, he opens with a pair of chapters that draw upon the strong analogy developed in the manuscripts between the action of human art in the production of domestic forms, and the actions of selection “by nature.” The resultant forms are presumed to have arisen through the action of human selection on the slight variations existing between individuals within the same species. The interpretation of this process as implying directional, and even intentional, selection by a providential “Nature” that we have seen in the manuscripts was, however, downplayed in the published work through the importance given by Darwin to the role of “unconscious” selection, a concept not encountered in the Natural Selection manuscript. Such selection denotes the practice even carried out by aboriginal peoples who simply seek to maintain the integrity and survival of a breed or species by preserving the “best” forms.

The domestic breeding analogy is, however, more than a decorative rhetorical strategy. It repeatedly functions for Darwin as the principal empirical example to which he could appeal at several places in the text as a means of visualizing the working of natural selection in nature, and this appeal remains intact through the six editions of the Origin.

From this model of human selection working on small individual natural variations to produce the domestic forms, Darwin then developed in the second chapter the implications of “natural” variation, delaying discussion of the concept of natural selection until Chapter IV. The focus of the second chapter introduces another important issue. Here he extends the discussion of variation developed in Chapter I into a critical analysis of the common understanding of classification as grounded on the definition of species and higher groups based on the possession of essential defining properties. It is in this chapter that Darwin most explicitly develops his own position on the nature of organic species in relation to his theory of descent. It is also in this chapter that he sets forth the ingredients for his attack on one meaning of species “essentialism”.

Darwin’s analysis of the “species question” involves a complex argument that has many implications for how his work was read by his contemporaries and successors, and its interpretation has generated a considerable literature (see the entries on species and Darwinism; Mallet 2013; R. A. Richards 2010; Wilkins 2009; Stamos 2007; Sloan 2009b, 2013; Beatty 1985).

Prior tradition had been heavily affected by eighteenth-century French naturalist Buffon’s novel conception of organic species in which he made a sharp distinction between “natural” species, defined primarily by fertile interbreeding, and “artificial” species and varieties defined by morphological traits and measurements upon these (see the entry on evolutionary thought before Darwin, Section 3.3). This distinction was utilized selectively by Darwin in an unusual blending of two traditions of discussion that are conflated in creative ways in Darwin’s analysis.

Particularly as the conception of species had been discussed by German natural historians of the early nineteenth-century affected by distinctions introduced by philosopher Immanuel Kant (1724–1804), “Buffonian” species were defined by the material unity of common descent and reproductive continuity. This distinguished them by their historical and material character from the taxonomic species of the “Linnean” tradition of natural history. This distinction between “natural” and “logical” species had maintained a distinction between problems presented in the practical classification of preserved specimens, distinguished by external characters, and those relating to the unity of natural species, which was grounded upon reproductive unity and the sterility criterion (Sloan 2009b).

Remarkable in Darwin’s argument is the way in which he draws selectively in his readings from these two preexistent traditions to undermine the different grounds of species “realism” assumed within both of these traditions of discourse. One framework—what can be considered in his immediate context the “Linnean” tradition—regarded species in the sense of universals of logic or class concepts, whose “reality” was often grounded on the concept of divine creation. The alternative “Buffonian” tradition viewed species more naturalistically as material lineages of descent whose continuity was determined by some kind of immanent principle, such as the possession of a conserving “internal mold” or specifying vital force (see evolutionary thought before Darwin 3.3). The result in Darwin’s hands is a complex terminological interweaving of concepts of Variety, Race, Sub-species, Tribe, and Family that can be shown to be a fusion of different traditions of discussion in the literature of the period. This creative conflation also led to many confusions among his contemporaries about how Darwin actually did conceive of species and species change in time.

Darwin addresses the species question by raising the problems caused by natural variation in the practical discrimination of taxa at the species and varietal levels, an issue with which he had become closely familiar in his taxonomic revision of the Sub-class Cirripedia (barnacles) in his eight-year study on this group. Although the difficulty of taxonomic distinctions at this level was a well-recognized problem in the literature of the time, Darwin subtly transforms this practical problem into a metaphysical ambiguity—the fuzziness of formal taxonomic distinctions created by variation in preserved specimens is seen to imply a similar ambiguity of “natural” species boundaries.

We follow this in reading how natural variation is employed by Darwin in Chapter Two of the Origin to break down the distinction between species and varieties as these concepts were commonly employed in the practical taxonomic literature. The arbitrariness apparent in making distinctions, particularly in plants and invertebrates, meant that such species were only what “naturalists having sound judgment and wide experience” defined them to be (Origin 1859 [1964], 47). These arguments form the basis for claims by his contemporaries that Darwin was a species “nominalist”, who defined species only as conventional and convenient divisions of a continuum of individuals.

But this feature of Darwin’s discussion of species captures only in part the complexity of his argument. Drawing also on the tradition of species realism developed within the “Buffonian” tradition, Darwin also affirmed that species and varieties are defined by common descent and material relations of interbreeding. Darwin then employed the ambiguity of the distinction between species and varieties created by individual variation in practical taxonomy to undermine the ontological fixity of “natural” species. Varieties are not simply the formal taxonomic subdivisions of a natural species as conceived in the Linnaean tradition. They are, as he terms them, “incipient” species (ibid., 52). This subtly transformed the issue of local variation and adaptation to circumstances into a primary ingredient for historical evolutionary change. The full implications to be drawn from this argument were, however, only to be revealed in Chapter Four of the text.

Before assembling the ingredients of these first two chapters, Darwin then introduced in Chapter Three the concept of a “struggle for existence”. This concept is introduced in a “large and metaphorical sense” that included different levels of organic interactions, from direct struggle for food and space to the struggle for life of a plant in a desert. Although described as an application of Thomas Malthus’s parameter of geometrical increase of population in relation to the arithmetical increase of food supply, Darwin’s use of this concept in fact reinterprets Malthus’s principle, which was formulated only with reference to human population in relation to food supply. It now becomes a general principle governing all of organic life. Thus all organisms, including those comprising food for others, would be governed by the tendency to geometrical increase.

Through this universalization, the controls on population become only in the extreme case grounded directly on the traditional Malthusian limitations of food and space. Normal controls are instead exerted through a complex network of relationships of species acting one on another in predator-prey, parasite-host, and food-web relations. This profound revision of Malthus’s arguments rendered Darwin’s theory deeply “ecological” as this term would later be employed. We can cite two thought experiments employed by Darwin himself as illustrations (ibid., 72–74). The first concerns the explanation of the abundance of red clover in England. This Darwin sees as dependent on the numbers of pollinating humble bees, which are controlled in turn by the number of mice, and these are controlled by the number of cats, making cats the remote determinants of clover abundance. The second instance concerns the explanation of the abundance of Scotch Fir. In this example, the number of fir trees is limited indirectly by the number of cattle.

With the ingredients of the first three chapters in place, Darwin was positioned to assemble these together in his grand synthesis of Chapter Four on “natural” selection. In this long discussion, Darwin develops the main exposition of his central theoretical concept. For his contemporaries and for the subsequent tradition, however, the meaning of Darwin’s concept of “natural” selection was not unambiguously evident for reasons we have outlined above, and these unclarities were to be the source of several persistent lines of disagreement and controversy.

The complexities in Darwin’s presentation of his central principle over the six editions of the published Origin served historically to generate several different readings of his text. In the initial introduction of the principle of natural selection in the first edition of Darwin’s text, it is characterized as “preservation of favourable variations and the rejection of injurious variations” (ibid., 81). When Darwin elaborated on this concept in Chapter Four of the first edition, he continued to describe natural selection in language suggesting that it involved intentional selection, continuing the strong art-nature analogy found in the manuscripts. For example:

As man can produce and certainly has produced a great result by his methodical and unconscious means of selection, what may not nature effect? Man can act only on external and visible characters: nature cares nothing for appearances, except in so far as they may be useful to any being. She can act on every internal organ, on every shade of constitutional difference, on the whole machinery of life. Man selects only for his own good; Nature only for that of the being which she tends. Every selected character is fully exercised by her; and the being is placed under well-suited conditions of life. (Ibid., 83)

The manuscript history behind such passages prevents the simple discounting of these statements as mere rhetorical imagery. As we have seen, the parallel between intentional human selectivity and that of “nature” formed the proportional analogical model upon which the concept of natural selection was originally constructed.

Criticisms that quickly developed over the overt intentionality embedded in such passages, however, led Darwin to revise the argument in editions beginning with the third edition of 1861. From this point onward he explicitly downplayed the intentional and teleological language of the first two editions, denying that his appeals to the selective role of “nature” were anything more than a literary figure. Darwin then moved decisively in the direction of defining natural selection as the description of the action of natural laws working upon organisms rather than as an efficient or final cause of life. He also regrets in his Correspondence his mistake in not utilizing the designation “natural preservation” rather than “natural selection” to characterize his principle (letter to Lyell 28 September 1860, Burkhardt Correspondence 8, 397; also see Darwin Correspondence Project in Other Internet Resources). In response to criticisms of Alfred Russel Wallace, Darwin then adopted in the fifth edition of 1869 his contemporary (1820–1903) Herbert Spencer’s designator, “survival of the fittest”, as a synonym for “natural selection” (Spencer 1864, 444–45; Darwin 1869, 72). This redefinition further shifted the meaning of natural selection away from the concept that can be extracted from the early texts and drafts. These final statements of the late 1860s and early 70s underlie the tradition of later “mechanistic” and non-teleological understandings of natural selection, a reading developed by his disciples who, in the words of David Depew, “had little use for either his natural theodicy or his image of a benignly scrutinizing selection” (Depew 2009, 253). The degree to which this change preserved the original strong analogy between art and nature can, however, be questioned. Critics of the use of this analogy had argued since the original formulations that the comparison of the two modes of selection actually worked against Darwin’s theory (Wallace 1858 in Glick and Kohn 1997, 343). This critique would also be leveled against Darwin in the critical review of 1867 by Henry Fleeming Jenkin discussed below.

The conceptual synthesis of Chapter Four also introduced discussions of such matters as the conditions under which natural selection most optimally worked, the role of isolation, the causes of the extinction of species, and the principle of divergence. Many of these points were made through the imaginative use of “thought experiments” in which Darwin constructed possible scenarios through which natural selection could bring about substantial change.

One prominent way Darwin captured for the reader the complexity of this process is reflected in the single diagram to appear in all the editions of the Origin. In this illustration, originally located as an Appendix to the first edition, but thereafter moved into Chapter Four, Darwin summarized his conception of how species were formed and diverged from common ancestral points. This image also served to depict the frequent extinction of most lineages, an issue developed in detail in Chapter Ten. It displayed pictorially the principle of divergence, illustrating the general tendency of populations to diverge and fragment under the pressure of population increase. It supplied a way of envisioning relations of taxonomic affinity to time, and illstrated the persistence of some forms unchanged over long geological periods in which stable conditions prevail.

Graph labeled on the horizontal-axis with the letters A to L and on the vertical-axis with Roman numerals I to XIV. From A branch up several dashed lines; all but two stop before reaching vertical-level I; from those two branch up several more dashed lines, some stop before the next vertical-level those that don't sprout up more lines, repeat though in some cases no line from a particular branch reaches the next vertical-level. Further description in the text following.
Figure: Tree of life diagram from Origin of Species (Origin 1859:“Appendix”.

Remarkable about Darwin’s diagram of the tree of life is the relativity of its coordinates. It is first presented as applying only to the divergences taking place in taxa at the species level, with varieties represented by the small lower-case letters within species A–L of a “wide ranging genus”, with the horizontal lines representing time segments measured in terms of a limited number of generations. However, the attentive reader could quickly see that Darwin’s destructive analysis of the distinction between “natural” and “artificial” species in Chapter Two, implied the relativity of the species-variety distinction, this diagram could represent eventually all organic relationships, from those at the non-controversial level of diverging varieties within fixed species, to those of the relations of Species within different genera. Letters A–L could also represent taxa at the level of genera, families or orders. The diagram can thus be applied to relationships between all levels of the Linnaean hierarchy with the time segments representing potentially vast expanses of time, and the horizontal spread of branches the degree of taxonomic divergence over time. In a very few pages of argument, the diagram was generalized to represent the most extensive group relations, encompassing the whole of geological time. Extension of the dotted lines at the bottom could even suggest, as Darwin argues in the last paragraph of the Origin, that all life was a result of “several powers, having been originally breathed into a few forms or into one” (Darwin 1859 [1964], 490). This could suggest a single naturalistic origin of all original forms either by material emergence, or through the action of a vitalistic power of life. Darwin’s use of Biblical language could also be read as allowing for the action of a supernatural cause.

In response to criticisms concerning this latter point, Darwin quickly added to the final paragraph in the second edition of 1860 the phrase “by the Creator” (1860: 484), which remained in all subsequent editions. as did the quotations on the frontispiece from familiar discussions in British natural theology concerning creation by secondary causation. Conceptual space was thereby created for the reading of the Origin by some contemporaries, notably by the Harvard botanist Asa Gray (1810–88), as compatible with traditional natural theology (Gray 1860).

The sweep of the theoretical generalization that closed the natural selection chapter, one restated even more generally in the final paragraph of the book, required Darwin to deal with several obvious objections to the theory that constitute the main “defensive” chapters of the Origin (Five–Nine), and occupy him through the numerous revisions of the text between 1859 and 1872. As suggested by David Depew, the rhetorical structure of the original text developed in an almost “objections and response” structure that resulted in a constant stream of revisions to various editions of the original text as Darwin engaged his opponents (Depew 2009; Peckham 2006). Anticipating at first publication several obvious lines of objection, Darwin devoted much of the text of the original Origin to offering a solution in advance to predictable difficulties. As Darwin outlined these main lines of objection, he discussed, first, the apparent absence of numerous slight gradations between species, both in the present and in the fossil record, of the kind that would seem to be predictable from the gradualist workings of the theory (Chps. Six, Nine). Second, the gradual development of organs and structures of extreme complexity, such as the vertebrate eye, an organ which had since Antiquity served as a mainstay of the argument for external teleological design (Chp. Six). Third, the evolution of the elaborate instincts of animals and the puzzling problem of the evolution of social insects that developed sterile neuter castes, proved to be a particularly difficult issue for Darwin in the manuscript phase of his work and needed some account (Chp. Seven). As a fourth major issue needing attention, the traditional distinction between natural species defined by interfertility, and artificial species defined by morphological differences, required an additional chapter of analysis in which he sought to undermine the absolute character of the interbreeding criterion as a sign of fixed natural species (Chp. Eight).

In Chapter Ten, Darwin developed his interpretation of the fossil record. At issue was the claim by Lamarckian and other transformists, as well as Cuvierian catastrophists such as William Buckland (1784–1856) (see the entry on evolutionary thought before Darwin, Section 4.1), that the fossil record displayed a historical sequence beginning with simpler plants and animals, arriving either by transformism or replacement, at the appearance of more complex forms in geological history. Opposition to this thesis of “geological progressionism” had been made by none other than Darwin’s great mentor in geology, Charles Lyell in his Principles of Geology (Lyell 1832 [1990], vol. 2, chp. xi; Desmond 1984; Bowler 1976). Darwin defended the progressionist view against Lyell’s arguments in this chapter.

To each of the lines of objection to his theory, Darwin offered his contemporaries plausible replies. Additional arguments were worked out through the insertion of numerous textual insertions over the five revisions of the Origin between 1860 and 1872, including the addition of a new chapter to the sixth edition dealing with “miscellaneous” objections, responding primarily to the criticisms of St. George Jackson Mivart (1827–1900) developed in his Genesis of Species (Mivart 1871).

For reasons related both to the condensed and summary form of public presentation, and also as a reflection of the bold conceptual sweep of the theory, the primary argument of the Origin could not gain its force from the data presented by the book itself. Instead, it presented an argument from unifying simplicity, gaining its force and achieving assent from the ability of Darwin’s theory to draw together in its final synthesizing chapters (Ten–Thirteen) a wide variety of issues in taxonomy, comparative anatomy, paleontology, biogeography, and embryology under the simple principles worked out in the first four chapters. This “consilience” argument might be seen as the best reflection of the impact of William Whewell’s methodology (see above).

As Darwin envisioned the issue, with the acceptance of his theory, “a grand untrodden field of inquiry will be opened” in natural history. The long-standing issues of species origins, if not the explanation of the ultimate origins of life, as well as the causes of their extinction, had been brought within the domain of naturalistic explanation. It is in this context that he makes the sole reference in the text to the claim that “light will be thrown on the origin of man and his history”. And in a statement that will foreshadow the important issues of the Descent of Man of 1871, he speaks of how “Psychology will be based on a new foundation, that of the necessary acquirement of each mental power and capacity by gradation” (ibid., 488)

3. The Reception of the Origin
3.1 The Popular Reception of Darwin’s Theory
The broad sweep of Darwin’s claims, the brevity of the empirical evidence actually supplied in the Origin, and the implications of his theory for several more general philosophical and theological issues, opened up a controversy over Darwinian evolution that has waxed and waned over more than 160 years. The theory was inserted into a complex set of different national and cultural receptions the study of which currently forms a scholarly industry in its own right. European, Latin American and Anglophone receptions have been most deeply studied (Bowler 2013a; Gayon 2013; Largent 2013; Glick 1988, 2013; Glick and Shaffer 2014; Engels and Glick 2008; Gliboff 2008; Numbers 1998; Pancaldi, 1991; Todes 1989; Kelly 1981; Hull 1973; Mullen 1964). To these have been added analyses of non-Western recptions (Jin 2020, 2019 a,b; Yang 2013; Shen 2016; Elshakry 2013; Pusey 1983). These analyses display common patterns in both Western and non-Western readings of Darwin’s theory, in which these receptions were conditioned, if not determined, by the pre-existing intellectual, scientific, religious, social, and political contexts into which his works were inserted.

In the anglophone world, Darwin’s theory fell into a complex social environment that in the United States meant into the pre-Civil War slavery debates (Largent 2013; Numbers 1998). In the United Kingdom it was issued against the massive industrial expansion of mid-Victorian society, and the development of professionalized science. To restrict focus to aspects of the British reading public context, the pre-existing popularity of the anonymous Vestiges of the Natural History of Creation of 1844, which had reached 11 editions and sold 23,350 copies by December of 1860 (Secord “Introduction” to Chambers 1844 [1994], xxvii]), with more editions to appear by the end of the century, certainly prepared the groundwork for the general notion of the evolutionary origins of species by the working of secondary natural laws. The Vestiges’s grand schema of a teleological development of life, from the earliest beginnings of the solar system in a gaseous nebula to the emergence of humanity under the action of a great “law of development”, had also been popularized for Victorian readers by Alfred Lord Tennyson’s epic poem In Memoriam (1850). This Vestiges backdrop provided a context in which some could read Darwin as supplying additional support for the belief in an optimistic historical development of life under teleological guidance of secondary laws with the promise of ultimate historical redemption. Such readings also rendered the Origin seemingly compatible with the progressive evolutionism of Darwin’s contemporary Herbert Spencer (see the entry on Herbert Spencer). Because of these similarities, Spencer’s writings served as an important vehicle by which Darwin’s views, modified to fit the progressivist views expounded by Spencer, were first introduced in non-Western contexts (Jin 2020, 2019 a,b; Lightman [ed.] 2015; Pusey 1983). Such popular receptions ignored or revised Darwin’s concept of evolution by natural selection to fit these progressivist alternatives.

Outside the United Kingdom, the receptions of Darwin’s work display the importance of local context and pre-existent intellectual and social conditions. Three examples—France, Germany, and China—can be elaborated upon. In France, Darwin’s theory was received against the background of the prior debates over transformism of the 1830s that pitted the theories of Lamarck and Etienne Geoffroy St. Hilaire against Cuvier (Gayon 2013; entry on evolutionary thought before Darwin, 4.1). At least within official French Academic science, these debates had been resolved generally in favor of Cuvier’s anti-transformism. The intellectual framework provided by the “positive philosophy” of Auguste Comte (1798–1857) also worked both for and against Darwin. On one hand, Comte’s emphasis on the historical progress of science over superstition and metaphysics allowed Darwin to be summoned in support of a theory of the progress of science. The Origin was so interpreted in the preface to the first French translation of the Origin made by Clémence Royer (Harvey 2008). On the other hand, the Comtean three stages view of history, with its claim of the historical transcendence of speculative and metaphysical periods of science by a final period of experimental science governed by determinate laws, placed Darwinism in a metaphysical phase of speculative nature philosophy. This view is captured by the assessment of the leading physiologist and methodologist of French Science, Claude Bernard (1813–78). As he stated this in his 1865 treatise on scientific methodology, Darwin’s theory was to be regarded with those of “a Goethe, an Oken, a Carus, a Geoffroy Saint Hilaire”, locating it within speculative philosophy of nature rather than granting it the status of “positive” science (Bernard 1865 [1957], 91–92]).

In the Germanies, Darwin’s work entered a complex social, intellectual and political situation in the wake of the failed efforts to establish a liberal democracy in 1848. It also entered an intellectual culture strongly influenced by the pre-existent philosophical traditions of Kant, Schelling’s Naturphilosophie, German Romanticism, and the Idealism of Fichte and Hegel (R. J. Richards 2002, 2008, 2013; Gliboff 2007, 2008; Mullen 1964). These factors formed a complex political and philosophical environment into which Darwin’s developmental view of nature and theory of the transformation of species was quickly assimilated, if also altered. Many readings of Darwin consequently interpreted his arguments against the background of Schelling’s philosophy of nature. The marshalling of Darwin’s authority in debates over scientific materialism were also brought to the fore by the enthusiastic advocacy of Darwinism in Germany by University of Jena professor of zoology Ernst Heinrich Haeckel (1834–1919). More than any other individual, Haeckel made Darwinismus a major player in the polarized political and religious disputes of Bismarckian Germany (R. J. Richards 2008). Through his polemical writings, such as the Natural History of Creation (1868), Anthropogeny (1874), and Riddle of the Universe (1895–99), Haeckel advocated a materialist monism in the name of Darwin, and used this as a stick with which to beat traditional religion. Much of the historical conflict between religious communities and evolutionary biology can be traced back to Haeckel’s polemical writings, which went through numerous editions and translations, including several English and American editions that appeared into the early decades of the twentieth century.

To turn to a very different context, that of China, Darwin’s works entered Chinese discussions by a curious route. The initial discussions of Darwinian theory were generated by the translation of Thomas Henry Huxley’s 1893 Romanes Lecture “Evolution and Ethics” by the naval science scholar Yan Fu (1854–1921), who had encountered Darwinism while being educated at the Royal Naval College in Greenwich from 1877 to 1879. This translation of Huxley’s lecture, published in 1898 under the name of Tianyan Lun, was accompanied with an extensive commentary by Yan Fu that drew heavily upon the writings of Herbert Spencer which Yan Fu placed in opposition to the arguments of Huxley. This work has been shown to have been the main vehicle by which the Chinese learned indirectly of Darwin’s theory (Jin 2020, 2019 a, b; Yang 2013; Pusey 1983). In the interpretation of Yan Fu and his allies, such as Kan Yuwei (1858–1927), Darwinism was given a progressivist interpretation in line with aspects of Confucianism.

Beginning in 1902, a second phase of Darwinian reception began with a partial translation of the first five chapters of the sixth edition of the Origin by the Chinese scientist, trained in chemistry and metallurgy in Japan and Germany, Ma Junwu (1881–1940). This partial translation, published between 1902 and 1906, again modified the text itself to agree with the progressive evolutionism of Spencer and with the progressivism already encountered in Yan Fu’s popular Tianyan Lun. Only in September of 1920 did the Chinese have Ma Junwu’s full translation of Darwin’s sixth edition. This late translation presented a more faithful rendering of Darwin’s text, including an accurate translation of Darwin’s final views on natural selection (Jin 2019 a, b). As a political reformer and close associate of democratic reformer Sun Yat-Sen (1866–1925), Ma Junwu’s interest in translating Darwin was also was involved with his interest in revolutionary Chinese politics (Jin 2019a, 2022).

3.2 The Professional Reception of Darwin’s Theory
The reception of the Origin by those who held positions of professional research and teaching positions in universities, leadership positions in scientific societies, and employment in museums, was complex. These individuals were typically familiar with the empirical evidence and the technical scientific issues under debate in the 1860s in geology, comparative anatomy, embryology, biogeography, and classification theory. This group can usually be distinguished from lay interpreters who may not have made distinctions between the views of Lamarck, Chambers, Schelling, Spencer, and Darwin on the historical development of life.

If we concentrate attention on the reception by these professionals, Darwin’s work received varied endorsement (Hull 1973). Many prominent members of Darwin’s immediate intellectual circle—Adam Sedgwick, William Whewell, Charles Lyell, Richard Owen, and Thomas Huxley—had previously been highly critical of Chambers’s Vestiges in the 1840s for its speculative character and its scientific incompetence (Secord 2000). Darwin himself feared a similar reception, and he recognized the substantial challenge facing him in convincing this group and the larger community of scientific specialists with which he interacted and corresponded widely. With this group he was only partially successful.

Historical studies have revealed that only rarely did members of the scientific elites accept and develop Darwin’s theories exactly as they were presented in his texts. Statistical studies on the reception by the scientific community in England in the first decade after the publication of the Origin have shown a complicated picture in which there was neither wide-spread conversion of the scientific community to Darwin’s views, nor a clear generational stratification between younger converts and older resisters, counter to Darwin’s own predictions in the final chapter of the Origin (Hull et al. 1978). These studies also reveal a distinct willingness within the scientific community to separate acceptance of Darwin’s more general claim of species descent with modification from common ancestors from the endorsement of his explanation of this descent through the action of natural selection on slight morphological variations.

Of central importance in analyzing this complex professional reception was the role assigned by Darwin to the importance of normal individual variation as the source of evolutionary novelty. As we have seen, Darwin had relied on the novel claim that small individual variations—the kind of differences considered by an earlier tradition as merely “accidental”—formed the raw material upon which, by cumulative directional change under the action of natural selection, major changes could be produced sufficient to explain the origin and subsequent differences in all the various forms of life over time. Darwin, however, left the specific causes of this variation unspecified beyond some effect of the environment on the sexual organs. Variation was presented in the Origin with the statement that “the laws governing inheritance are quite unknown” (Darwin 1859 [1964], 13). In keeping with his commitment to the gradualism of Lyellian geology, Darwin also rejected the role of major “sports” or other sources of discontinuous change in this process.

As critics focused their attacks on the claim that such micro-differences between individuals could be accumulated over time without natural limits, Darwin began a series of modifications and revisions of the theory through a back and forth dialogue with his critics that can be followed in his revisions to the text of the Origin. In the fourth edition of 1866, for example, Darwin inserted the claim that the continuous gradualism depicted by his branching diagram was misleading, and that transformative change does not necessarily go on continuously. “It is far more probable that each form remains for long periods unaltered, and then again undergoes modification” (Darwin 1866, 132; Peckham 2006, 213). This change-stasis-change model allowed variation to stabilize for a period of time around a mean value from which additional change could then resume. Such a model would, however, presumably require even more time for its working than the multi-millions of years assumed in the original presentation of the theory.

The difficulties in Darwin’s arguments that had emerged by 1866 were highlighted in a lengthy and telling critique in 1867 by the Scottish engineer Henry Fleeming Jenkin (1833–1885) (typically Fleeming Jenkin). Using an argument previously raised in the 1830s by Charles Lyell against Lamarck, Fleeming Jenkin cited empirical evidence from domestic breeding that suggested a distinct limitation on the degree to which normal variation could be added upon by selection (Fleeming Jenkin 1867 in Hull 1973). Using a loosely mathematical argument, Fleeming Jenkin argued that the effects of intercrossing would continuously swamp deviations from the mean values of characters and result in a tendency of the variation in a population to return to mean values over time. It is also argued that domestic evidence does not warrant an argument for species change. For Fleeming Jenkin, Darwin’s reliance on continuous additive deviation was presumed to be undermined by these arguments, and only more dramatic and discontinuous change—something Darwin explicitly rejected—could account for the origin of new species.

Fleeming Jenkin also argued that the time needed by Darwin’s theory to account for the history of life under the gradual working of natural selection was simply unavailable from scientific evidence, supporting this claim by an appeal to the physical calculations of the probable age of the solar system presented in publications by his mentor, the Glasgow physicist William Thompson (Lord Kelvin, 1824–1907) (Burchfield 1975). On the basis of Thompson’s quantitative physical arguments concerning the age of the sun and solar system, Fleeming Jenkin judged the time since the presumed first beginnings of life to be insufficient for the Darwinian gradualist theory of species transformation to have taken place.

Jenkin’s multi-pronged argument gave Darwin considerable difficulties and set the stage for more detailed empirical inquiries into variation and its causes by Darwin’s successors. The time difficulties were only resolved in the twentieth-century with the discovery of radioactivity that could explain why the sun did not lose heat in accord with Newtonian principles.

As a solution to the variation question, Darwin developed his “provisional hypothesis” of pangenesis, which he presented the year after the appearance of the Fleeming Jenkin review in his two-volume Variation of Plants and Animals Under Domestication (Darwin 1868; Olby 2013). Although this theory had been formulated independently of the Jenkin review (Olby 1963), in effect it functioned as Darwin’s reply to Jenkin’s critique. The pangenesis theory offered a causal theory of variation and inheritance through a return to a theory resembling Buffon’s theory of the organic molecules proposed in the previous century (see entry on evolutionary thought before Darwin section 3.2). Invisible material “gemmules” were presumed to exist within the cells. According to theory, these were subject to external alteration by the environment and other external causes. The gemmules were then shed continually into the blood stream (the “transport” hypothesis) and assembled by “mutual affinity for each other, leading to their aggregation either into buds or into the sexual elements” (Darwin 1868, vol. 2, 375). In this form they were then transmitted—the details were not explained—by sexual generation to the next generation to form the new organism out of “the modified physiological units of which the organism is built” (ibid., 377). In Darwin’s view, this hypothesis united together numerous issues into a coherent and causal theory of inheritance and explained the basis of variation. It also explained how use-disuse inheritance, a theory which Darwin never abandoned, could work.

The pangenesis theory, although not specifically referred to, seems to be behind an important distinction Darwin inserted into the fifth edition of the Origin of 1869 in his direct reply to the criticisms of Jenkin. In this textual revision, Darwin distinguished “certain variations, which no one would rank as mere individual differences”, from ordinary variations (Darwin1869, 105; Peckham 2006, 178–179). This revision shifted Darwin’s emphasis away from his early reliance on normal slight individual variation, and gave new status to what he now termed “strongly marked” variations. The latter were now the forms of variation to be given primary evolutionary significance. Presumably this strong variation was more likely to be transmitted to the offspring, although details are left unclear, and in this form major variation could presumably be maintained in a population against the tendency to swamping by intercrossing as Fleeming Jenkin had argued.

Darwin’s struggles over this issue defined a set of problems that British life scientists in particular were to deal with into the 1930s. These debates over the role of somatic variation in the evolutionary process placed Darwinism in a defensive posture that forced its supporters into major revisions in the Darwinian research program (Gayon 1998; Vorzimmer 1970). The consequence was a complex period of Darwinian history in which natural selection theory was rejected by many research, or defended in modified form by others (Bowler 1983, 2013a; Largent 2009).

4. Human Evolution and the Descent of Man
4.1 The Genesis of Darwin’s Descent
Darwin had retained his own conclusions on human evolution quietly in the background through the 1860’s while the defense of his general theory was conducted by advocates as diverse as Thomas Henry Huxley (1825–95) in England, Asa Gray (1810–88) in the United States, and Ernst Haeckel (1834–1919) in the emerging new Germany. Darwin’s own position on the “human question” remained unclear to the reading public, and his rhetorical situating of the Origin within a tradition of divine creation by secondary law, captured in the frontispiece quotations from William Whewell and Francis Bacon, allowed many before 1871 to see Darwin as more open to religious interpretations of human origins than those of some of his popularizers.

Darwin’s interest in developing his insights into the origins of human beings and the explanation of human properties through descent with modification was, however, evident in his correspondence as early as January of 1860 when he began collecting evidence on the expressions of the emotions in human beings (Browne 2002, chp. 9). He then developed a questionnaire specifically intended to gain such information from contacts in Patagonia and Tierra del Fuego (Radick 2018). Further engagement with these issues was then generated by the discussions of Lyell (1863) and A. R. Wallace (1864), both of whom suggested that natural selection could not account for the development of the “higher” rational faculties, language, and ethical motivation (R. J. Richards 1987, chp. 4). It was then in February of 1867 that Darwin decided to remove material from his massive manuscript of the Variation of Plants and Animals Under Domestication to create a “very small volume, ‘an essay on the origin of mankind’” (Darwin to Hooker, 8 February 1867 and CD to Turner, 11 February 1867, Burkhardt, Correspondence 15: 74, 80). At this time he also sent to several international correspondents a more detailed questionnaire asking for information on human emotional expression. Further impetus to develop his views was created by the arguments of William R. Greg (1809–1881) in an essay in Fraser’s Magazine (1868), with further support by arguments of A. R. Wallace in 1869, both of whom drew a sharp distinction between human properties and those of animals (R. J. Richards 1987, 172–184). These arguments denied that natural selection could explain the origins of these “higher powers”.

Darwin’s drafting of his views on human issues, begun in early 1868, expanded into a major enterprise in which he became deeply engaged with the issue of the implications of his theory for ethics. The result of this effort devoted to anthropological topics was two separate works: the Descent of Man and Selection in Relation to Sex, delivered to the publisher in June of 1870 with publication in 1871, and its companion, Expression of the Emotions in Man and Animals, which he commenced in early 1871 with publication in early 1872.

As commentators have noted, these two works differ markedly in their arguments, and reflect different relationships to Darwin’s causal theories of natural and sexual selection, with sexual selection predominting over natural selection for the major portion of the Descent, and both of these causal theories generally missing from the descriptive approach of the Expression (Radick 2018).

Sexual selection—the choosing of females by males or vice versa for breeding purposes—had received a general statement by Darwin in Chapter IV of the Origin, but this played only a minor role in the original argument, and its importance was denied by co-evolutionist A. R. Wallace. In the Descent this was now developed in extensive detail as a major factor in evolution that could even work against ordinary natural selection. Sexual selection could be marshaled to explain sexual dimorphism, and also the presence of unusual characters and properties of organisms—elaborate feeding organs, bright colors, and other seemingly maladaptive structures such as the antlers on the Irish Elk or the great horn on the Rhinoceros beetle—that would appear anomalous outcomes of ordinary natural selection working for the optimal survival of organisms in nature. In a dramatic extension of the principle to human beings, the combination of natural and sexual selection is used to explain the origins of human beings from simian ancestors. It also accounts for the sexual dimorphism in humans, and is a major factor accounting for the origin of human races (E. Richards 2017; R. A. Richards 2013).

4.2 Darwin on Mental Powers
Although the secondary causal role of sexual selection in the development of species generally was to be the main topic of the bulk of the Descent, this plays an ambiguous role initially in the “treatise on man” that occupies the initial chapters, and functions differently in his treatment of the origins of mental powers, the moral sense, and the origin of races in this opening discussion.

In constructing this presentation, Darwin reaches back to the early Notebooks that he had separated out from the “transformist” discussions to deal with his inquiries into ethics, psychology, and emotions (see Section 1.2 above). Of particular importance for the opening discussions of the Descent was the “M” notebook, commenced in July of 1838, and “N”, begun in October of that year. On occasion he also samples the collection of entries now entitled “Old and Useless Notes”, generally written between 1838 and 1840.

The initial topic of focus in the Descent deals with the far-reaching issues concerning the status and origin of human mental properties, faculties presumed traditionally to be possessed uniquely by human beings. These properties Darwin now places on an evolutionary continuum with those features of animal behavior long regarded as instinctual. In this he placed himself in opposition to the long tradition of discourse that had distinguished humans from animals due to the possession of a “rational principle” related to their possession of a rational soul. This tradition had been given a more radical foundation in the revolutionary reflections on the relation of mind and body initiated by René Descartes (1596–1650) in the middle of the seventeenth century. Descartes deepened this distinction with the separation of the two substances—thinking substance, or res cogitans, possessed only by humans, and extended material substance, res extensa that constituted the rest of the natural world, including animals and plants, rendering animals only lifeless machines without rational faculties.

Darwin’s collapse of this Cartesian barrier with his theory of human origins outlined in the Descent continued a discussion that had been a concern of his transformist predecessors, especially Jean Baptiste Lamarck (Sloan 1999). But Darwin took this issue to a new level as he interpreted the human-animal relationship in the context of his novel theory of divergent evolution from common ancestors. Darwin also broke with the view of humans as the summit of a natural teleological process. Darwin instead denies such teleological ordering, and effectively reduces human properties to those of animals—mental as well as physical—by tracing them to their origin in properties of lower organisms.

The warrant for the identification of human and animal mental properties, however, is not supported by substantial argumentation in the Descent. The opening discussions of the treatise summarize the anatomical evidence for “homologies” —true identities—between humans and animals due to descent from common ancestors, claims already set out in Chapter Thirteen of the Origin. But the transferal of this identity of structure to inner non-anatomical “mental” properties rested on premises that are not made explicit in this text, and were not identities drawn by Huxley, Wallace and Lyell, for example, in their treatments of humans in relation to evolutionary theory, although they acknowledged the anatomical continuities.

To understand Darwin’s arguments, it is useful to return to his Notebook discussions on which he was drawing for his reasoning (see above, Section 1.2). In his “C” Notebook, opened in February of 1838, Darwin has a remarkable entry that displays very early on his commitment to a metaphysical “monism”—the thesis that there is only one substance underlying both mind and body. With this goes the thesis of a parallelism of the complexity of mental properties with those of material structure. In this entry in “C” following on Darwin’s reflections on the issue of instinct, and also recording some of his observations on animals at the Regents Park zoological gardens, Darwin comments:

There is one living spirit, prevalent over this wor[l]d, (subject to certain contingencies of organic matter & chiefly heat), which assumes a multitude of forms <<each having acting principle>> according to subordinate laws.—There is one thinking […] principle (intimately allied to one kind of organic matter—brain. & which <prin> thinking principle. seems to be given or assumed according to a more extended relations [sic] of the individuals, whereby choice with memory, or reason? is necessary.—) which is modified into endless forms, bearing a close relation in degree & kind to the endless forms of the living beings.— We see thus Unity in thinking and acting principle in the various shades of <dif> separation between those individuals thus endowed, & the community of mind, even in the tendency to delicate emotions between races, & recurrent habits in animals.— (Barrett 1987, 305)
As we follow these issues into the “M” Notebook, the assumption of a single “thinking principle,” allied to one kind of organic matter, seems then to underlie Darwin’s subsequent reflections on mind and matter. The “M” Notebook cites numerous “mental”properties common to humans and animals that generally parallel levels of material organization, similar to the identities expressed in the later Descent. The range of this universal extension of mental properties is far-reaching in these early discussions: consciousness and “free will” extends to all animals, including invertebrates:

With respect to free will, seeing a puppy playing cannot doubt that they have free will, if so all animals., then an oyster has & a polype (& a plant in some senses […]; now free will of oyster, one can fancy to be direct effect of organization, by the capacities its senses give it of pain or pleasure, if so free will is to mind, what chance is to matter […] (Barrett 1987, 536).

When these themes reappear in Chapter Two of the first edition of the Descent, Darwin seems to draw implicitly upon this matter-mind identity theory as an obvious consequence of his theory of descent from common ancestry. There he enumerates a long list of traditional human mental and emotional properties to claim that each of them are identities with the properties of simpler forms of life. The list is expansive: courage, deceit, play, kindness, maternal affection, self-complacency, pride, shame, sense of honor, wonder, dread, imitation, imagination, and dreaming. All are considered to be represented in a wide range of animals, with “play”and “recognition” found even in the ants.

When he addresses the more complex mental properties that specifically had been considered by a long tradition of discussion to be the distinctive human properties—possession of language, reason, abstract conceptual thinking, self-reflection—these again are treated as having their manifestations in other forms of life, with none of them unique to human beings. Language, the property that Descartes, for example, had considered to be the primary distinguishing character denoting the human possession of mind as distinct from matter, Darwin treats a developing in a gradual process from animal sounds that parallel the differentiation of species, illustrated by the fact that languages “like organic beings, can be classed in groups under groups” (Darwin 1871 [1981], 60). He closes his discussion of mental powers with an analysis of religious belief that derives it from imagination and belief in spirits found in aboriginal peoples. It can even be homologized with the “deep love of a dog for his master, associated with complete submissions, some fear, and perhaps other feelings” (ibid., 68). Darwin’s discussions of the relation of human and animal mental and emotional properties would set the agenda for a complex discussion that would carry into contemporary debates over animal cognition and the relations of human and animal properties (see the entries on animal cognition; methods in comparative cognition; and animal consciousness).

4.3 The Ethical Theory of the Descent of Man
The subsequent treatment of ethical issues in the third chapter of the Descent was for Darwin a topic to be approached “exclusively from the side of natural history” (ibid., 71). This issue also presented him with some of his most difficult conceptual problems (CD to Gray, 15 March 1870, Burkhardt, Correspondence 18, 68). In this discussion he also employs natural selection theory as an explanatory cause.

Under the heading of “Moral Sense”, Darwin offered some innovations in ethics that do not easily map on to standard ethical positions classified around the familiar categories of Rule or Act Utilitarianism, Kantian Deontology, Hedonism, and Emotivism. Darwin’s closest historical affinities are with the Scottish “Moral Sense” tradition of Frances Hutcheson (1694–1746), Adam Smith (1723?–1790), and David Hume (1711–1776). More immediately Darwin drew from the expositions of the moral sense theory by his distant relative, Sir James Macintosh (1765–1832) (R. J. Richards 1987, 114–122, 206–219).

Traditional moral sense theory linked ethical behavior to an innate property that was considered to be universal in human beings, although it required education and cultivation to reach its full expression (see the entry on moral sentimentalism). This inherent property, or “moral” sense, presumably explained such phenomena as ethical conscience, the sense of moral duty, and it accounted for altruistic actions that could not be reduced to hedonic seeking of pleasure and avoiding pain. It also did not involve the rational calculation of advantage, or the maximization of greatest happiness by an individual prior to action, as implied by Utilitarianism. For this reason Darwin criticized John Stuart Mill’s version of Utilitarian theory because it relied on acquired habits and the calculation of advantage (Darwin 1871 [1981], 71n5).

Darwin’s reinterpretation of the moral sense tradition within his evolutionary framework also implied important transfomations of this theory of ethics. The moral sense was not to be distinguished from animal instinct but was instead derived historically from the social instincts and developed by natural selection. From this perspective, Darwin could claim a genuine identity of ethical foundations holding between humans and animals, with the precursors of human ethical behavior found in the behavior of other animals, particularly those with social organization. Natural selection then shaped these ethical instincts in ways that favored group survival over immediate individual benefit (ibid., 98). Human ethical behavior is therefore grounded in a natural property developed by natural selection, with the consequence that ethical actions can occur without moral calculus or rational deliberation.

When moral conflict occurs, this is generally attributed to a conflict of instincts, with the stronger of two conflicting instincts favored by natural selection insofar as it favors group benefit (ibid. 84). In human beings the “more enduring Social Instincts” thus come to override the less persistent “individual” instincts.

The adequacy of evolutionary ethical naturalism as a foundation for ethical realism proved to be a point of contention for Darwin’s contemporaries and successors following the publication of the Descent. For some moral philosophers, Darwin had simply reduced ethics to a property subject to the relativizing tendencies of natural selection (Farber 1994: chp. 5). It was, in the view of Darwin’s philosophical critics, to reduce ethics to biology and in doing so, to offer no way to distinguish ethical goods from survival advantages. Not even for some strong supporters of Darwinism, such as Thomas Huxley and Alfred Russel Wallace, was Darwin’s account adequate (ibid., chp. 4). Much of subsequent development of moral philosophy after Darwin would be grounded upon the canonical acceptance of the “is-ought” distinction, which emerged with new force from the critique of “evolutionary” ethical theory. This critique began with Thomas Huxley’s own break with Darwinian ethical theory in his Romanes Lecture, “Evolution and Ethics”of 1893 (Huxley 1893). This lecture, reflecting Huxley’s views eleven years after Darwin’s death, would play an important role in the Chinese reception of Darwinism (Huxley 1895; see above, section 3.1). This line of critique also received an influential academic expression in G. E. Moore’s (1873–1958) Principia Ethica—itself an attack on Spencer’s version of evolutionary ethics (Moore 1903). Debates over the adequacy of evolutionary ethics continue into the present (see the entries on biological altruism and morality and evolutionary biology; see also, R. J. Richards 2015, 2009, 1999, 1987, Appendix 2; Charmetant 2013; Boniolo and DeAnna (eds.) 2006; Hauser 2006; Katz (ed.) 2000; Maienschein and Ruse (eds.) 1999).

4.4 Reception of the Descent
The international reception of the Descent of Man and Expression of the Emotions is a topic in need of the kind of detailed studies that surround the historical impact of the Origin. These works presented the reading public after 1871 with a more radical and controversial Darwin than had been associated with the author of the popular Journal of Researches or even the Origin itself, and his anthropological works created a watershed in the public reception of Darwin’s views (Radick 2013). The Descent finally made public Darwin’s more radical conclusions about human origins, and seemed to many of his readers, even those previously sympathetic to the Origin, to throw Darwin’s authority behind materialist and anti-religious forces. Public knowledge of Darwin’s own conclusions on human evolution before 1871 had rested on the one vague sentence on the issue in the Origin itself. The Descent made public his more radical conclusions. Even though the question of human evolution had already been dealt with in part by Thomas Huxley in his Man’s Place in Nature of 1863 (Huxley 1863), and by Charles Lyell in the same year in his Geological Evidences of the Antiquity of Man (Lyell 1863), followed by Alfred Russel Wallace’s articles in 1864 and 1870 (Wallace 1864 and online), these authors had either not dealt with the full range of questions presented by the inclusion of human beings in the evolutionary process, or they had emphasized the moral and mental discontinuity between humans and animals. Only Ernst Heinrich Haeckel had drawn out a more general reductive conception of humanity from evolutionary theory and he had not ventured into the specific issues of ethics, social organization, the origins of human races, and the relation of human mental properties to those of animals, all of which are dealt with in the Descent. Darwin’s treatise presented, as one commentator has put it, “a closer resemblance to Darwin’s early naturalistic vision than anything else he ever published” (Durant 1985, 294).

Darwin’s extension of his theory to a range of questions traditionally discussed within philosophy, theology, and social and political theory, has shaped the more general history of Darwinism since the 1870s. It set the agenda for much of the development of psychology of the late nineteenth century (R. J. Richards 1987). It also hardened the opposition of many religiously-based communities against evolutionary theory, although here again, distinctions must be made between different communities (Ellegård 1990, chp. 14). Such opposition was not simply based upon the denial of the literal scriptural account of the origins of humankind, an issue that played out differently within the main religious denominations (Haught 2013; Finnegan 2013; Swetlitz 2013; Artigas, Glick, & Martinez 2006; Moore 1979). The more fundamental opposition was due to the denial of distinctions, other than those of degree, between fundamental human properties and those of animals.

Furthermore, the apparent denial of some kind of divine guidance in the processes behind human evolution and the non-teleological character of Darwin’s final formulations of the natural selection theory in the fifth and sixth editions of the Origin, hardened this opposition. His adoption from Herbert Spencer of designator “survival of the fittest” as a synonym for “natural selection” in the fifth edition of 1869 added to this growing opposition. As a consequence, the favorable readings that many influential religious thinkers—John Henry Newman (1801–1890) is a good example—had given to the original Origin, disappeared. The rhetoric of the Descent, with its conclusion that “man is descended from a hairy quadruped, furnished with a tail and pointed ears” (Darwin 1871 [1981], 389), presented to the public a different Darwin than many had associated with the popular seagoing naturalist.

The new opposition to Darwin is reflected in the many hostile reviews of the Descent to appear in the periodical press (R. J. Richards 1987, 219–230). Particularly at issue were Darwin’s accounts of the origin of ethical principles and intelletual powers, including language, self-reflection, abstract thinking and religious belief as derivations from animal properties (Anon. 1871)

The profound revolution in thought that Darwin created, however, was eventually recognized even by his one-time harsh critics. The once leading British comparative anatomist Richard Owen (1804–1892), who had long been estranged from Darwin since his harsh review of the Origin in 1860, nonetheless could comment on the occasion of Darwin’s burial in Westminster Abbey in a letter to Horace Walpole:

The great value of Darwin’s series of works, summarizing all the evidence of Embryology, Paleontology, & Physiology experimentally applied in producing Varieties of Species, is exemplified in the general acceptance by Biologists of the Secondary Law, by Evolution, of the ‘Origin of Species’ […] In this respect Charles Darwin stands to Biology in the relation which Copernicus stood to Astronomy. […] [Copernicus] knew not how the planets revolved around the sun. To know that required the successive labours of a Galileo, a Kepler and finally a Newton […] Meanwhile our British Copernicus of Biology merits the honour and the gratitude of the Empire, which is manifest by a Statue in Westminster Abbey. (Richard Owen to Horace Walpole, 5 November, 1882, Royal College of Surgeons of England Archives, MS0025/1/5/4).

The subsequent history of the debates surrounding Darwin’s achievement forms a complex story that involves much of the history of life science, as well as ethical theory, psychology, philosophy, theology and social theory since 1870. For a general summary of recent scholarship see Ruse 2013a and articles from this encyclopedia listed below.

5. Summary and Conclusion
This article has intended to give a historical overview of the specific nature of Darwinian theory, and outline the ways in which it differed from the theories of predecessors in the nineteenth century (see the entry evolution before Darwin). The eventual general consensus achieved by the middle of the twentieth century around the so-named “Synthetic” theory of evolution that would combine population genetics with a mathematical analysis of evolutionary change, has formed a successful research program for more than half a century (Smocovitis 1996; Mayr and Provine 1980; Provine 1971). This “synthesis” has been challenged in recent decades by the current movement known as evolutionary developmental theory, or “evo-devo”. This development represents in some important respects a return to presumably discarded traditions and lines of exploration of the nineteenth and early twentieth centuries which sought to link evolution with embryological development, and to a complex understanding of genetics, with re-examination of the effects of external conditions on inheritance (Gilbert 2015; Newman 2015; Laubichler and Maienschein 2007; Gissis and Jablonka 2011; Pigliucci and Müller 2010; Amundson 2005; Gilbert, Opitz and Raff 1996). Where these debates and revisions in evolutionary theory may lead in another fifty years is a matter of speculation (Gayon 2015 in Sloan, McKenny and Eggleson 2015).

More general philosophical issues associated with evolutionary theory—those surrounding natural teleology, ethics, the relation of evolutionary naturalism to the claims of religious traditions, the implications for the relation of human beings to the rest of the organic world—continue as issues of scholarly inquiry. The status of Darwin’s accounts of human mental powers and moral properties continue to be issues of philosophical debate. The adequacy of his reliance on sexual selection to explain sex and gender roles in human society form heated topics in some feminist scholarship. Such developments suggest that there are still substantial theoretical issues at stake that may alter the future understanding of evolutionary theory in important ways (Sloan, McKenny, & Eggleson [eds] 2015).

1. History
As noted in the separate entry, critical theory can be thought of narrowly or broadly. Thought of broadly, ‘critical theory’ picks out philosophical work which combines a moral-political conviction that human flourishing is presently blocked, and a methodological conviction that interrogation of prevailing norms, practices, and concepts is necessary (but perhaps insufficient) to remove this blockage. Thought of narrowly, ‘critical theory’ picks out a specific area of philosophy animated by these twin convictions – the work of philosophers associated with the Frankfurt Institut für Sozialforschung (Institute for Social Research). This group is often referred to as the ‘Frankfurt School’.

This entry will use ‘critical theory’ in the narrow sense. This entry will be further narrowed by focusing almost exclusively on the first generation of the Frankfurt School. For economy, I will use ‘critical theory’ as shorthand for the more unwieldy ‘first-generation critical theory’. Closely related figures – like Walter Benjamin (1892–1940) and Ernst Bloch (1885–1977) – will not be collected under this phrase, but explicitly picked out as and when they are relevant.

The Frankfurt School is often spoken of as having three generations. Core figures in the first generation include Max Horkheimer (1895–1973), Theodor Adorno (1903–1969), and Herbert Marcuse (1898–1979). Horkheimer, who would become a close collaborator with Adorno, took directorship of the Institute in 1930. The Institute was closed by the Nazis in 1933. Horkheimer was instrumental in relocating and re-starting the Institute, eventually settling in America in 1934. Adorno and Marcuse followed. The most famous of their works would be Dialectic of Enlightenment (Adorno & Horkheimer 1944 [2002]), One-Dimensional Man (Marcuse 1964), and Negative Dialectics (Adorno 1966 [2006]). As important as this American context – and exposure to American popular culture – would be to their aesthetics, so too was the German cultural milieu of the 1920s and 1930s. For example, before joining the Institute Adorno had studied musical composition with the atonal composer Alban Berg (later commemorated in Adorno’s Alban Berg: Master of the Smallest Link, 1968 [1991]), befriended philosopher and critic Siegfried Kracauer, and written musical criticism for the journal, Musikblätter des Anbruch (Claussen 2008: 52–56, 102–106, 152). Walter Benjamin’s ideas were broadly disseminated via his friendship with Adorno (for more on their relationship, including with respect to aesthetics, see Rosen 2004, Buck-Morss 1977 & 1991, Nicholsen 1997b). The ideas of Georg Lukács and Ernst Bloch were also influential on the first-generation critical theorists, as we will see.

The second and third generations of critical theory are roughly marked by the coming to prominence of Jürgen Habermas (1929–) and Axel Honneth (1949–), respectively. The three generations are not merely distinguished by their personnel. There are important theoretical differences. The Cambridge Habermas Lexicon begins its ‘Aesthetics’ entry (Duvenage 2019) with the statement that ‘Whereas aesthetics plays an important role among the thinkers of the first generation … this is not so for Habermas.’’ (For an opposing view of Habermas’ relationship to aesthetics, however, see Duvenage 2003, McMahon 2011, Mackin 2022.) Honneth seldom mentions aesthetics (though see Honneth 2007). While there are valuable remarks on aesthetics in the work of both, then, they do not obviously belong in a discussion of the characteristic shape of the interface between critical theory and aesthetics. Critical theory’s distinctive treatment of aesthetics is thus confined largely to the first generation.

2. Why Does Critical Theory Have an Aesthetics?
In 1937’s ‘Traditional and Critical Theory’ Horkheimer offers the following statement about the programme he and his colleagues pursue, and its moral urgency –

If activity governed by reason is proper to man, then existent social practice, which forms the individual’s life down to its least details, is inhuman, and this inhumanity affects everything that goes on in the society …. The goal at which the [critical theorist] aims, namely the rational state of society, is forced upon him by present distress … It is the task of the critical theoretician to reduce the tension between his own insight and oppressed humanity in whose service he thinks …. (Horkheimer 1937 [2002: 210, 217, 221])
It is not surprising that this approach produced books with titles like Eclipse of Reason (Horkheimer 1947), One-Dimensional Man (Marcuse 1964) or Prophets of Deceit (Lowenthal & Guterman 1949). But the emergence of books with titles like Aesthetic Theory (Adorno 1970 [2004]), or The Aesthetic Dimension (Marcuse 1978) is perhaps harder to anticipate. Given the nature of critical theory, and its urgent pursuit of concrete improvement in people’s material and social lives, one might wonder why critical theory has an aesthetics at all.

One answer is that ‘critical theory’ has no need for an aesthetics. Its practitioners simply happened to like to think about art and did so. It is certainly true that many of the members of the first generation had biographical connections to, or a pre-established interest in, the world of art. But critical theory has an aesthetics for theoretical, not biographical, reasons. To make these reasons clear we need to take a detour through the work of Karl Marx (1818–1883), and then Georg Lukács (1885–1971).

2.1 Commodity Fetishism
Critical theory is grounded in a very particular approach to Marx, which emphasizes capitalism’s power to determine the world of individual thought and experience (see Kautzer 2017). This approach rests on a keen interest in commodity fetishism, a phenomenon which Marx discusses relatively briefly in volume one of Capital:

A commodity is … a mysterious thing, simply because in it the social character of men’s labour appears to them as an objective character stamped upon the product of that labour; because the relation of the producers to the sum total of their own labour is presented to them as a social relation, existing not between themselves, but between the products of their labour. This is the reason why the products of labour become commodities, social things …. This I call the Fetishism which attaches itself to the products of labour, so soon as they are produced as commodities, and which is therefore inseparable from the production of commodities. (Marx 1867 [1932: 83])
For Marx, commodity fetishism is an effect produced by the objective structure of social exchange. The buying and selling of goods draws equivalences between the goods exchanged. But this equivalence is performed not by comparing the labour time expended on those goods, but by comparing what appear to be properties of the commodities themselves. Price indices are driven by social facts about exchange and production; but these social facts vanish from view, and the prices themselves appear to be properties of objects. (“This gold bar is worth £__, and thus equivalent in value to 1,000 coats, 2,000 bricks and so on” – not “The socially necessary labour time involved in gold mining is such that a gold bar’s exchange value is expressed as …”). Capitalism thus presents itself as natural. This conceals the fact that exchange value arises not from the nature of things, but rather from the way we organize our labour. In turn, this conceals the fact that the way we organize our labour is not natural but in fact open to change.

On Marx’s account commodity fetishism affects the way in which we experience, and therefore theorize about, the social world. It conceals the true nature of capitalism. This concealment can be understood as something like an optical illusion. Marx uses the instructive analogy of the appearance of air:

The recent scientific discovery, that the products of labour, so far as they are values, are but material expressions of the human labour … by no means, dissipates the mist through which the social character of labour appears to us to be an objective character of the products themselves …. [T]his fact appears to the producers … to be just as real and final, as the fact, that, after the discovery by science of the component gases of air, the atmosphere itself remained unaltered. (Marx 1867 [1932: 85–86])
While the appearance of air – or of commodities – is not altered by our coming into scientific knowledge of their true constitution, the fact remains that we can and have acquired this knowledge in spite of that appearance. Thus, for Marx all that is needed to ‘see through’ commodity fetishism is to employ reason to enquire into what lies beneath the apparent nature of capitalism.

2.2 Reification
Lukács’ most influential work, History and Class Consciousness (1923), extends and revises Marx’s analysis of commodity fetishism. Unlike Marx, Lukács does not see capitalism as merely presenting a misleading appearance (as an optical illusion might) but exerting an effect on our very way of thinking and perceiving altogether (as a hallucination or delusion might). Accordingly, Lukács held commodity fetishism to have a systemic and general influence on consciousness. He used the term ‘Verdinglichung’ or ‘reification’ to name the broader effects he saw as stemming from commodity fetishism. Reification covers not only thought about or adjacent to the economy, but thought in general:

In the process we witness, illuminatingly, how here, too, the contemplative nature of man under capitalism makes its appearance … all issues are subjected to an increasingly formal and standardised treatment and in which there is an ever-increasing remoteness from the qualitative and material essence of the ‘things’ to which bureaucratic activity pertains. (Lukács 1923 [1971a: 97–99])
The richness and unpredictability of the world is glossed over by a form of thought which presumes complete agreement between abstract concepts and particular things. And this narrowing of thought is replicated in a narrowing of experience. Reification as a form of thought is grounded in and enforced by a broader tendency towards standardization which capitalism carries with it, from commodification (the increasing tendency to convert goods into products produced for exchange in line with the demands of the market), to bureaucratization (the administration of the social world according to inflexible rules), and so on. The claim, then, is that under capitalism we come to conceive of and experience the world in terms of general categories.

This is a problem because these general categories are, it is claimed, overly restrictive. The world has properties (causal, moral, and functional) which are not captured by these categories, and hence are excluded from reified thought and reified experience. Facts which might undermine the present social order (the exploitation integral to capitalist production, for example) are excluded from thought and experience. This also has moral implications. General moral and political categories (like ‘citizen’, ‘human’, ‘worker’, and so on) will tend towards excluding persons who do not conform to the restrictive standards these categories come with.

The idea of reification – if we hope to overcome it, or indeed to explain our ability to perceive it – requires us to posit some counter-reifying force. For Lukács, it is the proletariat (working class) that are (potentially) this force. The proletariat need only realize the exploitative nature of capitalist production and recognize that they have the power to change this process. The proletariat are necessarily always on the brink of this realization, in Lukács’ view, as their working conditions are intrinsically counter-reifying. They themselves are the contingent human labour which is concealed by the apparently natural and necessary world of capitalism and commodities.

2.3 Critical Theory’s Account of Reification
While Lukács’ account of reification exerted great influence on the Frankfurt School (see Feenberg 2017, Kavoulakos 2017), the proletarian strand of his thought did not. Returning to Horkheimer’s seminal “Traditional and Critical Theory” we find the following remark:

But it must be added that even the situation of the proletariat is, in this society, no guarantee of correct knowledge. … Even to the proletariat the world superficially seems quite different than it really is (Horkheimer 1937 [2002: 213–214]).
This leaves critical theory in a difficult position. If reification is total, and counter-reifying forces are totally absent, then Horkheimer’s claim to be thinking in ‘service of’ those oppressed by capitalism is incoherent. Critical theory requires a counter-reifying force to explain how it can perceive and see beyond the epistemic errors produced by reification.

For Marx, commodity fetishism was a problem with the comprehension of labour, which could be solved either through reading more accurate literature about labour (hence the writing of Capital), or better acquainting oneself with the reality of the production process (hence Marx’s ability to write Capital). Lukács appears to identify revolutionary proletarian consciousness as the means to undo the effects of reification, although the mechanics of its formation are not entirely clear. For critical theory, by contrast, commodity fetishism and reification are not problems which can be overcome by modifying either the content of experience (by reading Capital, say) or the social position of the experiencer. One can learn as much as possible about the conditions of the working class, and be as close to the production process as one likes, but reification will still obtain.

For critical theory, reification is a problem with the very form of experience itself; and the solution to reification will come through processes which can engage and manipulate that form of experience. Thus, for critical theory reification is an aesthetic problem in its original and broadest sense: as concerned with the realm of sensible experience.

Critical theory’s task will be to find avenues which can disrupt the influence of reification and make the genuine state of things – and the genuine possibilities for change – open to thought and experience. Several avenues for producing this effect were explored, but chief among them was art, and aesthetic experience.

3. The Problem of Commodification
Lukács, whose early work had been so influential on Critical theory, later became much closer to Soviet orthodoxy, even to the extent that he repudiated his earlier work on reification. He also broke with his earlier, equally influential, work on aesthetics (like 1910’s Soul and Form). Here too Lukács moved into closer alignment with Soviet thought. The Soviet art movement known as Socialist realism explicitly thematized concrete social and political factors in art, in order to instil a correct understanding of them in the art appreciator. Lukács was not uncritical of the actual implementation of this movement, especially under Stalin (Lukács 1971b: 116–130), and nor does he deny the quality and power of the ‘critical realists’ who likewise include concrete historical detail, but without explicit socialist ideology (Lukács 1971b, chapters 2 and 3). But above all it is realism in opposition to the ‘decadent formalism’ (Lukács 1971b: 133–135) of modernism that Lukács urged as best serving the moral and political aims of Marxism.

Adorno, Marcuse, and Benjamin, by contrast, found their favourite examples of the liberating power of art in multiple schools and time periods, including modernism, nearly all of which refused any overt political content. They also openly questioned the efficacy and quality of much political art (see, e.g., Marcuse 1978: 19; 33–39, Schoolman 1976: 58–60, Klassen & Blumenfeld 2018, Adorno 1961 [1977a], 1977b). This rejection was seen by many, including the later Lukács, as evidence of elitism, political disengagement, and immoral indifference to the world at large (see Zuidervaart 1994: 28–44 for an overview).

However, critical theory’s rejection of ‘politically engaged’ art is not driven by disagreement with the politics of such artworks. Rather, it stems from an apparently apolitical disagreement about the necessary and appropriate relationship between content and form. critical theory generally emphasizes the primacy of form in explaining both art’s achievement and its counter-reifying effects (see Hartle 2018 for an overview of the development of this position). The demands of such formal success are (it is claimed) incompatible with direct political engagement. To clarify this, we need to look more closely at what form and content mean in this context.

3.1 Form and Content
For critical theory, aesthetic value is reducible neither to form nor content. A complex relationship between the two is at the core of critical theory’s aesthetics. It is claimed that form and content are inextricable and mutually informing. But here again, we should not confuse this with more familiar positions. The claim is not that form and content are identical (as in A.C. Bradley’s infamous claim in 1909’s Oxford Lectures on Poetry, or Cleanth Brooks’ (1947: 192–215) ‘Heresy of Paraphrase’). Rather, the claim most often advanced is that content is converted into, or ‘sedimented into’, form while still not becoming identical with it.

This idea requires further explanation. When Marcuse and Adorno claim that content is converted into form within art, they are best understood not as advancing the claim that the surface themes and content of the artwork are rendered formal, but as claiming that the meaning of the artwork is expressed primarily by the formal properties of the artwork.

For example, while Kafka’s The Trial has as its surface content a story about a man who is subjected to an interminable and senseless trial for an unknown crime, its true meaning (according to Adorno) is an expression of certain features of capitalism (see further O’Connor 2013). This expression of its deeper meaning is achieved through the texture and organization of the novel itself, rather than in its apparent themes. Nowhere does The Trial baldly state that capitalism has produced an absurd and inhuman form of life. Nor, importantly, is it necessary that Kafka believed such a thing. Critical theory’s claim is that the truth of life under capitalism is in some way communicated to the form of artworks directly. (Some problems with this view are presented in section 3.3.)

To see why content must be converted into form in this way for art to be successful, and why this seemingly abstruse issue prevents critical theorists from endorsing expressly political art, we need to look once more at reification.

The theory of reification claims that thought has taken on a characteristically abstract and instrumental character. It is this form of thought which ultimately underlies the persistence and dangers of capitalism. Anything which can be assimilated by this form of thought is rendered exchangeable and serves as evidence of the appropriateness of that form of thought itself. This means that moral or political claims in art can themselves become part of their commodity value, and fail to disrupt the form of thought which caused the moral or political injuries that motivated the art itself. The dissenting novel, music, or film is something which for all its sincerity is still offered alongside all the others, and whose mode of delivery and consumption replicates, and vindicates, the very form of exchange – and hence consciousness – it seeks to undermine.

3.2 Avoiding Commodification
If art is able to show a form of life and thought outside of capitalism, then it must resist absorption by the characteristic structure of capitalism. Via Marx, critical theorists see the characteristic structure of capitalism as commodity exchange. Commodity exchange has the characteristic function of rendering objects perfectly exchangeable by assigning them monetary value. Via Lukács, critical theorists see commodity exchange also having a characteristic, reified kind of experience and thought – that which sees objects as all conforming to general laws, concepts, and types.

From this, we see that successful art must resist being easily turned into a generic commodity, and must also resist being formed by and wholly comprehensible through pre-set types. In art’s case, these pre-set types would include compositional conventions, cliches, platitudes and the like.

These are structural reasons why art must resist easy adoption by the market (and, in turn, audiences). It must also resist easy adoption to avoid contradicting its own meaning. If art is aimed against exchangeability and cliché, then it must also be aimed against having its content easily converted into products and clichés.

This is why form is primary in understanding art’s ability to undo the effects of reification. It is only through the problematization of the relationship between form and content, and art and its consumption, that the meaning of an artwork can be protected from commodification and nullification. Art is obliged to ceaselessly formally innovate, and to ceaselessly reject pre-set established compositional norms.

In this way, art’s meaning – its critical relationship to capitalism – is communicated in its form, and not in its explicit subject matter. Artworks avoid baldly stating claims about the inhumanity of contemporary society – these could become slogans; be resold and defused – and instead show it through their challenging formal organization.

How, exactly, this critical content becomes converted into formal properties is not clear. Nor is it clear how broad social problems come to be encapsulated in specific artworks authored by specific artists. This is a problem which critical theory never fully mastered. In Adorno’s work, there is no suggestion that this formalization of content is a product of the artist’s conscious or subconscious intention. Rather, the process is ‘blind’, and the social content enters the artwork, and creative process, not as thematic content but as formal problems with which the artist is faced (see Hulatt 2016a).

Marcuse (1978: 14–15), for his part, likewise emphasizes the migration of social content into form, and notes that it is a central perplexity in Marxist aesthetics. In a move which mirrors Adorno’s attempt to see social problems as translated into artistic problems, Marcuse (1978: 41) explains this migration partly in terms of the social preformation of the meaning of artistic materials. The very stuff out of which art is made (‘word, colour, tone’) carries socially encoded meanings, expectations and conventions. This ‘limitation of aesthetic autonomy’, he writes, ‘is the condition under which art can become a social factor’.

Unlike Adorno, however, Marcuse also sees art as a repository of ‘transhistorical’ truths and features. These relate both to certain core definitional features of art and aesthetic response (Marcuse 1978: 15–16) and to core features of the transhistorical ‘species being’ he sees as underlying human experience (Marcuse 1978: 29). Marcuse introduces these non-historicist elements in order to rule out a reductive Marxist account which would claim that art’s function, quality and meaning is chained to its society and class position. Marcuse holds that aesthetic properties cannot be so reducible, as this would render our appreciation of artworks across epochs and economic systems inexplicable. Further, it would nullify art’s important ability to speak beyond and outstrip contemporary ideals and norms.

While for Adorno art’s relationship to its social content was thoroughly hostile – both in its defiance of contemporary norms, and its demonstration of the revisability of those norms – Marcuse offers a more variegated picture. Art critically engages with and negates society, but also describes unrealized potentials for improvement (see, e.g., Marcuse 2006: 140–149). This difference between the two thinkers will be discussed further in section 4.

3.3 Popular Culture
Adorno and Horkheimer coined the phrase ‘Culture Industry’ in their jointly authored book Dialectic of Enlightenment. It was intended ironically, as an insulting oxymoron. This irony has been overtaken by history. The music and film spheres, for example, proudly refer to themselves as industries. This outcome illustrates, after a fashion, the thesis and limits of critical theory’s critique of popular culture.

To critical theory, culture is in a process of coming to an end. This coming to an end is precipitated by ever-increasing strength of norms of exchange and standardization (‘industry’) in controlling the production of art (‘culture’) (see further Hulatt 2016b). This thesis is developed in part sociologically, through examination of the mechanics of radio transmission, the nascent Hollywood system, the distribution and sale of records, and so on. Empirical research into this claim was pursued in various ways, including the Princeton Radio Research Project at which Adorno worked once he arrived in America (see further Jenemann 2007).

The thesis was also developed through aesthetic analysis of popular culture itself. Critical theory found Western popular artforms wanting, judging whole genres and media devoid of merit. Adorno’s criticisms of specific popular artworks were often mordant and unsympathetic, and have had an outsize effect on perception of critical theory’s stance towards popular culture. It can appear that critical theory simply rejects popular culture as inferior, and seeks a return to the kind of high culture many critical theorists enjoyed in fin-de-siecle Germany. Such snobbery would appear particularly odd in supposedly radical Marxist philosophy. However, the broader account of popular culture – its superiority to ‘high culture’ in some respects, and the tragedy of its unrealized technical potential – is innovative and often overlooked.

In a 1936 letter to Benjamin, Adorno remarks that popular and ‘high’ art are ‘two torn halves, which do not add up to a whole’ (Adorno 1977c: 123). This remark conveys a number of things which must be borne in mind. The existence of two separate spheres of popular culture and high art is a reflection of the wrong state of things – their opposition and polarization would not be part of a good society. Both popular culture and high-art have capacities and deficiencies which the other lacks – indeed, they each form a mirror image of the other. However, these two spheres of culture cannot be re-unified by sheer force of will – they do not add up to a unified whole, because they have been objectively driven apart by the nature of the social whole. (Marcuse 1965 takes a similar view.)

We see, then, that Adorno does not see popular culture as merely coarse product. It in fact preserves properties key to art, and serves as a rebuke to ‘high’ culture. For example, popular music is pleasant to listen to, and more or less immediately accessible. This kind of accessibility and pleasure is part of what ideal art would be – and it is part of the failure of modern art that it has been forced to lose both its accessibility and its beauty. (We will enter into the reasons why it suffers this loss momentarily.) Adorno is also not blind to the economic injustices which govern the world of high art – the leisure time and disposable income necessary to acquire a taste in classical music for example.

Conversely, classical music has the virtue that it delivers on what it promises – genuine novelty, pure aesthetic satisfaction and formal achievement. By contrast, popular music promises novelty, ungoverned satisfaction of impulses, and perhaps some associated lifestyle, but is forced to repeatedly renege on these promises (see for example Adorno’s discussion of syncopation in Jazz, in Lewandowski 1996). One way of putting Adorno’s point is that popular culture is not objectionable because it stimulates the passions, but because it does not truly satisfy them (Rebentisch & Trautmann 2019: 22–23). This criticism is shared by Marcuse, who sees increasingly permissive popular culture not as objectionable because it is permissive (he is in favour of relaxed sexual mores, for instance) but because it never delivers on its promise. For Marcuse the release of emotions in cultural products – be they sexual longing, political frustration, or repressed aggression – is allowed just enough to ensure the popularity of the product, and not explored in its full transformative power.

This idea of reneging on promises also underwrites Adorno’s criticism of movements to popularize high culture. For example, Adorno deeply objected to the transmission of performances of Beethoven over the radio. This was not because Beethoven was too good for the public, but because the technology involved was not good enough for the public. The genuine experience of a live performance was being replaced by a low resolution transmission – and the public were invited to believe they had received the genuine article. (Or so Adorno claims, Adorno 1945: 209–210.)

This thread runs through critical theory’s treatment of popular culture – not a suspicion of popularity, accessibility, or pleasurability, but a suspicion of the failure to genuinely provide these things. Popular music and cinema promise excitement and novelty – but in fact work according to pre-set schema. Popular media promises to bring excitement of high culture into the home – but in fact the transmission is poor, and incapable of properly conveying what you wish to listen to. This is the mirror image of high culture’s failure. Quoting Brecht, Adorno notes that culture’s ‘mansion is built out of dogshit’ (Adorno 2006: 366). By this he means that high culture is dependent on a society whose inequality and inhumanity makes the better form of life high art outlines ever more impossible. (For more on the role of Brecht in Adorno’s thought, see Rothe 2018.)

Under capitalism, both high culture and popular culture are not good enough for the public; not vice versa.

4. Aesthetic Experience Against Reification
In section 3.2, the counter-reifying force of art was explained negatively. The unusual formal organization of artworks serves to protect their content from being nullified by the effects of commodification and reification. But the position is not simply that the artwork conceals its meaning such that it cannot be easily commodified. It is that the meaning of the artwork in some fashion breaks with and undermines the false consciousness it has been protected against. Art is thus not merely defensively organized, but aggressively organized also. It does not merely elude reification, but actively combats it.

This claim is one of the more vexed and complex elements of critical theory’s aesthetics. To anticipate, it will be the subject’s experience of the artwork which is held to have this aggressive counter-reifying effect. That experience will be elicited by the appreciator’s active participation in attending to the form/content organization of the artwork.

The counter-reifying effect of art appears to be socio-historically specific (it can be lost over time) and critical (the artwork appears to indict and overturn certain pathologies of thought and social organization). In this section we will look more closely at how various critical theorists explain this view.

4.1 Ernst Bloch
We can find one source of this idea in the work of a contemporary, Ernst Bloch, who had a marked influence on the Frankfurt School. Bloch saw art as combining a faithful account of both the current state of things, and of possibilities usually ignored. This is the ‘not-yet’ which Bloch saw as concealed by conventional experience, but forcibly disclosed by the successful artwork (as well as other cultural products – see Kellner and O’Hara 1976). The utopian aspect to the artwork – its representation of another form of life – is in some sense fantastical and imaginary. It is not a depiction of how things are, but a depiction of how they genuinely might be. But in this way, art discloses the close proximity of another way of ordering life, and the malleability of that which appeared as necessary and natural (see Moir 2018, Levitas 1990).

As with Adorno and Marcuse, Bloch apparently paradoxically combines a keen attention to the formal constitution of the artwork and its autonomy (Bloch 2000: 118) with a commitment to the claim that social conditions enter into the artwork (Bloch 2000: 129–141). Crucially, it is the combination of the autonomous processes of art and the participation of the appreciator which yields up a disruptive experience (Bloch 2000: 143). This disruption within the aesthetic experience serves to point beyond the integration of the artwork’s form and its material; and via the relationship between the artwork and the social content it integrates, it likewise points beyond the established social order (Bloch 2000: 117, 149, 155–156). This is the utopian moment integral to great art, for Bloch. In Spirit of Utopia Bloch largely develops this thought through analysis of music, but in later works like Principle of Hope (Bloch 1954–59), the same approach is recapitulated and applied not only to the various artistic media, but other cultural areas also (see Bloch 1989).

This core vision – of the artwork as eliciting in aesthetic experience a changed outlook on a reified society – is inherited by both Adorno and Marcuse. But both revise Bloch’s approach in differing ways.

4.2 Adorno
For Adorno art does not directly show the world as it really is, but makes plain the contradictions and distortions internal to reified consciousness itself. Rather than disclosing new potentials for action and change, art instead discloses the full estrangement between reified consciousness and the world. In other words genuine aesthetic experience is a process of disillusionment. Our reified consciousness perceives no obvious difference between the world as we take it to be, and the world as it is. But art forcibly discloses this difference. The art appreciator comes to learn the depth and extent of their ignorance, and the urgency of breaking with the dominant form of thought. The utopianism of Bloch reappears in a more muted form – art gives us awareness that the demands and tendencies of capitalist society are not absolute but could in principle change. Adorno’s caveat is that we do not know how or in what direction this change should be effected. This is due to the broader ethical dislocation produced by modern society. (For differing takes on Adorno’s negative ethics see Finlayson 2002, Freyenhagen 2011, 2013, Bernstein 2001; a transcribed discussion between Adorno and Bloch on the nature of utopian thinking provides useful further detail, in Bloch 1989: 1–18).

The way in which art demonstrates the disconnection between reified thought and the world is highly complex. We can say that for Adorno art engages the conceptual structure of thought and experience, and guides it such that this structure is lead to collapse in the course of its being applied. This is a power it shares with philosophy, with the key difference that philosophy achieves this explicitly – through manipulation of and argument about concepts in the course of their application in thought – and art accomplishes it through the manipulation of aesthetic material. To answer how the ‘hermetically sealed’ artwork is able to do this, we would need to spell out Adorno’s claim that extra-aesthetic content is sedimented into formal aesthetic problematics in individual artworks. This is beyond the scope of the present entry (but see Hulatt 2016a, Nicholsen 1997a, Paddison 2011, Sherratt 2009: 169–209).

4.3 Marcuse
Marcuse sees artworks as having a liberating potential, and as disclosing to us possibilities for change. Art discloses these possibilities in both a destructive and creative way. It is destructive in that it serves as an ‘indictment’ of certain governing forms of thought and experience. But it is also creative; art serves to re-present the genuine state of things, and thus uncovers the objective potentials for ‘liberation’ which are concealed there (Marcuse 1978: 6). Marcuse’s work can thus be understood as an amalgam of some of the formal sophistication of Adorno’s aesthetics with the utopian emphasis of Bloch’s account.

For Bloch and Adorno, engagement with the artwork leads in radically differing directions. For Adorno, aesthetic experience does not point towards a better future, nor show any signs of such a future in the present. It rather shows the inhumanity of the present. This is the ‘indictment’ Marcuse likewise finds in art. For Bloch, by contrast, aesthetic experience presents an account of the genuine state of things, which includes already existing anticipations of a better form of life. These ‘anticipations’ provide the intelligible, if incomplete, link between the present and the utopia that could emerge from it. These Marcuse often refers to as moments of ‘liberation’.

It may seem that the two points from Bloch and Adorno are in tension, and thus that Marcuse is ill-advised to try to combine them. However, Marcuse introduces a third theoretic element which resolves the apparent tension – the work of Sigmund Freud (1856–1939). The rational, critical element of Marcuse’s account conforms significantly to Adorno’s approach – but the utopianism of Bloch is recast in a psychoanalytic register.

Marcuse understands the utopian function of art to be discharged by its ability to facilitate ‘desublimation’ – the expression of repressed urges. This should not be confused with catharsis. Catharsis – in which emotions are activated and then ‘purged’ – leaves the subject pacified, free of the troublesome energies that were activated. This pacifying effect of catharsis in art is criticized by Marcuse, and desublimation is held to avoid it.

For Marcuse, desublimation is an expression of repressed emotions, urges and potentialities of which the appreciator was unaware. On learning of their existence, the appreciator is made aware of ‘repressed potentialities of man and nature’ and is granted an ‘emancipation of sensibility’ which points towards the form of life, and of sensibility, which revolution would bring about (Marcuse 1978: 8–9; see further 43–44). This is continuous with Marcuse’s broader political program, for which a better world would not only entail re-organization of the structure of society, but also of the psychological structure that society imposes on individuals (see Kellner 1999, Marcuse 1955).

For Marcuse, then, the aesthetic experience is both critical and rationally ordered, and an arena for the liberation of drives, emotions and potentials. These respectively articulate the contradictions and intolerability of the present, and unharness the libidinal resources which could realize the potential for a better future.

5. Natural beauty
In the 20th century philosophers – anglophone and non-anglophone – largely shifted away from discussing the aesthetics of nature. The Frankfurt School were a marked exception to this tendency. In their emphasis on the moral and aesthetic significance of nature’s beauty, critical theorists anticipate many features of contemporary work in environmental aesthetics. Like environmental aestheticians, critical theorists understand our appreciation of nature’s beauty to be morally significant. They also likewise see aesthetic appreciation of nature to be bound up with the recognition of and resistance to humanity’s destruction and exploitation of nature.

Critical theorists differ sharply from contemporary environmental aestheticians, however, in their account of what carries this moral significance. It is not nature ‘in itself’, without human interference, that is of prime importance. Any idea of nature being ahistorically beautiful ‘in itself’ is rejected. It is nature in relation to our current human capacities, needs, and projects which carries both beauty and a moral impetus to relate to nature in a less damaging fashion.

This section will touch briefly on some of the distinctive features of their work on this theme.

5.1 Nature and History
Adorno, Horkheimer, and Marcuse consistently problematized the distinction between nature and history. They did not claim that nature – as picked out by the physical sciences – was historically relative. They rather claimed that the concept (and experience) of nature – as a realm of facts and values outside of human control – was historically determined in its content and means of application.

When Adorno and Horkheimer claim that what is natural is historical they are interested in normative conceptions of nature which are used either to make the contingent appear necessary (‘capitalism simply follows human nature’) or to advocate for inhumane treatment of persons. Likewise, they propose that nature as experienced is influenced by these historical factors. (Adorno’s complex account of nature is developed in its various strands in Cook 2011, Vogel 1996: 51–101, Flodin 2018, 2022.)

Natural beauty in both its scope (what counts as natural) and quality (those aesthetic properties which can attach in virtue of an object’s being natural) is seen as a historical phenomenon (Hammer 2015: 45–72). This further means that natural beauty stands under the threat of cliché, ideological misuse, and co-optation, just as artworks do. Simply, the aesthetic properties of nature shift across time – and what is thus appropriate in judging natural beauty likewise develops over time (Daniels 2020).

Any well-developed aesthetics of nature includes not only a criterion of appropriate judgement, but also a criterion of the appropriate objects of judgement. Trivially, aesthetic judgements of nature cannot be well-formed when aimed at an object which is the product of, and perceived under the description of, complete artificiality. Conventionally, the meaningful debate to be had is over what degree, if any, objects produced by artifice are appropriate objects of the appreciation of natural beauty.

Critical theory adds a unique complication to this debate. It denies that the merely natural is an appropriate object for aesthetic experience (Johnson 2011). We will explore this in the next section.

5.2 Mere Nature
Critical theory sets a high store on the aesthetic experience of nature, but not on the experience of mere nature. This is made particularly stark in Aesthetic Theory, where Adorno compares raw nature with industrial materials:

[N]ature that has not been pacified by human cultivation, nature over which no human hand has passed – alpine moraines and taluses – resembles … industrial mountains of debris. … [Human artifice] is said to have ravished nature, yet under transformed relations of production it would just as easily be able to assist nature and on this sad earth help it to attain what perhaps it wants. … [I]n every particular aesthetic experience of nature the social whole is lodged. Society … determines what nature means[.] (Adorno 1970 [2004: 89])
This rejection of an aesthetics of nature in the raw is combined with a keen interest in natural beauty. This appears paradoxical, but can be elucidated through comparison with contemporary environmental aesthetics.

For environmental aesthetics, mere nature is indeed an appropriate object of aesthetic attention (see, e.g., Budd 1996: 211–213, Saito 1998). The properties of mere nature, as opposed to artworks, are held to undermine some traditional dichotomies. For example, Ronald Hepburn (1966) influentially observed that nature needs to be ‘framelessly’ appreciated as an enclosing space. The usual strict separation between an art-object and its environs is not present, as nature is both the immediate object of interest (a copse of trees, for example) and the enclosure continuous with the object (the vista in which the copse is situated). Separately, it has been claimed that appropriate aesthetic appreciation of nature benefits from, or requires, theoretical understanding of nature itself and its structure (for examples of such scientific cognitivism, see Carlson 1979, Eaton 1998, Parsons 2006). Such scientifically grounded appreciation of nature is held to be objective appreciation of nature as what it is.

Critical theory’s rejection of mere nature can be seen as stemming from a similar desire to appreciate nature ‘as what it is’, and a similar conviction that doing so will dissolve the oppositions and dichotomies familiar from art. But critical theory urges us to further dissolve the dichotomy between nature and human artifice itself.

Adorno, Horkheimer, and Marcuse see nature and humanity as not separate but continuous (for an overview of this, and its relation to Lukács and Marx, see Feenberg 1981: 240–255). And so proper contemplation of nature ‘as-it-is’ is of nature-for-us, as parts of that nature. Mere nature is nature which stands opposed to us, and which we are approaching as if it were radically different to us, rather than a fellow piece of nature. This is why Adorno sees untamed nature as resembling unrefined industrial material – in both cases (the merely natural; the industrial byproduct) we have objects which appear to stand opposed to human need, and present as hostile to us.

This is what stands behind remarks by both Adorno and Marcuse to the effect that both humanity and nature are not fully realized. Nature by itself, for Adorno and Marcuse, is unreconciled and hostile towards humans, who are themselves part of nature. For nature’s own benefit, a different kind of relationship between humans and nature is required. And natural beauty is held to point towards it (Krebber 2020: 184–186).

It is common to find in environmental aesthetics an admission that the area of enquiry is bound up either with moral intuitions about nature’s value, or in some way importantly tied to a broader moral project of environmental conservation and transformation (e.g. Saito 1984, Saito 2018, Carlson 2018, Alcaraz León 2022, Carlson & Lintott 2008). Here again, Adorno and Marcuse can be understood as sharing this feature and transforming it. Their environmental aesthetics is not embedded in care for nature-without-humans, but for nature-for-humans, and correlatively, humans-for-nature.

5.3 Reconciliation, Ruins and Landscapes
Adorno and Marcuse embed aesthetic response to nature into a broader project of reconceiving and reorienting the relationship between humanity and nature. Following on from a myriad of influences (some anthropological – chiefly Henri Hubert and Marcel Mauss (1902–1903), James George Frazer (1890), and Roger Caillois (e.g., 1937) – and some philosophical) critical theory understands the relationship between humanity and nature to have been predominantly ‘dominating’, just as humanity’s relationship to itself has been dominating and oppressive. Similarly, just as aesthetic experience offers a vision of a different order of social being, so too does aesthetic experience of nature offer a vision of a reconciled relationship between human agency and nature.

Mere nature, then, is ineligible to produce such an insight, as mere nature is outside of and opposed to a relationship with humanity. This leads Adorno to find images of reconciliation in, paradoxically, images of bygone eras of the exploitation of nature. Here Adorno intersects with the rich aesthetic traditions of both the picturesque and the ruin, but brings a very different sensibility to these phenomena. In Aesthetic Theory he writes,

Historical works are often considered beautiful that have some relation to their geographical setting, as for instance hillside towns that are related to their setting by the use of its stone …. So long as progress … does violence to the surface of the earth, it will be impossible – in spite of all proof to the contrary – completely to counter the perception that what antedates the trend is in its backwardness better and more humane. (Adorno 1970 [2004: 84])
What grounds Adorno’s positive aesthetic evaluation here is the image of a relationship between nature and humanity which, from our timeframe, appears more pacified. Given the environmentally disastrous logic of modern society, the images of a reconciled, utopian relationship to nature can be found only retrospectively, in the image of the less-bad relationships to nature which have now passed away.

6. Conclusion – Critical Theory and Aesthetics
We can pick out four features of critical theory’s distinctive treatment of aesthetics. The first of these is a product of critical theory’s general methodology at that time. First generation critical theory largely holds that any object of experience or theory is a part in and reflective of a social totality of facts and processes (see further Jay 1992). The form and depth of this ‘reflection’ varies; but the general view is that any element of this totality could be determined by, and inform us about, any other. This warrants speculative kinds of philosophical interpretation, in which facts apparently limited to one sphere (of logic, or psychology, say) are in fact determined by and reflective of apparently disconnected spheres (of economic exchange, or social institutions, say). Art is no exception to this approach. Both works of high art and ephemeral pieces of pop culture can have philosophical, social, and political content as parts of their objective constitution.

Secondly, this emphasis on the philosophical richness of art is combined with a primary interest in aesthetic form. In turn, this amalgam is wedded to a conviction that aesthetic experience – despite being formally rigorous and content-laden – can offer a form of insight unavailable through conventional conceptual reasoning. This insight – precisely by being a break with the kind of experience moulded to the ‘wrong state of things’ – is held to have emancipatory promise.

Thirdly, the tensions and instabilities between these jointly held aesthetic methodologies are not accidental, but intentional. Critical theory refuses to attempt to deliver static definitions, but also refuses to do without such definitions. (It is neither ‘rationalized’, nor irrational.) Art really does have general features; but successful artworks always both engage and destabilize general concepts. There is an emphasis on the necessity of using concepts to understand art, and on the ability of artworks to ultimately elude conceptual capture. This complex approach – which is incapable of delivering a closed definition of art or aesthetic value – is intended to prioritize fidelity to aesthetic experience over dogmatic conceptual structures.

Fourthly, and following from the preceding three features, there is the seemingly paradoxical conviction that artworks are political and practical via their very refusal of explicit politics and practicality. It is artworks of surpassing quality, attended to for their own sake, that have a liberating potential. Critical theory tends to assume (and sometimes explicitly argue) that artists who primarily pursue a non-artistic goal in their art (political or otherwise) cannot realize this level of quality, and art-appreciators who seek a pay-off in art (political or otherwise) cannot properly attend to the value of artworks.

These four features all reach their most extreme expression in the work of Theodor Adorno. But they are also pursued at differing levels of extremity and emphasis in other critical theorists and thinkers associated with them, most obviously Marcuse, Benjamin and Bloch.

For critical theorists, there is a balance to be struck between analysing art – and hence articulating it in conceptual terms – and making clear the importance of the artwork’s ability to outstrip concepts altogether. The preceding has been an account of the ways in which critical theory has explored and handled this demanding balancing act, and the broader theoretic considerations which, together with the artworks investigated, entered into that balance.

. History of Empirical Research on Art and Aesthetics
Modern scientific approaches to art and aesthetics find their origins in Germany in the nineteenth century, in some of earliest works in experimental psychology. Most notably, with his Vorschule der Aesthtik (1876), Gustav Fechner pioneered what came to be known as “bottom-up aesthetics”, which tried to discover general laws of taste by examining preferences for simple geometric shapes such as rectangles of varying proportions, colors, and arrangements of lines (for a summary of “bottom-up” aesthetics, see Nadal & Ureña 2022).

In mid-twentieth century, art historian and philosopher Thomas Munro—who founded the American Society of Aesthetics in 1942 and served as the editor of the society’s publication The Journal of Aesthetics and Art Criticism between 1945 and 1964—continually expressed optimism about the prospect of integrating philosophical and scientific approaches to aesthetics (1928, 1948, 1951, 1956, 1963). In “The Psychology of Art: Past, Present and Future” (1963), Munro observes that philosophers have actually been asking, for a long time, questions about art and aesthetics that are at least partly empirical, such as how do artists come to create works? how does the experience of art affect the audience’s character? are there rules by which the arts can please and instruct? do some works universally please across epochs and cultures? how can different species of aesthetic pleasure be taxonomized?. In “Methods in the Psychology of Art” (1948), he notes that authors in The Journal of Aesthetics and Art Criticism often make empirical claims as part of their arguments, and so should use empirical methods more.

Not all philosophers have been as optimistic as Munro. George Dickie (1962) argued that psychology is not relevant to aesthetics. Some of Dickie’s worries echoed earlier ones: for example, he argued that the psychology of art was impoverished by simplified stimuli, such as the use of geometric shapes rather than real artworks (compare Arnheim 1952). Other worries were due to his specific conceptions of philosophy of art and aesthetics, and philosophy in general. First, Dickie believed that aesthetics is “concerned only with the language and concepts which are used to describe and evaluate works of art” (1962: 289), and so questions outside of this conception—such as how do artists come to create works?—are simply irrelevant. Second, Dickie believed that philosophy is discontinuous with science, such that “the problems of ethics are not solved by a scientific study nor are the problems of the philosophy of science” and aesthetics is no exception (1962: 301–302).

While Dickie’s criticisms, and hardline view, held considerable sway over philosophical aesthetics and the philosophy of art in the second half of the twentieth century, this has not continued. From the late 1980s onwards, philosophical aestheticians and philosophers of art have increasingly appealed to the findings of cognitive sciences (for a summary, see entry on aesthetics and cognitive science), and to a lesser extent to the findings of empirical aesthetics, and particularly evolutionary aesthetics (see, for example, Dutton 2009). Indeed, from around 2010 onwards, philosophers joined the psychologists of art and empirical aestheticians in conducting empirical studies.

In some ways, it is difficult to pinpoint exactly where modern empirical aesthetics and the psychology of art ends, and the experimental philosophy of art and aesthetics, begins. But a rough characterization can be made along the lines that Dickie suggested. Empirical aesthetics and the psychology of art is primarily concerned with characterizing the psychological responses to art and aesthetically significant objects. It answers questions such as: what is the nature of the responses (such as chills, pleasure, changes in self-conception)? what features of aesthetic objects and artworks tend to elicit these responses (such as curvature, certain colors, etc.)? are there systematic individual differences in relation to this? Whereas experimental philosophy of art and aesthetics—as a branch of philosophy—is primarily concerned with empirically studying conceptual distinctions. It answers questions such as: do people think that a moral demerit can also be an aesthetic demerit? do people think that something can be art if it does not have any aesthetically valuable properties? what is the nature of the folk’s concept of art and beauty—are they purely descriptive or evaluative concepts?

Nonetheless, it is important to stress that, at best, this way of carving up the distinction picks out a central tendency of the two fields. In reality, the work done by researchers in philosophy, including experimental philosophical aesthetics, and empirical aesthetics overlaps in many ways. To give a few examples. Philosophers have had a longstanding concern in trying to establish whether there is a distinctive kind of aesthetic state of mind, and empirical aestheticians have recently become interested in this question. A couple of influential ideas about this from philosophy are that the pleasure taken in beauty is of a disinterested kind, where this roughly means that it is not the result of desire satisfaction, or does not essentially produce desires (see Kant 1790); and that approaching objects aesthetically involves adopting a distanced attitude where we disengage from the object practically, and do not relate it to our standing desires or interests (Bullough 1912). More recently, empirical aestheticians have attempted to tackle this issue with the tools provided by neuroscience and psychology. For example, Marcus Nadal and Martin Skov (2018) have argued against the idea that there is a distinctive sui generis state of mind, on the grounds that, for example, the same neural hardware that is involved in responding to pleasant tasting food and sex have been shown to be involved in the appreciation of aesthetic objects. By contrast, Amy Belfi and colleagues (2019), for example, have shown that aesthetic appreciation involves activation of the Default Mode Network, which they suggest may show that self-reflection, rather than self-detachment, may form part of what makes aesthetic responses unique. Philosophers have also been interested in explaining beauty in terms of a harmony between the beautiful objects and our psychological faculties in some ways (as present in, for example, Hume 1757a and Kant 1790), and psychologists have sought to explain aesthetic appeal in terms of processing characteristics, such as the fluency with which an object is experienced (Reber et al. 2004). Both experimental philosophers as well as aesthetic psychologists have tried to elucidate the features of moral actions and traits that lead to attributions of beauty, as well as the kind of psychological state appreciation of this kind of beauty gives rise to (see, for example, Doran 2023; see §6).

Unfortunately, notwithstanding the many overlapping concerns, the fields of philosophical aesthetics (including experimental philosophical aesthetics) and empirical aesthetics have remained largely siloed. On the side of philosophical aestheticians, this has continued to lead to missed opportunities for testing the empirical aspects of their theories and for experimental philosophical aestheticians to methodologically innovate. And on the side of empirical aestheticians, this has led to a failure to benefit from the theoretical and argumentative sophistication that tends to be characteristic of the best work in philosophy. However, there are signs that this is changing. Empirical aestheticians are increasingly attempting to test claims drawn from philosophy (for example, Brielmann & Pelli 2017; Winner 2019), and experimental philosophers of art and aestheticians are increasingly working with psychologists, if not empirical aestheticians yet (for example, Humbert-Droz et al. 2020). Nowhere is this more clear than in the case of work on awe and the sublime, where philosophers have worked productively with psychologists, and where philosophical claims have informed the design of empirical studies and the resultant theory building in turn (for example, Clewis 2021; Keltner & Haidt 2003; Shiota et al. 2007; Arcangeli et al. 2020; Shapshay 2021).

2. Definition of Art
“What is art?” stands as one of the central questions in philosophical aesthetics. In fact, we can ask different questions about the concept of art. First, we may ask about its extension: which works count as art? Second, we may ask about its intensional structure: are there conditions necessary and sufficient for a work to count as art? Third, we may ask about its function: is calling a work ‘art’ a praise, or merely a classification? Since many philosophers of art agree that the definition of art should be compatible with art practices and the way ordinary people think about art, unsurprisingly, it was also one of the first questions in aesthetics to be empirically investigated.

Which works count as art? In his first empirical study on intuitions about the extension of the concept of art, Richard Kamber (2011) presented participants with a large number of descriptions and images of objects and asked whether they would classify these objects as art. The main focus of this study was putting to test prominent definitions of art: aesthetic definitions claim that art is created with an intention to be aesthetically appreciated; institutional definitions claim that art is created by an artist and presented to an artworld; and historical definitions claim that art is created with an intention to belong to the same set of objects as previously created works of art. Kamber’s approach was to examine a variety of “hard cases” discussed in the aesthetics literature, such as objects of low aesthetic value and objects that were made prior to social art-making practices. He concluded that none of the art theories succeed in fully tracking people’s intuitions about the various hard cases, but the aesthetic definition of art, which holds an artwork to be an object created with an intention to provide people with aesthetic experiences, was somewhat more successful than others. In a follow-up study, Kamber and Taylor Enoch (2019) also asked participants to justify their decisions of what is art by selecting some of fourteen possible reasons, which included those that emphasized intentional creation, the creator’s consciousness, beauty or evoking imaginative experiences. In this study, justifications involving intentionality were the most often chosen. Nevertheless, this study again indicated that none of the main definitions of art fully aligned with what the study participants, predominantly art professionals or art lovers, found intuitive.

However, these studies have received some criticism. While Annelies Monseré (2015) is sympathetic to Kamber’s criticism of philosophers’ reliance on intuitions in defining art, she is equally skeptical of reliance on ordinary people’s intuitions. Instead, she advocates for a more indirect role for intuitions, on which they are not used to directly justify any specific definition of art, but as elucidations of how the concept gets invoked in practice. Ellen Winner (2019: 21) notes that Kamber “designed his study very informally, testing a grab bag of theories, using only one or two examples to test each one”, and that it might benefit from a more sensitive measure than a dichotomous choice of ‘yes’ or ‘no’, as was used.

Although neither folk nor expert intuitions strictly require a work to have high aesthetic value for it to be classified as art, more beautiful (or more liked—a more common concept in the psychological literature, which nowadays tends to steer clear of discussions of beauty) works do tend to be classified as art more often. Matthew Pelowski and colleagues (2017) investigated the relationship between ratings of liking and attributions of art status. Participants were shown a set of 140 digital images of abstract paintings, hyperrealistic paintings, poorly-executed paintings and ready-made sculptures, and were asked to spontaneously classify them as ‘art’ or ‘not art’. They were also asked to rate the extent to which they liked those images. Pelowski’s findings revealed a positive correlation where higher ratings of liking were associated with a greater likelihood of being categorized as art, which provides some support for the aesthetic definitions of art.

Can art be defined by necessary and sufficient conditions at all? Elzė Mikalonytė and Markus Kneer (forthcoming) investigate whether the folk concept of art is an essentialist or a non-essentialist one; in other words, whether it can be defined by a set of individually necessary and jointly sufficient conditions. In contrast to Kamber’s studies mentioned earlier, they asked people who were not art professionals. In two vignette studies, Mikalonytė and Kneer manipulated three properties of artworks—namely, being intentionally created, having aesthetic value, and being institutionally recognized—aiming to see whether any of those properties, corresponding to the main essentialist art definitions, are seen by the folk as necessary conditions for an object to be classified an artwork. The results, similar to Kamber’s, also suggest that the folk concept of art is not an essentialist concept, but rather a cluster concept. Interestingly, none of the three properties were considered necessary—there were cases where art status was ascribed even to accidentally created objects. This finding is surprising considering the role that intentional creation and the creator’s intentions are thought to play in this context in the literature on philosophical aesthetics (Mag Uidhir 2013), as well as some studies in the psychology of art. For example, Jean-Luc Jucker et al. (2014) discovered that when people are asked to classify artefacts into art and non-art, their decisions are guided by inferences about the creator’s intentions. George Newman and Paul Bloom’s (2012) results showed that participants’ beliefs about whether an object was intended to be an artwork or not had an important effect on how they see a physically identical copy of the same object. More generally, it is widely believed that people classify objects into artefact kinds by making inferences about the creator’s intentions (Bloom 1996). Mikalonytė and Kneer’s study, however, is not the only one showing that intentional creation is not seen by the folk as necessary—they have also discovered that although people consider AI-generated paintings to be art to a similar extent as human-created paintings, they are not very willing to consider AI-creators artists. In the context of artistic creation, mental state (including intention) ascription to AI agents is relatively low, and this might partially explain why AI robots are not accepted as artists (Mikalonytė & Kneer 2022). However, another study by Mikalonytė and Kneer suggests that the phenomenon of art without an artistic intention might not be confined to the realm of AI-generated art: even human creators are seen as capable of creating artworks without intending to do so (Mikalonytė & Kneer forthcoming).

Is calling a work ‘art’ to praise it, or to merely classify it? Shen-yi Liao, Aaron Meskin, and Joshua Knobe (2020) take a different tactic to understand the concept of art. Their aim is not to uncover its extension, or to defend any specific concept of art, but to clarify its nature. Descriptivists about the concept of art contend that to call something ‘art’ merely conveys a classificatory status, whereas evaluativists contend that to do so is to convey a positive evaluation. Liao, Knobe, and Meskin use linguistic patterns to argue that the concept of art is neither. Instead, it is a “dual character concept”, which involves characteristic values that are realized by concrete features (Knobe, Prasada, & Newman 2013). To diagnose the nature of the concept of art and other art concepts, they examine participant responses to sentences of the following schema:

That is not good, but it is true [concept].

Extant research shows that dual character concepts, but not descriptive concepts, tend to sound fine when combined with the “true” modifier (Knobe, Prasada, & Newman 2013). So, for merely descriptive concepts, the sentence makes little sense. For example, it sounds weird to say “that is a true sonnet”. Moreover, for positive evaluative concepts, the sentence also makes little sense because of the explicit negative evaluation. For example, it sounds weird to say “that masterpiece is not good”. Since participants think that the sentence “that is not good, but it is true art” sounds fine, Liao, Meskin, and Knobe argue that the concept of art is neither descriptive nor evaluative, but dual character.

3. Ontology of Art
Ontology of art (see entry on history of the ontology of art) aims to discover what kind of things works of art are, which ontological category or categories they belong to, whether it is possible and what it means to create or destroy them, and what it means for two different objects to be ‘the same’ work. Works of art can be divided into two categories: repeatable and non-repeatable. The former category consists of musical works and other kinds of works that exist in multiple instantiations. The latter category consists of singular works of art where there is only one original instance of that work and all others are merely copies of the original, for example, paintings or sculptures. This distinction also has implications for the way people evaluate work of art.

For repeatable artworks, the most pressing ontological question concerns the conditions under which two performances are of the same work. Christopher Bartel (2018) investigated intuitions on the repeatability of pop songs. He presented study participants with three scenarios describing three pairs of musical performances, with each of these pairs reflecting one of the following differences: a difference in provenance (two identically sounding performances are played by two different bands), in affect (one performance sounding humble, and one sounding dramatic), and in connotation (the two performances are played by different bands, with different lyrics and expressive of different emotions). Bartel found that a difference in provenance does not make a difference to whether the song is identical across different performances, but differences in affect and in connotation do.

Elzė Mikalonytė and Vilius Dranseika (2020) focused on works of classical music. They created scenarios that reflected the main points of disagreement among theories of the individuation of musical works, such as sonicism (which claims that identity of musical works depends on their acoustic properties only), instrumentalism (which also adds the instrument used to perform the musical work to the list of identity-conferring properties), and contextualism (which also emphasizes the importance of musico-historical context). In contrast to many other studies, Mikalonytė and Dranseika target intuitions about the identity of two performances at the same point in time. They presented the participants with seven scenarios, including, for example, two identically sounding performances of two identical scores which were independently created by two composers, or two performances that differ only with respect to their emotional expressivity. They concluded that folk intuitions correspond most with pure sonicism, the theory which claims that work identity depends solely on its (non-timbral) acoustic properties, although the identity of the composer is also an important factor. While Bartel concludes that pop music songs are not easily repeatable—in many cases, participants were inclined to deny that two performances were of the same song—Mikalonytė and Dranseika’s study points in the opposite direction: people consider works of classical music to be quite easily repeatable.

Nemesio Puy (2022) has criticized this approach for relying solely on textual vignettes, lacking real musical stimuli (for more on this discussion, see section 8). Puy’s experiments show that, compared to Bartel (2018) and Mikalonytė and Dranseika (2020), when study participants have the chance to hear musical works, they are even more likely to answer the individuation (or repeatability) question in the sonicist way. This tendency is especially apparent if the question is asked immediately after hearing two musical samples, without any contextual information being provided.

Two more empirical studies in this area of inquiry investigate people’s intuitions regarding the persistence of musical works—in other words, their identity over time. Mikalonytė and Dranseika (2022) explored the hypothesis that musical works’ identity crucially depends on their purposes: different versions of a musical work remain versions of the same work if and only if they retain the same overall point they were created for. Their results provide some support for this hypothesis, but purpose was not considered to be a necessary condition. Again, this study shows that people have mostly sonicist intuitions—they believe that the identity of musical works mostly depends on their acoustic properties, and this is considered to be a much more important criterion in judgments of identity compared to the overall purpose of the work as intended by the composer.

Elzė Mikalonytė and Clément Canonne (forthcoming) found that judgments of the identity of artworks—both musical works and paintings—are partially normative. Their results provide some support for the Phineas Gage effect—according to which, changes in valued qualities, and especially moral properties, change identity judgments—suggesting that if a musical work undergoes some changes and becomes more aesthetically valuable, people are more likely to say that it is still the same musical work compared to the condition when the musical work becomes less aesthetically valuable. However, the effect observed was easily overridden by changes in material identity or moral value and for this reason it does not seem sufficient to claim that musical works are essentialized in terms of their aesthetic value.

All of the empirical studies in the ontology of musical works so far have focused on their identity conditions. Many other topics remain unexplored by experimental philosophers, such as the way musical works come into existence and cease to exist. An overview of such topics and a systematic survey of philosophers’ appeals to ordinary intuitions regarding musical works is presented in Mikalonytė (2022), where she also discusses how the ontology of musical works could benefit from further empirical research.

Unlike repeatable artworks that can have many genuine and potentially equally valuable instances, other works of art, such as paintings or sculptures, can only have one physical object. The relationship between different instances of these artworks is of copy and original, where only one physical object can count as a given artwork. This has important implications both for identity judgments and aesthetic evaluation.

Given that many non-repeatable artworks share similarities with ordinary, non-artistic artefacts, it is helpful to compare studies that explore the role of material continuity in judgments of artefact and artwork persistence. Sergey Blok, George Newman, and Lance Rips (2005) investigated people’s intuitions about the persistence of various types of objects, including persons, animals, plants, and artefacts. Participants were presented with a vignette about each of these objects either (a) being disassembled into individual particles, transported and reassembled again, or (b) being replaced by an identical material copy, the original of which is destroyed. People were inclined to see artefacts as the same after being ‘copied’. In a related study, David Rose and colleagues (2020) have investigated intuitions about the Ship of Theseus puzzle across different cultures. Their results suggest that people are ambivalent about whether it is the continuity of form or the continuity of material that is decisive in matters of identity. Results of both studies suggest that material identity might not be the main criterion for judgments of persistence of artefactual objects. However, extant empirical research suggests that judgments of the persistence of artworks are different from those of other artefacts. When presented with a scenario about someone creating a copy of either an artwork or of a tool and destroying the original object, people are not willing to see the copy as ‘the same’ object, even if the only difference between the tool and the artwork is labeling them as such (Newman, Bartels, & Smith 2014).

Some philosophers, such as Arthur Danto (1973), claim that a copy of a non-repeatable artwork is always aesthetically less valuable. Empirical research also suggests that people tend to value a copy of an artwork less than the original, even if the two are perceptually indistinguishable (Rabb, Brownell, & Winner 2018). George Newman has conducted a series of studies to explain this effect. One possible reason is that the created object is evaluated as the result of a unique creative act; another is that there is a perceived physical contact between the object and the original creator (Newman & Bloom 2012). When a duplicate object is made by someone other than the original creator, people are less inclined to see it as the same object (Newman, Bartels, & Smith 2014). Since people believe that an object’s or person’s essence can be transferred by means of physical contact, Newman and Smith (2019) hypothesized—and confirmed—that differences in evaluation between a copy and an original painting are mediated by the artwork’s perceived anthropomorphism; that is, feelings that the artwork seems alive and expresses emotions. In some cases, physical contact is not necessary for beliefs in contagion: intentional contact may be enough (Stavrova et al. 2016). Shen-yi Liao, Aaron Meskin, and Jade Fletcher (2020) examined the contagion effect in the museum context. They asked the participants (a) whether the objects in the gallery embody “the very being” of their creator, and (b) whether they are unique, and they found that contagion has an effect on perceived aesthetic value both in the museum and laboratory context, while uniqueness matters only in the latter.

Finally, there is one more way aesthetic information has an effect on ontological judgments, even if this kind of research does not speak directly to the ontology of art: aesthetic preferences may influence judgments of personal identity. Previously, it had been thought that we consider humans and their ‘true selves’ to be fundamentally morally good, and that changes to someone’s moral character influence judgments of a person’s identity. Joerg Fingerhut and colleagues discovered that changes in our aesthetic taste are also seen as profoundly transformative changes: when someone’s aesthetic preferences change, they cease to be the same person (Fingerhut et al. 2021).

4. Aesthetic Judgments
A particularly fruitful area of experimental philosophical research has centered around the question of how objective our aesthetic judgments are, and related issues such as the possibility of aesthetic testimony. This has principally been done by either examining meta-aesthetic intuitions, or by examining the amount of agreement in aesthetic matters, and the source of this agreement.

With respect to the issue of objectivity, many philosophical aestheticians have thought that aesthetic judgments intend to express truths about the way the world is, and that some people have better access to these truths than others. David Hume (1757a) suggests that some people are better able to detect and weigh the aesthetic merits of a work than others—they have delicate taste—and that works that are reliably appreciated over time and across cultures are those which are truly good. Immanuel Kant (1790) suggests that while our judgments of beauty are based in pleasure, they command universal agreement—that is, we expect others to make the same judgments as us. In this respect, aesthetic judgments have been thought to be unlike statements of personal taste, such as ‘broccoli is delicious’, about which there can only be blameless disagreement; and like empirical judgments, such as ‘there is a piece of broccoli on my plate’, about which there can be genuine disagreement. Indeed, some have thought that the way the folk act presupposes such a realist conception of aesthetic judgments, with Noël Carroll (1999), Nick Zangwill (2005), and Peter Kivy (2015) noting that we argue with each other about aesthetic matters.

Taking this as a starting point, a number of psychologists and experimental philosophers have presented findings that suggest realism cannot be given special status as the commonsensical view, and philosophical accounts of aesthetic judgments do not need to accommodate realist intuitions. This line of research started with Geoffrey Goodwin and John Darley (2008), who asked people to determine whether comparative aesthetic judgments—such as ‘Shakespeare was a better writer than Dan Brown’—were true, false, or a matter of opinion. Most participants described aesthetic statements as opinions (despite the strength of agreement with each statement) and they did this more frequently than in the case of comparable moral, factual statements, or statements reflecting social conventions.

Then, in a series of studies led by Florian Cova, the folk’s meta-aesthetical views were further tested by presenting participants with an aesthetic disagreement—such as where someone finds a sunset beautiful and the other does not—between two interlocutors (or between the participant and an interlocutor), and asking participants whether one person is correct, both are correct, or neither is correct. Across different kinds of objects (including natural objects and art widely recognized to be beautiful, as well as objects that study participants personally find beautiful), type of aesthetic judgments (including judgments of beauty and ugliness), and across a wide range of different countries, it has been found that most select the option “Neither is correct” (Cova & Pain 2012; Cova, Olivola, et al. 2019; for further studies utilizing the disagreement method, see Andow 2022).

Returning to the comparative method, Nathaniel Rabb, Alex Han, and colleagues (2022) have presented further evidence against the idea that the folk are aesthetic realists by explicitly asking participants whether aesthetic judgments are matters of opinion or matters of fact. They showed that people believe that aesthetic judgments are subjective even after learning that one of the two works has been historically acclaimed, or even when they liked one artwork much more than another (though, for criticisms of this study, see Moss & Bush 2021).

Supporters of the presumption in favor of realism have, however, fought back. Zangwill (2019) argues that Cova and his colleagues’ studies are not about whether people think aesthetic judgments can be true or false, but rather about whether a given person is right or wrong, and so leave the presumption in favor of realism unscathed. The distinction Zangwill is aiming at is as follows: Someone who guesses correctly that it is raining outside would be saying something true when they say that “it is raining outside”, but they cannot be described as right. Being right is a matter of being justified in saying something. In addressing Zangwill’s critique, in the same design where participants are asked to consider an interlocutor disagreeing with them in making various kinds of judgments, including aesthetic judgments, Cova (2019) asked participants whether one, both or neither person said something true or false. The results here were quite different from those of the studies conducted to date: with the modal response being that only one person says something true (40%), followed closely by the response that says that both say something true (39%). Despite these differences, Cova suggests that these do not support the idea that the folk tend to be realists about aesthetic judgment on the grounds that the pattern of responses did not match the pattern for paradigmatic factual judgements (that is, a disagreement about whether something is steel, where 71% of participants selected the response that only one person said something true).

A further objection has been raised to this work on folk meta-aesthetics by Filippo Contesi and colleagues (2024). They point out that all the studies discussed above reveal that the folk’s explicit meta-aesthetic views are subjectivist, and that this is consistent with what supporters of aesthetic realism say. These supporters—such as Carroll (1999), Zangwill (2005), and Kivy (2015)—claim that the folk are implicitly realist in arguing about matters of taste, even if they hold explicit subjectivist attitudes, as expressed by hackneyed proverbs such as “there’s no accounting for taste”. As such, Contesi and colleagues suggest that Cova’s results are inconclusive, and that disproving folk aesthetic realism as it has been conceived of by realists to support the plausibility of their position would require a different methodological approach.

Turning away from critiques of aesthetic realism to positive accounts of folk meta-aesthetics, experimental philosophers have also suggested that folk meta-aesthetical views might nonetheless allow for some degree of objectivity, and have found that the concept of good taste might behave differently from that of aesthetic truth.

Cova (2019) suggests that the folk might be expressivists about aesthetic judgments, and that they may think that there can nonetheless be correctness conditions for aesthetic judgments, insofar as people can, for example, be mistaken about the cause of the feelings they express. In one study to begin to test this position, Cova presented participants with a case where someone judges the Eiffel tower to be beautiful as a result of being high on drugs, or as a result of seeing the Eiffel tower unimpaired. The results reveal that participants were less likely to say that a judgment of beauty was true and more likely to say that the judgment was false when the experience was the result of drugs. Similarly, across five studies that manipulated the type of disagreement (cross-cultural or intercultural, or internal disagreement of one individual over time) and asked participants about the possibility of error in aesthetic judgments, James Andow (2022) found that while people do not hold realist beliefs, they do believe that they have correctness conditions (though see Murray 2020 for results suggesting that people do not think that disagreement implies that they are seen as incorrect).

Moreover, although most studies on aesthetic judgments point in the direction of subjectivism, research on aesthetic taste suggests that people believe aesthetic taste can be good or bad. Constant Bonard et al. (2022) asked participants whether it makes sense to distinguish between good and bad taste, and then asked to define what it is. The majority of participants agreed with the distinction, and although a significant part defined good taste in terms of the ability to detect aesthetic properties, expressing the view compatible with aesthetic realism, for other participants, good taste was compatible with aesthetic subjectivism, since ‘good taste’ was defined simply as something corresponding to their own personal preferences. Another phenomenon that has been thought to be relevant to the issue of whether good taste exists, is that of ‘guilty pleasures’—enjoying aesthetic objects one feels one should not enjoy. As Kris Goffin and Florian Cova (2019) observe, the existence of guilty pleasure at first sight might be considered evidence for the existence of good taste among the folk. However, they present evidence suggesting that the guilt people experience should be understood as guilt for violating social norms, not aesthetic ones, and therefore should not be seen as evidence for folk aesthetic realism.

In addition to the meta-aesthetical method outlined above, psychologists and experimental philosophers have also examined realism about taste by considering the mechanisms that result in people’s aesthetic judgments.

Some philosophers have suggested that the idea that there be objective aesthetic value might be demonstrated simply by pointing to the fact that some artworks and not others are universally judged as aesthetically valuable. For example, Hume (1757a) suggests that some works are, truly, better than others, and that those works will pass the test of time: they will be judged to be good across cultures and epochs, and they will do this in virtue of truly having aesthetically good-making features.

However, James Cutting (2003) has presented evidence that has seemed to put pressure on this Humean view. Having found that merely exposing people to impressionist works made them like them more, Cutting suggests that we may like canonical works because they have been continually broadcast to the world. Armed with Cutting’s findings, the aesthetic skeptic might argue that passing the test of time isn’t an indication of aesthetic quality, but rather an indication that people have merely experienced the works more frequently.

In defense of the Humean view, Meskin et al. (2013) suggest that mere exposure might not indiscriminately improve liking of works, irrespective of their aesthetic quality; but rather, help us to more accurately appreciate their true aesthetic merits and demerits. As a corollary, they also suggest that works may enter the canon because they are truly better. Putting their Humean defense to the test, they merely exposed participants to works that the authors and many critics consider good and bad (namely, works by John Millais and Thomas Kinkade, respectively). The results revealed that participants liked the Kinkade paintings less the more they were exposed to them, and the results suggested a trend for participants to like the late Millais paintings more the more they were exposed to them (though this was not significant). Meskin and colleagues interpret this evidence as consistent with the existence of aesthetic value, as well as the reliability of the test of time: with repeated exposure, we are better able to appraise a work’s good- and bad-making features, and so those works that endure do so, at least in part, in virtue of having good-making features.

Bence Nanay (2017) has criticized the idea that mere exposure is relevant to aesthetic realism. First, studies on mere exposure target spontaneous reactions, while aesthetic judgments are traditionally thought to be reflective and unfolding in time. Secondly, the mere exposure effect seems to work only with good artworks and not with bad ones—exposure to good artworks makes positive aesthetic judgments more likely, but not the other way around. Most importantly, according to Nanay, experiments show that exposure to one artwork changes our preference for that particular artwork, but not for any other artwork. In order for these experiments to count as evidence against aesthetic realism, Nanay contends, we would need to demonstrate that exposure to one particular artwork can influence our preferences for other artworks of the same kind (for example, of the same artistic style).

Finally, another tightly related question is about the nature of aesthetic testimony: if our aesthetic judgments are similar to empirical judgments, we can reliably learn about aesthetic properties from what other people say—if during a phone call someone says that a piece of broccoli they are having for lunch ‘is beautiful’, should we trust their testimony to the same extent that we would trust their claim that ‘there is a piece of broccoli on my plate’?

Andow (2019) asked his study participants whether they think that forming aesthetic beliefs based on testimony given by a friend or an expert is less permissible and legitimate compared to forming such beliefs based on first-hand experience, and also compared to forming non-aesthetic beliefs, such as beliefs about size or price. Although his results confirm that there is an asymmetry between the extent to which people are inclined to trust aesthetic testimony, compared to testimony about non-aesthetic properties, interestingly, this effect was not moderated by the participants’ attitudes toward the status of aesthetic judgments. Moreover, another similarly designed study shows that aesthetic and moral beliefs based on testimony, in contrast to descriptive beliefs, are not seen as constituting knowledge (Andow 2020).

5. Aesthetic Adjectives
Aesthetic adjectives, such as ‘beautiful’ and ‘elegant’, are central to aesthetic communication: they are the most common tools with which we attribute aesthetic properties to works and communicate aesthetic judgments with others. Some philosophers contend that aesthetic adjectives constitute a segment of natural language that is interesting in its own right, for different reasons. Frank Sibley (1959, 2001) argues that aesthetic adjectives are distinctive in that they require taste to apply. By this, Sibley means that whether an aesthetic adjective applies to a work is never determined by any set of non-aesthetic properties. Tim Sundell (2017) argues that although aesthetic adjectives are not semantically distinctive, they are metalinguistically distinctive because of their role in coordinating and negotiating standards. By this, Sundell means that when you say ‘this artwork is beautiful’ and I say ‘no it is not’, we are not only attributing properties to the work itself, but communicating our different standards of beauty through our different applications of the term ‘beautiful’.

There is a nearby segment of natural language that has attracted much attention from philosophers and linguists: predicates of personal taste such as ‘tasty’ and ‘fun’. Indeed, some experimental philosophers have made valuable contributions to this debate (such as Kneer, Vicente, & Zeman 2017; Dinges & Zakkou 2020; Kneer 2021). However, scholars in this debate typically set aesthetic adjectives to the side in their investigations. For example, Peter Lasersohn (2005: 645) explicitly does so in order to avoid fundamental issues in aesthetics. In contrast to the lively scholarly activity on predicates of personal taste, there are only a few works that explicitly and primarily investigate aesthetic adjectives. As such, it remains an open question whether aesthetic adjectives are distinct from predicates of personal taste, or whether there exists a unified treatment of the two.

Louise McNally and Isidora Stojanovic (2017) argue that while predicates of personal taste are necessarily mind-dependent insofar as they entail an experiencer, aesthetic adjectives are semantically distinctive because they express evaluations without entailing an experiencer. McNally and Stojanovic’s diagnostic appeals to the fact that the verb ‘find’ tends to complement adjectives with an experiencer. For example, sentences like ‘I find him attractive’ tend to sound fine but sentences like ‘I find him tall’ tend to sound weird. Using the British National Corpus, they found that aesthetic adjectives do not tend to complement ‘find’, which they take to be evidence that “their evaluative component is not based directly on personal experience” (2017: 29).

Shen-yi Liao and Aaron Meskin (2017) argue that aesthetic adjectives are semantically distinctive because they exhibit a strange sort of context-sensitivity. Standardly, gradable adjectives are classified as absolute or relative. Absolute adjectives—such as ‘straight’ or ‘spotted’—have their standards of application built in, and do not rely on the context to fix this threshold. By contrast, relative adjectives—such as ‘warm’ or ‘long’—do rely on a context for its threshold of application. Through a series of experiments involving a diagnostic used to classify gradable adjectives, Liao and Meskin found that aesthetic adjectives behaved like neither absolute nor relative adjectives. Participants were presented with pairs of objects and asked to pick out ‘the [adjective] one’. The key to this diagnostic is that ‘the’ implies both existence (there is at least one) and uniqueness (there is at most one). As such, most participants are unable to pick out the spotted disc when presented with two discs that are spotted to different degrees because ‘spotted’, as an absolute adjective, has a context-insensitive threshold of application which is met in both cases. By contrast, most participants are able to pick out the long rod when presented with two rods that are long to different degrees because ‘long’, as a relative adjective, has a threshold of application that is sensitive to the context. In particular, participants are able to construct an implicit comparison class using the context of application: they pick out the longer rod as ‘the long one’. However, Liao and Meskin found that about half of the participants use ‘beautiful’ like ‘spotted’ and about half of the participants use ‘beautiful’ like ‘long’. Moreover, the same pattern holds also for negative aesthetic adjectives like ‘ugly’ and thick aesthetic adjectives like ‘elegant’. These results are difficult to explain for the standard typology of gradable adjectives.

Stojanovic (2019) argues that Liao and Meskin’s results do not provide grounds for drawing any interesting conclusions regarding semantic adjectives because the studies do not reveal a stable pattern. The 50/50 pattern in response to the request to pick out the beautiful / ugly / elegant object is just what would be expected if participants were answering by chance. Liao, McNally, and Meskin (2016) conducted further experiments and corpus observations to show the instability of aesthetic adjectives’ behaviors. On some diagnostics they pattern with absolute adjectives, but on other diagnostics they pattern with relative adjectives. In response to these results, they propose a different hypothesis: aesthetic adjectives are like relative adjectives insofar as both involve implicit comparison classes, but unlike relative adjectives insofar as their implicit comparison classes are not determined by the immediate context of application.

Where the studies described above have attempted to treat aesthetic adjectives as a homogeneous and sui generis class, more recent studies have pointed to important sources of heterogeneity amongst them. ‘Beautiful’ and ‘pretty’ are similar adjectives in that they can both express certain descriptive contents—namely, that an appearance is intrinsically pleasing, or that it is, for example, delicate, small, and soft. But they differ insofar as prettiness is thought to be more closely tied to appearances and less important than beauty. In trying to account for this patterning, Doran (forthcoming a) suggests that BEAUTY but not PRETTINESS is a dual-character concept, and that in addition to the descriptive senses they share, BEAUTY has a normative sense connected to our most cherished values, including, most prominently, moral goodness. In support of this claim, in one of the studies reported, he shows that ‘beauty’ but not ‘prettiness’ is judged to be able to felicitiously combine with the ‘true’ modifier, which is thought to be one source of evidence that the concept expressed by a given lexical item is dual-character (Knobe et al. 2013). “That is true beauty” sounds perfectly natural to native speakers of English, but “That is true prettiness” sounds decidedly odd.

6. Morality and Aesthetics
Morality and aesthetics stand as two prominent normative domains. How do the concerns in these two domains interact with one another? Drawing from a substantive philosophical literature on these interactions (see Harold 2023 for overviews), topics at the intersection have also been empirically investigated in recent years. Here, we roughly divide works into two aspects: concerning morality’s influence on aesthetics, and concerning aesthetics’ influence on morality.

In the first direction, concerning morality’s influence on aesthetics, philosophers have wondered about the influence of moral attitudes on aesthetic attitudes. In traditional philosophical aesthetics, this is sometimes known as the “value interaction” or “ethical criticism of art” debate (Clavel Vázquez 2018; Giovanelli 2007; Liao & Meskin 2018; McGregor 2014). There are three main positions: autonomists say that moral attitudes do not influence aesthetic attitudes; moralists say that negative moral judgments always negatively influence aesthetic judgments; and contextualists say that moral attitudes’ influence on aesthetic attitudes depends on the context.

This direction of value interaction might affect taste perception. Patrik Sörqvist and colleagues (2013) found that, between two qualitatively identical cups of coffee, participants whose attitudes are congruent with sustainability rated the one labeled as “eco-friendly” as tastier. However, Aaron Meskin and Shen-yi Liao (2018) were unable to conceptually replicate this result. Similarly, Beth Armstrong and colleagues (2019) found that the valence of ethical information affected consumers’ expected experience of food. Taken together, these results suggest that a folk psychology of moralism or contextualism is currently more plausible than a folk psychology of autonomism.

This direction of value interaction might also affect judgments of beauty. One longstanding debate in this context surrounds whether moral goodness can be beautiful in itself—with philosophers such as Plato (c. 370 BCE) and Shaftesbury (1711) claiming that moral beauty exists, and others such as Edmund Burke (1757) and Immanuel Kant (1790) denying this (though see Doran forthcoming d). Until recently, one of the principal ways that philosophers have tried to settle this matter is by examining the use of ordinary language from the armchair. Berys Gaut (2007), for example, argues in favor of the existence of moral beauty principally by noting that we call people beautiful when they are good. Gaut argues that this kind of talk cannot be intended non-literally, as was suggested by Burke (1757), as neither of the two defeators of literal use—obvious falsity (as in ‘my boss is a pig’) or trivial truthfulness (as in ‘I’m not over the moon’)—seem to apply to locutions that appear to express moral beauty. But as Ryan Doran (2021) notes, Gaut’s method of testing for non-literal use is too demanding, as it wrongly assumes that people are always truth-maximisers. To move past this apparent impasse from the armchair, and help to reveal the number of species of moral beauty that exist, Doran suggests that we turn to experimental studies. He shows that people tend to judge morally good people to be more beautiful, and that this cannot be deflated in terms of non-literal intent or an error (such as misattribution) on the grounds that making the source of the goodness salient, and giving people the opportunity to express their approval of the goodness prior to making the judgment of beauty, does not eliminate the effect of moral goodness on judgments of beauty. Doran also finds evidence that moral goodness can affect the beauty of physical appearances by affecting the determinants of thick aesthetic properties such as balance and delicacy, and that people’s moral character can be beautiful in itself, suggesting that beauty is not perception dependent.

Building on this work, experimental philosophy studies have also been used to help resolve apparent inconsistencies in the existing literature on which moral traits are beautiful, as well as reveal hitherto unacknowledged reasons why morally good traits and actions are beautiful, among other things.

Supporters of moral beauty can be divided into particularists about the beauty of traits—who tend to hold that only the ‘warmer’ virtues such as compassion are beautiful (for example, Kant 1764)—and universalists about moral beauty—who tend to argue that all virtues are beautiful, and indeed that certain colder non-moral traits such as intelligence can be beautiful too (Schiller 1793 [2003], 1793 [2005]; Gaut 2007; and Paris 2018).

Doran (2023) proposes that these positions only appear to be inconsistent with one another, as they range over different kinds of beauty: with universalists targeting the beauty that is found in good form, and particularists targeting the kind of beauty that lies in things that have a disposition to lead to an emotion that is variously described as ‘love,’ ‘elevation’ and ‘ecstasy’—which is characterized by feelings akin to being moved, inspired, and of unity with the object of this state. To test this view, he presented participants with a story about two individuals who are equally well-formed—in the sense that their mental states are all working harmoniously to lead them to do the right thing—but differ in the kind of virtue they exhibit, with one individual being just, and the other being compassionate. Consistent with the idea that there is a beauty in some traits which resides in the disposition to give rise to this special emotion in addition to well-formedness, participants found the fully just and fully compassionate individuals to be equally virtuous and good, but the latter to be more beautiful to the extent that this individual tended to give rise to this special emotion to a greater extent.

Examining the link between internal harmony and beauty more explicitly, Doran (forthcoming b) has tested the idea—which is most prominently found in Friedrich Schiller’s On Grace & Dignity (1793 [2005]) and Kallias (1793 [2002])—that actions are beautiful if and only if they are expressive of freedom by being the result of a high degree of internal harmony, as in cases where our desires, beliefs, and will all seamlessly work together to produce the good action. While Doran finds some evidence which is consistent with actions being beautiful to the extent that they are expressive of freedom by being the result of a high degree of internal harmony, his results also suggest that the moral actions of conflicted individuals can be as beautiful, or even more beautiful, as those of internally harmonious moral agents, and so Schiller’s claim need to be weakened and supplemented with additional claims. In one experiment, for example, participants were presented with two individuals who both do the right and good action in making necessary redundancies and giving financial support to those affected, where the only difference is that where one individual makes the redundancies without any internal conflict, the other does so with a great deal of conflict due to a reluctance to afflict the necessary suffering. Consistent with his earlier findings, the results show that the latter individual’s action is considered to be more beautiful, and that this is due to the latter individual’s tendency to move us, and make us feel at one with them. As such, Doran suggests that it is not only the internal harmony of the agent who performs an action that determines its beauty, but also the degree to which the action tends to make us feel as though we are harmoniously related to the agent that performs the action. Further elucidating some of the reasons why morally good actions can be beautiful, Doran (forthcoming c) finds that people tend to think that morally good actions are beautiful when the action is seen as expressing who the person truly is (their essence), and as stemming from a location deep inside of them, and in turn tends to lead to feelings of being moved and inspired.

Imagination may play an especially important role in mediating moral attitudes’ influence on aesthetic attitudes. Imaginative resistance refers to the phenomenon in which “an otherwise competent imaginer finds it difficult to engage in some sort of prompted imaginative activity” (Gendler & Liao 2016: 405; see also Miyazono & Liao 2016). Imaginative resistance is puzzling because imagination is standardly unconstrained. Typically, a competent imaginer finds no difficulty in imagining factual deviations, such as a fictional world in which humans and dragons co-exist. However, it has been hypothesized that imaginative activities that involve moral deviations are especially prone to evoke imaginative resistance (Gendler 2000, 2006). For example, it has been suggested that a fictional world in which female infanticide is morally right is likely to evoke imaginative resistance (Walton 1994). Philosophers disagree about many aspects of imaginative resistance, such as: whether the resistance is special to imagining moral deviations, whether the resistance reflects an intrinsic limitation of imagination, and indeed, whether the phenomenon is real in the first place. Experimental philosophers and psychologists have sought to bring systematic empirical evidence to help resolve these disagreements.

As an early example of this kind of work, Liao, Strohminger, and Sripada (2014) conducted two studies on imaginative resistance and its driving factors. In the first study, they asked participants to engage with a story in the style of Greek myths, in which it is morally right to trick a person into entering a romantic relationship. They found evidence for imaginative resistance being a real phenomenon: the extent to which this fictional world is counter to participants’ moral attitude is correlated with the extent of their self-reported imaginative difficulty. However, they also found evidence against the resistance reflecting an intrinsic limitation of imagination: the extent to which participants are familiar with the genre conventions of Greek myths is also correlated with the extent of their self-reported imaginative difficulty. In the second study, they presented a fictional world in which it is morally right to sacrifice an infant, but varied the genre of the story such that some participants engaged with a story in the style of police procedurals but others engaged with a story in the style of Aztec myths. Sure enough, participants do have a harder time accepting that infant sacrifice really is morally right in the police procedural world, but an easier time accepting the same for the Aztec myth world. This contrast found in this study (replicated by Mark Phelan and colleagues in Cova, Strickland, et al. 2021) lends further support to the reality and the non-intrinsicality of imaginative resistance.

Subsequent investigations by other philosophers and psychologists have found additional support for the reality of imaginative resistance and further uncovered its contours. Jessica E. Black and Jennifer L. Barnes (2017) have designed and validated a scale for measuring imaginative resistance. With this scale, they have also found that participants do experience imaginative resistance in response to moral deviance, albeit with contextual and individual variations (Barnes & Black 2016; Black & Barnes 2020). However, Hanna Kim, Markus Kneer, and Mike Stuart (2019) found that the resistance is not special to imagining moral deviations. Instead, imaginative resistance reflects the “weirdness” of the claim that participants are asked to imagine, which is itself an amalgam of three factors: unusualness, counterfactuality, and surprisingness. Morally deviant claims, as a class, are not necessarily more weird than factually deviant claims, as a class. Moreover, given that surprisingness is a component, weirdness depends on expectations which might be modified by genre expectations and other contextual factors. Dylan Campbell, William Kidder, Jason D’Cruz, and Brendan Gaesser (2021) found that the resistance does not reflect an intrinsic limitation of imagination. Instead, imaginative resistance reflects individual differences in emotional reactivity: participants who experience less negative affect in response to harms also experience less difficulty in imagining moral deviance.

In the second direction, concerning aesthetics’ influence on morality, philosophers have also wondered about the influence of aesthetic attitudes on moral attitudes. This direction comes up too, albeit much more rarely, in the “value interaction” debate (Harold 2006; Stecker 2005). In psychology, however, aesthetic attitudes’ influence on moral attitudes has been systematically studied in an extensive literature on the beauty-is-good stereotype (Dion et al. 1972; compare the metaanalyses in Eagly et al. 1991 and Langlois et al. 2000). Roughly, the idea is that positive aesthetic judgments always positively influence moral judgments of persons. This stereotype holds in a surprisingly wide variety of domains, such as pedagogy and politics.

Philosophers have been equivocal in their answer to the question of whether aesthetic appreciation has a salubrious effect on us morally. Cynics about beauty have suggested that appreciating beauty might have a corrupting influence. J. Robert Loftis (2003), for example, suggests that beauty might lead us to focus on the superficial, “skin deep”, features of the world. But some philosophers have been more sanguine about the prospect of moral cultivation via beauty. Plato, in the Symposium, suggests that the appreciation of physical beauties leads to the appreciation of non-perceptual kinds of goodness; and Kant (1785) suggests that a love of natural beauty in particular is a “mark of the good soul”, and indicates that a person is susceptible to the “moral feeling”. Since this issue is an empirical one to an important extent, it is perhaps no surprise that experimental philosophers and empirical aestheticians have entered the fray. Providing correlational support for the optimistic view, Diessner et al. (2013) found that the tendency to be sensitive to beauty (that is, to notice it, and be moved by it), and particularly sensitivity to natural beauty, was associated with the moral attitudes towards close and distant others (in line with Kant’s suggestion). Providing evidence of a causal relationship, appreciation of natural beauty has been found to lead to more morally admirable behavior (Zhang et al. 2014; see Silvers & Haidt 2008 and Landis et al. 2009 for evidence concerning the morally salubrious effects of appreciating moral beauty). In addition to this work on beauty, the moral effects of appreciating the sublime have been explored in the context of empirical work on the nature of awe (see Piff et al. 2015).

Philosophers have generally held two main positions about the role that something’s beauty can play in grounding moral standing. On the one hand, optimists about beauty have argued that beauty confers intrinsic moral standing—that is, beautiful things are worthy of protection independently of their relationship to humans and other animals (for example, G.E. Moore 1903; Routley, 1973). Pessimists about beauty, by contrast, think that beauty at best provides a non-intrinsic kind of moral standing, insofar as it is but one source of pleasure for humans (for example, Passmore 1974). Experimental philosophers and empirical aestheticians have recently tried to cast light on some of the mechanisms that might be involved in beauty’s effects on judgments of moral standing, with a view to interrogating its normative significance in some cases. Doran (2022), for example, argues that both the optimists and pessimists are incorrect. Across two studies with beautiful plants, he shows that to the extent that people tend to experience the beauty of plants—and in particular to the extent that they tend to feel moved and inspired by the beauty—they tend to judge that the plant can feel pain and has intrinsic moral standing. As such, he argues that the intuitions that optimists appeal to should be debunked, and that beauty tends to give rise to a state that is more valuable than mere pleasure, contra the pessimists. Investigating the issue through the lens of Moral Foundations Theory, Klebl and colleagues (2022) found that purity intuitions tend to underlie people’s willingness to protect beautiful things.

7. Emotion and Art
There is a rich set of puzzles in philosophical aesthetics concerning emotional responses to fictions, and here, both psychologists and experimental philosophers have made contributions, in some cases moving the debate beyond the standard philosophical concerns. Here we discuss a few of those that have received the most attention from philosophers: How can fiction elicit emotional responses when we know that the characters do not exist? If certain works of art, particularly music, can evoke negative emotions, like sadness, which we typically aim to avoid in everyday life, why do we pursue such experiences in art contexts? Moreover, how can music be expressive of emotions, if there is nobody in the music itself experiencing them?

The ‘paradox’ of fiction is motivated by the following observation: if we were to learn that events in life that make us feel sad have not in fact come to pass, our sadness would disappear. But the same is not true in art. I may know that Tolstoy’s Anna Karenina does not exist, and yet may feel sad reading about her fate in the novel (Radford & Weston 1975). With this in mind, the paradox of fiction has standardly been formulated as a trilemma of three individually plausible but mutually inconsistent claims (for example, Currie 1990):

We have emotional responses directed towards fictional entities and situations in literature and art;
In order to have emotional responses we need to believe in the existence of the entities and situations that they are directed at;
We do not believe in the existence of the fictional entities in literature and art.
Most philosophers have now jettisoned this paradoxical formulation, by rejecting proposition (2). But, even if there is no paradox per se, philosophers have noted that interesting questions remain here: Do our emotional responses to fictions differ from their real-life cognates? And, if so, what might explain this? Do our emotional responses to fiction involve different mental representations, for example? And are any differences that exist sufficient to constitute a different kind of emotional response?

In connection with this, some experimental philosophers have thought that the emotional responses that are had in response to fictional entities and events might differ in their intensity, as a result of differences in self-referential processes. Sperduti et al. (2016), for example, asked participants to watch clips of scenarios apt to elicit positive or negative emotions, or neutral video clips, presented as either mockumentaries (fiction), or documentaries or amateur films (non-fiction). Participants self-reported less intense emotions only in response to the negative clips when they were presented as fictions, and even here, there were no differences in the physiological responses (and specifically, in electrodermal activity). The authors interpret this as suggesting that the emotional responses to fiction are genuine emotions, on the grounds that there are no physiological differences, but that appraisals of fictionality might nonetheless cause people to psychologically distance themselves from the content (for discussion, see Pelletier 2019). Humbert-Droz et al. (2020), by contrast, found that longer clips of sad scenes lead to lower skin conductance when labeled as non-fictional versus fictional, as well as greater self-reports of sadness—suggesting that believing that the clip was real led to greater sadness. Given the mixed findings in this context, the issues of whether the emotions that we feel in response to fiction differ from those we feel in non-fictional contexts, and if so why, remain open questions.

The paradox of negative emotion (Hume 1757b), has intrigued philosophers since the time of Aristotle: why do we seek exposure to art arousing negative emotions if negative emotions is something that we tend to avoid in our everyday life? One important example is listening to sad music, which is often thought to evoke sad mood in listeners (though for dissent, see Kivy 1990). There is vast psychological literature on emotional responses to music that are relevant to this philosophical discussion (see Mitterschiffthaler et al. 2007; Juslin & Västfjäll 2008; Vuoskoski & Eerola 2012; Koelsch, 2014; Peltola & Eerola 2016; Juslin 2019), and it has received some attention from experimental philosophers as well.

Mario Attie-Picker and colleagues (2024) tested the hypothesis that people choose to listen to sad music because of the emotions music is expressive of: listening to sad music allows people to feel more connected. In the first study, participants were presented with vignettes describing musical pieces with differing levels of musical proficiency and emotional expressiveness. They were then asked to what extent they agreed that the described piece of music was good and embodied the essence of what music is ‘all about’. The results revealed that emotional expressiveness, more so than technical proficiency, influenced judgments on what are the characteristic values of music. In the second study, participants were asked to complete sentences about (a) the characteristic values of music, (b) feeling connected in conversations, and (c) pleasantness of music. They found an overlap between the emotions people listed as embodying what music is “all about” and the emotions that make people feel connected in conversations. Attie-Picker and colleagues thus try to explain the paradox by shifting the focus away from the traditional emphasis on the listener’s felt emotions and instead centering it on emotions one perceives in music.

The paradox of emotional expressiveness is related not to the emotions we feel when we listen to music, but rather emotions we hear in the music itself. In our everyday conversations, we often characterize music as joyful, sad or angry. We use those terms when discussing a piece of music—an entity that does not have mental states and is incapable of experiencing emotions.

One way to empirically study the relationship between music and emotional expressiveness is through cross-cultural research. Psychological literature suggests that cross-cultural recognition of emotions in music is quite limited. Some studies have shown that the list of cross-culturally recognizable emotions in music is limited to three basic emotions of happiness, sadness and fear (Fritz et al. 2009). Other studies suggest that even major and minor chords may not, after all, be universally associated with happiness and sadness (Lahdelma et al. 2021; Smit et al. 2022). However, at least aversion to dissonant musical chords appears to be cross-cultural (Lahdelma et al., 2021).

The question of cross-cultural recognizably has also been tackled in Constant Bonard’s experimental philosophy paper (2019). Bonard argues that the affective meaning of a musical piece depends on musical grammar, as there is an overlap of cognitive mechanisms constituting the capacity for language and capacity for music. According to him, listeners familiar with certain musical idioms and grammatical organizations are better able to perceive the affective meaning of a piece. Bonard presented his participants in Geneva and India with excerpts from Western classical music, South Indian music, as well as a set of atonal melodies that do not belong to either of these cultures. They were asked to identify musical excerpts that do not correspond to musical grammatical rules. For both Indian and Western participants, the Western and atonal (but not Indian) stimuli were easier to encode for those familiar with the musical idiom. Participants were also asked to listen to musical extracts and continually rate how much the music expressed a given emotion. The study confirmed that participants were better at recognizing the affective dimension of music that originated from their region. Taken together, these studies present tentative evidence that the recognition of emotions in music may depend on familiarity with local musical grammar rules (for more readings on musical semantics, also see Schlenker 2017, 2019, 2022).

The topic of art and emotion induction may also be relevant to discussions on art and morality. Angelika Seidel and Jesse Prinz (2013b) found that music can be used to induce positive or negative emotions, which in turn modifies moral evaluations. Roughly, happy music increases judgments of goodness, and angry music increases judgments of wrongness. Seidel and Prinz (2013a) further discovered that different negative musically-induced emotions, anger and disgust, can impact the severity of different kinds of moral judgments. A more complex result comes from Ansani and colleagues (2024), which shows that musical expertise is likely to lead to more individualizing moral foundations as opposed to binding ones.

8. Methodological Debates
Throughout this entry, we have generally focused on recent empirical research done by philosophers on topics in philosophy of art and aesthetics. However, this scope is admittedly arbitrary. As noted at the start, the research program that we have surveyed is continuous with empirical aesthetics in psychology, and comes from a long historical tradition that encompasses both philosophy and psychology. The principal reasons to draw boundaries are pragmatic ones.

Like other branches of experimental philosophy, experimental philosophy of art and aesthetics involves gathering data using empirical methods and bringing analyses of the data to bear on philosophical theorizing. As a matter of general fact, research in experimental philosophy is relatively replicable (Cova, Strickland, et al. 2021), and relatively free of scientific misconduct such as p-hacking (Stuart, Colaço, & Machery 2019). While experimental philosophy of art and aesthetics is bolstered by this general track record, it also inherits a number of methodological challenges from experimental philosophy and related areas of psychology regarding instruments, samples, and stimuli.

By far, the most common instrument used in experimental philosophy of art and aesthetics is—like other branches of experimental philosophy and related areas of psychology—the questionnaire. Participants’ responses are measured by their answers to questions posed by the researchers. Nick Zangwill (2019) expresses a general skepticism toward studies that use questionnaires, and criticizes experimental philosophy of art and aesthetics for its wide use of this specific measurement instrument. Drawing inspiration from Wittgenstein, Zangwill is pessimistic about the questionnaire’s attempt to use language to reveal agents’ thoughts generally. In addition, he is pessimistic about the questionnaire’s capacity to reveal agents’ normative judgments, such as judgments of beauty, as opposed to non-normative judgments, such as judgments of agreeableness. Zangwill’s critique could be taken as an invitation for experimental philosophers to explore methodological tools beyond the questionnaire. In fact, some philosophers have already experimented with eye movement tracking (Wright et al. 2019), virtual reality (Francis et al. 2016), electroencephalography (Bricker 2020), and corpus analysis (Liao, McNally, & Meskin 2016; McNally & Stojanovic 2017; Sytsma et al. 2019; Chartrand 2022; Doran, forthcoming a). Some of these or other proposed methods (see Fischer & Curtis 2019; Fischer & Sytsma 2023) might also enrich experimental aestheticians’ toolboxes.

The most common sample used in experimental philosophy of art and aesthetics is—once again, like other branches of experimental philosophy and related areas of psychology—WEIRD: participants from Western, Educated, Industrialized, Rich, and Democratic countries (Henrich, Heine, & Norenzayan 2010). Whether responses from these WEIRD participants are representative of people in general remains an open question. Within experimental philosophy (and related areas in psychology), there is an ongoing debate about the legitimacy of making theoretical generalizations based on empirical results from WEIRD samples (for criticisms, see Stich & Machery 2023 and Peters & Lemeire 2024; for defenses, see Knobe 2019, 2021). Clearly, this ongoing debate impacts the evidentiary value of existing research in experimental philosophy of art and aesthetics as well.

That said, it is important to highlight a couple of cross-cultural works in experimental philosophy of art and aesthetics. In one work, Florian Cova, Christopher Olivola, and colleagues (2019) extend Cova’s earlier research on the intersubjective validity of aesthetic judgments to a sample that includes participants from 19 countries on four continents. Across six geographical areas (Europe, Middle East, Central and North America, South America, East Asia, and South and Southeast Asia), they found both variations and convergences in patterns of responses. While participants from East Asia tend to endorse ‘subjectivism’ about aesthetic judgments (when two people disagree, both can be correct), participants from other geographical areas tend to endorse ‘nihilism’ (when two people disagree, neither is correct or incorrect). At the same time, people everywhere tend to not endorse ‘realism’ (when two people disagree, at most one can be correct). In another work, Constant Bonard (2019) conducted studies in Switzerland and India to vindicate the hypothesis that musical idioms have grammatical structures. The grammar of Western classical music was found to be more recognizable to Switzerland participants than Indian participants, but no reverse asymmetry was found for South Indian classical music. Another study investigated aesthetic judgments of mathematical beauty between Chinese and British mathematicians and found that they do not seem to be strongly influenced by cultural differences (Sa et al. 2024). As things stand, these three cross-cultural works remain the exception, and not the norm, in experimental philosophy of art and aesthetics. The fact that the vast majority of work has been conducted with Western European and American samples is not dissimilar to the situation in empirical aesthetics (see Che, Sun, Gallardo, & Nadal 2018) or music cognition (see Jacoby et al 2020). As such, this is a problem that needs to be addressed in all fields that empirically study art and aesthetics.

In addition, samples used in experimental philosophy of art and aesthetics tend to be ordinary people with no special expertise in philosophy or the relevant arts. One criticism of experimental philosophy’s relevance for philosophical theorizing, commonly called the expertise objection, endorses privileging experts’ responses over ordinary people’s. While the existing debate primarily concerns the expertise of philosophers—insofar as the objectors privilege philosophers’ intuitions from thought experiments—in the domain of philosophy of art and aesthetics, expertise in the respective artforms might be relevant as well. Many psychology studies have shown differences between ordinary people and art experts in aesthetic judgments and preferences (Hekkert & Van Wieringen, 1996; Leder, Ring, & Dressler 2013), as well as emotional responses to art (Silvia 2013; Leder, Gerger, et al. 2014), and these differences are relevant to at least some of the topics experimental philosophers are interested in. As such, we want to highlight a few works in this domain that use experts as samples.

Three studies in experimental philosophy of aesthetics have compared expert and non-expert samples. In one empirical study based on moral foundations theory, Alessandro Ansani and colleagues (2024) found that musical experts tend to have a higher preference for individualizing moral foundations, Harm and Care. Elzė Mikalonytė and Vilius Dranseika (2020) compared intuitions on the individuation of musical works between musicians and non-musicians and found that although they tend to be similar, musicians’ intuitions are usually more pronounced. However, Mikalonytė and Dranseika (2022) found no notable differences between professional singers and orchestra musicians working in the opera and participants with no music education. Most of Richard Kamber’s (2011) study participants were art professionals or ‘art buffs’, so the study itself does not allow us to compare experts’ and non-experts’ responses. Kamber explains this methodological decision by stating that if there is a consensus between professional artists on what counts as art, philosophers are inclined to agree with professional artists.

In other branches of experimental philosophy, many studies rely on intuitions that arise from thought experiments. This is less so in experimental philosophy of art and aesthetics. Indeed, Cova and Réhault (2019b: 3) speculate that it is because intuitions play a much less prominent role in philosophical aesthetics that the field did not draw the initial attention of experimental philosophers. With that said, it is important to stress that there is variation with respect to this within this branch of experimental philosophy too. Emanuele Arielli (2018) distinguishes studies that solicit intuitions and other cognitive responses and studies that solicit aesthetic reactions and other perceptual and phenomenological responses. While critical of the former type of studies, he finds the latter type of studies more promising insofar as they are more continuous with empirical aesthetics in psychology.

Others have remarked on this difference between experimental philosophy of art and aesthetics and other branches of experimental philosophy. Clotilde Torregrossa (2020, 2024) argues that insofar as experimental philosophy of art and aesthetics is more reliant on reactions to aesthetic phenomena, standard objections against experimental philosophy that turn on the reliance on intuitions from thought experiments are less applicable. Jonathan Weinberg (2019) argues that the availability of artworks means that experimenters need not rely solely on descriptive vignettes. The presentation of actual artworks can fill in gaps that are usually left by the short textual vignettes that are typical of philosophical thought experiments. We should note, however, that in actuality such studies remain relatively rare (some examples are Kamber 2011; Meskin et al. 2013; Liao & Meskin 2017; Bonard 2019; Puy 2022; Mikalonytė & Canonne forthcoming).

There is ongoing debate about whether studies about music should depend on the use of acoustic stimuli. Building on Weinberg’s argument, Nemesio Puy (2022) contends that ontological judgments about artworks involve an aesthetic dimension and must therefore be grounded in the experience of real works of art. This contention receives indirect support from a study that shows people are generally unwilling to base their beliefs about aesthetic dimension of an artwork on testimony alone, without first-personal perceptual access (Andow 2019). Moreover, this contention receives direct support from two studies that show that the decision to include or exclude acoustic stimuli has an effect on the results of studies investigating ontological judgments, even if the descriptive part of the stimuli is kept as consistent as possible (Puy 2022; Mikalonytė & Canonne forthcoming). Notwithstanding this, Elzė Mikalonytė (forthcoming) points out several reasons why purely textual vignettes are so widely used and might not always be easily replaceable. Such vignettes might help the participants to focus on the most relevant aspects and filter out irrelevant factors. In fact, additional perceptual information may actually distract participants, as may occur, for example, in making judgments in the ontology of art, which arguably should be made on the basis of conceptual rather than perceptual information (such as information about the artist’s intentions). Especially in the case of music, presenting the participants with short descriptions without corresponding works of music might help to avoid relying on sustained attention over extended periods of time.

. Morality
When philosophers engage in moral theorizing, what is it that they are doing? Very broadly, they are attempting to provide a systematic account of morality. Thus, the object of moral theorizing is morality, and, further, morality as a normative system.

At the most minimal, morality is a set of norms and principles that govern our actions with respect to each other and which are taken to have a special kind of weight or authority (Strawson 1961). More fundamentally, we can also think of morality as consisting of moral reasons, either grounded in some more basic value, or, the other way around, grounding value (Raz 1999).

It is common, also, to hold that moral norms are universal in the sense that they apply to and bind everyone in similar circumstances. The principles expressing these norms are also thought to be general, rather than specific, in that they are formulable “without the use of what would be intuitively recognized as proper names, or rigged definite descriptions” (Rawls 1979, 131). They are also commonly held to be impartial, in holding everyone to count equally.

1.1 Common-sense Morality
… Common-sense is… an exercise of the judgment unaided by any Art or system of rules : such an exercise as we must necessarily employ in numberless cases of daily occurrence ; in which, having no established principles to guide us … we must needs act on the best extemporaneous conjectures we can form. He who is eminently skillful in doing this, is said to possess a superior degree of Common-Sense. (Richard Whatley, Elements of Logic, 1851, xi–xii)
“Common-Sense Morality”, as the term is used here, refers to our pre-theoretic set of moral judgments or intuitions or principles.[1] When we engage in theory construction (see below) it is these common-sense intuitions that provide a touchstone to theory evaluation. Henry Sidgwick believed that the principles of Common-Sense Morality were important in helping us understand the “first” principle or principles of morality.[2] Indeed, some theory construction explicitly appeals to puzzles in common-sense morality that need resolution – and hence, need to be addressed theoretically.

Features of commons sense morality are determined by our normal reactions to cases which in turn suggest certain normative principles or insights. For example, one feature of common-sense morality that is often remarked upon is the self/other asymmetry in morality, which manifests itself in a variety of ways in our intuitive reactions. For example, many intuitively differentiate morality from prudence in holding that morality concerns our interactions with others, whereas prudence is concerned with the well-being of the individual, from that individual’s point of view.

Also, according to our common-sense intuitions we are allowed to pursue our own important projects even if such pursuit is not “optimific” from the impartial point of view (Slote 1985). It is also considered permissible, and even admirable, for an agent to sacrifice her own good for the sake of another even though that is not optimific. However, it is impermissible, and outrageous, for an agent to similarly sacrifice the well-being of another under the same circumstances. Samuel Scheffler argued for a view in which consequentialism is altered to include agent-centered prerogatives, that is, prerogatives to not act so as to maximize the good (Scheffler 1982).

Our reactions to certain cases also seem to indicate a common-sense commitment to the moral significance of the distinction between intention and foresight, doing versus allowing, as well as the view that distance between agent and patient is morally relevant (Kamm 2007).

Philosophers writing in empirical moral psychology have been working to identify other features of common-sense morality, such as how prior moral evaluations influence how we attribute moral responsibility for actions (Alicke et. al. 2011; Knobe 2003).

What many ethicists agree upon is that common-sense is a bit of a mess. It is fairly easy to set up inconsistencies and tensions between common-sense commitments. The famous Trolley Problem thought experiments illustrate how situations which are structurally similar can elicit very different intuitions about what the morally right course of action would be (Foot 1975). We intuitively believe that it is worse to kill someone than to simply let the person die. And, indeed, we believe it is wrong to kill one person to save five others in the following scenario:

David is a great transplant surgeon. Five of his patients need new parts—one needs a heart, the others need, respectively, liver, stomach, spleen, and spinal cord—but all are of the same, relatively rare, blood-type. By chance, David learns of a healthy specimen with that very blood-type. David can take the healthy specimen's parts, killing him, and install them in his patients, saving them. Or he can refrain from taking the healthy specimen's parts, letting his patients die. (Thomson 1976, 206)
And yet, in the following scenario we intuitively view it entirely permissible, and possibly even obligatory, to kill one to save five:

Edward is the driver of a trolley, whose brakes have just failed. On the track ahead of him are five people; the banks are so steep that they will not be able to get off the track in time. The track has a spur leading off to the right, and Edward can turn the trolley onto it. Unfortunately there is one person on the right-hand track. Edward can turn the trolley, killing the one; or he can refrain from turning the trolley, killing the five. (Thomson 1976, 206).
Theorizing is supposed to help resolve those tensions in a principled way. Theory construction attempts to provide guidance in how to resolve such tensions and how to understand them.

1.2 Contrasts Between Morality and Other Normative Domains
1.2.1 Morality and Ethics
Ethics is generally understood to be the study of “living well as a human being”. This is the topic of works such as Aristotle’s Nicomachean Ethics, in which the aim of human beings is to exemplify human excellence of character. The sense in which we understand it here is that ethics is broader than morality, and includes considerations of personal development of oneself and loved ones. This personal development is important to a life well lived, intuitively, since our very identities are centered on projects that we find important. Bernard Williams and others refer to these projects as “ground projects”. These are the sources of many of our reasons for acting. For Williams, if an agent seeks to adopt moral considerations, or be guided by them, then important ethical considerations are neglected, such as personal integrity and authenticity (Williams 1977; Wolf 1982). However, Williams has a very narrow view of what he famously termed “the morality system” (Williams 1985).

Williams lists a variety of objectionable features of the morality system, including the inescapability of moral obligations, the overridingness of moral obligation, impartiality, and the fact that in the morality system there is a push towards generalization.

There has been considerable discussion of each of these features of the morality system, and since Williams, a great deal of work on the part of standard moral theorists on how each theory addresses the considerations he raised. Williams’ critique of the morality system was part of a general criticism of moral theory in the 1980s on the grounds of its uselessness, harmfulness, and even its impossibility (Clarke 1987). This anti-theory trend was prompted by the same dissatisfaction with consequentialism and deontology that led to the resurgence of Virtue Ethics.

A major criticism of this view is that it has a very narrow view of what counts as a moral theory. Thus, some of these approaches simply rejected some features of William’s characterization of the morality system, such as impartiality. Others, however, Williams’ included, attacked the very project of moral theory. This is the ‘anti-theory’ attack on moral theorizing. For example, Annette Baier argued that morality cannot be captured in a system of rules, and this was a very popular theme amongst early virtue ethicists. On this view, moral theory which systematizes and states the moral principles that ought to guide actions is simply impossible: “Norms in the form of virtues may be essentially imprecise in some crucial ways, may be mutually referential, but not hierarchically orderable, may be essentially self-referential” (Baier 220).

Robert Louden even argued that the best construal of virtue ethics is not as an ethical theory, but as anti-theory that should not be evaluated as attempting to theorize morality at all. (Louden 1990). According to Louden, moral theories are formulated to a variety of reasons, including to provide solutions to problems, formulas for action, universal principles, etc. Louden notes that this characterization is very narrow and many would object to it, but he views anti-theory not so much as a position against any kind of moral theorizing, but simply the kind that he viewed as predominant prior to the advent of Virtue Ethics. This is a much less severe version of anti-theory as it, for example, doesn’t seem to regard weightiness or importance of moral reasons as a problem.

Some of the problems that Williams and other anti-theorists have posed for morality, based on the above characteristics, are:

Morality is too demanding and pervasive: that is, the view that moral reasons are weighty indicates that we should be giving them priority over other sorts of reasons. Further, they leach into all aspects of our lives, leaving very little morally neutral.

Morality is alienating. There are a variety of ways in which morality can be alienating. As Adrian Piper notes, morality might alienate the agent from herself or might alienate the agent from others – impartiality and universality might lead to this, for example (Piper 1987; Stocker 1976). Another way we can understand alienation is that the agent is alienated from the true justifications of her own actions – this is one way to hold that theories which opt for indirection can lead to alienation (see section 4 below).

Morality, because it is impartial, makes no room for special obligations. That is, if the right action is the one that is impartial between persons, then it does not favor the near and dear. On this picture it is difficult to account for the moral requirements that parents have towards their own children, and friends have towards each other. These requirements are, by their nature, not impartial.

Morality is committed to providing guides for action that can be captured in a set of rules or general principles. That is, morality is codifiable and the rules of morality are general.

Morality requires too much. The basic worry is that the morality system is voracious and is creeping into all aspects of our lives, to the detriment of other important values. The worry expressed by 4 takes a variety of forms. For example, some take issue with a presupposition of 4, arguing that there are no moral principles at all if we think of these principles as guiding action. Some argue that there are no moral principles that are complete, because morality is not something that is codifiable. And, even if morality was codifiable, the ‘principles’ would be extremely specific, and not qualify as principles at all.

Since Williams’ work, philosophers have tried to respond to the alienation worry by, for example, providing accounts of the ways in which a person’s reasons can guide without forming an explicit part of practical deliberation. Peter Railton, for example, argues in favor of a form of objective consequentialism, Sophisticated Consequentialism, in which the rightness of an action is a function of its actual consequences (Railton 1984). On Railton’s view, one can be a good consequentialist without being alienated from loved ones. Though not attempting to defend moral theory per se, other writers have also provided accounts of how agents can act on the basis of reasons – and thus perform morally worthy actions, even though these reasons are not explicitly articulated in their practical deliberations (Arpaly 2002; Markovits 2014). Deontologists have argued that autonomous action needn’t involve explicit invocation of, for example, the Categorical Imperative (Herman 1985). Generally, what characterizes these moves is the idea that the justifying reasons are present in some form in the agent’s psychology – they are recoverable from the agent’s psychology – but need not be explicitly articulated or invoked by the agent in acting rightly.

One way to elaborate on this strategy is to argue that the morally good agent is one who responds to the right sorts of reasons, even though the agent can’t articulate the nature of the response (Arpaly 2002). This strategy makes no appeal to codifiable principles, and is compatible with a wide variety of approaches to developing a moral theory. It relies heavily on the concept, of course, of “reason” and “moral reason,” which many writers on moral issues take to be fundamental or basic in any case.

There has also been debate concerning the proper scope of morality, and how moral theories can address problems relating to impartiality. Kant and the classical utilitarians believed that moral reasons are impartial, what others have termed agent-neutral. Indeed, this is one point of criticism that virtue ethics has made of these two theories. One might argue that moral reasons are impartial, but that there are other reasons that successfully compete with them – reasons relating to the near and dear, for example, or one’s own ground projects. Or, one could hold that morality includes special reasons, arising from special obligations, that also morally justify our actions.

The first strategy has been pursued by Bernard Williams and other “anti-theorists”. Again, Williams argues that morality is a special system that we would be better off without (Williams 1985). In the morality system we see a special sense of “obligation” – moral obligation – which possesses certain features. For example, moral obligation is inescapable according to the morality system. A theory such as Kant’s, for example, holds that we must act in accordance with the Categorical Imperative. It is not optional. This is because morality is represented as having authority over us in ways that even demand sacrifice of our personal projects, of the very things that make our lives go well for us. This seems especially clear for Utilitarianism, which holds that we must maximize the good, and falling short of maximization is wrong. A Kantian will try to avoid this problem by appealing to obligations that are less demanding, the imperfect ones. But, as Williams points out, these are still obligations, and as such can only be overridden by other obligations. Thus, the theories also tend to present morality as pervasive in that morality creeps into every aspect of our lives, making no room for neutral decisions. For example, even decisions about what shoes to wear to work becomes a moral one:

Once the journey into more general obligations has started, we may begin to get into trouble – not just philosophical trouble, but the conscience trouble – with finding room for morally indifferent actions. I have already mentioned the possible moral conclusion that one may take some particular course of action. That means that there is nothing else I am obliged to do. But if we have accepted general and indeterminate obligations to further various moral objectives…they will be waiting to provide work for idle hands… (Williams 1985, 181)
He goes on to write that in order to get out of this problem, “…I shall need one of those fraudulent items, a duty to myself” (Williams 1985, 182). Kantian Ethics does supply this. Many find this counterintuitive, since the self/other asymmetry seems to capture the prudence/morality distinction, but Kantians such as Tom Hill, jr. have made strong cases for at least some moral duties to the self. In any case, for writers such as Williams, so much the worse for morality.

Other writers, also concerned about the problems that Williams has raised argue, instead, that morality does make room for our partial concerns and projects, such as the norms governing our relationships, and our meaningful projects. Virtue ethicists, for example, are often comfortable pointing out that morality is not thoroughly impartial because there are virtues of partiality. Being a good mother involves having a preference for the well-being of one’s own children. The mother who really is impartial would be a very bad mother, lacking in the appropriate virtues.

Another option is to hold that there are partial norms, but those partial norms are themselves justified on impartial grounds. This can be spelled out in a variety of different ways. Consider Marcia Baron’s defense of impartiality, where she notes that critics of impartiality are mistaken because they confuse levels of justification: “Critics suppose that impartialists insisting on impartiality at the level of rules or principles are committed to insisting on impartiality at the level of deciding what to do in one’s day-to-day activities” (Baron 1991). This is a mistake because impartialists can justify partial norms by appealing to impartial rules or principles. She is correct about this. Even Jeremy Bentham believed, for example, that the principle of utility ought not be applied in every case, though he mainly appealed to efficiency costs of using the principle all the time. But one can appeal to other considerations. Frank Jackson uses an analogy with predators to argue that partial norms are strategies for maximizing the good, they offer the best chance of actually doing so given our limitations (Jackson 1991). Similarly, a Kantian such as Tom Hill, jr., as Baron notes, can argue that impartiality is part of an ideal, and ought not govern our day-to-day lives (Hill 1987). Does this alienate people from others? The typical mother shows the right amount of preference for her child, let’s say, but doesn’t herself think that this is justified on the basis of promoting the good, for example. A friend visits another in the hospital and also does not view the partiality as justified by any further principles. But this is no more alienating than someone being able to make good arguments and criticize bad ones without a knowledge of inference rules. Maybe it is better to have an awareness of the underlying justification, but for some theories even that is debatable. For an objective theorist (see below) it may be that knowing the underlying justification can interfere with doing the right thing, in which case it is better not to know. For some theorists, however, such as neo-Aristotelian virtue ethicists, a person is not truly virtuous without such knowledge and understanding, though Rosalind Hursthouse (1999) does not make this a requirement of right action.

Recently consequentialists have been approaching this issue through the theory of value itself, arguing that there are agent-relative forms of value. This approach is able to explain the intuitions that support partial moral norms while retaining the general structure of consequentialism (Sen 2000). Douglas Portmore, for example, argues for a form of consequentialism that he terms “commonsense consequentialism” as it is able to accommodate many of our everyday moral intuitions (Portmore 2011). He does so by arguing that (1) the deontic status of an act, whether it is right or wrong, is determined by what reasons the agent has for performing it – if an agent has a decisive reason to perform the act in question, then it is morally required. Combined with (2) a teleological view of practical reasons in which our reasons for performing an action are a function of what we have reason to prefer or desire we are led to a form of act-consequentialism but one which is open to accepting that we have reason to prefer or desire the well-being of the near and dear over others.

Though much of this is controversial, there is general agreement that moral reasons are weighty, are not egoistic – that is, to be contrasted with prudential reasons, and are concerned with issues of value [duty, fittingness].

1.2.2. Morality and Aesthetics
Moral modes of evaluation are distinct from the aesthetic in terms of their content, but also in terms of their authority. So, for example, works of art are evaluated as “beautiful” or “ugly”, and those evaluations are not generally considered as universal or as objective as moral evaluations. These distinctions between moral evaluation and aesthetic evaluation have been challenged, and are the subject of some interesting debates in metaethics on the nature of both moral and aesthetic norms and the truth-conditions of moral and aesthetic claims. But, considered intuitively, aesthetics seems at least less objective than morality.

A number of writers have noted that we need to be cognizant of the distinction between moral norms and the norms specific to other normative areas in order to avoid fallacies of evaluation, and much discussion has centered on a problem in aesthetics termed the “Moralistic Fallacy” (D’Arms and Jacobson 2000).

One challenge that the anti-theorists have raised for morality was to note that in a person’s life there will be certain norm clashes – including clashes between types of norms such as the moral and the aesthetic. It is giving too much prominence to the moral that judges a person’s life as going well relative to the fulfillment or respect of those norms. Can’t a human life go well, even when that life sacrifices morality for aesthetics?

This sort of debate has a long history in moral theory. For example, it arose as a form of criticism of G. E. Moore’s Ideal Utilitarianism, which treated beauty as an intrinsic good, and rendering trade-offs between behaving well towards others and creating beauty at least in principle justified morally (Moore 1903). But the anti-theorists do not pursue this method of accommodating the aesthetic, instead arguing that it is a separate normative realm which has its own weight and significance in human flourishing.

2. Theory and Theoretical Virtues
There is agreement that theories play some kind of systematizing role, and that one function is to examine important concepts relevant to morality and moral practice and the connections, if any, between them. For example, one very common view in the middle of the 20th century, attributed to John Rawls, was to view moral theory as primarily interested in understanding the ‘right’ and the ‘good’ and connections between the two (Rawls). Priority claims are often a central feature in the systematizing role of moral theory. Related to this is the issue of explanatory, or theoretical, depth. That is, the deeper the explanation goes, the better.

Theories also strive for simplicity, coherence, and accuracy. The fewer epicycles the theory has to postulate the better, the parts of the theory should fit well together. For example, the theory should not contain inconsistent principles, or have inconsistent implications. The theory should cover the phenomena in question. In the case of moral theories, the phenomena in question are thought to be our considered moral intuitions or judgements. Another coherence condition involves the theory cohering with a person’s set of considered judgments, as well.

One last feature that needs stressing, particularly for moral theories, is applicability. One criticism of some normative ethical theories is that they are not applicable. For example, Virtue Ethics has been criticized for not providing an account of what our moral obligations are – appealing to what the virtuous person would do in the circumstances would seem to set a very high bar or doesn’t answer the relevant question about how we should structure laws guiding people on what their social obligations are. Similarly, objective consequentialists, who understand “right action” in terms of actual consequences have been criticized for rendering what counts as a right action in a given circumstance unknowable, and thus useless as a guide to action. Both approaches provide responses to this worry, but this supports the claim that a desideratum of a moral theory is that it be applicable.

2.1 The Tasks of Moral Theory
One task (though this is somewhat controversial) of a moral theory is to give an account of right actions. Often, this will involve an explication of what counts as good – some theories then get spelled out in terms of how they approach the good, by maximizing it, producing enough of it, honoring it, etc. In addition, some theories explicate the right in terms of acting in accordance with one’s duties, or acting as a virtuous person would act. In these cases the notions of ‘duty’ and ‘virtue’ become important to the overall analysis, and one function of moral theory is to explore the systematic connections between duty or virtue and the right and the good.

Moral theories also have both substantive and formal aims. Moral theories try to provide criteria for judging actions. It might be that the criterion is simple, such as right actions maximize the good, or it may be complex, such as the right action is the one that gives adequate weight to each competing duty. Sometimes, in recognition that there is not always “the” right action, the theory simply provides an account of wrongness, or permissibility and impermissibility, which allows that a range of actions might count as “right”.

In addition to simply providing criteria for right or virtuous action, or for being a virtuous person, a given moral theory, for example, will attempt to explain why something, like an action or character trait, has a particular moral quality, such as rightness or virtuousness. Some theories view rightness as grounded in or explained by value. Some view rightness as a matter of reasons that are prior to value. In each case, to provide an explanation of the property of ‘rightness’ or ‘virtuousness’ will be to provide an account of what the grounding value is, or an account of reasons for action.

In addition, moral theories may also provide decision-procedures to employ in determining how to act rightly or virtuously, conditions on being good or virtuous, or conditions on morally appropriate practical deliberation. Thus, the theory provides substance to evaluation and reasons. However, moral theories, in virtue of providing an explanatory framework, help us see connections between criteria and decision-procedures, as well as provide other forms of systemization. Thus, moral theories will be themselves evaluated according to their theoretical virtues: simplicity, explanatory power, elegance, etc. To evaluate moral theories as theories, each needs to be evaluated in terms of how well it succeeds in achieving these theoretical goals.

There are many more specialized elements to moral theories as well. For example, a moral theory often concerns itself with features of moral psychology relevant to action and character, such as motives, intentions, emotions, and reasons responsiveness. A moral theory that incorporates consideration of consequences into the determination of moral quality, will also be concerned with issues surrounding the proper aggregation of those consequences, and the scope of the consequences to be considered.

2.2 Theory Construction
There’s been a long history of comparing moral theories to other sorts of theories, such as scientific ones. For example, in meta-ethics one issue has to do with the nature of moral “evidence” on analogy with scientific evidence. On what Ronald Dworkin terms the “natural model” the truths of morality are discovered, just as the truths of science are (Dworkin 1977, 160). It is our considered intuitions that provide the clues to discover these moral truths, just as what is observable to us provides the evidence to discover scientific truths. He compared this model with the “constructive model” in which the intuitions themselves are features of the theory being constructed and are not analogous to observations of the external world.

Yet, even if we decide that morality lacks the same type of phenomena to be accounted for as science, morality clearly figures into our normative judgments and reactions. One might view these – our intuitions about moral cases, for example – to provide the basic data that needs to be accounted for by a theory on either model.

One way to “account for” our considered intuitions would be to debunk them. There is a long tradition of this in moral philosophy as well. When scholars provided genealogies of morality that explained our considered intuitions in terms of social or evolutionary forces that are not sensitive the truth, for example, they were debunking morality by undercutting the authority of our intuitions to provide insight into it (Nietzsche 1887 [1998], Joyce 2001, Street 2006). In this entry, however, we consider the ways in which moral theorists have constructed their accounts by taking the intuitions seriously as something to be systematized, explained, and as something that can be applied to generate the correct moral decisions or outcomes.

Along these lines, one method used in theory construction would involve the use of reflective equilibrium and inference to the best explanation. For example, one might notice an apparent inconsistency in moral judgements regarding two structurally similar cases and then try to figure out what principle or set of principles would achieve consistency between them. In this case, the theorist is trying to figure out what best explains both of those intuitions. But one also might, after thinking about principles one already accepts, or finds plausible, reject one of those intuitions on the basis of it not cohering with the rest of one’s considered views. But full theory construction will go beyond this because of the fully theoretical virtues discussed earlier. We want a systematic account that coheres well not only with itself, but with other things that we believe on the basis of good evidence.

3. Criteria
Consider the following:

Malory has promised to take Chris grocery shopping. Unfortunately, as Malory is leaving the apartment, Sam calls with an urgent request: please come over to my house right now, my pipes have broken and I need help! Torn, Malory decides to help Sam, and thus breaks a promise to Chris.
Has Malory done the right thing? The virtuous thing? Malory has broken a promise, which is pro tanto wrong, but Sam is in an emergency and needs help right away. Even if it is clear that what Malory did was right in the circumstances, it is an interesting question as to why it is right. What can we appeal to in making these sorts of judgments? This brings to light the issue of how one morally justifies one’s actions. This is the task of understanding what the justifying reasons are for our actions. What makes an action the thing to do in the circumstances? This is the criterion of rightness (or wrongness). We will focus on the criterion of rightness, though the criterion issue comes up with other modes of moral evaluation, such as judging an action to be virtuous, or judging it to be good in some respect, even if not right. Indeed, some writers have argued that ‘morally right’ should be jettisoned from modern secular ethics, as it presupposes a conceptual framework left over from religiously based accounts which assume there is a God (Anscombe 1958). We will leave these worries aside for now, however, and focus on standard accounts of criteria.

The following are some toy examples that exhibit differing structural features for moral theories and set out different criteria:

Consequentialism.
The right action is the action that produces good amongst the options open to the agent at the time of action (Singer). The most well-known version of this theory is Classical Utilitarianism, which holds that the right action promotes pleasure (Mill).

Kantian Deontology.
The morally worthy action is in accordance with the Categorical Imperative, which requires an agent refrain from acting in a way that fails to respect the rational nature of other persons (Kant).

Rossian Deontology.
The right action is the action that best accords with the fulfillment and/or non-violation of one’s prima facie duties (Ross).

Contractualism.
An action is morally wrong if it is an act that would be forbidden by principles that rational persons could not reasonably reject (Scanlon).

Virtue Ethics.
The right action is the action that a virtuous person would characteristically perform in the circumstances (Hursthouse 1999).

These principles set out the criterion or standard for evaluation of actions. They do not necessarily tell us how to perform right actions, and are not, in themselves, decision-procedures, though they can easily be turned into decision procedures, such as: you ought to try to perform the action that maximizes the good amongst the options available to you at the time of action. This might not be, and in ordinary circumstance probably isn’t, a very good decision-procedure, and would itself need to be evaluated according to the criterion set out by the theory.

These theories can be divided, roughly, into the deontological, consequentialist, and virtue ethical categories. There has been a lively debate about how, exactly, to delineate these categories. Some have held that deontological theories were just those theories that were not consequentialist. A popular conception of consequentialist theories is that they are reductionist in a particular way – that is, in virtue of reducing deontic features of actions (e.g. rightness, obligatoriness) to facts about an agent’s options and the consequences of those options (Smith 2009). If that is the case, then it seems that deontological approaches are just the ones that are not reductive in this manner. However, this fails to capture the distinctive features of many forms of virtue ethics, which are neither consequentialist nor necessarily concerned with what we ought to do, our duties as opposed to what sorts of persons we should be.

One way to distinguish consequentialist from deontological theories is in terms of how each approaches value. Philip Pettit has suggested that while consequentialist theories required promotion of value, deontological theories recommend that value be honored or respected. On each of these views, value is an important component of the theory, and theories will be partially delineated according to their theory of value. A utilitarian such as Jeremey Bentham believes that hedonism is the correct theory of value, whereas someone such as G. E. Moore, a utilitarian but a pluralist regarding value, believes that hedonism is much too narrow an account. A Kantian, on the other hand, views value as grounded in rational nature, in a will conforming to the Categorical Imperative.

Because of the systematizing function of moral theory discussed earlier, the simplest account is to be preferred and thus there is a move away from endorsing value pluralism. Of course, as intuitive pressure is put on each of the simpler alternatives, a pluralistic account of criteria for rightness and wrongness has the advantage of according best with moral intuitions.

Reasons-first philosophers will delineate the theories somewhat differently. For example, one might understand goodness as a matter of what we have reason to desire, in which case what we have reason to desire is prior to goodness rather than the other way around. Value is still an important component of the theories, it is simply that the value is grounded in reasons.

Another distinction between normative theories is that between subjective and objective versions of a type of theory. This distinction cuts across other categories. For example, there are subjective forms of all the major moral theories, and objective versions of many. An objective standard of right holds that the agent must actually meet the standard – and meeting the standard is something ‘objective’, not dependent on the agent’s psychological states – in order to count as right or virtuous. Subjective standards come in two broad forms:

Psychology sensitive: are the justifying reasons part of the agent’s deliberative processes? Or, more weakly, are they “recoverable” from the agent’s psychology [perhaps, for example, the agent has a commitment to the values that provide the reasons].
Evidence sensitive: the right action isn’t the one that actually meets the standard, but instead, is the action that the agent could foresee would meet that standard. [there are many different ways to spell this out, depending on the degree of evidence that is relevant: in terms of what the agent actually foresees, what is foreseeable by the agent given what the agent knows, is foreseeable by someone in possession of a reasonable amount of evidence, etc.]
Of course, these two can overlap. For theorists who are evaluational internalists, evidence-sensitivity doesn’t seem like a plausible way of spelling out the standard, except, perhaps, indirectly. The distinction frequently comes up in Consequentialism, where the Objective standard is taken to be something like: the right action is the action that actually promotes the good and the Subjective standard is something like: the right action is the action that promotes the good by the agent’s own lights (psychology sensitive) or the right action is the action that promotes the foreseeable good, given evidence available at the time of action (evidence sensitive standard). It is certainly possible for other moral standards to be objective. For example, the right action is the action that the virtuous person would perform, even though the agent does not realize it is what the virtuous agent would do in the circumstances, and even if the person with the best available evidence couldn’t realize it is what the virtuous person would do in the circumstances.

We certainly utter locutions that support both subjective and objective uses of what we ‘ought’ to do, or what is ‘right’. Frank Jackson notes this when he writes:

…we have no alternative but to recognize a whole range of oughts – what she ought to do by the light of her beliefs at the time of action, …what she ought to do by the lights of one or another onlooker who has different information on the subject, and, what is more, what she ought to do by God’s lights…that is, by the lights of one who knows what will and would happen for each and every course of action. (Jackson 1991, 471).
For Jackson, the primary ought, the primary sense of ‘rightness’ for an action, is the one that is “most immediately relevant to action” since, otherwise, we have a problem of understanding how the action is the agent’s. Thus, the subjective ‘ought’ is primary in the sense that this is the one that ethical theory should be concerned with (Jackson 1991). Each type of theorist makes use of our ordinary language intuitions to make their case. But one desideratum of a theory is that it not simply reflect those intuitions, but also provides the tools to critically analyze them. Given that our language allows for both sorts of ‘ought,’ the interesting issue becomes which, if either, has primacy in terms of actually providing the standard by which other things are evaluated? Moral theory needn’t only be concerned with what the right action is from the agent’s point of view.

There are three possibilities:

neither has primacy
the subjective has primacy
the objective has primacy
First off we need to understand what we mean by “primacy”. Again, for Frank Jackson, the primary sense of ‘right’ or ‘ought’ is subjective, since what we care about is the ‘right’ that refers to an inward story, the story of our agency, so to speak. On this view, the objective and subjective senses may have no relationship to each other at all, and which counts as primary simply depends upon our interests. However, the issue that concerns us here is whether or not one sense can be accounted for in terms of the other. Option 1 holds that there is no explanatory connection. That is not as theoretically satisfying. Option 2 holds either there really is no meaningful objective sense, just the subjective sense, or the objective sense is understood in terms of the subjective.

Let’s look at the objective locution again “He did the right thing, but he didn’t know it at the time (or he had no way of knowing it at the time)”. Perhaps all this means is “He did what someone with all the facts and correct set of values would have judged right by their own lights” – this would be extensionally the same as “He performed the action with the best actual consequences”. This is certainly a possible account of what objective right means which makes use of a subjective standard. But it violates the spirit of the subjective standard, since it ties rightness neither to the psychology of the agent, or the evidence that is actually available to the agent. For that reason, it seems more natural to opt for 3. An advantage of this option is that gives us a nice, unified account regarding the connection between the objective and the subjective. Subjective standards, then, are standards of praise and blame, which are themselves evaluable according to the objective standard. Over time, people are in a position to tell whether or not a standard actually works in a given type of context. Or, perhaps it turns out that there are several standards of blame that differ in terms of severity. For example, if someone acts negligently a sensible case can be made that the person is blameworthy but not as blameworthy as if they had acted intentionally.

As to the worry that the objective standard doesn’t provide action guidance, the objective theorist can hold that action guidance is provided by the subjective standards of praise/blameworthiness. Further, the standard itself can provide what we need for action guidance through normative review (Driver 2012). Normative review is a retrospective look at what does in fact meet the standard, and under what circumstances.

Now, consider a virtue ethical example. The right action is the action that is the actual action that a virtuous person would perform characteristically, in the circumstances, rather than the action that the agent believes is the one the virtuous person would perform. Then we evaluate an agent’s “v-rules” in terms of how close they meet the virtuous ideal.

4. Decision Procedures and Practical Deliberation
Another function of moral theory is to provide a decision procedure for people to follow so as to best insure they perform right actions. Indeed, some writers, such as R. M. Hare hold action guidance to be the function of the moral principles of the theory (Hare 1965). This raises the question of what considerations are relevant to the content of such principles – for example, should the principles be formulated taking into account the epistemic limitations of most human beings? The requirement that moral principles be action guiding is what Holly Smith terms the “Useability Demand”: “…an acceptable moral principle must be useable for guiding moral decisions…” (Smith 2020, 11). Smith enumerates different forms satisfaction of this demand can take, and notes that how one spells out a principle in order to meet the demand will depend upon how the moral theorist views moral success. For example, whether or not success is achieved in virtue of simply making the right decision or if, in addition to making the right decision, the agent must also have successful follow-through on that decision.

There has been enormous debate on the issue of what is involved in following a rule or principle, and some skepticism that this is in fact what we are doing when we take ourselves to be following a rule. (Kripke 1982) Some virtue theorists believe that it is moral perception that actually does the guiding, and that a virtuous person is able to perceive what is morally relevant and act accordingly (McDowell 1979).

As discussed earlier in the section on criteria, however, this is also controversial in that some theorists believe that decision procedures themselves are not of fundamental significance. Again, objective consequentialist who believes that the fundamental task of theory is to establish a criterion for right argues that decision procedures will themselves be established and evaluated on the basis of how well they get us to actually achieving the right. Thus, the decision-procedures are derivative. Others, such as subjective consequentialists, will argue that the decision-procedures specify the criterion in the sense that following the decision-procedure itself is sufficient for meeting the criterion. For example, an objective consequentialist will hold that the right action maximizes the good, whereas the subjective consequentialist might hold that the right action is to try to maximize the good, whether or not one actually achieves it (Mason 2003 and 2019). Following the decision-procedure itself, then, is the criterion.

The distinction between criterion and decision-procedure has been acknowledged and discussed at least since Sidgwick, though it was also mentioned by earlier ethicists. This distinction allows ethical theories to avoid wildly implausible implications. For example, if the standard that the theory recommends is ‘promote the good’ it would be a mistake to think that ‘promote the good’ needs to be part of the agent’s deliberation. The consequentialist might say that, instead, it is an empirical issue as to what the theory is going to recommend as a decision-procedure, and that recommendation could vary from context to context. There will surely be circumstances in which it would be best to think in terms of meeting the standard itself, but again that is an empirical issue. Likewise, it is open to a Virtue Ethicist to hold that the right action is the one the virtuous agent would perform in the circumstances, but also hold that the agent’s deliberative processes need not make reference to the standard. Pretty much all theories will want to make some space between the standard and the decision-procedure in order to avoid a requirement that agent’s must think in terms of the correct standard, in order to act rightly, or even act with moral worth. There is a distinction to be made between doing the right thing, and doing the right thing for the right reasons. Doing the right thing for the right reasons makes the action a morally worthy one, as it exhibits a good quality of the will. It is possible for a theory to hold that the ‘good will’ is one that understands the underlying justification of an action, but that seems overly demanding. If consequentialism is the correct theory, then demanding that people must explicitly act intentionally to maximize the good would result in fewer morally worthy actions than seems plausible. The ‘for the right reasons’ must be understood as allowing for no explicit invocation of the true justifying standard.

This has led to the development of theories that advocate indirection. First, we need to distinguish two ways that indirection figures into moral philosophy.

Indirection in evaluation of right action.
Indirection in that the theory does not necessarily advocate the necessity of aiming for the right action.
To use Utilitarianism as an example again, Rule Utilitarianism is an example of the first sort of indirection (Hooker 2000), Sophisticated Consequentialism is an example of the second sort of indirection (Railton 1984). One might hold that some versions of Aristotelian Virtue ethics, such as Rosalind Hursthouse’s version, also are of the first type, since right action is understood in terms of virtue. One could imagine an indirect consequentialist view with a similar structure: the right action is the action that the virtuous person would perform, where virtue is understood as a trait conducive to the good, instead of by appeal to an Aristotelian notion of human flourishing.

The second sort relies on the standard/decision-procedure distinction. Railton argues that personal relationships are good for people, and explicitly trying to maximize the good is not a part of our relationship norms, so it is likely good that we develop dispositions to focus on and pay special attention to our loved ones. The account is open to the possibility that people who don’t believe in consequentialism have another way of deciding how to act that is correlated with promotion of the good. If the criteria a theory sets out need not be fulfilled by the agent guiding herself with the reasons set out by the criteria, then it is termed self-effacing. When a theory is self-effacing, it has the problem of alienating a person from the justification of her own actions. A middle ground, which is closer to Railton’s view, holds that the correct justification is a kind of “touchstone” to the morally good person – consulted periodically for self-regulation, but not taken explicitly into consideration in our ordinary, day-to-day lives. In this way, the theory would not be utterly self-effacing and the agent would still understand the moral basis for her own actions.

1. Background
Writers on aesthetics in the empiricist tradition such as Shaftsbury, Hume, and Reid thought of their contributions as broadly empirical (see Shelley 2006 [2020]), and among the very first experimental investigations in psychology were studies of aesthetic preferences and responses, for example Fechner’s attempt to discover whether the “golden section” is especially preferred to other ratios (1871). The late nineteenth and early twentieth centuries were rich in work of this kind, and there were more speculative studies of “embodied” responses to architectural structures, a debate that brought the term “empathy” to the English language (Vischer 1873; Lipps 1903). But for most of the twentieth century aesthetics was seen, by its proponents and its detractors, as an “armchair” project. Wittgenstein, whose conception of philosophy strongly influenced the field’s direction in the century’s latter half, said

There doesn’t seem to be any connection between what psychologists do and any judgement about a work of art. (1967, 19; on Wittgenstein’s own experimental work on the perception of rhythm see Guter 2020)

To the extent that aesthetics in this period was influenced by thinking about the mind it was more often prompted by ideas from psychoanalysis (Wollheim 1993). The last thirty years have seen a shift back towards empirical inquiry, assisted by a resurgence of interest in the imagination, now often treated as a capacity with an evolutionary and developmental history (Fuentes 2020; Harris 2000) and as subject to selective damage (Currie 1996).

It has never been plausible to think of aesthetics as wholly a priori. Even those who think its main business is the analysis of widely shared folk concepts (Dickie 1962) will agree that a philosopher of music should have a good deal of knowledge of the history, art making practices and traditions of criticism of some musical tradition. In this respect aesthetics is closer to the philosophy of physics or economics than it is to metaphysics. There is also a frequently acknowledged connection between aesthetics and the study of perception. When Baumgarten (1750–58) first introduced the term “aesthetics” he called it a “science of perception” and according to Nanay (2014: 101)

many, maybe even most traditional problems in aesthetics are in fact about philosophy of perception and can, as a result, be fruitfully addressed with the help of the conceptual apparatus of the philosophy of perception.

This is a stronger claim than many would make (see Margolis 1960; Sibley 1965; Schellekens 2006; and Robson 2018) but theses in aesthetics do sometimes depend on claims, including scientifically tractable claims, about the nature of perception. A notable example is the debate about whether perception is cognitively penetrable; if it is, the way a picture looks or a piece of music sounds may depend on what the observer knows about contextual factors (for the rejection of cognitive penetrability see Danto 2001; for criticism see Rose & Nanay 2022).

Philosophical doubts about the relevance of empirical work to aesthetics are of various kinds. Some authors merely suggest that philosophers are apt to make hasty generalisations from slender experimental evidence, give insufficient attention to their details and limitations, and fail to acknowledge the existence of conflicting expert opinion (Konečni 2013; Stock 2014). Philosophers, aestheticians among them, can certainly overestimate their expertise on occasion and it may well be that they are even more prone to do so when it comes to empirical matters. None of this points to anything in principle problematic about their enthusiasm for the empirical. Other doubters emphasise what they see as more systemic dangers. Roger Scruton (2014) suggests a tendency to try to assimilate aesthetic phenomena to available scientific frameworks that turn out to be ill fitting; he cites the attempt to use Chomskian linguistics to found a generative theory of music which, he claims, fails to accommodate either music’s structure or purpose. Gordon Graham (2014), contrasting Hume’s aesthetic theory unfavourably with that of Reid, says that the project of an “aesthetic science” must ignore or deny the role of reason and judgement. Again, one may be alive to both kinds of dangers while retaining an openness to empirical work. In particular, Graham’s challenge might be responded to by noting that studies of the role actually played by reasons in aesthetic judgement point to a sometimes striking disconnect between what people think of as their reasons and the factors that determine their preferences (Lopes 2014 and Irvin 2014; see also below, Section 3); this can hardly be irrelevant to someone investigating the rationality of aesthetic judgement. Further, work which aestheticians have thought of as conceptual analysis in a broad sense has often presumed answers to what are in fact empirical questions. Noel Carroll says that

The supposition that aesthetic properties are objective also explains better how we talk about them than does the projection theory. …people involved in disputes about aesthetic properties … speak as if one side of the disagreement is right and the other wrong. (Carroll 1999: 117)

Studies in the new field of “experimental philosophy” (for some overviews of this field, as applied to aesthetics, see Cova & Réhault 2018 and Torregrossa 2020) challenge this view. One study (Cova, Olivola, et al. 2019) gathered more than two thousand responses across 19 countries to an imagined disagreement about whether an object of aesthetic interest is beautiful. It found that in all populations the least popular view was that “someone is right and someone is wrong”. The study itself has come in for criticism (Zangwill 2018) but, regardless of its success, it highlights the general point that we should not assume without evidence that the philosopher’s understanding of folk concepts (or folk practice) matches that of the folk themselves: something that should be of concern to those, such as Dickie, who conceive of the work of aestheticians as largely involving the elucidation of folk concepts.

The question discussed above and to which Carroll and the members of the Cova team give such different answers is a higher order question, concerning whether people think of aesthetic judgements as having normative force. We can ask similar questions about lower level judgements. Consider the claim that we shouldn’t form aesthetic judgements on the basis of testimony, a claim said to be supported by our supposed practice of refraining from forming such judgements (Kant 1790 [2000: 9]; Nguyen 2020: 1127). Contrary to this, Robson (2014) argues that this descriptive claim about our judgement forming practice is mistaken—something which would, if true, undermine one significant motivation for the normative claim.

From an entirely different perspective, there are those who think that philosophers have very little role to play in answering key aesthetic questions and that we should seek to replace, rather than merely supplement, traditional philosophical methods with more scientific approaches. Exemplifying this tendency, Semir Zeki says

no theory of aesthetics that is not substantially based on the activity of the brain is ever likely to be complete, let alone profound,

going on to say that painting is an inquiry into the laws of the brain and that what pleases us is what pleases our brains (1999: 1–2). While attitudes such as this may not constitute a complete dismissal of philosophical aesthetics they show little awareness of its results, or understanding of the limitations of neurological studies. Facts about brain processes do not tell us—at least without some substantive and controversial bridging premises—what objects are art works, or what works have value (see Hyman 2010 for wide ranging criticism of this approach). The relations between empirical work and normative aesthetics will recur throughout this entry.

2. Bottom-up and Top-Down Approaches to Aesthetics
A good deal of empirical work on the aesthetic, while not deriving from hostility to philosophical ideas, adopts a “bottom up” approach, focusing on the immediate reactions of untutored subjects to simple stimuli. We have seen that, by contrast, philosophical aesthetics is much concerned with normative issues of judgement and value, and with the claimed dependence of these things on training, knowledge and what is sometimes called “taste”, But these empirical studies are not philosophically irrelevant; we should not assume that the aesthetic responses of experts are discontinuous with those of naïve subjects (though for a discussion of the burden of proof here see Williamson 2011), nor that expert judgements are sensitive only to the factors that experts themselves endorse. It is important to ask whether there are baseline aesthetic responses, perhaps invariant across cultures, from which the great variety of aesthetic traditions emerge, and which may impose limits on those traditions and their products (for a defence of this “bottom up” approach to experiments in aesthetic see McManus 2011). Wölfflin, a founder of modern art history, had an interest in questions framed in this way: he claimed, for example, that there is a general tendency to prefer a rightward placement of a significant object within an image (1928). Subsequent research suggests a more complex picture, with preference dependent on physical and cultural factors: handedness, and whether one reads/writes left-to-right or right-to-left (see Palmer, Gardner, & Wickens 2008 for references and discussion; Chahboun et al. 2017 found some limited support for the idea that placement preference depends on the subject’s direction of reading/writing). Other studies have shown robust preferences for certain colours (Palmer & Schloss 2010), shapes, positioning of objects within a frame (Palmer, Gardner, & Wickens 2008) and size (Linsen, Leyssen, Sammartino, & Palmer 2011). These preferences often turn out to be ecologically driven; for example, people tend to like the colours of liked objects, with strong and culturally invariant liking of saturated blue and invariant hostility to colours associated with faeces and vomit. There are cultural variations; for example Japanese subjects appear to be unusual in their lack of enthusiasm for dark red (Palmer & Schloss 2010). Some colour preferences are very culturally specific, as with the preferences of college students for colours associated with their schools (Schloss, Poggesi, & Palmer 2011).

Studies such as these may be thought valuable in their capacity to explain persistent features of aesthetic artefact-making but are unlikely to provide more than a general background against which aesthetic preferences and judgements, debates and disagreements concerning particular artefacts are played out. Saturated blue will be the right colour in a certain context, while muddy brown will be right in another. We cannot say that the presence of saturated blue in a picture is in general a reason, even a pro tanto reason, for admiring it or preferring it to a picture without that colour. When it comes to aesthetic reasons and judgements rather than unreflective preferences—when, that is, we consider top-down effects—cognitive science so far offers little to help us. This may to some extent be due to the nature of human cognition itself. Aesthetic reasons, in so far as we have them at all, are highly resistant to formulation in general terms (Sibley 1959), and once we abandon the view that aesthetic qualities supervene on an object’s appearance narrowly described (colour, shape and size in the case of visual art), there is no obvious way to limit the factors that legitimately impact on such judgements. This suggests a domain where, roughly speaking, everything is relevant to everything: the isotropy that is crucial to Fodor’s (1983) scepticism about a cognitive science of thinking. One recent study does attempt a unification of top-down and bottom-up approaches. Bullot and Reber (2013) develop a “psycho-historical” process that begins with a perceptual confrontation with the work, and culminates in artistic understanding, mediated by the viewer’s adoption of the design stance which involves reconstructing the genealogy of the work. This approach encounters two difficulties. First is their assumption that progress between stages is able to be done largely by the extraction of information from the perceptual signal. In fact the work’s appearance is often ambiguous or misleading as to its history—as when a work is carefully constructed to look haphazard in its construction (Levinson 2013; Ross 2013). The model needs to recognise the importance of art-historical knowledge gained from such sources as lectures and text books, knowledge which will often precede and inform the first stage. The second objection concerns the role of presumed essentialist assumptions in people’s approach to art works. Bullot and Reber argue that the historical nature of appreciation is explained by our commitment to psychological essentialism which makes us look beyond a things appearance to investigate its essence (2013: 132). But an inclination to look beyond appearances need not depend on essentialism; it might be that the interest or value of a thing sometimes resides in its relational and contingent properties (Korsgaard 1983). Valuing a work on account of its history of making no more implies an essential connection between the work and its history than valuing an object because it was a gift from a loved one implies an essential connection between the object and the giver.

3. Preference, Judgement and Reasons
As well as studies designed to elicit preferences, there are empirically motivated theories that purport to explain them. Among the earliest is Wundt’s (1874) suggestion that we judge a form pleasing to the extent that the eye finds it easy to follow the contour. Recent work generalises this thought: there is said to be a tendency for stimuli to be experienced positively when our perceptual or cognitive grasp on them comes easily (Reber, Schwarz, & Winkielman 2004). This idea of processing fluency is not limited to the aesthetic domain; we generally find a proposition more believable, apparently, if it is expressed in rhyme or in an easy to read font and this is said to be because these things increase fluency (Reber & Schwarz 1999; McGlone & Tofighbakhsh 2000). So aesthetic and fluent phenomena are not coextensive, and no reduction of the one to the other is possible. The most that can be said (and this is not insignificant) is that certain kinds of fluency underpin experiences of aesthetic pleasure and displeasure, symmetry offering a plausible example; for comments on the significance of such research into underlying mechanisms see Section 4 below.

One concern about an approach to the aesthetic by way of fluency is that fluency apparently encourages a less careful examination of the stimulus (Song & Schwarz 2008), a suggestion at odds with the aesthetic ideal of a finely discriminating attitude to art. Another is that fluency-based likings for stimuli seem to have very limited application in aesthetics beyond the domain of simple shape preferences. Pictures which are visually complex are often widely admired and not merely by the art-world elite (see for example Frith’s busy genre paintings). It is said that the pleasure derived from fluency is relative to expectation: pleasure taken in a Bach fugue depends on it being more fluent than one expects (Reber 2012: 228, citing Hansen, Dechêne, & Wänke 2008). But why must lovers of Bach have unrealistic expectations about the fluency of his music? Finally (a theme we will return to) citing fluency would not be a reason for admiring the picture or fugue in question; this approach seems to focus on pleasure and leave notions of reason and judgement out of account. (For criticism of the fluency program in aesthetics see Cochrane 2021a, Section 2.3.)

Another aspect of fluency is said to be the mere exposure effect: our tendency to find a statement more believable if we have heard it often, repeated hearings leading to progressively more fluent processing (Begg, Anas, & Farinacci 1992). Cutting (2003) investigated an aesthetic variant of the idea: liking for a picture is increased by repeated exposure to it. This, it is suggested, may explain the stability of the artistic canon: works canonical at t are more available to be seen, and the mere exposure effect raises the likelihood of their being canonical at t + 1. Cutting does not claim that exposure is the only factor contributing to aesthetic judgement, so accepting this view does not make one an error theorist about aesthetic value. It does, however suggest that the critical robustness of canonical judgements has been overestimated, since one’s exposure to a picture is not a reason for thinking it good. However, Meskin, Phelan, and colleagues (2013) compared the effect of mere exposure to (what critics have widely judged to be) good and bad art, finding that there was increased liking for good art but decreased liking for bad art, the implication being that increased exposure makes observers more aware of the objective qualities of the work (see also Delplanque et al. 2015). In that case significant exposure to a work, while not a reason why it is good or bad, is a reason why one’s judgement of it is reliable and so may be said to belong to the space of aesthetic reasons. Cutting (2017), while offering some methodological reservations, expresses broad agreement with the Meskin et al. study.

Recently the link between aesthetic effects and pervasive features of perception and cognition has been highlighted again by the theory of predictive processing: the idea that the fundamental activity of the brain is to make predictions and test and revise them against incoming information from the senses, the goal being the reduction in predictive errors or what is also called reduction in uncertainty (for a survey of philosophical applications of this idea see Hohwy . It is suggested that positive affect is the product of such reductions, while negative affect results when uncertainty is increased. Works of art are said to provide the brain with exercises, sometimes challenging ones, in error reduction (van de Cruys & Wagemans 2011). But why should we seek more exercises in prediction error reduction than the many that the world throws at us continually? What is to say that the eventual reduction in error outweighs the initial increase posed by a work of art?

We see, then, that there are a number of suggestions for how empirical work may shed light on our aesthetic preferences and their aetiology, while doubts remain about the capacity of this work to illuminate the normative structure of aesthetic judgement, which is said to be reason-focused and involve Kantian features such as disinterestedness (though see Meskin, Phelan, et al. 2013: 140–1). A second and familiar objection is the Wittgensteinian thought that merely explaining the origins of a phenomenon doesn’t give us the kind of explanation which philosophers are concerned with (Vrahimis 2020). However, the idea of reasons in aesthetics itself deserves critical interrogation, given the evidence that the reasons people give seem often to be confabulations and that focusing on reasons while making a judgement can make you a worse judge rather than a better one (see Irvin 2014 and Lopes 2014, mentioned above, Section 1). Nor is the problem here confined to the aesthetic domain: Hugo Mercier and Dan Sperber (2017) argue that, quite generally, reasoning works well as an instrument of public debate but poorly as a guide to personal judgement and decision.

4. Art, Empathy and Neuroaesthetics
German aesthetics of the late nineteenth century was particularly focused on explaining human attraction to form in picturing, sculpture and building. Not always easy to interpret in detail, the broader themes of this work include the ways that our bodily and ecological situation determine the aesthetic preferences we have for such things as symmetry (Wölfflin 1886), how architectural form is appreciated in terms of its capacity to facilitate movement through space (Schmarsow 1894, and how a sense of beauty arises from our projecting the feelings provoked by an external object into that object (Lipps 1903, see Currie 2011 for discussion). After a long period of neglect, these and related topics have reappeared under the banner “embodied cognition.” Freedberg and Gallese (2007) have drawn attention to the ways our bodies tend to reproduce the posture of a statue, to produce implicit or simulated movements that mirror those that seems to have produced a brush stroke or chisel mark, to resonate sympathetically with the pain of a represented figure. These, they say, are intrinsic aspects of aesthetic experience neglected by theorists who emphasise an intellectualist approach to art. They also claim that evidence for these effects based on introspective reports can now be supplemented by an empirically verified theory of brain processing that appeals to mirror and canonical neurons. Critics have alleged that this approach neglects the aesthetic impact of top-down factors (Kesner & Horáček 2017) and that motor responses are absent in many encounters with art (Casati & Pignocchi 2007: 410). Arguably though, Freedberg and Gallese seek only to identify an aesthetic factor of some significance and need not claim either exclusiveness or universality for it. Formalists in art might object even to this restricted claim, arguing that what Freedberg and Gallese have identified are obstructions to the sort of “purely optical” attention to pictures that Greenberg (1960) advocated (on which see Steinberg 1965; Currie 2007). But here again aesthetic prescription cannot afford to ignore empirical work: standards of aesthetic attention that no one has ever lived up to are not to be taken seriously.

Attempting to illuminate aesthetic phenomena by appeal to mirror neurons and other neurological processes is now so common that we have a substantial genre of neuroaesthetic writings (see Chatterjee 2013 for the field’s growth over 30 years). What remains controversial, though, is the significance (if any) this research into brain structures and processes has for aesthetics. We have already seen that—despite the bold claims sometimes made by neuro-aestheticians—some critics are inclined to dismiss this kind of work as irrelevant to evaluating the kinds of claim which aestheticians are concerned with. Gallese and Freedberg, responding to critics, say that

no esthetic judgment is possible without […] mirroring mechanisms in the forms of simulated embodiment and empathetic engagement that follow upon visual observation. (2007: 411)

But to understand the aesthetic significance of facts about such mechanisms we need to distinguish between two claims:

Evidential claim: facts about mechanisms may provide evidence to support or undermine a claim about what is involved in aesthetic experience or judgement.
Constitutive claim: facts about mechanisms may be constitutive parts of the story we tell about what is involved in aesthetic experience or judgement.
The evidential claim is more plausible than the constitutive claim. Consider first the evidential relevance of cognitive and neurological mechanisms for aesthetics. We have just now referred to a dispute about how much of our experience of visual art depends on a work’s tendency to encourage bodily empathy with what is depicted. While people sometimes report experiences of these kinds it may be that they vary in accessibility, with some unnoticed without high levels of attention, though still making a contribution to our overall liking for/valuing of the work. Studies of brain activity across a range of artistic stimuli might suggest that these empathic responses are very common indeed—or that they are relatively unusual—because (let us suppose) empathy has an identifiable neurological signature. Such studies would be useful as evidence for the claim that something needs to be factored in to an account of aesthetic experience. But the relevant something would be the empathic response, not the brain process (See Carroll, Moore, & Seeley 2012: 54 where studies of this kind are described as “data” for aesthetic theories).

The difference between aesthetic effects and the mechanisms that realise them is an important one. Take the shimmering quality we find in impressionist art. It is said that this depends on the fact that the visual system involves two separate processing streams and that certain colour combinations are processed exclusively by one of them (Livingstone 2002). Should this fact, if it is one, be regarded as an aesthetic fact? Arguably no. What matters aesthetically is the experienced shimmering quality; a world in which just that shimmering quality was produced by some other mechanism of perceptual processing would not be aesthetically different from our world, at least in this respect. The same applies to scientific studies of the stimuli themselves; chemical analysis of an ancient pigment might show that it was a hard medium to work in, and that would be relevant to understanding the works of art produced by its means. But what matters is the difficulty of the medium; discovering its chemical formula simply provides evidence for that.

5. Authenticity
A Kant-inspired view of long standing is that aesthetics is concerned not with how things are but with how they appear (e.g., Urmson 1957), a view sometimes called aesthetic empiricism (Currie 1989) On this view aesthetics takes no cognisance of authenticity, which depends on history and not on appearance; a fake Vermeer does not become authentic by being visually indistinguishable from a genuine one. Is an object’s history really aesthetically irrelevant? Those with an interest in art, craft and the design of artefacts generally are much concerned with the object’s history, and there are arguments to support the view that the application of at least some aesthetic properties depends on assumptions about that history. Consider two such attributions from Sibley’s (1959) extensive list of aesthetic properties: being delicate and being dynamic. A line that is seen as delicate when thought to be drawn by hand may not seem so when revealed as the product of a machine, and Walton (1970) argued that, of two works which are visually indistinguishable, one may be fairly described as dynamic and the other not, depending on differences in their category membership (for defences of aesthetic empiricism concerning visual art see Zanwill and, on music, Dodd; for the aesthetic relevance of genuineness or authenticity see Korsmeyer 2019). The suggestion of at least the first of these examples (being delicate) is that the aesthetic properties of a thing, and the aesthetic values that possession of these properties entails, depend on the kind of achievement that the fashioning of the work represents. What may be a considerable achievement for one person at one time may be a greater, lesser or at least a different achievement for someone else, working with different materials or in a distinct artistic culture (Dutton 1979; Currie 1989; Huddleston 2012; Levinson 2016); James Grant (2020) suggests that we do better to think in terms of a work’s capacity to exhibit the skills of its maker rathen than in terms of its constituting an achievement of the maker (see also Currie 2018).

Both formulations imply a close connection between valuing the work and valuing the maker, helping thereby to explain how an interest in the authenticity of a work can belong to the space of aesthetic reasons. It also suggests a connection with our desire to preserve and possess otherwise unremarkable objects because of their relation to some person or event that interests us (JFK’s sweater). Some psychologists have thought to bring art works and other valued artefacts together under the heading of contagion, the idea that

a person’s immaterial qualities or ‘essence’ can be transferred to an object through physical contact; (Newman, Diesendruck, & Bloom 2011)

an idea that goes back to early anthropological work by Frazer (1890 [1994]) and others. As the examples just given indicate, the idea that a person’s essence is transferable to an object does not depend on the object’s aesthetic merits, and this severely limits the usefulness of this idea in explaining the role of authenticity in the arts (see, however, Korsmeyer 2019 where it is argued that genuineness is itself an aesthetic property). Bloom and colleagues stress the role of physical contact in the contagion process: “An original Picasso may be valuable because Picasso actually touched it” (Newman & Bloom 2012: 3). But Picasso may have got no closer than a brush length from Guernica, a picture likely to command higher art-world respect (and higher prices) than a restaurant napkin sketch he then wiped his hands on. However, a more general and perhaps rather vague sense of “closeness” to the artist and their act of making does seem to be explanatory of some art-world practices, such as a preference for lower numbered (and hence earlier) prints even where there is no decline in quality across later ones (Smith, Newman, & Dhar 2016).

Bloom and colleagues offer another explanation for our interest in authentic items, this one closer in spirit to the suggestion above that aesthetic judgements are sensitive to achievement or the manifestation of ability:

[A]n original is different from a forgery because it is the end point of a different sort of performance . The original is a creative work while the forgery is not. (Newman & Bloom 2012: 559)

Guernica, very likely, is a more creative work than the napkin sketch and plausibly valued more for that reason. A question which arises is this: how do people make judgements of the quality of, say, a painting, if not solely on the basis of how it looks? For a few highly trained experts the answer may be: through deep immersion in the cultural and artistic context of the work. The rest of us, where we make a judgement at all, may be dependent on short cuts such as the “effort heuristic”, which treats evidence of effort as evidence of quality. In an experiment, people asked to judge the relative merits of pictures A and B tended to judge A as better than B when told A took longer to paint, while the group who were told that B took longer preferred B. This effect was found equally among experts and among laypersons, though the experts were “self-described” (Kruger et al. 2004).

6. Pictures, Imagination and Perception
Wollheim (1980) said that what is distinctive about pictorial representation is its capacity to generate a certain kind of experience: the experience of “seeing the subject in the picture”. For many this has seemed to capture something deeply important about the nature of depictive representation, though Wollheim’s specific claims about it are disputed. What exactly is seeing-in? One subsequent suggestion has been that we see something, X, in a picture when we experience a resemblance between the outline shape visible in the picture and the outline shape that would be presented from that same perspective by X (Hopkins 1998; for a related proposal see Peacocke 1987). Another proposal is that we see X in a picture when we are prompted by it to imagine, of our act of seeing the picture, that it is a seeing of X (Walton 1992). Is cognitive science able to help us adjudicate between rival theories in this area? It does look as if these ostensibly philosophical theories are committing themselves, if somewhat vaguely, on empirical issues. Surely, we cannot settle from the armchair whether the perception of pictures draws on imaginative capacities. Scientists have gone a long way towards locating areas of the brain implicated in certain kinds of functions, emotion and the forms of perception being good examples. But we are not similarly able to localise imaginative activity and there may be an in-principle barrier to our doing so; there is some reason to suppose that there are not dedicated mechanisms of imaginative activity, but that imagining involves the reuse of systems designed for other purposes. This issue has been a central contention in the debate over how we understand the minds of other people, a debate originally drawn in terms of two opposing outlooks, theory-theory and simulation theory, though other approaches have come into view (Gallagher & Hutto 2008). Theory-theory attributes to us a (perhaps tacit) theory of the mental states of others, their connection to action and so forth, from which we derive predictions and explanations of behaviour (Fodor 1992; Carruthers 1996). Simulationism, by contrast, argues that we have a capacity to use our own mental systems of inferring and deciding to model or simulate the thoughts and decisions of others (Gordon 1986). While Heal has emphasised what she takes to be the a priori principle that when we examine the thinking of another person we have to reproduce in our own minds the contents of and the logical relations between the propositions thought (1986), others have developed an empirically oriented version, postulating causal mechanisms by which practical and theoretical reasoning can be taken “off-line”, or disconnected from experiential inputs and behavioural outputs (A. I. Goldman 1989). It has been suggested that the simulation approach, understood largely in this empirically oriented way, enables us to explain a good deal about our interest in and responses to fiction (Currie & Ravenscroft 2002). Questions about causally effective mental architecture have played a role in other aesthetic debates such as the explanation of our capacity to become immersed in a narrative (Schellenberg 2013) and of the contrary tendency to “resist” imaginative involvement with stories we perceive as morally or in other ways problematic (Weinberg & Meskin 2006; Miyazono & Liao 2016).

While some of these ideas come with a detailed “boxology” that describes the cognitive implementation of the proposal, they are generally the product of work at the more philosophical and speculative end of inquiry into the architecture of mind where evidence is at best very indirect. An exception is the suggestion that there is empirical confirmation for Wollheim’s (1998) notion of twofoldness in picture perception, according to which spectators are simultaneously aware of both the surface qualities of the picture and the depicted content. In particular, it has been argued that

the twofold experience of pictures Wollheim talks about corresponds to the dichotomy between our dorsal visual processing of the surface of the picture and our ventral visual processing of the depicted scene. (Nanay 2011: 464)

Support for this idea comes from evidence that people with damage to their ventral processing often have difficulty deciphering the content of a picture without corresponding difficulty in perceiving the ordinary properties of the surface of the picture (Turnbull, Driver, & McCarthy 2004). This illustrates another way that the investigation of mechanisms may further aesthetic inquiry. An aesthetic phenomenon—in this case twofoldness—is postulated and the question arises as to whether there is a plausible story about how this is implemented. If no such story were available, doubt would be thrown on the claim.

7. Emotion
A good deal of aesthetic thinking has been taken up with arguing about the limits to its capacity to appeal to the emotions. Two issues are particularly notable, one descriptive and the other, in part, normative. What, first of all, are the facts about our (apparently) emotional responses to fictions? Do we really admire, despise or pity people we know do not exist? This sounds like an empirical question, perhaps one to be resolved by studies of the brains of people engaged by fictional work. But the prospects for this approach are poor, and not only because of practical difficulties in data gathering (see Cova & Teroni 2016). Those who deny that we pity Anna Karenina do no deny that readers may display all the physiological signs that go with that emotion. What they claim is that genuine fear has a cognitive component lacking in this case: belief in the object of one’s fear. Suppose we could show empirically that readers of Tolstoy do experience all the pity-relevant physiological states while failing to believe in the existence of Anna Karenina, having instead cognitive states such as “imagining that Anna exists”. The philosophical problem would remain: are people with that psychological profile genuinely in a state of pitying, or is their state merely one of what Walton (1978) calls “quasi-pity”, which involves the typical physiological and psychological reactions of pity but which falls short of being full-fledged pity because it does not go with belief in its objects, or with the typical corresponding dispositions to action? We might at this point wonder whether what looked like a substantive question about fear and pity has been shown to be merely one about labelling. However, there are empirical considerations that bear indirectly on the issue. Gendler and Kovackovick suggest that plausible assumptions about the evolutionary proper function of the emotions tells against the idea that fear requires belief. It is likely on Darwinian grounds that our emotions were shaped not merely by their capacity to have us avoid present dangers, but also to have us avoid merely possible ones. Imagining a dangerous creature lurking in the forest may be enough to send me by a safer route, raising my chances of surviving and passing on my genes. If imagined dangers are part of the reason fear has been selected for and retained why insist that responses to the imagined creatures and events of fiction are, as Walton (1978) claims, merely quasi-fears? For other connections between aesthetics and evolutionary thinking see below, Section 9.

A similar problem arises when we consider our responses to music. We sometimes talk of sad music making us sad, though the music does not provide us with any reason for thinking that something sad has happened (sad music sometimes reminds us of a sad event, but this is not a general feature of cases where sad music affects us). Here appeal to the imagination seems less helpful; unlike fictional narratives, emotionally affecting music does not usually provide us with the materials for imagining some sad event. Kivy has argued that sadness on the part of those who listen to sad music is, where it occurs, irrelevant to musical appreciation and will indeed not occur in episodes of listening which instantiate his preferred model of musical listening, one which requires exclusive attention to the structural, phenomenological, and expressive properties of the music (1990: ch. 8). Kivy does not deny however that musical listening can and indeed should be a deeply emotional experience; we may be overwhelmed by the compositional and performance qualities the work represents. Some attempt has been made to challenge Kivy on empirical grounds by presenting evidence that music does reliable engender the emotions or moods it expresses (Sizer 2007). But Kivy denied this possibility only for the case of canonical music listening, and says that there is no reason to think that subjects in the relevant experiments were listening in that canonical way (2007). Certainly it would not be easy to control experimental conditions so as to rule-out listening which is non-canonical in Kivy’s sense (see also Kivy 2006; Carroll 2003; Carroll & Moore 2007). However, if experimental tests do consistently provide evidence of emotion-generation concordant with the emotions expressed by the music, it will not do simply to say that we have not yet tested the right listeners. The friend of Kivy will have to find robust instances of the sort of listening he approves of, and not depend merely on the personal testimony of those who favour his theory. We take it, after all, that Kivy’s ideal mode of listening is presented as a practically achievable goal. Zangwill 2004 represents a formalism that is less willing to accommodate the emotions; for a more limited defence of the formalist position see Cochrane 2021b.

Another aesthetically important question about the emotions is this: why are we attracted to representations and other devices that generate negative emotions such as sorrow and fear? It is not a satisfactory answer to this question to make the suggestion referred to above that we do not really fear Dracula and other creatures of fiction but merely quasi-fear them, because fear and quasi-fear are supposed to be qualitatively the same, so if fear is unpleasant quasi-fear is also. The question can be asked about both narrative works and about music; recall that even Kivy grants that (non-canonical) musical listening may generate sadness. However, fiction has been the greater part of this discussion, and will be here also. On this issue philosophers have tended to take one of three positions (but see Smuts 2009 for a wider range of options):

Compensation: audiences tolerate the negative emotions of tragedy, horror and other genres because they recognise compensatory benefits (Carroll 1990; Feagin 1983)
Conversion: emotions which would otherwise be experienced as unpleasant are experienced as positive in artistic contexts (Hume 1757 [1987]).
Neutrality: it is wrong to think that the so called “negative emotions” provoked by tragedy or horror are intrinsically unpleasant and hence in need of compensation or conversion. They are not intrinsically valenced and may be experienced negatively in some situations and positively in others (Gaut 1993; Walton 1990: 255–8)
Neutrality is a general claim about the emotions and relevant here as one way to argue in favour of conversion. But a conversion theorists need not be committed to Neutrality. We focus here on the contrast between Compensation and Conversion. Compensation, unlike Conversion, appeals to a type of psychological process that is hardly controversial; we accept many kinds of unpleasant experiences because avoiding them will have even less desirable consequences. Conversion sounds more problematic: how can an emotion “flip” its hedonic value and still be the same emotion? Psychologists interested in negative emotions in art have cited research which purports to reveal hedonic flip for pain: subjects who expected an intense pain but experienced only a moderately painful stimulus described the experience as “pleasant”, while subjects expecting nonpainful warmth described the same stimulus as unpleasant (Leknes et al. 2013). This doesn’t by itself show that the same thing can happen in the case of tragedy or horror, but it suggests that the conversion claim is less outlandish than it might initially seem.

While compensation may appeal to a familiar kind of trade off, it needs to tell us what specific compensatory benefits are to be had from the negative emotions provoked by art. Philosophers have long cited epistemic benefits: the distressing events of tragedy are a source of moral and psychological learning, sometimes about ourselves (Collingwood 1938; Schier 1983). Empirical scientists have added to the list: painful emotions generate strong pro-social feelings that help to unite us with both characters and authors (Bastian, Pe, & Kuppens 2017; Egloff 2017).

While philosophers have long offered theories to resolve this “paradox of tragedy,” only one substantial study of it claims to be grounded in empirical research. Menninghaus and colleagues propose what they call “the Distancing-Embracing model” (Menninghaus, Wagner, Hanich, et al. 2017) according to which an aesthetic context, as with watching a play or film, distances us from the situation represented and allows the positive effects of tragic emotions, notably their capacity to focus attention, to sustain them. While a large and relevant body of empirical work is called on in support of the idea, its theoretical commitments are unclear. In some of their formulations the function of distancing seems to be the reduction in unpleasantness of negative emotions to the point where they are “not inevitably incompatible with art-specific expectations of hedonic reward” (2017: 6); this leaves them open to the charge made against compensation theories that the work’s being apt to generate negative emotions seems to be a major factor in attracting people to the work, rather than something negative we can be persuaded to live with. In other formulations they speak of the factors “involved in making negative emotions enjoyable” (2017: 3), which suggests the conversion theory. Yet they claim that their theory is a version of neither of these approaches (2017: 15; see S. Davies 1997). (For more on the relationship between fiction and emotion see the supplement to Liao & Gendler 2018 [2020]). See below, Section 7 for further remarks on fiction and emotion.

To conclude the discussion of fiction, we note another direct appeal to work at the empirical level. Derek Matravers (2014) argues that it has been a mistake of recent theorising about fiction to appeal to the imagination. Matravers claims that work on mental models does a good job of explaining our processing and comprehension of, and responses to, both fictional and nonfictional narratives without any need to distinguish fictional cases by their connection with the imagination.

8. The Aesthetics of Literature and Literary Language
Through the latter part of the twentieth century, theoretical and interpretive studies of literature have been somewhat hostile to both cognitive and aesthetic inquiry, often thought of as irrelevant to serious interpretive work and a distraction from favoured political agendas. Cognitive studies of literature have developed somewhat in the last twenty years but remain a minority enterprise (Hartner 2017). One question of long standing that has concerned scholars in psychology, literary studies and aesthetics is the idea that we learn from literature about the world beyond the text, an idea treated with some suspicion by those influenced by deconstructive or post-modern theorising, who argue that such ambitions depend on failing to realise that characters of fiction are not, and are not like, real people (Cixous 1974). Others argue that such cognitive benefits, if they exist, are not aesthetically relevant (Lamarque & Olsen 1994: ch. 17; for criticism see Gaut 2007: ch. 7; Currie 2020: §9.6). There is, however, a strong tendency to suppose that the artistic merit of, say, a Shakespearean drama depends in part on our sense that it is revelatory of deep insights into the human condition. Similar claims are made for other arts; contemplating van Gogh’s lithograph Sorrow Kendall Walton notes responding imaginatively to the woman in ways that “gain for me an understanding of what a particular sorrow is like” (2008: 78).

Recently efforts have been made to test the idea that literature does, on occasion, provide cognitive benefits. It has been claimed that exposure to fiction—even single episodes of reading—measurably improves empathy and theory of mind (Kidd & Castano 2013); the effects, if real, seem to be small and the claimed results have been hard to replicate (Panero et al. 2016; Kidd & Castano 2019). Other work in this growing field also does not point in a single direction. Some studies suggest that fiction has a capacity to improve aspects of social cognition (Calarco et al. 2017; Mar 2018a,b) while others find no such effect (e.g., Wimmer et al. 2021a, b; see Currie 2020; chs 9–11 for general discussion). Humanistic scholars who claim educative effects for fiction may respond that these effects are slow and cumulative, and unlikely to be visible in studies of single episodes of reading; testing such claims will be difficult. But their claims are, nonetheless, empirical.

Among other examples of the cognitive study of literature are investigations of emotional responses. While aestheticians have tended to focus on the apparently “paradoxical” aspects of our emotional responses to fictions (for example why we are emotionally affected by the non-existent, see above Section 7), researchers in the cognitive sciences has begun a broader attempt to understand the role of emotions of all kinds in generating and maintaining interest in narrative and poetry (Menninghaus, Wagner, Wassiliwizky, et al. 2017); Jenefer Robinson’s (2005) is an example of work from within aesthetics that takes up this broader ambition while being strongly informed by empirical work. More recently, Kukkonen (2020) attempts an alignment between the expectations of a reader sometimes surprised by plot development and the predictive processing approach to perception and cognition (see above Section 3). It is an open question whether the predictive processing account sheds aesthetically relevant light on the reader’s experience rather than simply providing an account of the mechanisms involved (see above Section 4).

A striking example of an area long thought of as resistant to theory from outside the domain of art and the aesthetic is that of literary language. Insight into the kind of language we think of as distinctive of poetry, drama and the novel has traditionally been sought from those whose expertise is literature itself rather than from those developing general theories of communication, a view endorsed by Peter Lamarque, who regards the idea that there is value in seeing literary works as akin to quotidian genres of utterance such as letter-writing or political speech making as “utterly misconceived” (Lamarque 2007: 34). But advocates of relevance theory, a naturalistically inclined development of Gricean pragmatics, reject the idea that there is anything fundamentally special or autonomous about literary language, claiming that

stylistic and poetic effects traditionally associated with figurative utterances arise naturally in the pursuit of relevance, and call for no special treatment not required for the interpretation of ordinary literal utterances. (D. Wilson 2018: 191)

(for work that seeks empirical confirmation for relevance theory see, e.g., Happe 1993; Sperber & Wilson 2002; van der Henst, Carles, & Sperber 2002; Noveck & Posada 2003; and van der Henst & Sperber 2004).

One ambition of relevance theory is to encourage us to see “poetic uses” of language, where an idea is very indirectly suggested by the words used, as less marginal than we would if we thought of the paradigm of communication as the case where an agent utters a sentence that means exactly what the speaker wishes to communicate. Relevance theorists say that such cases of literal meaning are rare or non-existent and do not constitute any kind of communicative ideal. They point to the widespread phenomenon of “weak implicature”: audiences draw a range of conclusions from an utterance, some of them obviously intended but others harder to identify as intended (Sperber & Wilson 1995: 197–9). On this view the totality of what is meant, even in mundane cases, is never more than vaguely specifiable and would, if we bothered to investigate, be subject to the same unresolvable disputes as we find in poetic criticism. It need not be concluded that poetic discourse is entirely of a piece with over-the-garden-wall conversation; the relevance theorist’s point is that the differences are ones of degree and not of kind.

9. Aesthetics and Evolution
Theories of human evolution over the last two million years are severely limited by the very incomplete fossil record and the fact that soft tissue disappears quickly. Given these constraints it is surprising the extent to which cognitive theorising has reached into the very distant past, though its claims are agreed on all hands to be highly provisional. A vital resource has been the study of stone artefacts going back two million years or more, artefacts which preserve very well and which are available in great quantities. We are able to reconstruct a good deal about the methods of their construction and to speculate in a reasonably informed way on the cognitive capacities they require. Based on these speculations innovations in stone tool manufacture have been linked to the development of language (Higuchi et. al. 2009).

Any topic on which aesthetic and evolutionary methods converge is likely to be approached with two questions in mind.

Is the emergence and development of art-making and related activities explainable wholly or very largely in cultural terms, or is there a substantial biological component?
Is art-making an adaptation or a non-adaptive consequence of developments which may themselves have adaptive advantages (or something else)?
It might be thought that the second question arises only if one answers the first in a way that gives an important explanatory role to biology. But culturally determined “phenotypes” can also be adaptive, maladaptive or neutral. Cooking, certainly a cultural innovation, is highly adaptive and has led to significant change in gut size and perhaps in brain size as well (Godfrey-Smith 2013; for scepticism concerning the relation to brain size see Cornélio et al. 2016). Human biological and cultural evolution are closely connected.

On the question whether there is a role for biological explanation when it comes to human aesthetic activity, there is a constituency of scholars hostile to this idea; they argue that “art” and “aesthetic” are notions of recent and essentially western invention, the application of which to other and older cultures is mistaken (Gell 1998: 97). Opponents of this view readily grant the huge cultural variability of aesthetic activity. They argue that there are enough commonalities between the ways very different cultures invest in the shaping and decoration of objects, in music, dance and in story-telling to make it plausible that biology provides both the initial impetus to and a set of constraints on these activities (Dutton 2009; Currie 2012). If we thought, as we once did, that these activities could be traced no further back than the cave depictions of the European Upper Paleolithic it would be likely that the aesthetic is too late-emerging to have a biological basis. Very recent discoveries have now suggested a somewhat earlier origin; depictions in Indonesia have been given dates prior to 45,000 years ago (Brumm et al. 2021). More dramatically, though, the temporal depth of aesthetic activity is vastly increased if we turn our attention to the stone tools mentioned above, many of which show a notable symmetry of construction. Hand axes from the Acheulean industry which arose about 1.7 million years ago are sometimes too large, small or sharply pointed to be practical implements and strongly suggest an interest in the display of skilful making that we commonly recognise in, say, the art of the European renaissance (see Currie & Zhu 2021 and Gowlett 2021, both of which in different ways emphasise the importance of seeing aesthetic practices emerging in a social context). Some have seen these elaborated instruments as products of sexual selection, as peacock’s tails are said to be: reliable indicators of the maker’s qualities as a mate (Kohn & Mithen 1999). Another view has it that they were indicators of trustworthiness, and hence of one’s value as a co-operator (Spikins 2012); for criticism of both views see Hiscock 2014.

Hand axes are unlike a peacock’s tail in being detached from the body and so may be passed from one person to another—one reason to doubt their reliability as signals of any particular agent’s suitability as a mate. Where symmetry of the body itself is at issue that objection does not apply, and bodily and especially facial symmetry has been offered as an example of something evolution has tuned our sensibilities to because it is an indicator of health in a reproductive partner. However, robust evidence has been hard to find. One recent study did “not support the idea that facial symmetry acts as a reliable cue to physiological health” (Pound et al. 2014; see also Kalick et al. 1998), another that there is “little evidence that female appearance predicted health” (Foo et al. 2017; this study did support a connection between male facial appearance and fertility). For ethical arguments, supported by empirical findings, that we should rethink our standard approach to the aesthetics of human appearances, see Irvin 2017.

It should be noted that even a very early dating of the emergence of aesthetic interests does not establish that they have a biological origin; the Acheulean period seems to have been marked by high levels of planning and organisation that suggest strong social relations (Hiscock 2014). In this sense aesthetic activity may be a culturally derived “technology”, as writing is, rather than an adaptation, as language may be (S. Davies 2012: ch. 10). Could we account, on that hypothesis, for the seeming ease with which young children take to forms of aesthetic activity such as drawing and singing? By contrast, learning to write is effortful and requires great investment in pedagogy. Recent work (Heyes 2021) seeks to reshape our assumptions about what is learned, arguing that such an early and reliably developing ability as interpersonal understanding is really a socially acquired “gadget” (Heyes & Frith 2014). To add to a complex menu of options we also note that what begins as a gadget or technology might, under certain circumstances fall under complete or partial genetic control. This so-called “Baldwin effect”, once despised in evolutionary thinking, has attracted interest more recently (Weber & Depew 2003). It proposes a mechanism by which acquired characteristics can become biologically heritable, without giving any ground to the Lamarkian idea that changes that accrue in an organism’s lifetime can be passed directly to the next generation. For example, if advantages flow from learning a skill, there may be selective pressure to ease the burden and uncertainty of learning by making the skill, or some of its components, innate (Papineau 2005). Given the multiply crossing paths between cultural and biological evolution there is little definite to be said about the origins of aesthetic interests other than that we see evidence for it in human populations more than half a million years ago.

We turn now to our second question: Is art-making an adaptation or a non-adaptive consequence of developments which may themselves have adaptive advantages? Or something else entirely? Strong and contrary views have been expressed on this question; some have argued that the development of depiction, story-telling and music have been crucial for social bonding (Dissanayake 1992, 2000, 2017) or mate-choice (Miller 2000; Dutton 2009; for criticism see, e.g., C. Wilson 2016), others say that the creation of aesthetic artefacts offers no adaptive advantage but that they gained their hold on us because they provide rewards to sensory and other mechanisms in the mind that arose for quite other purposes (Pinker 1997). From a somewhat different perspective it is suggested that we do best by seeing human aesthetic activity as simply the continuation of ubiquitous practices of signalling and manipulation in the world of plants and animals. An interesting feature of this idea is that it replaces the traditional distinction between the aesthetics of artefacts and the aesthetics of nature with a distinction between, on the one hand artefacts and natural entities such as animal calls and flower colouring, and on the other natural objects such as rocks, sunsets and the night sky which “do not coevolve with sensory evaluations of them” (Prum 2013: 821; see also De Tiège, Verpooten, & Braeckman 2021). It is not clear whether we currently know enough to decide between the available alternatives (S. Davies 2012: ch. 12; for the case of fiction, Currie 2020; §7.4). But would deciding whether art-making is adaptive advance the cause of aesthetic inquiry? That is doubtful. The question whether art is an adaptation concerns whether the reason we have art now is that it contributed to the fitness of our species. That could be true without it also being true that art now enriches our lives in any of the ways commonly claimed—giving pleasure, educating our emotions, instructing us about morality. And it is possible that art does now have all those advantages while having been an evolutionary irrelevance. It is also true that even if art was not originally adaptive, it might have become adaptive (an “exaptation”) at some stage and might be adaptive now. Different answers may apply to different art forms. It is said that the novel is a particularly appropriate means by which to exercise our capacities for empathy and mind reading (Nussbaum 1990, 1995; Mar and Oatley 2008); perhaps these advantages did not appear until the eighteenth or nineteenth centuries. While questions about art posed in evolutionary terms are certainly of scientific interest, what matters to the aesthetician is more likely to be the values that art currently and historically exemplifies and the ways those values are currently and historically responded to by us.

10. The Aesthetics of the Environment
We have referred rather briefly to the aesthetics of the natural and humanly constructed environment and we conclude with a brief selection of aesthetically and cognitively relevant work in this area. Much of this discussion continues the evolutionary theme. Note that some of this work relies for its evidence on people’s responses to pictures of environments rather than to the environments themselves, leaving it uncertain how much of the response is to the environment and how much to its representation.

The empirical study of environmental preferences has long been of interest to planners, and largely represents the bottom-up mode of inquiry referred to above (see Section 2), as the aim is to discover what people in general like rather than to assess their likings against the normative constraints of connoisseurs and philosophers. Topics explored include the differences in preference across age groups, ethnicity, education and income (e.g., Kaplan & Talbot 1988). One conclusion often drawn is that there is a widespread, perhaps universal, human preference for savanna landscapes, even among communities whose own historically stable habitat is very different, and that this preference is reflected in the design of parks and gardens (Falk & Balling 2010). It is further asserted that this is the product of our evolutionary development in an East African context (E. O. Wilson 1975 is an early source of this idea); for detailed discussion, references, and some reservations see S. Davies 2012: ch. 6.

The non-prescriptive nature of much empirical research into responses to the environment contrasts with a view influential in philosophical aesthetics according to which there are quite demanding cognitive requirements for a correct aesthetic appreciation of nature. The question mirrors one we have already discussed for the arts: what factors, other than the sensory appearance of an object, are relevant to enjoying, appreciating and judging it aesthetically? In the case of the arts we saw that one answer is to consider the work’s category—the (artistic) kind of thing it is (Walton 1970; see above Section 5). Allen Carlson (2000) extends this idea to the aesthetics of nature, arguing that a scene or object must be understood as belonging to a natural kind, and as having the causal history characteristic of that kind; that is the right way to perceive it and aesthetic judgements about it are correct only if they are tied to that category. This implies that much human aesthetic experience of nature has been radically incorrect, being uninformed by the relevant scientific facts and often infused with notions of supernatural creation. Some will find this an acceptable consequence; we are used to thinking that many long-standing human ethical judgements have been radically mistaken, and aesthetic judgements might go the same way. Others however, question whether the aesthetic delight one takes in, say, a bird in flight depends for its acceptability on understanding the natural history of the creature (Budd 2001).

A different and perhaps more accommodating approach to identifying what is distinctive in aesthetic appreciation of the environment connects an older way of thinking with recent work on cognition. The eighteenth century focused attention on notions of the sublime (notably Burke [1757], but in a line of thought from Longinus) and the picturesque (Gilpin 1782, with roots in the older concept of pittoresco). These, particularly the former, have generated controversies about their relations to beauty—are they subspecies of beauty or categories distinct from it?—and about their extensions—is it only nature that can be sublime? The question also arises as to whether terms like “the sublime” pick out a class of objects to which there is actually a common aesthetic response. This sounds like something on which we could get help from the cognitive sciences, and work by Keltner and Haight (2003), drawing on a range of empirical and reflective sources, has been particularly noticed. Their work was on the concept of awe rather than the sublime but they note obvious connections, given the thought that the sublime involves a response to things physically or conceptually vast. They suggest that awe involves the recognition of the apparent vastness of the object or scene attended to and the inability of the subject to assimilate it to their existing mental schemas. Other research suggests a strongly pan-cultural component in nonverbal expressions of this emotion (Keltner et al. 2019), and its association with a diminished sense of self (Piff et al. 2015; Tom Cochrane (2012) has argued that the sublime is characterised by a feeling of self-negation). It is suggested therefore that the experience of the sublime is an aesthetic form of awe wherein the object is attended to for its own sake (Clewis 2019; Arcangeli et al. 2020), an idea elaborated by Shapsay (2021) who suggests that the sublime sometimes takes a cognitively elaborated form involving reflection of the challenge posed to existing schemata by the scene or object one confronts.

1. Speaking of Evil
“Evil” and related terms in the Germanic branch of Indo-European have referred, at various points, to suffering and wrongdoing, but also to defecation, latrines, spoiled fruit, diseases, prostitution, and (oddly enough) forks.

The Greek term “kakos” may be related to the Proto-Indo-European term “kakka”—“defecation”. But only the first two meanings survive in English, and non-ironic uses of the term are relatively rare outside of ceremonial and literary contexts. Indeed, speaking of evil nowadays often feels like an exercise in anachronism—like speaking of wickedness, abomination, uncleanness, and iniquity.

The Oxford English Dictionary explains:

In modern colloquial English it [evil]; is little used, such currency as it has being due to literary influence. In quite familiar speech the adjective is commonly superseded by bad; the noun is somewhat more frequent, but chiefly in the widest senses, the more specific senses being expressed by other words, such as harm, injury, misfortune, disease, etc. (“evil, adj. and n.1”, under A., abbreviations expanded, OED Online, accessed September 2021)

This trend is found in other modern languages, but not in all. Ruppel (2019) notes that in German-speaking lands “das Übel” declined just like “evil” did in England, but was soon replaced by “das Böse”, which is still alive and well in Germany.

This slow erasure of “evil” and its cognates from many European languages, which began in the seventeenth century, was due to the rejection of the concept of evil, especially by elites. Doctors, moral philosophers, natural scientists, and even theologians shied away from evil—preferring more tractable notions like badness, harm, and misfortune, or quasi-quantifiable concepts like pain, suffering, trauma, and disutility. Traditional views of ontologically substantive and supernatural evil—something able to possess a body or terrorize a soul—came to be seen as quaint, unscientific, embarrassing (Ruppel 2019).

Philosophers of religion are a half-exception to the rule. They did and do continue to speak of evil, at least when discussing the “problem” thereof. (See the entry on the problem of evil.) If pressed, though, they typically admit that this is because the great framers of the problem—Augustine, Aquinas, Leibniz, Bayle—used the term (in Latin or French), and then proceed to gloss it generically as, in Michael Tooley’s words, “any undesirable states of affairs” (2002 [2019]). Philosophers of religion in the broadly Continental tradition are less likely to assimilate evil to more general or anodyne notions in this way, and more likely to discuss the nature of evil as opposed to the “problem” it raises for theism (e.g., Kearney 2001 and Matuštík 2008).

Despite this widespread squeamishness about “evil” in both scientific culture and common parlance, there are moments when the pull of the ancient lexicon is irresistible—at the very least expressively, in the mode of both condemnation and lament. Premeditated mass shootings aren’t just bad or traumatic; rather, they are something else: here people still reach for “evil” or even “radical evil”. The years-long imprisonment and rape of children by their parents is a misfortune that produces negative utility, to be sure, but the transfixing horror of it seems only to be captured by the invocation of “evil”. The same is true of most instances of genocide, sex-trafficking, torture-slaying, terrorism, serial killing, and slavery: these are one and all bad, harmful, and traumatic activities, but they are also something else—something excessive, mesmerizing, and revolting all at once (see Stone 2009 for a psychologist’s account). In the face of such acts, we—along with our spiritual leaders, newscasters, and politicians—are still willing to speak, preach, and tweet about “pure evil”.

Thus after a school shooting in February 2017, Donald Trump (@realDonaldTrump) tweeted that “we must keep ‘evil’ out of our country”. (Despite the quotation marks, it was clear that he meant evil the entity, and not “evil” the word.) After the Las Vegas mass shooting in October 2017, Trump and many others in leadership referred to the event as “an act of pure evil” (Matuson 2017). Less recently, George W. Bush referred to Iran, Iraq, and North Korea as the “Axis of Evil” in a state of the union address on 29 January 2002 (see Other Internet Resources), and Ronald Reagan repeatedly characterized the Soviet Union as “the evil empire”, famously at a speech on 8 March 1983 to the National Association of Evangelicals (see Other Internet Resources).

But when we do this—when we speak of evil, das Böse, il male nowadays—what is it that we are referring to, and where does it come from?

Pressed with such questions, many people (philosophers included) revert to the more tractable terms. Of course what we are really talking about (whispering about, thundering about, shaking our heads about) in those moments of condemnation and lament is an extreme instance of suffering or disutility. Of course “evil” is to “bad” what “wicked” is to “immoral”: a conceptual vestige of a pre-scientific, credulous past that we invoke for the sake of solemnity, empathy, or emphasis. A concept that—outside of horror films and fiction—is best analyzed in terms of nature’s frustration of the basic needs of sentient creatures, or as the effects of illness and ill-parenting. Yes, evil happenings have an excessive, egregious quality that makes them notable, even transfixing. But they are not, in the end, sui generis or metaphysically mysterious: neuroscience, medicine, psychology, and law have domesticated evil. Taken to its logical extreme, the doctrine that characterizes this camp would be that all evil is “natural” (a product of various causal processes in nature).

Others prefer to answer the questions about the origins of evil in terms of choice, agency, and will. For people in this camp, evil consists in malevolent intentions, malice with forethought, and self-conscious cruelty that leads to extreme suffering and tribulation. They may allow that there are contributing factors and preconditions, but ultimately hold the agents themselves responsible for evil. Note, however, that the appeal to human free will can also be seen as an effort to domesticate evil—to make it explicable in terms of familiar concepts, to set it on a continuum with other, familiar acts and events. Taken to its logical extreme, the doctrine held by people in this camp is that all evil has “moral” origins—it is a product of choice or agency of some sort.

This debate about the roots of evil plays out not only in philosophy seminar rooms and psychology labs, but also on cable news stations and op-ed pages. People in the second camp tend to the political right, and sometimes even make a show of using “evil” because they think that people in the first camp (who tend to the political left) are uncomfortable with the idea of personal responsibility and blameworthiness.

I said these were the two opposing camps. In truth there is another one—one that used to be very popular but now seems sparsely populated, at least among philosophers. People in this third camp eschew efforts to domesticate evil; for them, what we mean by “evil” is not equivalent to what we mean by “bad” or “wrong” or even “very very very bad” or “very very very wrong”. In other words, evil is not just illness, misfortune, or malevolent choices by another name but rather a positive, substantial rottenness in the universe. It is, or has its origin in, some non-agential force or shadow side of reality—something spooky, imperceptible, but out there (“in them woods”).

2. Two Distinctions in Evil: Kinds and Origins
The late antique (Plotinus, Proclus, Augustine, Boethius), medieval (Anselm, Ibn Sina, Aquinas), and early modern (Descartes, Leibniz, Bayle, Kant) eras contain sophisticated traditions of reflection on questions about evil—about its being or non-being, its intrinsic features and natural manifestations, and its origins in nature, will, or supernature. Over the course of that centuries-long discussion, two main distinctions emerged.

The first main distinction has to do with the nature or kinds of evil: is evil at bottom just an empirical phenomenon—something that is given in the causal, phenomenal world of our experience? Or is there a deeper, metaphysical aspect to some evils? Note that this is not an exclusive distinction: people who endorse the idea of metaphysical evil typically assume that it also has an empirical character or manifestation.

Suppose, for example, we come across the sort of scene that drove Friedrich Nietzsche mad in Turin: a coachman mercilessly beating his horse (Prideaux 2018). In this version of the case, however, suppose that the coachman’s cruelty is a response to his having been recently diagnosed with terminal cancer. So here there is certainly some empirical evil: the cancerous disruption to the body, the cruelty of the man, the pain of the horse. Some philosophers will say that there is also metaphysical evil: neither the man nor the horse is metaphysically perfect, and so on the Absence Theory considered below (section 3.1.1) both are in that respect evil. We might also regard the body and character of the man as corrupted and conclude that he is metaphysically evil in a “privative” way too (see section 3.1.3). Metaphysical evils like these are distinct from the empirical evils of the cancer, the cruelty, and the suffering of the horse, though on many accounts they are the ground of the latter.

The second main distinction has to do with the origins of evil, and tracks the differences between the three camps mentioned above. The first option here is to say that a specific evil arises entirely from natural phenomena for which no one is responsible. In the case of the man and his horse, it is common to think that their metaphysical finitude and incapacities, as well as the cancerous tumor and the canine pain, are “natural” in this way: they seem to be based in facts about the natures, events, and causal laws involved.

An alternative is to say that a specific evil has its origin in moral actions and intentions. Applied to our case, it is common to think that the man’s agency—the choice to beat his vulnerable steed—is the origin of the cruelty and the pain. If there is metaphysical evil here, then it too might have a moral origin: on some religious pictures, for instance, the corrupted human nature that leads to disease, cruelty, and enmity between him and other creatures is a result of free choice on the part of his primordial ancestors. (If there is agency in any non-human creatures—animals or angelic—then it would also fit here.)

The third (and now-quite-unpopular) view about origins says that a specific evil arises ultimately not from nature or from choice but from something that is both supernatural and non-agential (call this a “spooky non-agential” origin). On such views there is a dark force or side of reality that is the ultimate origin of, say, the metaphysical evil in the man’s nature. It may also be the ultimate source of the empirical evil involved.

Three further preliminary notes:

The second main distinction here is often regarded as exclusive with respect to a specific evil, since we are asking about its ultimate origin. If the man’s cancer and ill-treatment of the horse originate entirely in the causal powers of the physical universe, then they are not also based in either free choice or supernatural spookiness (and vice versa). “Typically” here is key, however, since a compatibilist picture of free will (O’Connor & Franklin 2018 [2021]) says that free choices themselves are determined by natural causes. On that view, perhaps, the origin of the man’s cruel act is both moral and natural. Compatibilisms between natural and spooky origins are also conceptually possible.
Although some theorists think that all instances of evil (whether metaphysical or empirical) are grounded in just one of these ultimate origins, most will allow that different evils have different ultimate origins. For instance, someone might coherently think that the man’s cancer has a natural origin, that his cruelty has a moral origin, and yet that the ferociousness of the beating has a spooky or “dark force” origin. Section 4 considers some historical efforts to suggest that all evils are ultimately moral in origin.
Although these conceptual distinctions are fairly clear, there is terminological variation in the historical and contemporary literature with respect to the term “natural evil”. Some philosophers and theologians use “natural evil” to refer not to an origin but to a kind—the kind that is here called “empirical evil”. When the distinctions are maintained, however, it should be clear that they are orthogonal: both metaphysical evil and empirical evil can have natural, moral, or spooky origins (see Figure 1).
Origins:	Natural	Moral	Spooky non-agential
Kinds:	 
Metaphysical	The finitude, susceptibility to pain and disease, and other incapacities essential to the coachman and the horse and that are ultimately based in facts about natures	The finitude, susceptibility to pain and disease, and the inclination to cruelty that are essential to the man and the result of damage to his nature and/or that of his species, which damage is ultimately based in facts about immoral acts and intentions (e.g., Original Sin)	The finitude, and susceptibility to pain and disease in the coachman and the horse, and the corruption in the coachman’s nature and/or that of his species, and that are ultimately based in facts about a dark force or shadow-side principle in reality
Empirical	The cancer of the coachman, whose ultimate explanation consists in causal facts about natural phenomena	The cruelty of the coachman and the suffering of the horse, whose ultimate explanation consists in facts about the man’s immoral acts and intentions.	The cancer, anger, cruelty, and suffering of the coachman and the horse whose ultimate explanation is based in facts about a dark force or shadow-side principle in reality.
Figure 1. The Table of Evils, applied to Nietzsche case

The distinctions represented in the Table of Evil are the topics of Sections 3 and 4. Sections 5 through 7 look at three varieties of evil (systemic, symbolic, and radical) whose positions within the Table are more difficult to discern.

3. Kinds of Evil: Metaphysical and Empirical
The first key distinction is concerned with the kinds of evil—with what evil is or consists in, and thus with where and how it manifests. Again, the distinction is not exclusive: someone might hold that there is both metaphysical evil and empirical evil, and that the latter is typically a manifestation of metaphysical evil. Someone else, however, might hold that there is no such thing as metaphysical evil, and that all evils can be accounted for at the empirical, causal level.

3.1 Metaphysical Evil
Many of the traditional kakologists believed in metaphysical evil—i.e., evil that has to do with the way things exist or fail to exist. Typically, metaphysical evil is supposed to be a function of a thing’s nature and characterized by a kind of unintelligiblity. As we have seen, many such theorists also typically assume that metaphysical evil has empirical manifestations.

Both metaphysical and empirical evil have been described in terms of four main theory-templates: Absence, Matter, Privation, and Real Property. These templates are laid out in more detail in the discussion of metaphysical evil in this section, and applied again in section 3.2’s discussion of empirical evil.

3.1.1 Absence Theory
The Absence Theory of Evil has its origins in the Platonic idea that there are different “degrees of being” corresponding to the number and kinds of capacities a thing has. Roughly speaking, the more numerous and impressive a thing’s capacities, the more real and thus better it is, metaphysically-speaking. A dog cannot stand erect; an ape can. A rock cannot pass through walls; an angel can. These lacks or absences are essential to being the kind of finite creature that a dog or a rock is; miracles aside, a rock is just the kind of thing that cannot pass through walls. All the same, the lack of that ability is an evil.

Absence theorists typically add a “plenum” thesis here: it is fitting, or beautiful, or perhaps even necessary, that all the different degrees of being are exemplified, and thus that every link in the “great chain of being” is occupied. Evil is a function of the way things ought to be or even must be.

Absence Theory was popular across antiquity, but it was particularly attractive to philosophers in monotheistic traditions because it allowed them to say that evil is not a thing—and thus not some thing that a good, all-powerful God created or sustains. Anselm writes in On the Fall of the Devil:

Just as nothing that is not good comes from the Supreme Good, and every good is from the Supreme Good, likewise nothing that is not being [essentia] comes from the Supreme Being [essentia], and all being is from the Supreme Being. Since the Supreme Good is the Supreme Being, it follows that every being is a good thing and every good thing is a being. Therefore, just as nothing and non-being [non esse] are not being [essentia], likewise they are not good. So, nothing and non-being are not from He from whom nothing is unless it is good and being. (De Casu Diaboli, v.1, 235; translation by Sadler [Other Internet Resources])

A lingering problem in the theistic context, however, is that Absence Theory entails that finite things have a degree of evil just in virtue of not being at the top of the chain. So even if God does not create evil (because absence is uncreated), God creates beings that are essentially evil.

3.1.2 Matter Theory
Plotinus rejects Absence Theory for a related reason: it compels us

to say that there are evils in the higher world too; for there the Soul is inferior to Intellect, and Intellect is lesser than [the One]. (Enneads I, 8, 13)

For Plotinus, it is not merely being lower than the highest One that makes something evil; rather, evil consists in being so low as to be associated with matter. Indeterminate or “unformed matter” is the final term on the cosmic chain from being to non-being—it is as far away from intelligence as possible, and thus equally far away from goodness. This is the Matter Theory of Evil that was influential in various gnosticisms, early Christian heresies, and late antique platonisms (see O’Meara 2019).

3.1.3 Privation Theory
Augustine, as well as many scholastics and early moderns, rejected Matter Theory on religious grounds. God created matter, and so it cannot be bad in itself. Instead of reverting to pure Absence Theory, however, these monotheists developed the Privation Theory of Evil. This can be construed as Absence Theory plus the Aristotelian idea that goodness is relative to a thing’s kind. Individuals of different kinds have different ends dictated by their natures: as long as the dog achieves the ends set out by its nature, it counts as fully good of its canine kind, even if it essentially lacks the good-making capacities (or “realities”) of beings higher on the chain. (For more on Augustine’s version, see King 2019; on Aquinas, see Davies 2019).

Privation Theory thus reduces pressure on monotheism: evil is not a being but rather an absence, and so God did not create it. Moreover, evil is the kind of absence that is not a function of the essential natures of things, and so God cannot be faulted for creating things that are essentially evil. Failing to accomplish the end set out by one’s nature—failing to be the way one ought to be—is a privation, however, and so it is evil.

Friends of Privation Theory offer different accounts of how and why things fail to accomplish their natural end. Most ascribe the failure to something in the individual creature—culpable ignorance, Original Sin, free agency—rather than to God, thereby grounding metaphysical evil in moral evil (on which see section 4.1 below). The extent to which these appeals to privation succeed in getting God off the hook is, naturally, controversial.

Plotinus’s view is effectively a hybrid of Privation Theory and Matter Theory: for him, privation only occurs when some of the matter in something is unformed or unmastered by a form (see Enneads I, 8, 5, 19–26). But even if other Privation Theorists do not view privation in this way, the conception of evil as infinitely distant from reason and intelligibility survives. In other words, Ignorance, Original Sin, and other misuses of freedom are not necessarily a function of irrational matter, but they are still opposed to rational mind. Descartes is illustrative here: for him, the only teleology (and privation) in the world relates to the souls—and in particular the wills—of human beings. Material substance is mechanistic, and aggregates of it (in the forms of animals and plants) can be explained mechanistically, without invoking teleology or kind-relative values (compare Newlands 2019).

3.1.4 Real Property Theory
A fourth major account of the nature of metaphysical evil takes it to be something more substantive than absence, privation, or unformed matter. Call this the Real Property Theory of Evil: evil is some sort of reality—a determinate feature of certain finite beings (see J. Russell 1977, 1981, and Frankfurter 2006). Some versions of this picture say that evil is ultimately dependent on the good. Other, more Manichaean versions take the two to be coeval and independent, locked in an eternal axiological struggle. Although the relevant “property” here is supposed to have more reality or substance than mere absence or privation, there is still a kind of unintelligibility to it. The evil side of reality, the dark force, or the malevolent will is a kind of black hole for the “natural light” of reason—positively real, but inaccessible to complete explanation.

3.2 Empirical Evil
Empirical evil is a capacious category: it covers bodily pain, damage, and disease as well as the psychological concomitants or effects of these physical phenomena—suffering, terror, depression, mental illness. Traditionally, it has also included social ills such as oppression, poverty, and structural injustice (see Sharpe 1909). Philosophers who believe in metaphysical evil often take them to manifest in empirical evils. Philosophers who reject metaphysical evil, by contrast, take the empirical kind to be fundamental.

Calling pain an evil might raise eyebrows, since clearly some pain is beneficial: it protects us from collisions, diseases, and predators. But the idea is that, whatever instrumental uses it has, pain qua phenomenal quality—the feeling of it—is intrinsically bad (setting aside for these purposes tricky cases like that of the masochist who takes pleasure in experiencing pain). Pain in the horrendous amounts and kinds that we encounter in human history as well as in the “charnel house” of evolutionary history is sickeningly and obviously bad (Murray 2008; Martin & Watkins 2019).

The templates used to characterize metaphysical evil above can be applied to empirical evil, too. An Absence Theory of empirical evil construes it simply as the absence of physical-psychological states of pleasure, health, stability, justice, and even life. Matter Theory regards pain, disease, mental malaise, and social ills as effects of our standing as material beings, vulnerable to the “matter” in our organism breaking down or coming into conflict with other parts of material creation. Privation Theory says that empirical evil is the absence of some such good which ought to exist. There will then be different accounts of why the good ought to exist, and why it doesn’t—some of these will be based in a theory of metaphysical evil.

A Real Property Theory of empirical evil, by contrast, insists that pain and suffering are positive realities and not mere absences (it is thus compatible with Matter Theory, but not with Absence or Privation Theory). As Malebranche notes, this is problematic in theological contexts, since God is supposed to be the ground of all positive beings (see Malebranche 1674–5 [1997: 348 and 392]). In a letter to a mathematician named Arnold Eckhard, G.W. Leibniz discusses this issue, and suggests “with some scruples” that “pain too is a perfection” (1677 [1969: 177]). That is a fairly unusual view, one that is made particularly poignant by the fact that Leibniz himself spent the last few years of his life in immense pain. He apparently had a habit of sleeping in a chair near his writing desk, and it

led to his having an open sore on his right leg. This caused him difficulty in walking; he tried to remedy it, but only by putting blotting paper on it. Later, to reduce the pain and to make the nerves insensitive he had a number of wooden clamps made, and these he screwed onto himself wherever he felt pain. I suspect that by doing this he so damaged his nerves that eventually he could no longer use his feet and had to stay in bed. (Guhrauer 1842 [1966: vol 2, p.336]; quoted in Mates 1989: 29)

Although such pain is a “perfection” and thus a real property, for Leibniz, it still involves a kind of weakness or imperfection in the person who has it, and so God cannot, in the end, exemplify this “perfection”. Rather, God’s possession of maximal pleasure is somehow sufficient to ground the “reality” that is found in both pleasure and pain (Leibniz 1677 [1969: 177]). This seems fishy, and other philosophers argue against Leibniz that if pain is a real property (rather than a mere absence), then God as the “ground of all reality” must indeed exemplify it. Some recent theologians and philosophers even welcome this idea, arguing that a conception of God as grounding empirical evil by suffering it has advantages for projects in theodicy (Hartshorne 1984; Wolterstorff 1988).

Mental illnesses can be classified as “empirical evils” if we assume that they have empirical causes and neural bases (Bhattacharjee 2018). Such illness often generates further empirical evil in the form of inexplicably cruel or destructive behavior to self and others, as will be familiar to anyone who has tried to live (or love someone) with mental illnesses like posttraumatic stress disorder (PTSD), borderline personality disorder, schizophrenia, and so on. It is unclear whether the theologians just mentioned would want to say that this kind of empirical evil, too, must have its ground in the divine by way of exemplification. The theological consequences of such a suggestion seem unattractive, to say the least.

4. Origins of Evil: Moral and Natural
4.1 Moral Evil
Moral evil is metaphysical or empirical evil that arises out of the acts or intentions of agents: other traditional terms for it include “sin”, “wickedness”, “trespass”, and “iniquity”.

Philosophers in the Abrahamic tradition typically hold that we can be damaged by moral evil even before we have performed any actions whatsoever. Augustine, for example, characterizes Original Sin as a result of a primordial choice that damaged our very nature such that each member of the species is born already worthy of infinite punishment and strongly inclined to engage in further moral evil. So this is a case of metaphysical evil that has its origin in moral evil: bad choices on the part of the forefather led to damaged natures all the way down the spermatic line.

Such metaphysical evil will often manifest in empirical evil (although it need not do so); it also makes it likely that there will be further metaphysical evil. Thus an initial moral choice starts off a kind of snowballing into hellishness. It is clear why ancient and medieval and even some contemporary responses to the “Unde Malum?” question focus on how a morally uncorrupted creature (Adam, Eve, or Lucifer) could have started the process in the first place (see, e.g., Anselm De Casu Diaboli, vol.1 and Johnston forthcoming).

Kant appropriates this idea in a modern context, arguing that we are all originally afflicted by a propensity to moral evil (Hang zum Bösen), even apart from any specific actions that we perform. This “radical evil”—the metaphysical evil at the root of our nature (“radix” = Latin for “root”)—is something for which not Adam but we as individual agents (or perhaps the species itself) are somehow responsible. And this is reflected even in garden-variety peccadillos: any act that subordinates commitment to the moral law to something else is an expression of radical evil. This makes it clear that people who use “radical evil” to refer to something particularly horrendous or awful (Arendt 1951, Bernstein 2002) are departing from the Kantian concept (see Section 7 below). That said, whether it is intelligible to say that we are culpable for a status that is not temporal is a notoriously open question in Kant-interpretation (see Card 2010, Wood 2010, and other essays in Anderson-Gold & Muchnik 2010).

Although moral evildoing often leads to empirical evil, it needn’t do so, at least on non-utilitarian accounts. Some crimes can be “victimless” at the empirical level.

Once again, the four traditional theoretical templates can be used to further characterize the evil acts and intentions that make an evil “moral”. Absence Theory says that the absence of a good will—either because something lacks a will altogether, or because its will is not good—is evil just by way of being an absence. Privation Theory says that a will is evil when it ought not have the absence of good orientation that it does. Matter Theory says that our embodiment and other engagements with matter explain the misorientation of our will. Real Property Theory insists that a will that is oriented to the bad is a real thing, and that its orientation to the bad is a real feature of it, not just a privation.

Declaring that moral evil is rooted in the will does not fully explain it. We would need a further account of how evil choices are made—of what sort of moral psychology could explain them. For Kant, explanation ceases at some point; evil choices, at bottom, are irrational—surds that we can identify and impute, but never fully explain. “There is no conceivable ground for us, therefore, from which moral evil could first have come in us” (Kant 1793 [AK 6:43; 1998: 64]).

Other philosophers offer partial explanations. Augustine says that although there is no determining cause of the devil’s choice, it is able to be partly “rationalized” in terms of Satan’s self-obsessed delight in his own powers (see King 2019). This is an early version of what is now called a “dispositional” account of evil agency (L. Russell 2014: ch.10; Kamtekar 2019). Early Islamic interpreters of the Qu’ran, by contrast, offer explanations in terms of ignorance: there is something that the supremely evil agent (Iblis) didn’t realize, or an inference that he failed to make, and this is what explains his orientation to the bad (see Germann 2019).

Moral evil is what contemporary people—including philosophers—tend to have in mind when they talk of “evil”. Extreme forms of it are viewed by many philosophers view as “unintelligible”—as defying ordinary explanation in significant and threatening ways. Such extreme and unintelligible moral evils are what many philosophers (though not Kant) are referring to when they speak of “radical” evil (Arendt 1951; L. Russell 2014; see also Section 7).

4.2 Natural Evil
Natural evil refers to metaphysical and/or empirical evils whose origins are “natural”—i.e., grounded in the natures of things and/or the natural laws. The very nature of a horse makes it incapable of language: if that incapacity is a metaphysical evil (as it would be on Absence Theory), then given its origin it also counts as a natural rather than a moral evil. Likewise, cancer, pandemics, earthquakes, meteor strikes, aging and perhaps even death itself are (typically) regarded as natural rather than moral evils. In the tradition there are characterizations of natural evil that use one or more of the four templates discussed earlier: Absence, Privation, malfunctions in Matter, or some other Real Property.

Outside of religious contexts, however, many philosophers (and people generally) will be reluctant to characterize hurricanes, diseases, and meteor strikes as a source of “evil”. The very idea of natural evil seems most at home in theological debates: can the Author of Nature be supremely good, wise, and powerful and yet still create a world that contains so much pain and suffering, not to mention Category Five hurricanes, animal predation, and Alzheimer’s Disease?

There are different kinds of responses to the problem of natural evil in theological traditions: Aesthetic responses say that we don’t presently have the right perspective to see the overall beauty of the natural system, and thus that there really is no natural evil; Soul-making responses say that this present vale of natural evil is justified because it gives us the chance to become virtuous; Skeptical theistic responses say that given our limited faculties we cannot reasonably expect to understand why God would allow natural evils. (For more on these responses see M. Adams 1998, Tooley 2002 [2019]).

A very different kind of response involves recharacterizing at least some natural evils as moral evils. For instance, we might focus on ways in which human activity has set in motion the kinds of environmental, climatic, microbial, and biospheric changes that lead to “natural” disasters, pandemics, famines, and other empirical evils. Or, in a more religious context, we might seek to explain the suffering and misery caused by “nature” by appeal to sin, karmic law, or divine justice.

On some versions of this view, the morally responsible agent can be someone other than the victim: Adam sins, and now the non-human “creation has been growning” (Romans 8:22, NRSV)—and makes the rest of us groan along with it. Or: we emit the greenhouse gasses, and our descendants three generations later suffer.

Other versions insist that the fault lies with the victim of natural evil himself: Eliphaz the Temanite says to Job

Think now, who that was innocent ever perished?
Or where were the upright cut off?
As I have seen, those who plow iniquity
and sow trouble reap the same.
By the breath of God they perish,
and by the blast of his anger they are consumed.
The roar of the lion, the voice of the fierce lion,
and the teeth of the young lions are broken.
(Job 4: 7–10, NRSV)

Eliphaz suggests that if Job continues to suffer, then there must be some explanation for these natural evils in Job’s own past behavior. The risk in this kind of doctrine will be obvious to less ancient sensibilities: to suggest that a victim of natural evil must be morally responsible for it seems like the very definition of adding insult to injury.

Another way to recharacterize natural evil as moral evil is by appealing to the actions of moral agents who are neither divine nor human. This appears to have been Augustine’s position in places; more recently, it has been invoked by Alvin Plantinga as an at least broadly logically possible scenario which could be used in a “defense” against the logical problem of evil (Tooley 2002 [2019]). The scenario says that

[n]atural evil is due to the free actions of nonhuman persons; there is a balance of good over evil with respect to the actions of these nonhuman persons; and it was not within the power of God to create a world that contains a more favorable balance of good over evil with respect to the actions of the nonhuman persons it contains. (Plantinga 1989: 58)

A final way to recharacterize natural evil as moral would simply be to hold God alone morally blameworthy for it, since God created a world in which sentient creatures suffer so terribly. Obviously this would not be a winning strategy if the goal is a successful theodicy. Indeed, some theistic traditions block this route a priori by saying that it is conceptually impossible for God to do wrong: a perfect creator is either unbound by moral principles, or essentially incapable of violating them (see Murphy 2017).

If these efforts to locate a moral basis for natural evil (whether empirical or metaphysical) are unsuccessful, then “natural” remains a distinct category of evil’s origin.

Here again is our Table of Evils, now with more examples that go beyond Nietzsche’s horse case:

Origins:	Natural	Moral	Spooky non-agential
Kinds:	 
Metaphysical	The finitude and other limitations that are essential to an individual or species-nature and that are ultimately based in facts about natures.	The finitude, limitations, and corruption that are essential to an individual or species-nature and the result of damage to natures, which damage is ultimately based in facts about immoral acts and intentions (e.g., Original Sin)	The finitude, limitations, and corruption that are essential to an individual or species-nature and are ultimately based in facts about a dark force or shadow-side principle in reality.
Empirical	Pain, suffering, and illness (including mental) whose ultimate explanation consists in causal facts (e.g., aging, accidents, genetic defects, disasters and other natural phenomena).	Pain, suffering, and illness (including mental) whose ultimate explanation consists in facts about immoral acts and intentions (e.g., interpersonal violence, social ills, self-harm)	Pain, suffering, and illness (including mental) whose ultimate explanation consists in facts about a dark force or shadow-side principle in reality.
Figure 2. The Table of Evils, with general examples

Some types of evil do not seem to fit nicely in the Table of Evils. The three dealt with in what follows are systemic evil, symbolic evil, and radical evil. The nature and the origins of such evils are difficult to discern, and may require an expansion of the Table.

5. Systemic Evil
Systemic evil is the kind of evil that exists at the level of systems or groups rather than merely at the level of individuals. Organized structures like governments, corporations, teams, and religious institutions can be evil in this way; so can more loosely-organized systems such as “Academia”, “White Supremacy”, and “Wall Street”. Indeed, Google includes the motto “Don’t Be Evil” in its Company Code of Conduct (for the origins of this, see Chang 2019); disgruntled employees later sued the company alleging that it had violated that pledge (Allyn 2021).

Systemic evil seems empirical rather than metaphysical, but its origins are difficult to identify. It does not appear to be a merely natural phenomenon, or a spooky non-agential one, and yet its supra-agential character makes it seem not entirely moral either.

Hannah Arendt’s early work on totalitarianism (1951) depicts systemic evil as a kind of empirical evil for which no individual or even collection of individuals is fully responsible. The cogs in the machine, as well as the leader or leadership, may be the origin of some of the harms involved, but the evil of the whole structure (on Arendt’s view) is somehow greater than the sum produced by its parts.

Racism is another prominent example of systemic evil. Recent accounts of entrenched racist structures in certain societies (the United States, for instance) suggest that such evil has its origin not merely in actions and intentions but also in omissions and passivity: people who do not explicitly support the systemic evil can count as agents of it. If this is right, then active work against the evil in question—“anti-racist” activity rather than “non-racist” activity, for example—becomes morally required (Kendi 2019). But even such active opposition efforts may not be sufficient to avoid complicity in systemic evil: some theorists argue that even anti-racist people living in racist societies are “tainted” by its evil all the same (Rothstein 2017). That leads to the next kind of problem case.

6. Symbolic Evil
Symbolic value is a less familiar idea in philosophy than it is in Anthropology, Religious Studies, and the other social sciences that deal with production, exchange, and consumption. The main idea is that an object or act can have far more “symbolic” value to a certain individual than its exchange or monetary value on some market or other, typically because of its causal history. That bauble given to you by a now-deceased friend has far more symbolic value (to you, at least) than the monetary or exchange value that it would fetch at auction. This is because the gift had its origin in the generosity of a friend who has since died, has the ability to invoke his memory, and so on.

Symbolic disvalue works in an analogous way. Products that fetch a certain monetary value on an open market may have significant symbolic disvalue that is not reflected in their price. This disvalue often arises, again, from the product’s provenance: an industrial chicken sandwich is a result of the obscene degradation of animals, workers, and the environment on the part of an industry that pays revolving-door lobbyists to promote food policy that, in turn, keeps production costs and prices artificially low, in part by externalizing most of the harms it causes. In some cases, such disvalue may be significant enough to make purchasing the product wrong, even if doing so does not lead, causally, to any actual harm or rights-infringement (see Chignell 2016).

The term “evil” is typically only applied in cases of symbolic disvalue when there is something excessive about them. Stepping on a flag or consuming a chicken sandwich might have some symbolic disvalue, but it would be strange to say that these are cases of symbolic evil. Having anything to do with soap made from the body fat of people murdered at the Stutthof concentration camp, by contrast, seems downright evil, even if the intended consequences (i.e., getting oneself clean) are good. Indeed, the symbolic evil attached to such a product may “touch” everyone who was part of the society that permitted its manufacture, whether they were directly involved or not. The evil of sustained chattel slavery may have a similar sort of symbolic power, even generations later.

Both the nature and the origins of symbolic evil are hard to characterize; thus it is hard to see where it fits in the Table of Evils. Is there a metaphysical aspect to symbolic evil, or is it fully empirical? Is its origin entirely natural, or moral, or is there something spooky and non-agential about it? A related set of difficulties has to do with the fact that, in some contexts anyway, the transfer of symbolic disvalue operates via the complex logic of “taint”, contagion, or uncleanness. Some philosophers who write about symbolic value argue that the only way to avoid being “touched” by such evil is via active and explicit dissociation—a symbolic “standing with the good” (R. Adams 1999). In other words, even if our abstinence does not make a difference, we must symbolically oppose an evil practice by, say, explicitly signaling opposition and (where possible) refusing to consume or benefit from its results (see Hill 1983; Appiah 1986).

7. Radical Evil: Four Conceptions
Kant is the source of “radical evil”, but his way of using the term is now out of favor. In fact, most people writing on this issue use the term in a precisely non-Kantian way to refer to something spectacularly excessive—an act or event whose badness is deeper and more mysterious than the badness of ordinary states or activities (Bernstein 2002).

In her famous account of the trial of Adolf Eichmann in Jerusalem, Arendt (1963) promoted the idea that even the worst evils can be “banal” and bureaucratical. A decade earlier, however, she conceived of “radical evil” quite differently. In a March 1951 letter to Karl Jaspers she wrote:

We know that the greatest evils or radical evil has nothing to do anymore with humanly understandable, sinful motives. What radical evil is I don’t know, but it seems to me to somehow have to do with the following phenomenon: making human beings as human beings superfluous. (Arendt & Jaspers 1992: 166, emphasis added)

Arendt went on in the letter to insist that “making human beings as human beings superfluous” is not the same as treating them as “mere means to an end”. She thus rejected the Kantian view that radical evil—no matter how benign or awful the effects—has its root (Latin: radix) in the willful violation of the categorical imperative by individual free agents (see Louden 2010: 98).

Jaspers’s view of radical evil, by contrast, was consistently non-exotic and Kantian: “there is evil because there is freedom. It is only possible for the will alone to be evil” (Jaspers 1947 [1958: 532], emphasis added). According to one commentator, this focus on human freedom as the root of all evil is “significant and commendable”:

Kant [and following him Jaspers] refuses to cater to our prurient craving for a special account that applies especially to the most extreme cases of evil…. He fears that occupying our imaginations with extreme cases of evil may be merely a way of indulging some of our nastier human traits—rationalizing our resentment and vindictiveness by supplying it with an object that would seem to justify it. (Wood 2010: 157)

The concerns expressed in these passages are common in discussions of the nature and origins of evil. Call them Jaspersian concerns for short. They are second-order concerns about how we should conceive and speak of evil, especially when calling it “radical”. The concerns fall into two broad kinds: (1) concerns about exoticizing wrongdoing with excess-locutions like “evil” and “radical”; and (2) concerns about tainting people and things that are touched by such evil, beyond the straightforward condemnation of the perpetrators (for more on such concerns, see Card 2002, Cole 2006, and Calder 2013 [2018]).

The Kantian conception of radical evil is considered in the next sub-section. Sections 7.2–7.4 survey three other conceptions and look at how each might raise Jaspersian concerns.

7.1 Radical Evil as Violation of the Moral Law
Kant argues in Religion within the Bounds of Reason Alone (1793) that free choices against the moral law are unintelligible in the sense that they are irrational; our propensity to make them is thus an inexplicable mystery at the “root” (radix) of our moral psychology. The post-Kantian idealist F.W. J. Schelling, picking up the refrain, rejects the Privation Theory of radical evil in favor of the view that it has its origin in the positive, irrational decision to prefer self-advantage over the moral law, though “just how the decision for good or evil comes to pass in the individual, that is still wrapped in total darkness” (Schelling 1809 [1936: 59]).

On the Kantian view of radical evil, then, there is a normative sense in which it is “unintelligible”: it is an irrational propensity and thus cannot be “understood” in the sense that it cannot be sanctioned by proper reason. Likewise, an immoral choice cannot be fully explained: full explanations appeal to good reasons, and there are no good reasons for wrongdoing.

There is a broader sense of “understand” or “explain”, however, in which such evil is no mystery at all: it is the most depressingly familiar thing in the world. Everyday immoral agents presumably see what they are doing under the aspect of some good or other—good for their company, good for their bonuses, good for their reelection efforts—even if they also know that what they are doing is ultimately wrong. If we interpret the war cry of Milton’s Satan—“Evil be thou my good!” (1667, Paradise Lost, Bk IV, line 110)—as implying that he is taking evil under the guise of the good, then it is not absurd. But it is still not wholly intelligible, either.

The Kantian conception of radical evil, then, says that that the unintelligibility of wrongdoing does not prevent us from assigning blame, holding perpetrators responsible, and refusing to taint the innocent. This explains why Jaspers found the conception so attractive:

To rank the will to happiness, which dominates among men’s motives, above the unconditioned law that shows itself in reason—that is the root of evil, the “propensity” which Kant calls “radical evil”. (Jaspers 1962: 321)

7.2. Radical Evil as Choosing Evil for its own Sake
Some philosophers, and more than a few novelists and screenwriters, find the view that agents are always choosing under “the guise of the good” as inadequate to the psychology of extreme malevolence. It may have suited the melioristic conceptions of the Enlightenment, but the well-publicized, mechanized horrors of the recent past allegedly demand a bleaker picture of perpetrator psychology. Serial killers, murderous dictators, torturers, derivatives traders: the idea is that at least some of these malign actors see their own actions as atrocious—as making the world worse rather than better on the whole (and sometimes worse for themselves)—and yet still choose to perform them. They are thus not saying “Evil be thou my good”, at least on the interpretation just offered. Rather, they are self-consciously male-volent: they will the bad under the aspect of the bad. And yet they are not insane—this is what makes their actions especially difficult for the rest of us to understand. This is a second common way in which the term “radical evil” is used. (See Pauer-Studer and Velleman 2015 for a reading of Milton according to which Satan’s war cry is interpreted in this way.)

Augustine reports in his Confessions that during the pears incident he took pleasure in

the theft and sin itself.… Behold, now, let me heart tell Thee what it was seeking there, that I should be gratuitously wanton, having no inducement to evil but the evil itself. It was foul, and I loved it … I loved my own error – not that for which I erred, but the error itself. (Confessions Bk 2, Chap. IV, paragraph 9 [1876: 30])

It is tempting to say that in “loving the sin itself”, Augustine was in some sense taking it to be good. But he at least gestures here at this second conception of radical evil: some acts can be performed under the aspect of their own abject deformation and rottenness—as ultimately bad even for the agent himself.

As we have seen, the Prussian philosopher who coined the term “radical evil” 1400 years later did not think that it can involve choosing evil for its own sake. In fact, Kant argues that such a “diabolical” conception of evil is incoherent or at least psychologically inapplicable to human beings. Kant’s skepticism, however, did not prevent Dostoyevsky from composing Notes from the Underground (1864) as an extended and somewhat plausible portrait of one man’s effort to choose evil qua evil. And there are more recent accounts of people who confess—in private diaries or braggadocios depositions—that they did what they did because it was evil.

In this context, consider (if you can bear it) Stone 2009’s portraits of the worst serial killers: although some perpetrators report that they take what they are doing to be good—ridding the world of “garbage women”, giving someone his “just deserts”, correctly following the orders of the voices in their head, and so on—others openly admit that what they are doing is bad, wrong, evil, despicable, and so on. In such cases, the perpetrators are not making a series of unsound inferences, or mistaking the bad for the good. Rather, they seem to be engaged in a self-conscious turning away from anything that could be regarded as good by anyone. Radical evil on this conception is sometimes described as a self-conscious turning away from being itself (Eagleton 2009: 16; L. Russell 2014: 23).

If Augustine’s confessions about the pears—or these more spectacular recent confessions—are accurate, then there may be (contra Kant) a baffling diabolical state that some people can fall into, and that the rest of us cannot entirely fathom. The unintelligibility here thus threatens to raise Jaspersian concerns about exoticization and taint.

7.3. Radical Evil as Repudiation of the Moral Law
A third conception of “radical evil” takes the term to refer to acts or practices (like slavery and genocide) that do not merely violate rational principles but also constitute an effort to repudiate moral rationality altogether, or at least to transcend it. When we steal or lie, there is a sense in which we might be failing to treat others with the respect that they deserve. And as we have seen, Kant does not hesitate to view such irrational choices as stemming from our propensity to “radical evil”. But radical evil on this third conception is different: it involves an intentional refusal to acknowledge that some group of persons has any moral standing at all—the kind of moral standing that would prohibit us from instigating or complying with their humiliation, degradation, or extinction.

Radical evil of this sort, in other words, denies the universal scope—and thus, perhaps, the very existence—of the moral sphere altogether. It is anti-rational rather than merely irrational: this is what threatens to make it incomprehensible or inexplicable in a unique way. This is also presumably what the early Arendt means when she says that radical evil involves making human beings “superfluous”.

By way of analogy: suppose that ordinary moral wrongdoing is like making a bad move in chess, or like cheating by moving one’s pieces in an illegal way when one’s opponent isn’t looking. A radically evil act on the present conception, by contrast, would be like crushing all of the opponent’s pieces and upending the table. The player who does the latter is no longer or perhaps never was a player: she cannot explain her behavior by saying that she was trying to win by making what turned out to be a bad move or a cheat. She cannot explain her behavior in terms of chess at all. Likewise, a radically evil act is supposed to transcend the terms of moral rationality.

The analogy extends only so far, however. That’s because there are still some reasonable explanations left to our non-player—explanations external to the game:

I was hungry, so I crushed all of your pieces and swept them off the board in the hopes that you would suggest lunch.

By contrast, it is not obvious how there can be any credible reason given for doing something that constitutes a denial of reason altogether. That is why radical evil in the repudiative sense threatens to be uniquely unintelligible and troubling. If someone—not a beast or a machine, but a human being—acts in a way that entirely disclaims not just an awareness of moral authority but also the basic rules of moral reason altogether, he effectively places himself in an antelapsarian state, unburdened with the knowledge of good and evil. His act asserts that he has transcended entirely the moral sphere—that what he does cannot be wrong.

Can human beings really perpetrate radical evil in this sense? Richard Ramirez, the “Night Stalker” serial killer in 1980’s Los Angeles, certainly took himself to be doing so. He repeatedly snuck into people’s houses to rape and kill them, sometimes cutting off body parts and taking them with him. After his fourteenth murder, he was caught and then boasted to his captors:

You don’t understand me… you are not capable of it. I am beyond good and evil…I love to kill people. I love to watch them die. I would shoot them in the head and they would wiggle and squirm… I love all that blood. (quoted in Stone 2009: 208).

This idea—that a human being could do something that would enact his own transcendence of moral norms, make other persons superfluous, and establish his own status as somehow “beyond good and evil”—is what concerned Karl Jaspers, and what he was hoping Arendt would resist. In her face-to-face confrontation with the quotidian, bureaucratic evil of Adolf Eichmann, she seems to have changed her mind (though see Cesarani 2007 and Margalit 2019 for a portrait of Eichmann that resists her famous “banality thesis”). But even if Arendt ultimately repudiated the repudiative conception of radical evil, others remain sympathetic to some version of it (e.g., Bernstein 2002 and Motzkin 2019).

7.4. Radical Evil as Systemic Evil: Human Beings Made Superfluous in Another Way
“Systemic” or “structural” evil exists at the level of groups, networks, races, and collectives rather than merely at the level of individuals (see section 5). The fourth conception of “radical evil” applies the concept to particularly rampant or entrenched evils of the systemic sort.

Although Arendt’s interest was in totalitarian state systems, contemporary philosophers are equally interested in non-state but still super-human systems: corporations, collectives, markets, artificial intelligences. These are now some of the most potent sources of value and disvalue at work in the world. As noted in section 5, the nature of systemic evil is empirical, but its origin is more difficult to grasp. Corporations have boardrooms and executive suites, and are even treated as persons by some legal systems, but (as investigation after investigation indicates) it is hard to find the heart of their darkness when assigning responsibility. Still-powerful systems of white supremacy are based in structures of which no individual human mind was or is fully aware (Rothstein 2017). Likewise, markets, algorithms, blockchains, and various forms of artificial intelligence arise out of innumerable individual human efforts, but are also designed to make human beings superfluous in a literal and unprecedented way. Some of this is and will be for the good—there are already fewer back-broken menial laborers in the fields or exhaust-guzzling toll collectors on the highways. But some will surely be for the bad, and in ways that are not foreseeable. Radical systemic evil—especially in a technological age—does not seem natural or spooky, but it does not seem fully moral either.

In sum: although natural, moral, and spooky non-agential conceptions of the origins of evil were the focus of most traditional discussions of the origins of evil, it looks like some varieties of radical evil have a different origin altogether—one that is not entirely intelligible. This raises Jaspersian concerns: a world in which (non-Kantian) radical evils are widespread is one in which ascriptions of moral responsibility are increasingly difficult to make.

1. On Poets: How to Judge Poetry?
This work, a dialogue in three books, was apparently quite widely read in the ancient world. While the Poetics seems to have received no echo in antiquity, On Poets seems to have acquired the status of a reference work on Aristotle’s aesthetics; the fragments that we have come from a wide array of sources, including Philodemus, Ps-Plutarch, Athenaeus, Diogenes Laertius, Macrobius, and Proclus. Many fragments deal with entertaining stories such as the birth and death of Homer, or the presentation of the rivalries between the poets. However, it would be a mistake to draw the conclusion that the whole work would have consisted of such stories without any theoretical background. Actually, two topics that are crucial in the Poetics seem to have been central in On Poets as well: mimesis and the shortcomings of poets.

When opening the Poetics, the reader is struck by the repetition of the word mimêsis (and the verb mimeisthai), to the point that it defines what is (what we call) a work of art. Very roughly, one might say that the word mimêsis has both a static, or “pictorial” aspect, and a “dynamic”, or “theatrical” aspect. According to its “pictorial” aspect, mimêsis designates the fact that in such and such mimetic work, the receiver recognizes a resemblance. In the Poetics, Aristotle gives us a very telling example in evoking a painting or a sculpture in front of which the beholder recognizes, about a character represented, that “such and such a character is so-and-so” (4, 1448b17). According to its “dynamic” aspect, it is rather the behavior of the one who makes a mimêsis, which may range from the mimicking of noises or gestures to theater enactment. In Latin, mimêsis was rendered as imitatio, which indeed could include both meanings; but the English “imitation” hardly works, and perhaps the best solution after all is to keep the Greek term, transliterated as “mimesis” (“representation”, or “depiction”, works for the first connotation, but hardly for the second). Of course, often the use of the word, especially in poetry, includes both connotations: a play is a mimesis both in the sense of an enactment of some actions that are made by the characters of the play, and we can also recognize them as being the actions of such-and-such characters. Traditionally, a poetic work was defined in its opposition to prose, by versification (see, e.g., Gorgias’ definition of poetry: “I consider and call poetry every speech that possesses meter”, Helen 8). Aristotle opposes that idea, on the grounds that it does not allow us to understand the specificity of a poetic work, by giving the example of Empedocles “who has nothing in common with Homer except for the metric form” (Poetics 1, 1447b17–18): we do not infer from the fact that Empedocles writes in the same kind of verses as Homer that his work is epic poetry! What distinguishes Homer from Empedocles is that the former wrote a mimetic work, whereas Empedocles is a “philosopher of nature” (phusiologos, b19), who did not compose a mimesis. This concern is also to be found in On Poets, where Aristotle asks this question:

Are we not going to say that even though not in verse, the so-called mimes of Sophron are works in prose and works of representation, and that the same goes for the dialogues of Alexameneus of Teos, which were written before the Socratic dialogues? (Janko 2011, F44a)

Since such written dialogues are meant to be a mimesis of dialogues that did, or rather might have taken place, they too must be considered as a kind of poetry (or what we would call literature). Athenaeus, who quotes that question, interprets this as an attack against Plato:

While in the Republic Plato expelled Homer and mimetic poetry, he himself wrote his dialogues in mimetic form, and he is not even the inventor of that genre: before him, Alexamenus of Teos and Sotion invented that type of work in prose. (Janko 2011, F44a)

We cannot say whether Aristotle also intended this to be an attack against Plato; and it is important to note that we do not find anything like an explicit rebuttal of Plato’s views in the fragments we have, but it is difficult not to see in the quoted question at least a certain irony against Plato’s critique of mimesis.

The first century BC Epicurean philosopher Philodemus wrote a treatise also called On Poetry in which he seems to offer quotations or perhaps summaries of some passages of On Poets. What Aristotle seemed to have focused on is the nature of poetry, and the importance of mimesis (Janko 2011, F4: “mimêsis has been posited as essential to the art of poetry”). And he seems to have clearly stated that mimesis, at least in the case of poetry, involves people in action (Janko 2011, F6a: Poets “depict the actions of people acting…”), and that this action must be complete (Janko 2011, F45: “The poet is a representer of a complete action”), all of which will be elaborated upon in the Poetics.

The second theme that seems to have been central to this dialogue is that of the shortcomings of poets. It is on this theme that Aristotle refers to his dialogue in the Poetics, where he analyzed, Aristotle puts it, the “many mistakes” that poets can make

with regard to what affects the reactions of the public which are necessarily connected to the art of poetic composition. (15, 1454b15–18)

This sentence has often seemed cryptic. But we find an example of such a mistake in one of our fragments. It is a passage from the later Roman author Macrobius, who quotes an excerpt in Greek assuming that he is quoting Aristotle’s words (ipsa Aristotelis verba), and where we see Aristotle denouncing an error of Euripides, who in one of his plays states that Aetolian warriors fought without sandals on their left foot. It is an error because those warriors habitually fought without sandals on their right foot. As benign as it may seem from a historical point of view, it is a deep flaw if one considers the impact on spectators. Imagine that spectators realize the error in a theater setting: the scene would no longer be tragic, and the error would become comical and provoke laughter.

This topic is not at all marginal. On the contrary, pointing out the mistakes that poets, even the best ones, commit should help us readers tell the difference between good and bad poetry (or at least good and bad passages or scenes in a poem or play), that is, to make us “critical” readers of poetry, or watchers of theater plays. It is the first century AD rhetorician Dio Chrysostom who reports a tradition according to which Aristotle was “at the origin of literary criticism (kritikê)” (Janko 2011, T4). By that, he surely meant primarily the work of scholars such as Aristarchus of Samothrace, which consisted in commenting on Homer’s epics, or of those who commented on Aristophanes; but such kinds of works made sense only if one supposes that discriminating or judging (which is the core meaning of the verb krinein) the qualities and defects of such and such a literary work is what is at stake. And that activity, as we can see from On Poets, was not a domain reserved to the academic happy few. Rather, every educated person could be expected to engage in such critical assessment. In his Protagoras, Plato makes the famous sophist state:

In my opinion, the most important part of a man’s education consists in being proficient in poetry, that is, in being able to understand, in the productions of poets, those that are correctly made and those that are not, in knowing how to distinguish between them, and in knowing how to give an account of these judgments, if asked. (338e–339a)

Plato certainly mocks such a claim, just as, in the Ion, he mocks the rhapsode who believes he possesses a “science of poetry” or a “technique of poetic composition” (in 532c, Plato equivalently uses the words technê and epistêmê poiêtikê, or simply poiêtikê). In writing a “Treatise on poetic composition” (Peri poiêtikês), we can hypothesize that, unlike Plato, Aristotle followed the path indicated by Protagoras. And in publishing a more accessible work such as On Poets, Aristotle seems to take it for granted that every person should be offered the opportunity to become a good judge of poetry so that she can better appreciate the value of the poetry she reads or the plays she regularly goes to see in the theater. [3] (Note that in Aristotle’s time, many tragic and comic authors were still writing numerous plays, and that several of the plays of Aeschylus, Sophocles, or Euripides were available in book form, and were also regularly staged in Athens and elsewhere in the Greek world).

2. Homeric Problems: How to Defend Poetry?
Literary criticism is at the very core of the other major published work dealing with poetry, the so-called Homeric Problems. One cannot overestimate the role and importance of Homer in ancient Greek culture: he is commonly called “the poet”, and every educated Greek person knows many passages by heart. And yet, Homer had also been harshly criticized from very early on, notably by Xenophanes and Heraclitus, who reproached Homer for giving wrong images of the gods. This is in part because both read Homer literally, as if Homer were describing the real world of the gods. Plato famously follows suit: he too addresses the way people usually read Homeric epics as a sort of moral description and prescription of right and wrong behaviors; and since gods and heroes are to be taken as our moral paradigms, we must condemn (and withdraw or perhaps rewrite) the numerous passages where those gods and heroes commit wrongdoings. In turn, those critiques provoked equally strong reactions aimed at defending the poet. Some simply defended the Iliad and the Odyssey as offering right ethical models: after all, according to Homer, Achilles is the paradigmatic example of courage, and Odysseus of practical intelligence and resilience. This seems to be why the Socratic philosopher Antisthenes took Odysseus as one of his philosophical heroes, as a man whose endurance may be seen as paradigmatic of the endurance required for a virtuous life. A rather different way of defending Homer was to read his poems in an allegorical manner, as, notably, did the philosopher Metrodorus of Lampsacus (a contemporary of Socrates), who interpreted many Homeric passages in the light of the cosmology of Anaxagoras.

Aristotle’s Homeric Problems offers yet another manner of defense. As one can see from the fragments that we have, Aristotle never tries to exonerate Homer’s apparent shortcomings by arguing from an ethical or allegorical perspective. What he instead proposes is to respond to criticisms made against Homer from an art-centered perspective. He sought to determine, that is, how such and such a passage or verse should be judged by reference to the aim or function of the art of poetry, considered as art and in no other way. As he clearly states in the Poetics, which seems to recap how he presented his material in the Homeric Problems:

It is not the same criterion of correctness that applies in poetry and in politics, nor in poetry and in any other art. (25, 1460b13–15)

Judging poetry from the perspective of another domain, such as politics, biology or psychology, would be a methodological mistake, since their respective aim or function is not the same. In response to ethical condemnations faulting Homer for depicting the gods in a morally bad fashion, Aristotle calmly answers:

It is quite possible that the poets speak about them neither by idealizing them nor in a true way, and that things are as indeed as Xenophanes states: but in any case, it is how people speak of them. (1460b36–61a1)

Aristotle seems to agree with Xenophanes that it is wrong to believe that the gods look like human beings and share our bad behaviors; but the poets must take into account how people generally imagine them to be if they want to have them intervening in their plots. For representing the gods as morally good beings would actually make Homer’s epics rather odd to the people they were addressed to, which would have disturbed their involvement in the plot, and spoilt their pleasure. Another example comes from the scene in which Achilles pursues Hector: the way Achilles prevents the army from taking up arms against him and lets him go by a simple nod of the head is, from a psychological point of view, totally implausible (1460a14–16; Iliad 22, 205–206). But this is not an error we have to blame Homer for, Aristotle replies, since this adds to the effect of wonder, which is part of our pleasure: even if it is a mistake from a psychological perspective,

it is right if it achieves poetry’s aim […], if that way an even more striking effect is produced in that part of the poem or at a later stage. (1460b24–26)

In Homeric Problems, Aristotle presumably only dealt with Homer. But in Poetics 25, he wants to extend his approach to tragedy. One example concerns Menelaus in Euripides’ Orestes. There Aristotle agrees (presumably with other critics) that Euripides made a mistake in representing him as a coward (15, 1454a28–29; 25, 1461b19–21)—but not for ethical reasons. The offense is purely “poetical” or “artistic”: since pity and fear require that we admire the heroes on stage, having a base character must jeopardize the audience’s emotional reaction; if, on the other hand, the plot requires having such a hero (which is not the case in that play), that would not be a fault. One will also notice that Aristotle takes for granted that we can extend such views to the other domains of art. Another example is that of the painting of a horse “with two right legs stretched out towards the front” (1460b18–18). Aristotle believes (wrongly, as it happens) that this is physically impossible. Still, he avers that we must not judge the quality of the painting from a biological point of view. On the contrary, if the horse’s galloping in such a way effects a stronger emotional reaction in the viewer, that is the right way to represent it!

3. The Poetics: How to Understand Poetry ?
In these two published works, Aristotle’s primary goal was to offer instruction for becoming a sophisticated reader or spectator of poetic works. There is no reason why this general aim might have been different in the Poetics. This text has often been held, since its rediscovery in the Renaissance, as a manual for a would-be poet. And indeed, Aristotle’s tone is often very prescriptive: this “Treatise on the art of composing poetry” seems to lay down the rules that one must follow if one wants to write a successful play. But Aristotle also says, emphatically, that “the art of poetic composition belongs to a naturally gifted man” (17, 1455a32–33), and that making good metaphors, which is the prerogative of a good poet, is “something that cannot be learnt from someone else, but is the sign of natural talent” (22, 1459a4–6). It is thus unlikely that Aristotle had the ambition of training poets. Surely, what Aristotle proposes is to reconstruct what he takes the best set of composition rules, which in his view had helped, or would help, poets write good tragedies. But the exposition of these rules (which the poets may or may not be aware of: 8, 1451a23–24) is meant to show what good poetry should be like, such that his readers could appreciate the quality of a piece. And indeed, this is what the conclusion of the Poetics states:

This is all there is to say about tragedy versus epic … about the reasons why some are good and others not so good…. (26, 1462b16–18)

What the readers of the Poetics are offered are the reasons or causes why such and such feature of a play is to be considered good or poor. Armed with such knowledge, they should be better able to judge the quality of the tragedies they read or see in the theater.

As Aristotle posits, notably in the first book of the Metaphysics, searching for causes defines philosophical inquiry; knowing the cause of x allows you to understand what x consists in. And, crucially in Aristotle’s eyes, the final cause is what matters the most: when one knows the final cause of x, one can truly understand not only what x consists in, but should consist in if it is to be the x it is supposed to be. More precisely, the end of x amounts to the ergon, literally, the “work” or the “activity”, or what we more usually call the “function” that x performs; thus, for an eye, its aim or end amounts to its function, or “functioning” (or “working”, energeia) which is, of course, its seeing. Similarly, in the case of a hand: its function is grasping things, and when we talk of the hand of a dead body, we use the name “hand” only homonymously —a dead, non-functioning hand is no longer what it is to be a hand, or a “real” hand. And when an eye is seeing well, this is what Aristotle calls its entelecheia, that is when it performs its telos in a perfect (entelês) way. It is true that in the Poetics, we don’t find the typically Aristotelian technical words energeia and entelecheia. But presumably one may take the phrase “the best tragedy” (kallistê tragôgia) which is emphatically used in Poetics 13 as the equivalent, in common parlance, to a tragedy in entelecheia, that is a tragedy that performs its function, or its telos, in the best possible way. This phrase does not refer to any particular outstanding tragedy (say, Sophocles’ Oedipus-Rex, which Aristotle seems to like very much), or to an ideal tragedy that a poet should try to emulate, but rather to any tragedy that would or does indeed fulfill its function properly.

This very rough characterization of what the aim and the method of the Poetics consist in is in fact announced from its very first sentence:

This treatise is about how to compose poetry: what is poetry as such? What are the poetic genres? What power (dunamis) does each of them have? How should plots be constructed so as to end up with a successful work of poetry? How many components should there be, and what should these components be like? (1, 1447a8–11)

This gives us a clear plan of the Poetics, which divides into two parts: a first part is devoted to poetry “as such” (ch. 1–5), which can be considered as a kind of general introduction to what poetry is; and a second part, actually the bulk of it, is dedicated to its genres, that is, mainly tragedy and comedy, where the plot is treated as the main “component”. But perhaps most crucially, it also introduces the question of the “power” of each of the poetic genres. The word used is dunamis, which is here to be taken in the sense of “the ability to put something into movement”, that is, in our case, the power it exercises on the poetry’s recipient, or the “effect” it has on its consumer. It is, one may say, the “subjective” counterpart to the more “objective” side of the same thing, that is the function or work(ing) (the ergon or energeia) itself. So, the function of each genre of poetry, or its power or effect, is really what is of central importance in this inquiry. And (for reasons we are going to see), plot is seen by Aristotle as the best tool for implementing that effect. Now, it is not to be denied that a successful poet is the one who concentrates on plot when writing his plays. But this is not Aristotle’s main point of focus. His dominant agenda is to warn his readers right at the beginning of his treatise that they must focus on how the plot is constructed if they want to judge the extent to which such and such work of poetry succeeds, i.e., how well it performs its function.

Now, what concretely is the aim or the function of poetry? Homer has already told us very explicitly, notably in the famous episode of the Sirens (Odyssey 12. 39–54; 154–200), that the aim of his poetry is pleasure. Listening to the Sirens who are singing poetry, presumably Homer’s own Iliad (as they sing everything that took place under the walls of Troy), is something Odysseus, and actually every man, strongly desires, so strongly, as this episode amply illustrates, that he might even forget the very goal of his journey, namely the goal of returning home and being reunited with his family. Aristotle does not hesitate in mentioning that episode when, in the passage from the Eudemian Ethics already quoted, he describes what gazing at beautiful statues or listening to beautiful songs, or poetry, should amount to. In the Poetics, this is what he takes for granted: he assumes, as Homer does, that providing pleasure is the aim a poet must seek. A piece of poetry is successful when it provides pleasure to its consumers. But what precisely is this pleasure that poetry is meant to provide? How shall poetry accomplish that function? These are the questions that underlie the Poetics.

3.1 What is poetry as such?
Two major themes run through the first part of the Poetics on “poetry as such”: the naturalness of poetry and the division of poetry into serious and comic poetry.

The first sentence of Poetics 4 is famous for stating that two causes presided over the birth of poetry, and that those two causes are natural: the instinct that all men have for mimesis and the pleasure they take in the objects of mimesis (1448b4–5). A few lines further down, Aristotle adds to the instinct for mimesis, the instinct for melody and rhythm (1448b20–21). What he means exactly by these two causes is disputed. It might seem more natural to opt for mimetic instinct and pleasure, taking the musical instinct as part of the mimetic instinct (music also being a mimesis for Aristotle). But it should be noted on the one hand that this instinct for rhythm explains the versification (which in Greek is based on the rhythmic alternation of long and short syllables), which can hardly be qualified as mimesis. And on the other hand, that the pleasure is not only the one we take in the works resulting from the mimesis, but also in the mimesis itself. It seems that Aristotle apparently wants to speak not only about the two causes which preside over the poetic creation, but also about the causes which make for our attraction to poetic works, the two perspectives being intimately linked. Both poetic creation and our attraction to poetic works have as their causes our mimetic instinct and our musical instinct, as well as the pleasure that accompanies the expression of these two instincts. Here again, Aristotle has a totally different vision from Plato’s. Poets are not divinely inspired people: they are people who are naturally more gifted than most other humans (1448b22). And unlike Socrates who in the Republic seems to advocate a “natural city” which would not contain the mimetic arts, Aristotle takes them as part of human nature which a “natural” city must take into account. (One will remember the vivid response of Glaucon against Socrates’ proposal: “But this is a city for pigs!” [Rep. II 372d], meaning that such a city would be deprived of everything that makes for a properly human city. Aristotle would have applauded)

It is from this insistence on the naturalness of poetry and the centrality of pleasure that one should understand the division that Aristotle operates within poetry, between “laudative” and “serious” poetry, and “denigrating” and “funny” poetry, whose points of arrival are the genres of comedy and tragedy. At first sight, when Aristotle introduces the history of this division, he seems to rely on an ethical or social distinction:

Poetry branched into two, according to each poet’s character: the more serious-minded poets represented admirable actions, that is to say the actions carried out by that kind of person, whereas the more trivial poets depicted the actions of base people. (Poetics 4, 1448b24–26)

Presumably, Aristotle takes it that the first poems to date must have been what we call “lyric poetry”, with on the one hand the poetry of praise (such as those that Pindar would later write) and on the other hand satirical poems (predating those of Archilochus), and which are the latest ancestors of the tragic and comic plays. However, Aristotle himself qualifies such a presentation, adding that between those first lyrical poems and these two much later genres, stands Homer, who is the author of poems depicting admirable actions in his Iliad and Odyssey, and ridiculous ones in the Margites (a comic epic poem Aristotle takes to be Homeric). Insofar as Homer cannot be both below and above average, we must conclude that this distinction refers rather to what we would call “fictional” possibilities. A good poet is the one who, like a good actor, knows how to put himself in the shoes of his characters, whoever they may be (17, 1455a32–33), and Homer was particularly good at that (24, 1460a5–11). Moreover, there is no evidence that Aristotle held comedy as inferior to tragedy, nor is there any reason to believe that he held the spectators or readers of satires, the Margites or theater comedies to be “inferior” people. To say that “superior” or “inferior” people invented serious and comic poetry is in fact to say that they were particularly good at impersonating those types of characters. And the reason why the characters themselves must be represented either as “superior” or “inferior” is due to the aims of these poetic genres. In the case of tragedy, only “superior” characters can elicit our fear and pity: the more we admire someone, the more we pity him or her when they don’t merit their fate. Conversely, in comedy characters must be represented as “inferior” to elicit our mockery and laughter.

Aristotle supposes a temporal and essential filiation between these poetic genres: lyric poetry, both laudative and satiric (which, Aristotle oddly supposes, must have begun before Homer); serious and comic epic; and the genres of tragedy and comedy. The key moment is Homer. It is in Homer that “tragedy and comedy loomed out” (4, 1449a2–3), that is to say that poets saw in Homer’s poems the promises of comedy and tragedy; it is from there that they gave birth to these new genres and developed them (Aeschylus and Sophocles are named for being such developers). But above all, Aristotle adds that once these genres were discovered from Homer, all the poets abandoned lyric and epic poetry, and wrote in these two genres, “because these new genres had more prestige and value than the older ones” (1449a5–6). That is to say, the poets realized that by writing comedies or tragedies instead of epics, they could gain more prestige, and it is because of their value that people immediately became attached to these new genres. But why? Because these genres were entirely dramatic, and involved a fully enactive mimesis and used music (while epics were recited without music, at least in Aristotle’s time), they fully implement our natural instincts for both mimesis and music, and so they were more pleasant. If pleasure is the aim of poetry, it is only reasonable to focus on the most pleasurable genres, tragedy and comedy. (It is true that Aristotle goes back to epic after his treatment of tragedy, in Poetics 23–26, but it is essentially to help better understand tragedy, and to oppose other critics who took epics to be the most paradigmatic genre of poetry).

It is now time to ask ourselves what this pleasure of poetry might exactly amount to. In Poetics 4, Aristotle notoriously introduces the paradoxical example of an abject animal: while seeing such an animal provokes disgust and pain in the real world, seeing a picture of it produces pleasure. He explains why:

Seeing a likeness is pleasurable, because in contemplating it, people come to understand (manthanein) through inference, what each of its details are: for example, that the man there is so-and-so. (1448b15–17)

This sentence has often been taken as a commitment to what we might roughly label a cognitivist approach to aesthetic pleasure. The pleasure a work of art, be it a picture or a tragedy, affords would come from the understanding, or actually the “learning” (the verb manthanein can mean both), it allows; and the example of the man depicted in the picture would point to the idea that gazing at it, we could learn something new and fresh about that man.[4] (Some interpreters have even gone so far as to read the phrase “the man is so-and-so” as referring to his essence or a certain essential quality that the picture would allow us to grasp [Gallop 1990]). And since this is the pleasure that a mimesis generally speaking seems to afford, it is tempting to conclude that the pleasure that a tragedy or a comedy provides must be one species of such cognitive pleasure. But as others have replied (notably Lear 1988, and Ferrari 1999), such an interpretation is based on an over-reading of the text, especially if one fully takes into account what Aristotle immediately adds:

In case you never saw the man before, you will not derive any pleasure from his likeness qua representation. But you will get pleasure from the brilliant execution or the colours, or for some other such reason. (1448b17–19)

In other words, the “understanding” here barely amounts to the recognition of the man you already knew as so and so, like Socrates in the portrait of him in front of you.

To be sure, there may be cases where a more complex cognitive process takes place, such as in the case of a god which you recognize as being such and such, because you infer from, e.g., the statue having a thunderbolt in his hand, that it is intended to be Zeus. But in all such cases, there is no new learning involved. This reading of the text, however natural, may seem rather unappealing. But one should remember that here Aristotle is only giving a description of the general cause of our being attracted to mimesis: and indeed, were you not able to recognize what the object of the mimesis is, be it the voice of such and such a person, or the identity of the person depicted in this portrait, you wouldn’t be able to enjoy it qua mimesis. In tragedy and comedy, we do enjoy such pleasures as well; it is certainly pleasant to recognize the characters and their features when they intervene in the play, and that recognition is indeed a sine qua non of your following a plot, and enjoying the whole play; and the same goes, more basically, in cases where someone, in the real world or on stage, mimics the voice or the accent of a certain person: this affords you with the pleasure of recognizing who is meant. But all these pleasures are common to all sorts of mimesis. This is perhaps the most important point. As we have seen from the very first sentence of the Poetics, what Aristotle is interested in is inquiring into each of the poetic genres, and the power each has. And indeed, what Aristotle repeatedly emphasizes throughout the Poetics is that the poet must seek to produce the pleasure that is proper to such or such poetic genre: “one should not seek any kind of pleasure from tragedy but only the appropriate kind” (14, 1453b10–11). As for tragedy, Aristotle leaves no doubt: “What the tragic poet must produce is the pleasure derived from pity and fear through mimesis” (1453b11–13). Since book 2 is lost, we no longer have the formulation that Aristotle must have made in the case of comedy, but it is fairly obvious that he would have mentioned the pleasure associated with the amusement provoked by the comic plot’s jokes and gags. We do have something of an echo of such a statement in Poetics 13, which mentions the “pleasure proper to comedy”, and gives the example of a comedy where Orestes would make friends with Aegisthes instead of killing him: this parodic treatment of the tragic end of Sophocles’ or Euripides’ corresponding play, Electra, is what creates our amusement, that is our comic pleasure (1453a35–39).

Thus, the pleasure that is the aim of tragedy is an emotional pleasure, and the same goes for comedy. In the latter case, amusement (of which laughter is the physical expression) is certainly not an emotion strictly speaking, but is rather the experience of a state of mind, which, like an emotion, is an affect or what early modern philosophers will call a “passion”. (Here we may note that in the quoted passage from the Eudemian Ethics, Aristotle does not shy away from using the word paschein, i.e., undergoing a pathos, to describe the experience of gazing at a beautiful thing or listening to a fine tune.) As Plato had said, when we watch tragic heroes suffering on stage,

we take pleasure and, surrendering ourselves, we follow and share the hero’s sufferings and earnestly praise as a good poet whoever most affects us in this way; (Rep. X 605d)

and the same goes for comedy, which offers the opportunity of “taking great pleasure” (606c) in letting us “give in violent laughter”, and even “be overcome by laughter” (III 388e-89a). To be sure, for Plato, this is a surrender to the irrational part of our soul, which may have some deleterious consequences. Aristotle does not seem to be worried by that, at least not in the case of adults. In one passage of the Politics, he warns that letting children go to the theater and watch comedies where people insult one another or make obscene jokes can be damaging, and he does not hesitate to prohibit them from going to the theater. But once “their education has rendered them immune to the harm such things can do” (VII 17.1336b22–23), there is no reason why adults should be prohibited, or even discouraged, from enjoying comic theater. In fact, a similar point can be made in the case of tragic poetry as well: if in the theater (or in an epic recital), we do take pleasure when, as Plato vividly depicts it,

we hear Homer or any other tragic poet representing one of the heroes in a state of grief and making a long speech of lamentation or even chanting and beating his breast, (Rep. X 605c-d)

it would be a shameful thing to do so in the real world (where men at least were not allowed to express their grief aloud). Aristotle seems to take it as evident that the world of the theater is a fictive world that obeys other rules than the real world, and provided we have received a good ethical education, certain “politically incorrect” features, such as laughing at incongruous insults or “sharing the hero’s sufferings” and his “state of grief” in a boisterous manner should not cause any harm. Quite to the contrary, Aristotle seems to take tragic emotions and amusement as typical human propensities, which give us lots of pleasures when they are experienced in the theater.

3.2. Tragedy
The best tragedy, as we have seen, is the one that can best produce the power typical of a tragedy, i.e., producing pity and fear, and therefore can best achieve its function or aim, which is the pleasure that comes from the experience of these emotions. What Aristotle proposes in his analysis of tragedy is highlighting the means by which the poet can implement this function, which in turn should provide theater goers with the right understanding they need to have in order to be able to judge the quality of such and such a play they may attend, or read. As Aristotle announced right at the beginning, the plot is to be considered the most important means and indeed it is given the most expansive treatment, while the other “elements” of the tragedy, such as the depiction of the characters and their expression (or what we more commonly call the style, in which their dialogues are written), come next. This focus imposes itself from the perspective of the aim or function of poetry. A tragedy typically depicts the change of fortune which includes reversal of circumstances and sufferings, and rightly so: this is of course how fear and pity for the main heroes can be produced. Thus, the actions of the heroes that lead to such an outcome must be what a tragedy should mainly depict, or represent, as well as other features that are part and parcel of that outcome. The way plots are constructed or assembled from the various deeds and words of the characters (or what Aristotle calls the “events”, pragmata) should be what constitutes “the aim” of the poet (Poetics 6, 1450a22–23). This is the aim a poet must seek if he wants to end up with a tragedy that can fulfill its aim or function properly.

If a poet were to string together tirades describing characters, however perfectly composed in terms of expression and reasoning they might be, he will not be able to achieve what we have said is the function of tragedy: (1450a29–31)

presumably he might well provide a certain pleasure to his public (if only for the beauty of his style), but he would not obtain the proper aim or function of tragedy.

There are two series of requirements for a plot to be a good plot. One series involves the qualities of the plots, which includes totality, unity and generality (or: universality); the second one involves the turning points of the plot, which include the reversal of circumstances, the recognition, and the sufferings. But both series are based on what a proper consumption of tragedy requires: the first series is about our being involved in a plot; the second series, about what creates the emotions of pity and fear. Producing the pleasure that comes from the emotions of pity and fear is the aim of tragedy, but in order to achieve this, the poet must create a plot the hearers can immerse themselves in; as we would say, a theater audience must “believe” in the story that is unfolding and in the characters who make up the story. Otherwise, they would just lose attention and interest, which would prevent any strong emotional involvement. One such requirement is that of “the fitting size”. In the case of gazing at a beautiful animal, whether in reality or in a picture, our admirative enjoyment cannot hold if the animal or the picture is so big that it cannot be grasped in one glimpse, or if it is too minute to be seen at our ease. The case of a tragic plot is similar: a proper size is needed to make the whole play “easy to remember” (6, 1450b34–51a6). One must be able to remember the important features and events the full time we watch it, which is a sine qua non condition for our being unflaggingly attentive and attracted to the plot.

Another such sine qua non requirement is what one may call the “law of likelihood”, or “plausibility”. Aristotle strongly insists on this: all events must offer the appearance of causality, and follow not one after the other, but from each other (10, 1452a20–21). Faced with an event that is totally unexpected in being disconnected from any normal causal sequence would just be incredible, and, in worst cases, hearers would laugh instead of feeling pity or fear. Of course, unexpectedness can be an efficient tool for evoking strong reactions. For example,

when the statue of Mitys in Argos killed the person responsible for the death of Mitys himself by falling on him as he was staring at it, (9, 1452a7–9)

it must have created a big surprise, and putting such an event into a plot might be very powerful. But even if the event happened by pure coincidence, the poet must suppose that his audience will, even if subconsciously, admit a certain divine vengeful intention behind the event, so it appears to them as having a certain plausible cause. The poet has full license for inventing whatever events he wants, but they must appear “plausible” in one way or another. Or as Aristotle summarizes,

the function of the poet is not to speak of what has happened but of things such as they might happen, that is to say, to tell us of possible outcomes in all likelihood or out of necessity. (1451a36–38)

The weight is not so much on the fictionality of events, since the poet can also draw his material from events that actually occurred, but in the way he presents them: whether they actually happened or not, and whether they are physically possible, he must describe them in the way we would think they might happen. It is to be noted that “in all likelihood or out of necessity” is a rephrasing of the well-known “for the most part or out of necessity” motto in the Physics, where “for the most part” describes what actually happens to physical things which obey causal necessity, barring a few exceptions. In the case of poetry, or any other mimetic genre, the only causality we need is “subjective” causality, or plausibility. Aristotle even goes so far as to say: “What is impossible but plausible must be preferred to what is possible but not credible” (24, 1460a27): an event that has taken place, and so is physically possible, but which would not be presented in a plausible way would not succeed in gripping hearers.

It is in this context that Aristotle makes a comparison with history: while history must report hard facts as they actually happened, poetry must tell them as they might happen according to the law of plausibility. It is in this context where we find one of the most famous, and famously contentious, sentences of the Poetics:

This is the very reason why writing poetry is more philosophical and more worthy than writing history. For poetry tends towards a general picture (katholou), whereas history tells us of particular case studies. (9, 1451b5–7)

It is very tempting to interpret this as if Aristotle were proposing that poetry dealt with “universals” in the usual sense of the term, and thus conveyed “universal truths”. Many philosopher readers have assigned Aristotle a grandiose view of poetry, while historians have blamed him for undermining the importance of history. Both are probably overreactions. Aristotle does not say that history is not philosophical, but that poetry is “more philosophical” than history. Since philosophy is the search for causal understanding, we may suppose that “philosophical” means, in effect: “that which sees things under the perspective of causality”. Of course, history, as Herodotus claims in the very first sentence of his Histories, is also a search for the causes of the events he reports; but his main focus must be to report and explain those events as they actually happened, for example “what Alcibiades did or what happened to him” (1451b11). What the poet does is to take whatever event he may want to introduce into his plot and turn it into a plausible one—even the most factually impossible events!

For nothing prevents what really happened to be turned into things such as they might happen in all likelihood or be possible—it is this which makes him the poet of these. (1451b30–32)

This makes poetry, in the active sense of the term “making poetry” (the word poiêsis allows for both meanings), a “more philosophical” craft. And this involves “universals” in a non-technical sense, as Aristotle explains:

A general picture is this: the kind of thing a certain type of person would say or do in all likelihood or out of necessity. (1451b8–9)

“General”, or “universal”, does not describe here a specific item, but the way how one may expect someone will say or do things given the person she is. And that goes not only for tragedy, but also for comedy where (contrary to most tragedies which draw their plot from well known myths) particular names of the characters are up to the poet’s choice and added after the plot is written (1451b11–14): thus, here too, the crucial thing is to create a plausible plot where all the deeds and words done or uttered by the play’s characters seem to be causally related; this is what makes them plausible to an audience.

The second type of requirement involves the content of the plot. Generally speaking, a plot is constituted by all the events making up, as we say, the “dramatic action”. But what counts primarily among such events are three features. First, the reversal of circumstances which “is a volte-face change in the sequence of events” (11, 1452a22–23). This must happen “in all likelihood or out of necessity” as Aristotle insists, otherwise they would not achieve their aim, which is to provoke strong emotional reactions in the public. Emotional reaction is also created by recognitions: after, or just before, something important happens to a character, he or she is recognized as having such and such relation towards his or her protagonist (1452a36–b3). And, last but not least: audience members respond to sufferings (pathê), or rather what Aristotle determines as “an action conducive either to death or great pain” (1452b11–12), thus an act of violence that causes great suffering. This action is best conducted when it involves kin: it is much more powerful, emotionally speaking, to watch a scene in which, e.g., a mother is going to kill her son, or a daughter her father (14, 1453b19–22). In such tragic scenes, involving unexpected yet plausible changes of fortune, startling recognitions, and acts of violence, managing them in the right way is absolutely key if one wants to elicit the tragic emotions. These are pity and fear, which are the two moments, or aspects, of the same emotional experience, where fear concerns primarily the moment when a character is about to commit the irreparable towards his kin, while pity comes about at the sufferings and deep misfortunes of the involved parties.

If plot is at tragedy’s core, that is not to say that the play’s other features are of no importance. That is especially the case for how the characters are depicted, and how they speak. Both are a significant factor in rendering a plot successful. In a word, characters must be credible: when we see a character doing or saying such and such, we must believe in them. Characters must be normally virtuous, for otherwise we couldn’t admire them, and pity requires that we think that their misfortune is unmerited. Conversely, a woman shouldn’t be presented as talking like a philosopher (such as Menalippe in one of Euripides’ play), because no ancient Greek spectator would ever expect to see a woman speaking like a male philosopher (15, 1454a16–32). Building characters that correspond to an audience’s expectations is key if one wants to immerse them in a tragic play. As to the “expression”, or the style, characters must speak in a relatively clear and common way, so the spectators can easily follow the plot. But figures of style such as rare words or metaphors must be added at the right times, especially when what a character says may add to the scene’s emotional impact. Aristotle compares two ways of saying the same thing:

In his Philoctetes, Aeschylus had written: “The ulcer which eats the sole of my foot”, whereas Euripides replaced “eats” by “feasts on” (thoinaô). (22, 1458b19–24)

The rare, poetic verb that Euripides used produces an unusual impression, and for that very fact strikes the spectators, which is of course a means of still further increasing the pity they feel for this character whose foot is affected by a painful gangrene.

By reconstructing how tragedies can best implement their function, Aristotle intended to help his readers to become better judges and appreciators of the tragedies they could read or attend in the theater. But for any modern reader, there remain two perplexing questions. Whereas pity and fear are normally painful emotions, how are we to conceive of them as pleasurable? And what about the most enigmatic word of the Poetics, katharsis, which also seems to be presented as the aim of tragedy?

Since the Renaissance, the theme of katharsis, which appears in the definition of tragedy (tragedy is “a mimesis of a momentous action”, which “by stirring up pity and fear, brings about a katharsis of such emotions”—6,1449b25–28), has been the subject of endless debates, as Aristotle himself never explains himself about it. The interpretive conundrum is basically this. Normally, the word itself refers to the action of rendering something “pure” (katharos), with all the possible senses or connotations of “pure”: purification in a religious context (such as Orestes who undergoes a katharsis when digging in the sea to be “purified” of the murder of his mother, which Aristotle refers to at Poetics 17, 1455b15), purgation in a medical context, or cleaning in the case of an object that is dirty. It might mean either in principle, but we might expect the word to get its meaning from its context of use. But what is the context supposed to be in the case of tragedy? Aristotle does not tell us. In Politics VIII, he briefly mentions a kind of music, the so-called “enthusiastic music”, which provides a medical cure that consists in a katharsis for those who are especially prone to “enthusiasm” (or what we would call “frenzy”, or “agitation”). And then he adds:

The same thing, then, must be experienced by those who are especially prone to pity and fear and in general by those who are suffering from their emotions (pathetikoi) on the one hand, and by any other person to the extant as she shares in those emotions on the other hand: they all undergo a certain katharsis and get a pleasant feeling of relief. (Pol. VIII 7, 1342a11–15)

At least for the pathetikoi, the context seems to be medical. But is it the case for “each other person to the extent that she shares in those emotions”, i.e., notably the spectators of tragedy? When Aristotle refers to “a certain katharsis” (tina katharsin), he may mean either that all these people, the pathetikoi as well as anyone else, undergo the same sort of medical katharsis, or that they each undergo a different sort of katharsis.

The best known scholar forcefully endorsing the first interpretation remains Jakob Bernays (whose nephew by marriage, Freud, adapted the views to psychoanalysis): Aristotle, a doctor’s son, would have defended tragedy against Plato’s rejection by conceiving of it as sort of beneficial cure for all theater spectators (Bernays 1858). That interpretation (which has known several refinements, especially in German scholarship; collected in Luserke 1991) has been fiercely criticised for reducing tragedy to being a medical cure. Whereas Bernays was actually reacting against the strong ethical views of the German writer and philosopher Lessing, many contemporary scholars have proposed coming back to such views. According to one reading, defended by Richard Janko, the tragic katharsis should be conceived of as the purgation of the excessive emotions so as to obtain the right measure of pity and fear, which nicely matches Aristotle’s conception of virtue (see especially Janko 1992). But Aristotle seems adamant in the text of Politics VIII that music for katharsis is to be differentiated from music for moral education (7, 1341a21–24; 1341b38). And in the Poetics, Aristotle takes it as evident that emotions must be strongly experienced; aiming at the right, moderated measure of pity would actually spoil the typical pleasure that a good tragedy provides! Others, notably Martha Nussbaum, have suggested that in the case of people who go to the theater to enjoy the emotions of fear and pity, katharsis might mean “clarification” (i.e., the removal of obscurities; in his logical works, Aristotle does use the adverb katharôs in the sense of “clearly”); the tragic theater would then aim at providing spectators with a clarification of the pitiful, indeed tragic, human condition.[5] As philosophically engaging as that reading may be, there is no textual proof that Aristotle would have adopted such a grandiose view; and contrary to Nussbaum’s own views on ethics, where pity is considered a central ethical emotion, pity only plays a very marginal role in Aristotle’s ethics. Yet another kind of reading, relying on the idea that pity presupposes that the object must primarily be the spectator him- or herself, has insisted on the relief that such an emotional releasing might offer, consisting in a “consolation”: as Jonathan Lear states,

In tragedy, we are able to put ourselves imaginatively in a position in which there is nothing further to fear. There is consolation in realizing that one has experienced the worst, there is nothing further to fear, and yet the world remains a rational, meaningful place in which a person can conduct himself with dignity. (1988: 326; A reading of a similar kind has been offered by Munteanu 2012: 131–136)

Again, this is a fascinating approach of the ultimate meaning of tragedy, but it does not seem that Aristotle himself ever expressed such an idea of “consolation”.

It seems, therefore, that a much more minimalist reading might better suit Aristotle’s texts. One such reading, advocated by John Ferrari, is to take the word katharsis as a way to describe the process of relieving the tension created by the stimulation of the tragic emotions (Ferrari 1999, 2019). The great advantage of this interpretation is that it does not presuppose anything beyond the context of the Poetics, and it does not seem to contradict any other explicit statement of Aristotle’s; but one may wonder if it really explains the phrase, the “katharsis of such emotions”, where the idea of “tension”, or “suspense”, does not seem to be present. Another such reading might look like the following. In his biological works, Aristotle regularly uses the word katharsis to refer to the menstrual blood or bleeding as well as to the male ejaculation: in those cases, katharsis means the flowing itself (or by metonymy, the blood); and the fluid is nothing deleterious (interestingly enough, against Hippocratic views, Aristotle does not take menstrual blood to be “impure”). He holds rather only that keeping such fluid inside the body without discharge can be unhealthy, and so a discharge is needed from time to time. As Aristotle knew very well, ancient theater audiences showed their emotional reactions in a very physical way by screaming and weeping loudly. So, the katharsis of the emotions of pity and fear could be meant to name that sort of physical expression or outlet of such emotions. This last reading might perhaps not appear worthy of Aristotle’s philosophical genius. But it would fit the aim Aristotle has himself proposed: to explain how a tragedy accomplishes its function, which is to produce the emotions of pity and fear, and the pleasure accompanying them. Saying that a tragedy is a mimesis which “by stirring up pity and fear, brings about a katharsis of such emotions” might simply mean that tragedy should indeed aim to allowing spectators to express and unleash their emotions in the theater.[6]

The second perplexing question involves what modern aestheticians call the “paradoxical pleasure of negative emotions”. How is it that we can enjoy emotions such as pity and fear that are normally painful? It is quite often assumed that katharsis can do just that, transform the pain of those emotions into pleasure, through the feeling of relief that accompanies it. But it would be very counter-intuitive to reduce the pleasure any audience gets from a play to just that pleasure, which follows or is the consequence of a katharsis. For one would then have to suppose that a theater audience would suffer all through the play to finally undergo a katharsis, and get their pleasure at the play’s end, on leaving the theater! As Aristotle surely noticed himself, an audience that has felt great fear for heroes on the verge of grave suffering and has wept and cried during a two hour show, will normally leave the theater with a physical sense of relief. But when he says that the poet must “produce the pleasure from pity and fear through mimesis (dia mimêseôs)”, Aristotle probably wanted to allude to the fact that mimesis is what makes those emotions a source of pleasure. How are we understand this more precisely? Relying on Kendall Walton’s theory of “make-believe”, one might be tempted to take mimesis here as what would allow spectators to pretend to have those emotions. But nothing indicates that Aristotle would have shared such a conception; on the contrary, describing what even the simple reading of such a powerful plot as Sophocles’ Oedipus-Rex would produce, he speaks of shuddering or getting goosebumps (phrittein), which seems to indicate that we actually experience strong emotional reaction (14, 1453b3–6). (And the same would hold for pity which produces tears). Thus, insofar as we immerse ourselves in a tragic plot and “believe” in its characters, it is probably in some way a painful emotional experience. But we also know that a story experienced in this way takes place in an imaginative world, where there is no real object to be feared. Thus mimesis, one might say, allows us to experience fear for itself (and as Aristotle says in a passage from De Anima, imagining fearful objects is “up to us”, while seeing them in the real world is not: 427b14–21), which is pleasurable. This is not to say, though, that this would annihilate the painfulness of the experience. As Plato explicitly said (and there is no reason to think Aristotle would have disapproved), this is precisely what makes tragic pleasures so paradoxically attractive: they are a kind of mixture of pain and pleasure (Philebus 48a).[7]

3.3 Comedy
Many if not most scholars seem to consider tragedy to be the best possible kind of poetry in Aristotle’s eyes. But Aristotle never suggests that; on the contrary, he insists that tragedy and comedy, each constituting a fully enactive mimesis, are the most perfect genres of poetry, each one corresponding to our natural inclinations for tears and laughter. Whereas the tragic poet must produce strong emotions in order to enjoy a tragic play, the comic poet must produce amusement, which finds its physical expression in laughter. (Also, as a few lines from the neo-platonists Iamblichus and Proclus forcefully suggest, it might well be the case that Aristotle thought there was a katharsis in comedy as well, which would perfectly fit the last proposed interpretation: a comic katharsis would just amount to the expression or the outlet of laughter.)[8]

In chapter 5 of our Poetics, Aristotle presents comedy with these terse words:

Comedy, as we have already said, is the representation of men of lesser value, but not in a sense that would imply all defects: ridicule is only a part of what is shameful. What makes people laugh is indeed a form of error or physical ugliness which does not cause suffering or death, as is immediately seen from a comedy mask: it is something ugly and deformed, but which does not express any suffering. (1449a32–37)

Scholars have often drawn on the idea that aggressiveness or, as Bergson would say, “malice”, would be at the heart of comedy as Aristotle sees it. And indeed, this is already what Plato defends in a famous passage of the Philebus (47d-50b): it would be phthonos (an emotion that is often translated as “malice” or “ill will”, but that designates above all “envy”) that would be the hidden cause of our laughter (Imagine your neighbor, whose new Ferrari you envy, inadvertently crashing it into his garage door: the strength of your laughter would be proportional to your envy!).[9]

But let us return to the example of the comedy he mentions in Poetics 13, where spectators see Orestes ending up being reconciled with Aegisthes. What makes them laugh at that ending? Undoubtedly, the ancient spectators must have felt a sense of indignation: not avenging one’s father by killing his murderer is a moral fault. But it cannot be indignation that causes them to laugh (if anything, indignation provokes anger, not amusement). What makes them laugh, rather, is the complete oddity of such a reconciliation, its sheer incongruity. So more generally, one may suppose, what makes one laugh is the incongruity of the blunders of the characters on stage, perhaps coupled with their ugliness (which is moreover accentuated by the mask the actors wear). That these characters must be “inferior” is a psychological requirement that is the opposite of that of tragedy: if we can only feel fear and pity towards a hero who does not deserve his fate, we readily laugh at a man full of himself who slips on a banana peel. Similarly, Aristotle’s insists that a character’s blunders must not cause him to suffer, and that therefore a comedy cannot end with the characters’ misfortune or death. That would not be funny: a comedy in which the arrogant character killed himself on a banana peel would end our amusement (provided we are average, morally good people). And this also implies that our negative feelings towards such characters, made up of a certain contempt and perhaps a feeling of superiority (as Hobbes would say), is really just a kind of game: we do not feel any real animosity or condescension towards comedy characters. If we really felt indignation when attending that comedy of Orestes, we would not be able to laugh.

In the third book of the Rhetoric, dedicated to the figures of speech, Aristotle recalls that in his Poetics, presumably in its second book on comedy, he spoke of different “types of jokes” (III 18, 1419b6–7). There is perhaps a difference of emphasis on this point between comedy and tragedy. If a comedy must also have a good plot, having good jokes is essential:

It is especially in regard to these [funny comparisons] that poets fail with the public if they do not make them well, and if they do make them well, that they are popular. (11, 1413a10–11)

It is impossible to reconstruct what exactly those “types of jokes” would have been. But in his treatment there of the figures of speech, Aristotle evokes those that the comic poet uses. The central idea that emerges is that of incongruity. Aristotle argues that a serious speech that wants to persuade its listeners must use a “suitable”, or “appropriate” style, where the words chosen are “in proportion” (to analogon) to the things they signify. If there is disproportion, or what we call “incongruity”, that speech’s style will be “like that of comedy”. And to exemplify what he seriously states, Aristotle makes a joke at the expenses of a tragedy writer, a certain Cleophon, whose style was (at least in Aristotle’s eyes) rather like a comedy writer’s: “Some of his expressions were like saying: august fig tree” (III 7, 1408a10–16). This expression is funny (and not at all appropriate to the tragic style), because there is a total incongruity between this adjective which is normally reserved for a goddess or a queen, and that tree which, in ancient Greece, was considered of little value.

In the case of tragedy, Aristotle’s aim is to reconstruct for his readers what the art of poetic composition should be, in order to enable them to distinguish a good tragedy from a bad one and to explain why. There is no reason to think that this should not also have been his goal in writing on comedy. We have no direct echo of this in our Poetics, but a passage from the Nicomachean Ethics provides a clue worth following. It comes from the chapter devoted to the virtue of “sense of humor” (eutrapelia), which consists in being able to make good jokes among friends as well as in being able to take mockery against oneself with good grace. It is in this context that we read this statement:

The amusement of the free man is very different from that of the slave, that of the educated man from that of an uneducated man. This can be seen also in the ancient and recent comedies: in the former, what makes one laugh is obscene language, in the latter, it is rather the innuendos (huponoia), and this difference is not small in view of elegance (euschêmosunê). (IV 8, 1128a20–25)

To be sure, this is an analogy that is intended to make clear what kind of jokes decent citizens should make or hear in the real world. But this analogy also reveals the normative judgment that Aristotle suggests when it comes to theater: good comedy, that which is intended for educated audiences, should use innuendo and allusion, not obscene language. This is not an ethical normativity, but a normativity intrinsic to the art of making people laugh. Jokes that use crude and obscene language are what might be called “easy jokes”, which require no originality and inventiveness on the part of the jokester. On the contrary, good jokes must be “refined”, or “elegant”, which show a good, truly incongruous and sophisticated use of the figures of speech.[10]

4. Music and the Value of Art
What is the value of poetry, or art more generally? Neither in the Poetics nor in the published works on poetry does Aristotle seem to be bothered by that question. But since this is yet another perplexing question for us, many scholars have been tempted to supply an ethical answer. Interpreting the katharsis clause in this way has been one major way of satisfying the urge to answer this question. But even without relying on that admittedly controversial phrase, other ethically tinged answers have been offered. For example, why can’t we read tragedies as providing us an attractive way to develop a typically “emotional understanding” of important ethical features, such as the importance of being moved by other people’s misfortunes (Halliwell 1986, 2002)? Or, more specifically, shouldn’t tragedies allow for imagining ethical situations that would help spectators illuminate issues linked to their use of practical wisdom (Frede 1992; Belfiore 1992; Donini 2004)?[11] There is certainly much to say in favor of such readings, especially if one focuses on, say, Antigone or Philoctetes. But when Aristotle mentions these plays, he does not at all give the impression that he takes them to be paradigmatic of the genre (In the Poetics, he mentions the former in the framework of a critique of the quite untragic way Sophocles has depicted Haemon, who did not dare to kill his father Creon: 14, 1454a1–2; as to the latter, one verse of Euripides’ lost play is quoted for the appropriate use of a rare verb: Poetics 22, 1458b22–24). Instead, the two plays that he seems to take as paradigmatic (and to which he refers the most) are Sophocles’ Oedipus-Rex and Euripides’ Iphigenia in Tauris. Certainly, Oedipus-Rex can easily be read as providing a kind of insight into the deep miseries a human being can be subjected to; but one may fairly doubt that it might really help people in their use of practical wisdom. As to Iphigenia in Tauris, it would require a tremendous battery of arguments to persuade modern readers that they should read it in a either such way—and it is no surprise that no scholar has attempted to do so!

More generally, there are at least two main rebuttals to be made against such ethical readings of the Poetics (and presumably Aristotle’s aesthetics in general).[12] First, what then about comedy? When he mentions a possible positive use of comedy, Plato proposes that virtuous citizens watch them for a better grasp of what vices look like: “We must learn to recognizes buffoonery in order to avoid doing or saying anything ridiculous out of ignorance” (Laws VII 816e). It is telling that Aristotle never mentions such an odd suggestion: how can we possibly learn about vice while we are enjoying the jokes and gaffes that pepper comedic plots? A second reply comes from what Aristotle says about music in Politics VIII. There, he begins by repeating faithfully what Plato had proposed: since music can represent virtues like courage, children must learn to play it and it is through enjoying singing and playing such music that they will subconsciously come to enjoy those virtues. But then, in a second instance, Aristotle vigorously, if implicitly, opposes Plato. In the Laws, Plato very much insists that adult citizens of Magnesia must continue singing and dancing in order to bolster their virtues (II 664d). Aristotle is no less insistent that once adults, the citizens of his ideal city stop singing and playing music and instead hire professional musicians and enjoy listening to them during their “free time” (VIII 6, 1340b35–39).

“Free time” or “leisure” (scholê) is a key concept (on this, see Too 1998; Heath 2014; and Ferrari 2019). It does not mean the pause or the rest one takes from work; it is a time, or a mode of life, where activities are enjoyed for themselves. In the Nicomachean Ethics, it is at the core of the argument for the primacy of theoretical activity: while contemplation is typically a leisured activity, political activities constitute the non-leisured life, one which is meant to achieve practical goals (X 8, 1177b4–24). And in Politics VII-VIII, when defending his own proposal as how organize a perfect city, Aristotle goes as far as saying: “To be able to enjoy leisure rightly is the principle of everything” (VIII 3, 1337b31–32). In the case of music, Aristotle makes it clear that if music can be listened to for the practical purpose of relaxation (a little bit like our ambient music), or fostering virtue (as children must do), music can also be listened to for its own sake, just for the sake of enjoying it. Here Aristotle seems to be repeating what he says in the passage of the Eudemian Ethics already quoted, but he adds something we do not find there: music “for the sake of leisure” is characterized as a music “for the sake of intelligence (phronêsis)” (VIII 5, 1339a14–26).

Unfortunately, Aristotle does not spell out what exactly he means by that, and the phrase has been variously interpreted. Again, some scholars have proposed an ethical reading: the intelligence involved would amount to the practical intelligence, or wisdom (which is typically called phronêsis), that is required in any moral action. Thus, by listening to music that depicts, or “represents”, say, courage, one may better understand what courage is. Despite its seeming natural, this reading contradicts what Aristotle repeats in those same pages: moral, or political, action is fundamentally a non-leisured activity (ascholia). It would be odd then if Aristotle were recommending such a leisured use of music while aiming to describe how to manage non-leisured moral life! Another theme that is also repeated in those pages should give us a better clue: the final aim of learning how to sing and play an instrument is to help these future citizens become “good judges” of music (VIII 6, 1340b35–39). In the Laws, Plato also used that phrase, and meant by it that adult citizens should be able to recognize morally good from morally bad songs, and thus enable them to decide which songs must be sung in Magnesia (II 669a-670c). There is no reason to believe Aristotle would have endorsed such a strong ethical-cum-political agenda. Instead, it is very likely that by “judging”, Aristotle just means that by having the first-hand experience of playing music, citizens will be able to judge and appreciate the good quality of music. And, as all musical connoisseurs know, such an appreciation is both perceptual (as we do enjoy listening to sounds and rhythm) and also somehow intellectual: a connoisseur, that is, equally enjoys how well or inventively a piece of music is constructed.[13]

Admittedly, all of this is absent from the Poetics, where the word “leisure” does not even appear. But when in the Politics, he presents his conception of a music that should be listened to and appreciated for its own sake, it is surprising that Aristotle gives as justification the example of Homer, and cites several verses from the Odyssey: besides music for relaxation and moral education, there is

music for a life spent in leisure, which is the very reason why people bring it in. They give it a place among the leisure time that they think befits free people. That is why Homer wrote these verses: […] “They invite the bard who charms them all”. And elsewhere, Odysseus says that the best way to spend one’s life is in view when men are rejoicing: “the guests sit in a row in the room to listen to the bard”. (VIII 3, 1338a21–30)

Of course, Aristotle must have been aware that the bard is the one who sings poetry, whether lyric or epic, with the accompaniment of the lyre. This argument therefore implies that it is actually the listening and appreciation of performed poetry that must constitute such a leisured activity. And since in the Poetics, tragedy and comedy are presented as poetic forms that are more valuable than epic or lyric poetry, Aristotle must also have considered attending tragic and comic plays as part of these leisured activities, or more generally of what he calls in that passage of the Politics, a “free life”, that is a life of free citizens (not of slaves), but also a life that in which time is spent enjoying music or poetry for their own sake.

In the case of music, Aristotle strongly recommends that children learn how to play an instrument (actually, the lyre) so that once adults they will be able to fully enjoy beautiful songs since they will have become able to “judge the beautiful songs” and therefore “enjoy them for themselves” (Pol. VIII 6, 1340b38–39). This is also the case for visual arts: children, Aristotle proposes, should learn how to draw images in order to be able “to contemplate the beauty of bodies” (1338a40–b2). In both cases, their pleasure can be taken along the lines in which Aristotle defines pleasure in his Nicomachean Ethics: it is the unimpeded activity, or “activation”, of their natural capacity, or faculty, of hearing and seeing respectively. But Aristotle importantly adds: “when it comes to the best possible object” to be heard or seen (NE 10.4, 1174b14–23). We therefore need to learn how to judge how good the objects of our listening or seeing are. And once we have learned this, we can fully enjoy pieces of music and paintings or sculptures that we know are those that best suit our respective faculties.

Aristotle never makes such a suggestion in the case of poetry; and indeed, if one holds that poetry is a matter of exceptional natural gift, as Aristotle does, it would be odd to propose that every child should practice composing poetry. One might then perhaps take his writings on poetry offered as a sort of late education on such artworks. Through their reading of either the Poetics (if they get the chance of enrolling in the Lyceum) or Aristotle’s published works, people can become such connoisseurs of poetry, and enjoy it fully too.

It is often claimed that the ancients did not value artworks in the ways we moderns do. Ancient Greek theater, which includes poetry, scene painting and music, the argument goes, is only one moment of religious festivals where a whole city came to unite in shared activities and values. And despite all his critiques of the theater, for which he coined the despising word “theatrocracy” (Laws III 701a), Plato nevertheless emphasized that the right sorts of poetry and music should play a crucial role in the moral education of youth. But Aristotle seems very much unconcerned about the religious and political context of theater performances; and it is telling that he doesn’t say anything worth noticing about the role of the gods in the tragedies. (Actually, these elements are even a matter of reproach that classicists often make against him![14]) And he vividly opposes a complete subjection of art to any other useful objective: “To search everywhere for what is useful is totally inappropriate for those who are great in soul and free” (Pol. VIII 3, 1338b2–4). In other words, if indeed it may be useful to listen to some sorts of music for educational or therapeutic purposes, music can, and should, also be enjoyed for itself, and the same goes for painting and poetry. To be sure, by themselves, the objects of mimesis may not be worthy. But even the lowest animals, as Aristotle states in the preface of his Parts of Animals, do offer “extraordinary pleasures to those who are able to know their causes and are naturally gifted for philosophical understanding” (I 5, 645a9–10). In the case of animals and plants, we admire the way “artistic nature” (dêmiourgêsasa phusis) has built them. In the case of artworks,

we enjoy gazing at likenesses of animals because we are at the same time contemplating how artistic craft (dêmiourgêsasa technê), whether painting or sculpture, has produced them; (645a11–12)

that is, when we are connoisseurs of art. True, as Aristotle also says in that preface, divine beings such as celestial bodies and unmoved gods are much more worthy objects to contemplate (mostly because they are eternal). And indeed, as he repeats in his Nicomachean Ethics and Politics, philosophical contemplation, which culminates in exercising our intellect towards such divine objects, is the highest activity one can attain. But such philosophical contemplation, whether it comes to these divine entities or to the causes of the animals and plants, is deemed to remain for the “naturally gifted for philosophical understanding” which are few, as Aristotle seems to admit with regret. By contrast, provided one gets the right artistic education leading to connoisseurship, contemplating art can be part and parcel of everyone’s happiness (or typically human flourishing: eudaimonia).

1. Inner Speech as Actual Speech
The auditory-sensory character of inner speech is usually thought to be due to its involvement of auditory-verbal imagery (for an exception, see O’Brien 2013). Mental images (in any modality) are generally viewed as representations of particular things (or kinds of thing), not instances of those things. A visual image of a duck, for example, is a representation of a duck, not an actual duck. Likewise, it may seem that inner speech, insofar as it involves auditory imagery, is a representation of speech (and of its sounds, in particular), not actual speech. “Grass is green”, produced in inner speech, would then represent an utterance of the sentence, “Grass is green”, but it would not actually be an utterance of that sentence.

Notwithstanding this, many philosophers working on inner speech hold that inner speech really is a kind of speech. When we produce inner speech, we are literally speaking, albeit silently. We will call this view the “actual speech view”. Proponents include Carruthers (1996), Martínez-Manrique & Vicente (2010, 2015), Gauker (2011, 2018), O’Brien (2013), Jorba & Vicente (2014), Gerrans (2015), Gregory (2016, 2018) (though Gregory has indicated in more recent work (e.g., Gregory forthcoming) that he no longer holds the view), Machery (2018), Wilkinson & Fernyhough (2018), Wilkinson (2020), and Frankfort (2022). Martínez-Manrique & Vicente argued for the view in their 2010 paper; their 2015 paper, discussed in Section 3.3.2, sets out an updated version of their theory which incorporates some further commitments. Historically, the view can be traced at least to the Soviet psychologist, Lev Vygotsky (1934 [1986]), and it was also held by Ryle (1949 [2009]). However, Gauker develops a somewhat different version of the view—one that sharply distinguishes inner speech from the auditory-verbal imagery typically associated with it (see Section 3.2 for discussion)—which has its origins in Sellars (1956).

If inner speech is a kind of speech, instances of inner speech could aptly be called “inner speech utterances”, as producing inner speech would really amount to saying something. However, in order to be neutral on the issue, we will use the term, “inner speech episodes”, in this section and throughout the entry. An important issue for a proponent of the actual speech view is to explain how inner speech can consist of genuine linguistic tokens, given that it seems to be an imagistic phenomenon—where, as noted, the images may appear to be representations of speech sounds. For, even if inner speech consists of images of speech sounds, this only suggests that it consists of representations of linguistic items, not linguistic items themselves.

One style of answer has been offered by Sam Wilkinson (2020), who draws a distinction between imagery and imagination. He holds that sensory imagining is a “personal-level phenomenon”, which has components (2020: 16). One of the components of sensory imagining (as opposed to propositional or “attitudinal” imagining, which is typically assumed to be non-imagistic in nature) is mental imagery. For example, if one sensorily imagines a duck, then one component of this personal-level mental state may be a mental image resembling the appearance of a duck. There might also be other components, such as a stipulation that the image is an image of a duck and not another bird of similar appearance. But, Wilkinson emphasizes, mental imagery can be involved in many personal-level mental attitudes apart from the attitude of imagining, such as remembering, judging, reasoning, and others. “In a similar way”, he claims,

imagery … may be involved in an inner assertion. That does not, however, make the inner assertion simply nothing more than the imagery involved in its production, still less an act of imagination. (2020: 16).

Imagery can play many roles, Wilkinson is saying, and there is no reason that one of those roles should not be as a medium for linguistic tokens. The inner assertion is “a genuine assertion”—an instance of language consisting of imagery.

It might be replied that, although imagery can play a role in many personal-level mental states apart from imagining, it plays a very similar role in all of them, viz., representing how a concrete object (whether actual or possible) appears or sounds. Mental imagery does not tend to play a role similar to that of a linguistic token. So, even if mental imagery is involved in a range of personal-level mental states, it is not obviously well-suited, in the case of inner speech, to play the specific role of actual linguistic tokens.

This challenge might be met by connecting the actual speech view with work on the metaphysics of word tokens, as proposed by Wade Munroe (2022a, 2023). Munroe holds that

what makes something, φ, a token of a word type, w, is that the process of generating φ is explained and guided by one’s (tacit) knowledge of w (or the morphological structure of w), e.g., one’s semantic, syntactic, morphophonological/orthographic, knowledge of w stored in one’s mental lexicon. (2022a: 4)

This allows him to hold that inner speech episodes can involve word tokens, insofar as their generation is guided by the relevant kind of tacit knowledge. (Though Munroe himself does not hold the actual speech view; see Section 3.3.1 for discussion of his view.) Relatedly, J. T. M. Miller (2021) explicitly denies that word tokens are necessarily substances and holds, instead,

that particular or token words are objects, which are bundles of various sorts (most notably semantic, phonetic, orthographic, and grammatical) properties. [sic] (2021: 5737)

One might hold that inner speech episodes in fact consist in such bundles.

Although the matter of how inner speech episodes can involve genuine linguistic tokens is of great importance for the actual speech view, it is only beginning to receive attention. However, several arguments have been given in support of the theory generally. These include the following:

Inner speech may be a developmental descendant of a kind of external speech. Piaget (1923 [1926/1959]) observed that young children have a practice of speaking to themselves aloud. He described this kind of speech as “egocentric speech” (ibid, passim) (egocentric speech can be seen as one kind of private speech; see Introduction). Vygotsky (1934 [1986]) presented empirical evidence that inner speech develops in children as they internalize the practice of producing egocentric speech (though see Gregory (forthcoming) questioning this evidence). Vygotsky held that egocentric speech becomes silent, inner speech, but that it does not change in its fundamental nature, so it remains a kind of actual speech (see also Wilkinson & Fernyhough (2018), Wilkinson (2020)).
Introspectively, it seems like we can perform speech acts—e.g., make assertions and ask questions—in inner speech. But it would only be possible to perform speech acts in inner speech if inner speech is a kind of speech (Wilkinson 2020; Wilkinson & Fernyhough 2018). (This issue is addressed further in Section 4.1.)
On the face of it, we produce inner speech for purposes such as focusing our attention, motivating ourselves, and evaluating our actions. These correspond to purposes which instances of external speech also often serve: focusing the attention of others, motivating them, and commenting on their actions. There are also parallels in terms of how inner speech episodes and instances of external speech are constructed. Both often take the form of short, sub-sentential items when this is sufficient (e.g., “Here!”, upon finding something which was lost) and more fully elaborated sentences when this is necessary (e.g., when carefully listing the considerations relevant to a difficult decision which needs to be made, whether by oneself or by a group). Marta Jorba, Agustín Vicente, and Fernando Martínez-Manrique have taken these systematic parallels as evidence that inner speech and external speech are simply different types of one phenomenon, namely, speech (Jorba & Vicente 2014; Martínez-Manrique & Vicente 2015).
There seems to be a contrast between imagining speaking and engaging in inner speech, as it is ordinarily understood. This contrast, Gregory (2016) suggests, parallels the contrast between two kinds of external actions which we can perform. When an actor says the lines in their script, what they are producing is a representation of speech that someone else might produce. The actor is, of course, speaking, but they are doing so in the context of a pretense. What the actor is doing contrasts with the speech which they produce in, e.g., an ordinary conversation with someone. The contrast between imagining speaking and producing inner speech seems to map neatly onto the contrast between what the actor does on the stage and what they do in an ordinary conversation. If this is so, then a natural analysis is that the contrast between imagined speech and inner speech is a contrast between a representation of speech and actual speech—which implies that inner speech is a kind of actual speech.
A couple of philosophers who hold the actual speech view but express it in different terms, or who hold very similar positions, should be mentioned. First, Philip Gerrans (2015) describes inner speech as involving “imaginary action” (2015: 296), but he is explicit that, by this, he means only to say that producing inner speech is an action performed covertly. He takes inner speech to involve speaking, but doing so silently.

Second, Johannes Roessler (2016) holds that there are different kinds of inner speech, one of which involves imagining speaking (rather than actually speaking), but in a particular way. He points out that we can imagine things, or imagine doing things, for different purposes. An act of imagining will then be successful to the extent that it achieves the purpose for which it is performed. So, one might, for example, imagine making an assertion, but do so with the intention of imagining making an assertion which is true and relevant to context. Then the act of imagining making the assertion “incurs the same liabilities” (2016: 548) that the act of actually making the assertion would incur. If you are puzzling over some question, and you imagine asserting a possible answer, then the act of imagining will be successful only if you have imagined asserting the correct answer. Although you have only imagined performing the speech act of making an assertion, your imagined assertion will be “in some ways tantamount to an assertion” (2016: 548).

It would be an open position, though not one Roessler takes, that all inner speech episodes could be analyzed in this way. On such a view, inner speech episodes would be something very similar to actual speech, yet without quite being speech acts, and thus without the commitment that producing inner speech involves producing actual linguistic items.

2. Inner Speech and Thought
A second question about inner speech is how it relates to thought. It seems that there must be some relationship, but it is an open question what that relationship is. In general, there are three views about the nature of the relationship: (1) inner speech episodes express thoughts; (2) inner speech episodes facilitate thoughts; and (3) inner speech episodes (at least sometimes) are thoughts of a certain kind.

The views are not mutually exclusive: one can certainly hold that inner speech is related to thought in multiple ways.

2.1 Inner Speech and Thought Expression
Langland-Hassan & Vicente (2018b: 10) observe that the view that inner speech (at least often) expresses thoughts that are distinct from the inner speech episodes themselves coheres with some larger theories about thought and language. If one is attracted to these theories, then they may well also be attracted to the view that inner speech merely expresses thought.

First, there is a natural connection between the language of thought hypothesis, most closely associated with Jerry Fodor (1975), and the view that inner speech expresses thought. On the language of thought hypothesis, our thoughts do take place in a language, but not in a natural language. Rather, our thoughts take place in a kind of mental language, often referred to as “Mentalese”. If the language of thought hypothesis is true, then, insofar as inner speech is keyed to a natural language, it seems that inner speech can at most serve to express the thoughts which occur in the mental language.

Second, on Willem Levelt’s influential theory about language production, speaking involves conveying a pre-existing “message” (1989: passim). The structure of this message is conceptual but not linguistic. Via several stages of processing, natural language sentences (or sub-sentential items) are formulated which, once articulated, express the conceptually structured message with which the process started. If one thinks that inner speech is actually a kind of speech, then one might incline to think that inner speech also expresses a pre-existing message.

Thus, Peter Carruthers (2009, 2018) approaches matters from a Fodorian and Leveltian angle when he proposes that

the first metacognitive access subjects have to the fact that they have a particular belief is via its verbal expression (whether overtly or in inner speech). (2009: 125)

For Carruthers, the inner speech episode is not a belief or judgment itself, but rather the expression thereof (see Section 5.2). In a similar way, Ray Jackendoff (1996, 2007, 2011, 2012) emphasizes the distinction between thought itself and the auditory imagery by which it may be expressed, identifying only the latter with inner speech (see Section 3.1). Likewise, José Luis Bermúdez (2003) and Jesse Prinz (2011) distinguish between conceptual thought itself and inner speech, while holding that we often come to know what we are thinking by attending to inner speech sentences that we might use to express such thoughts. They stop short of explicitly claiming that such sentences actually express thoughts, however, specifying instead that the inner episodes are sentences through which such thoughts “might be expressed” (Bermúdez 2003: 164), or that we “would use” to express them (Prinz 2011: 186) (see Section 5.1).

One can, however, hold that inner speech episodes express thoughts without committing to the view that a thought must be fully-formed prior to the production of the relevant inner speech episode. José Luis Bermúdez (2018), for example, holds that producing an inner speech episode can actually play a role in forming the thought which it expresses. For Bermúdez, a thought can be refined and precisified as an external utterance is being produced and, equally, a thought can be refined and precisified while an inner speech episode is being produced. Nonetheless, by the time an inner speech episode has been produced, it will express an existing thought.

Finally, it is worth noting the following point of contact between the actual speech view, discussed in Section 1, and the question of whether inner speech expresses thought. If it is an essential feature of speech that it serves to express thought, then defenders of the actual speech view are likewise committed to the view that inner speech expresses thought. If, on the other hand, one holds that there can be (inner) speech that does not express thought, then the question arises as to what the difference between (inner) speaking and thinking in a natural language might be—and whether there is indeed a difference.

2.2 Inner Speech and Thought Facilitation
There have been several suggestions as to how inner speech might play a substantive role in facilitating thought or thought processes—a role that goes beyond merely expressing thought processes.

First, inner speech is often thought to play an important role in working memory. According to Alan Baddeley’s influential theory of working memory (e.g., Baddeley 1992), we can retain a series of words or numbers in working memory by reciting them in inner speech. A short series of items will be retained long enough to recite them again. One can iterate this process via a “phonological loop” for as long as desired.

Following Vygotsky (1934 [1986]), Clowes (2007) and Jorba & Vicente (2014) hold that inner speech can serve as a tool for directing our own attention, just as external speech can serve as a tool to direct the attention of others. In making this case, both draw on the Vygotskyan developmental account of inner speech, on which inner speech is derived from the external phenomenon. See also Martínez-Manrique & Vicente (2015), who make the same point but are less directly influenced by Vygotsky’s original (1934 [1986]) developmental account.

There is evidence that inner speech facilitates various executive function tasks, such as planning, task-switching, and inhibiting impulsive and inappropriate responses, without being essential to them. The evidence that inner speech can play a role in these tasks is primarily empirical. For reviews of the relevant literature, see Alderson-Day & Fernyhough (2015) and Petrolini, Jorba, & Vicente (2020).

Munroe (2022b; forthcoming) argues that inner speech plays a role in reasoning which goes beyond merely aiding or improving it. He notes that reasoning processes often involve preserving representations in working memory. In doing complex mental arithmetic, for example, one might recite in inner speech the word for a number which they have determined will be needed later in the process, e.g., when regrouping values (i.e., “carrying” and “borrowing”). The number word will be stored in working memory via the process described above. But, on Baddeley’s model of working memory, which Munroe is working with, only sensory representations can be stored in working memory. In the present context, this means that only auditory representations of the relevant word sounds can be stored, not the conceptual content which the word would have if spoken aloud (or, possibly, if it were produced in inner speech in a different context, depending on one’s view on the contents of inner speech—see Section 3). When one needs to use the number at a later stage in the process, they will need to interpret the sensory representation which they are producing. For example, if they are reciting a sound corresponding to the word, “six”, in inner speech, they will need to interpret that as the word referring to the number, six, so that six becomes the number that they now use to continue their calculations. If this is so, then interpreting the inner speech that one was producing, and thus the inner speech itself, was essential to the reasoning process, not merely a dispensable aid. Munroe holds that the same will apply in many reasoning processes performed that require making use of an intermediate conclusion.

A number of theorists—especially those working in neo-empiricist (Barsalou 1999; Prinz 2011, 2012) and embodied cognition traditions (Borghi et al. 2017; Dove 2014)—have also proposed that inner speech plays an important role in facilitating abstract thought, i.e., thought about objects or properties that are not easily perceived. Here the idea is that language perception and production abilities—and their internalization, via inner speech—provide means for explaining the acquisition and use of abstract concepts in broadly sensorimotor terms. In particular, Guy Dove (2014, 2018, 2020, 2022) develops a view where language—often in the form of inner speech—is used as a “scaffold” or “tool” for enabling thought about abstract entities, and where the capacity for abstract concept use is closely tied to the capacity for language.

Finally, if subsystems and modules in the mind function in isolation from one another to any significant extent, then inner speech may play an important role in integrating their output. Carruthers (2002, 2006) suggests that the process of language production generally, including the production of inner speech, is especially well suited to integrate the output of multiple modules, because of the combinatorial nature of language. In producing an episode of inner speech, one can thus express complex content, which is then distributed to mental modules and subsystems for further processing. Other sources relevant to inner speech and the integration of information produced by different parts of the mind include Baars (1988) and Dennett (1991).

2.3 Inner Speech as Thought
A number of philosophers have argued that at least some inner speech episodes actually are thoughts or, at least, parts of thought processes. Gauker (2011, 2018) holds that all conceptual thought occurs in inner speech, where, as elaborated in Section 3.2, he takes inner speech to involve the tokening of items of a natural language in neural states that are distinct from the auditory-verbal representations that many identify with inner speech. In his 2011 book, he responds to arguments that conceptual thought cannot occur in natural language.

With respect to inner speech understood as a partly sensory phenomenon, Keith Frankish (2018) describes how inner speech can be used to break a complicated problem into smaller problems, which can then be addressed by lower level, automatic thought processes. Deciding whether to accept an invitation from colleagues to attend a party, for example, one might produce the inner speech episode, “What will it be like?”. This more circumscribed question can be addressed by autonomous processes, such as recalling previous parties with colleagues. Along with other autonomous processes, this might generate the prediction that an annoying colleague, Henry, will likely be at the party. If this is significant, it could result in the inner speech episode, “Henry will probably be there”, in turn prompting a largely autonomous evaluation of the effort involved in enduring Henry’s company. The process could result, depending on the outcome of this evaluation, in producing the inner speech episode, “I can’t face that; I won’t go”. (Quotes from Frankish [2018: 234], though the example is slightly modified.) The inner speech episodes, Frankish believes, are critical to making the decision, and are thus rightly considered parts of the process of thinking itself. See Kompa (forthcoming) for a similar argument; cf. Munroe (2022b), discussed above, who also holds that an inner speech episode can be essential to a thought process but does not infer from this that an inner speech episode can actually be a part of the process, but see also discussion of Munroe (2023) below.

Frankish (2018) also holds that inner speech episodes can be thoughts in the form of conscious commitments, where these are “a distinct kind of mental attitude” (2018: 237), which cannot be analyzed in terms of other conscious mental states, such as conscious decisions, beliefs, or desires, or expressions of other mental states. They are simply commitments made to oneself to “regulat[e] our future activities, including our intentional reasoning, in line with the choice or view expressed” (2018: 237). For example, the inner speech episode, “I will go to the gym today”, is a commitment to go to the gym today, not just the expression of a decision to do so, because it also generates a kind of obligation to oneself, as it were, to do so. For Frankish, this follows from treating inner speech as an internalized version of interpersonal speech, in which commitments also generate obligations.

On Frankish’s account, an inner speech episode can be like a judgment, insofar as it may involve committing oneself to act and reason in a way which is consistent with the truth of the proposition expressed by the inner speech episode. Munroe (2023), by contrast, holds that an inner speech episode can actually function as a judgment. If an inner speech episode is accompanied by what has been called a “Feeling of Rightness” (Munroe cites Thomson et al. 2013 and Unkelbach & Greifender 2013), then it will play roles typically attributed to judgments such as “terminating inquiry and causing overt actions” (Munroe 2023: 309). Munroe connects his claim to a model proposed by Ackerman & Thompson (2015, 2017a, 2017b) on which the roles that mental states play is determined partly by metacognitive monitoring. The “Feeling of Rightness” is a cue to a metacognitive monitoring system that a particular mental state can appropriately play the roles of a judgment. Munroe’s claim is that inner speech episodes can function as judgments if this is deemed appropriate by the metacognitive monitoring system, on account of being accompanied by the appropriate “Feeling of Rightness” (or at least by a feeling of sufficient certainty).

Nikola Kompa (forthcoming) adds a quite different argument for the identity of (some) thoughts and (some) inner speech episodes. She operates with a broad notion of inner speech, on which any “inner episode that substantially engages the speech production system” is an instance of inner speech (forthcoming: 4, emphasis removed). On this understanding of inner speech, any thought with semantic content and syntactic structure will be an instance of inner speech, even if it does not become conscious. Kompa rejects the language of thought hypothesis, on which thoughts can have linguistic properties because they occur in a non-natural language. Accordingly, for Kompa, the only way that a thought can have semantic content and syntactic structure is if its formation substantially involves the speech production system (which she understands in Leveltian terms, citing Levelt 1989; Levelt et al. 1999; and Indefrey & Levelt 2004). Insofar as we have any thoughts that have semantic content and syntactic structure, then, these are, on her definition, instances of inner speech. If the production of such thoughts does not proceed further through the speech production process, such that they are morpho-phonologically encoded in addition to having semantic content and syntactic structure, they will occur as unconscious inner speech episodes.

Finally, it has been suggested that there is a close connection between inner speech and a phenomenon known as “unsymbolized thought”. Using the Descriptive Experience Sampling paradigm, Russell Hurlburt and Christopher Heavey (e.g., Hurlburt & Heavey 2002; Heavey & Hurlburt 2008) have gathered introspective data that they interpret as providing evidence that people sometimes have the experience of

thinking a particular, definite thought without the awareness of that thought’s being conveyed in words, images, or any other symbols. (Heavey & Hurlburt 2008: 802)

Martínez-Manrique & Vicente (2015), Vicente & Martínez-Manrique (2016), and Vicente & Jorba (2019) suggest that these “unsymbolized thoughts” occur when the production of an inner speech episode is aborted at the earliest stage of production, when only the content or message to be expressed has been formulated. Appealing to accounts on which we experience conscious representations of actions which we begin to perform but abort, they suggest that an unsymbolized thought is a representation of the message which one commenced expressing in inner speech, which becomes conscious because the process was aborted. Insofar as the process was aborted prior to the message being organized in phonetic form, the representation is entirely amodal. See also Kompa (forthcoming).

3. Content-Based Theories of Inner Speech
We have seen that there are a variety of views taken on whether inner speech is indeed a kind of speech, or a kind of thought, or both. A popular way to gain added leverage on those questions is to advance an account of the contents of inner speech. Focusing on questions concerning the contents of inner speech also helps to clarify the depth of some of the puzzles and controversies already introduced.

Most generally, the content of a representation is what the representation is of or about—it is what the representation represents. The content of the word “cat” is a certain type of animal (namely, a cat). And, the content of the sentence “cats are animals” is the proposition that cats are animals. Two distinct representations can have the same content. For instance, the French word “chat” has the same content as the English word “cat”; and the French sentence “les chats sont des animaux” has the same content as the English sentence “cats are animals”. Thus—to borrow analogies from Siegel (2005 [2021])—the contents of a mental state, in the present sense, are akin to the contents of a newspaper article and not akin to the contents of a bucket. Mental contents are not things that are contained within mental states themselves (just as cats are not contained within the word “cat”) but are, instead, what the mental states are of or about.

We will distinguish three broad classes of views about the contents of inner speech and several sub-views within them, noting their main motivations and relationships to questions concerning inner speech’s proposed cognitive roles. According to what we will call the “phonological content view”, inner speech episodes always and only have phonological contents. The competing content-based theories to be discussed hold either that inner speech only has semantic contents (the “semantic content view”, as we will call it) or that inner speech has phonological contents and semantic and/or other kinds of contents (the “mixed contents view”).

As we will see, the phonological content view is a natural fit with the view, discussed at the beginning of Section 1, that inner speech is merely a representation of speech and not actually a kind of speech. This is because the phonological content view sees inner speech as consisting in imagistic representations of speech and as lacking the kinds of contents (or meanings) associated with word tokens themselves. Likewise, those who hold that inner speech is actually speech will typically hold either a mixed contents view or a semantic content view, as these views allow inner speech episodes to have the kinds of semantic contents that are typically viewed as essential to being a linguistic token.

3.1 The Phonological Content View
To say that inner speech has phonological contents is to say that inner speech episodes represent phonemes (or phones), where phonemes are the most basic meaningless building-blocks from which any word of a language can be built. There are 44 phonemes in English, different combinations of which account for the distinct sound each word has in relation to all other words from which it can be aurally distinguished. The notion of a phoneme is somewhat of an abstraction, however, as slightly different sounds (in terms of pitch, timbre, and frequency) can fall within the sonic range that constitutes a single phoneme type. These more specific, concrete sounds that can qualify as instantiations of a phoneme are known as phones. Whether inner speech episodes represent phonemes or, instead, the finer-grained property of being a phone is a matter of dispute among those who hold that inner speech episodes have phonological contents (Patel 2021; Langland-Hassan 2018; Hill 2022).

Note also that, while the phonemes of most natural languages are auditory in nature—and are thus perceived through the sense of hearing—the notion of a phoneme has also been applied to gestural languages, such as American Sign Language (Sandler 2012; Stokoe 2005). So, the concept of a phoneme is not specific to any modality. It refers to the smallest meaningless units of a language that can be arranged and recombined to form the smallest meaningful units of that language, no matter which modality the language occurs in. In spoken languages, however, the auditory modality takes precedence over the visual/written modality, insofar as the phonemes are typically held to be sounds, while the graphemes are held to be letters or groups of letters that represent phonemes. While most will not consider the visualization of graphemes and written words to be cases of inner speech, it bears noting that such visualizations satisfy the neutral characterization of inner speech provided at the outset.

There are several reasons one might hold that inner speech episodes have phonological contents. The first is phenomenological in nature. What it is like to have an inner speech episode is similar to what it is like to hear oneself saying the corresponding words aloud. One might explain this phenomenological similarity by appeal to the fact that inner speech episodes and the corresponding cases of hearing represent similar properties—either phonemes or phones of a certain sort—and, accordingly, have similar contents. A second reason appeals to the fact that we can use inner speech episodes to judge whether two visually dissimilar written words—such as “blood” and “mud”—rhyme. As rhyming is a relationship between the sounds of words, the usefulness of inner speech episodes in judging rhymes would be explained if inner speech episodes represented word sounds and thereby allowed us to compare those sounds (Langland-Hassan 2014). A third reason that has been proposed for thinking that inner speech has phonological contents is that it is the representation of those features that allows one to discern which language we are exploiting when engaged in inner speech (Langland-Hassan 2018). (See Patel 2021 for a rebuttal.)

Jackendoff (1996, 2007, 2011) proposes that auditory contents exhaust the contents of inner speech. Jackendoff’s view is motivated in part by a prior commitment to the thesis that we do not think in a natural language. Like many in cognitive science, he sees natural language primarily as a means for communicating thoughts that themselves occur unconsciously in some other medium (such as a Fodorian “Mentalese”). According to Jackendoff, thought itself is never conscious, nor is the use of concepts. By contrast, inner speech—what he calls the “talking voice in the head” (1996: 10)—occurs consciously and does not involve the use of concepts. In having inner speech, he explains, “[w]e experience organized sounds”, whereas,

the content of our experience, our understanding of the sounds, is a different organization … called conceptual structure. (emphasis original, 1996: 12–13)

“The organization of this content”, he holds, “is completely unconscious” (1996: 13). Jackendoff identifies the inner voice with a representation of “phonological structure”, a representation having phonological content, yet no conceptual or semantic content. Whereas, the mental states constituting our understanding of what the voice is saying, he notes, are distinct conceptual states that occur unconsciously:

What we experience as our inner monologue is actually the phonological structure linked to the thought,

he explains.

We are aware of our thinking because we hear the associated sounds in our head. (Jackendoff 2011: 613)

(See also Jackendoff [2007: 80–85] where he remarks on the counterintuitive nature of his view: “How can the contents of consciousness consist of just a string of sounds?” [2007: 85].)

It should be noted that Jackendoff also suggests that inner speech episodes “express” thoughts, which would seem to support the view that such episodes have the semantic contents of our thoughts (e.g., “the linguistic modality can make reasons as such available in consciousness” [1996: 19] and “only through language can such concepts form part of experience rather than just being the source of intuitive urges” [1996: 23]). On the other hand, he equally emphasizes the overlooked fact that “linguistic structure has three major departments: phonological, syntactic, and semantic/conceptual structure”, and that “the forms in awareness—the qualia—most closely mirror phonological structure” (2007: 81). Most recently, he has proposed a view where what we intuitively mark as “conscious thought” has three components: a “pronunciation” of the thought, a feeling of meaningfulness, and the meaning attached to the pronunciation. There he holds that only the first two are conscious and appears to identify inner speech with the “pronunciation” component. This is in keeping with the phonological content view, as the (semantic) meaning of the pronunciation is something separate from the pronunciation and is only represented “backstage” (i.e., unconsciously) (Jackendoff 2012: 84–5).

Langland-Hassan (2014) provides a qualified defense of a phonological content view, motivated by worries about how a single mental state—in particular an episode of inner speech—can be said to represent both word sounds and word meanings simultaneously. He notes that a word’s meaning and its sound are entirely distinct properties, related only by convention. If mental states are individuated by their contents, then it seems that distinct neural or functional states will be needed to represent these distinct properties. This has become known as the “binding problem” for inner speech (see Munroe 2023; Patel 2021; Bermúdez 2018 for different approaches to resolving it; see also Prinz 2011 for related remarks). In light of this problem, Langland-Hassan proposes that ordinary episodes of inner speech likely consist in two or more mental states triggered at roughly the same time (this would be a multiple-state version of the “mixed contents” view, discussed below). Yet he adds that, when inner speech has been divided into distinctly occurring states in this way, there are good reasons to identify inner speech solely with the component that represents word sounds. Doing so results in a phonological content view.

3.2 The Semantic Content View
In contrast to the phonological content view, the semantic content view holds that inner speech episodes always and only have semantic contents. By “semantic contents”, we mean the kinds of contents had by ordinary words, phrases, and sentences of a natural language. Such contents are typically equated with the meaning of a word, phrase, or sentence.

One version of a semantic content view, defended by Christopher Gauker (2011, 2018), holds that inner speech episodes exclusively have semantic contents and entirely lack both auditory contents and auditory phenomenology. Gauker allows that episodes of auditory verbal imagery often accompany inner speech. However, on his view, this auditory imagery is not to be identified with inner speech itself. Rather, according to Gauker, inner speech is a non-sensory linguistic phenomenon occurring in the brain that is (often) represented by episodes of auditory verbal imagery. Just as we may use auditory representations to represent someone else’s speech that we are actually hearing, so too, for Gauker, our inner speech is often represented by verbal imagery—imagery that is in fact distinct from the (inner) speech itself. (Here Gauker develops related remarks of Wilfrid Sellars (1956).) Notably, Gauker (2018) grants that, in the case of inner speech, this auditory-verbal imagery misrepresents our inner speech as having sonic features (i.e., as instantiating phones or phonemes), given that the neural events that constitute inner speech episodes are themselves silent.

Gauker’s style of pure semantic content view is not widely endorsed. This may be because it clashes with the widespread view that inner speech has a sensory character similar to that of hearing speech. On the other hand, Gauker’s view can be said to have an advantage in providing a literal sense in which, when we engage in inner speech, we are thinking in words of a natural language and not merely about them. On Gauker’s (2011) view, the neural events that carry semantic content are themselves tokens of words and phrases of a natural language, and the question of how auditory-verbal images can also be linguistic tokens does not arise. His view is also motivated by an opposition to what he calls the “Lockean” view that sees conceptual thought as something prior to and separate from the speech that expresses it. One can see Gauker (2011) as trying to preserve the idea that abstract (conceptual) thought occurs in a language (and is often non-conscious), while divorcing it from the thesis that there exists an innate, Fodorian “language of thought” (and one that must be exploited in order to learn a natural language).

Bermúdez (2018) offers a different style of semantic content view that allows for inner speech to retain a characteristic auditory phenomenology. According to Bermúdez, the auditory sensory character of inner speech is a result of inner speech episodes having non-representational auditory properties. For Bermúdez, the only representational contents had by inner speech episodes are those pertaining to the meanings of words. In response to the those who argue that inner speech episodes must also have phonological contents (e.g., to explain why we can use inner speech to judge whether two words rhyme), he argues that there is no entailment from the fact that inner speech episodes can be useful in judging rhyme relations to the conclusion that they represent phonemes (2018: 216–7).

A third type of theory on which inner speech exclusively has semantic content proceeds by arguing that inner speech is a genuine form of speech. This argument is typically made on either phenomenological or functional grounds. From there it is inferred that inner speech must have the same kind of contents as external speech. If episodes of external speech—i.e., the words we hear when someone speaks—have semantic content but no phonological content (because they do not represent phonemes), so too must episodes of inner speech. This approach to theorizing about inner speech is discussed in more detail in Section 1. Assuming that (unlike Gauker) proponents of such a view wish to maintain that inner speech episodes constitutively have auditory sensory character, they may concur with Bermúdez in his claim that the auditory phenomenology of inner speech does not entail the representation of auditory properties; or, alternatively, they may provide some other account of why, in many instances, inner speech seems to represent phonemes even if it does not really do so.

3.3 Mixed Contents Views
Mixed contents views hold that inner speech episodes typically have at least two kinds of content—phonological and semantic—simultaneously. On a mixed contents view, the inner speech episode “Dogs are mammals” represents both the sound of the sentence “Dogs are mammals”, as uttered aloud, and the proposition that dogs are mammals. We can distinguish two species of mixed contents view: single-state and multiple-state. Single-state views hold that what we intuitively mark as a single inner speech episode consists in a single mental state that has both auditory and semantic contents. Multiple-state views hold that the apparent unity of a single inner speech episode is in some sense illusory, as such episodes typically consist in the contemporaneous occurrence of two or more mental states, where one of the states represents phones or phonemes and another has semantic contents. (Some multiple-state views hold that inner speech episodes involve additional distinct states with articulatory and syntactic contents as well.) As earlier noted, some phonological content views hold that mental states with corresponding semantic contents occur contemporaneously with the representations of phonemes that are identified with inner speech. These phonological content views differ from multiple-state mixed contents views in that the former identify inner speech solely with the state that has phonological content, perhaps on the grounds that it is the only sort of state of which one is consciously aware (this appears to be Jackendoff’s motivation).

3.3.1 Single-State Mixed Contents Views
Carruthers (2011, 2018) defends a single-state mixed contents view, proposing that inner speech involves the generation of a representation of word sounds (i.e., phonemes) which—in a process akin to what occurs in outer speech perception—is then interpreted by one’s speech comprehension mechanisms so that a semantic content can then be assigned to the represented utterance. (He notes that a representation of the semantic content of the represented phrase—referred to as the “message” on Levelt’s [1989] speech-production framework—sometimes precedes the representation of the word sounds, albeit non-consciously.) Once the represented word sounds are interpreted, Carruthers suggests, the information that the represented utterance has a certain semantic content is “bound into” a single “event-file” that contains information both about the sound and the meaning of the represented utterance (2018: 41–42). (See Frankish [2004: 57; 2018] for a similar view.) Carruthers analogizes such binding to the way in which the color, shape, and category properties of a visually perceived object are said to be “bound into” a single object-file that accumulates multiple forms of information about a single object, despite those properties being represented in temporally distinct stages and in distinct neural regions. These event-files, when activated and globally-broadcast, are said to constitute a single conscious inner speech episode that has both auditory and semantic contents.

Munroe (2023) develops a similar style of single-state mixed contents view, arguing that, in addition to representing phonemic and semantic features, inner speech episodes also represent the likelihood that the content of the represented utterance is true. The latter is necessary, he holds, for inner speech episodes to qualify as judgments (see Section 2.3). These three distinct features are, for Munroe, bound into a single mental state in the sense that a single mental state predicates these three distinct properties of a single represented utterance (Munroe 2023: 304).

3.3.2 Multiple-State Mixed Contents Views
Other mixed contents views of inner speech—inspired by Levelt’s (1989) multi-stage model of speech production—attribute the different representational contents entertained during an inner speech episode to multiple distinct states that tend to co-occur. Martínez-Manrique & Vicente (2015) defend a multiple-state view under the moniker of the “activity view” of inner speech, highlighting the multi-component processes of both inner and outer speech. “It is quite natural”, they explain,

to try to understand inner speech in terms of all the representations that are mobilized in speech, i.e., semantic, syntactic, maybe articulatory …. The representations involved—from conceptual to phonological—form an integrated system. (2015: 8)

The view which Martínez-Manrique & Vicente set out in their 2015 paper bears clear similarities to the actual speech view, insofar as they hold that inner speech is functionally similar to external speech. What separates it from the actual speech view, however, is that they do not hold that inner speech consists of actual words and sentences which express semantic content, but of distinct representations of phonological and semantic (and other) content. (For complementary multiple-state mixed contents views in cognitive neuroscience, see Grandchamp et al. 2019 and Lœvenbruck et al. 2018.) While these representations are unified in the sense of occurring within a single system for language production, they remain distinct mental states—distinguished, in part, by their distinct contents, and their ability to occur in isolation of each other. (Note, however, that this way of categorizing the view assumes that each mental state is composed of exactly one mental representation. It may be possible to articulate a view where one mental state is composed of multiple mental representations. The question then becomes: in virtue of what do the multiple representations qualify as a single mental state, as opposed to components or stages of a single cognitive system?)

Christopher Hill (2022: 136–139) develops a similar multiple-state mixed content view, emphasizing that the representations of semantic content lack any associated phenomenology. The phenomenology of inner speech is, for Hill, entirely a function of its auditory-phonological contents. He further specifies that these phonological contents are (the more abstract) phonemes, and not phones, to account for the relatively impoverished sensory character of inner speech in comparison with speech perception. Patel (2021) also defends a multiple-state mixed contents view, on which, in addition to having some combination of semantic, syntactic, auditory, and articulatory contents, inner speech episodes have vocal contents. To have vocal contents is to represent some particular person’s voice as communicating some combination of semantic, syntactic, auditory, or articulatory information. According to Patel, whether we are representing the semantic, auditory, or articulatory contents, these mental events involve one’s representing a certain person’s voice as attempting to convey such information. This common representation of a voice, he argues, provides a kind of unity to the class of mental events that can be considered inner speech.

Because multiple-state views allow that the distinct components of inner speech can potentially occur in isolation, they face a question of which components need to occur for the episode to be properly counted as an instance of inner speech. Vicente & Jorba (2019), Martínez-Manrique & Vicente (2015), and Vicente & Martínez-Manrique (2016) see this as an advantage, insofar as it allows them to place different phenomena related to inner speech on a single continuum (see also Kompa & Mueller forthcoming and McCarthy-Jones & Fernyhough 2011). For instance, when the semantic and syntactic contents of ordinary inner speech are represented in the absence of any auditory-phonological contents, they propose, this can be understood as a case of so-called “unsymbolized thought” (Heavey & Hurlburt 2008; Heavey, Moynihan, et al. 2019). See Section 2.3 for further detail.

A notable feature of the surveyed mixed contents views (as well as the phonological content view) is that they need not (and often do not) hold that inner speech episodes occur in a natural language. Rather, on these views, inner speech episodes represent natural language utterances (in virtue of their phonological contents), without necessarily being instances of such utterances themselves. This is because, on mixed contents views, the semantic content of an inner speech episode may not be represented by tokens of a natural language. For instance, for Carruthers, the semantic contents of an inner speech episode are represented via symbols of an amodal language of thought (e.g., a Fodorian [1975] Mentalese), which are coupled with sensory representations of the sound of the corresponding sentence as spoken aloud. One language (Mentalese) is used to represent the meaning of an expression in another (e.g., English). In this way, Carruthers (2010, 2018) deviates from Carruthers (1996), with the latter defending the idea that inner speech episodes literally occur in—and are expressions of—a natural language. Carruthers now emphasizes the point, raised also by Machery (2005), that introspection does not provide grounds for claims about the representational format of our inner speech episodes.

4. Inner Speech and Pragmatics
In general, the philosophy of language has focused primarily on language used interpersonally. It is natural to wonder to what extent this material is applicable to inner speech. This question can be asked whether or not one thinks that inner speech is actually a kind of speech, as no one denies that there is some interesting relationship between inner speech and interpersonal speech.

4.1 Inner Speech and Speech Acts
As mentioned in Section 1, the intuition that we can perform speech acts in inner speech is the basis of an argument that inner speech is a kind of speech. There are different ways, however, that we might understand the claim, depending on how one thinks of speech acts.

On the traditional analysis of Austin (1962) and Searle (1969), performing a speech act is inherently something one does in accordance with conventions tacitly understood by both speaker and listener. For example, for Searle, asserting p involves (approximately) undertaking to someone that p is true, where the speaker does not know that the listener already knows that p is true. The reason that an assertion can be effective is precisely that both speaker and hearer understand that this is the nature of the transaction. It is hard to see how this kind of analysis could apply to inner speech. One would need to explain how one individual can have two distinct roles, as speaker and listener, such that the conventions that make interpersonal language-use possible can have any relevance (see Gregory 2017, 2020a for related discussion).

Not every version of speech act theory, however, emphasizes conventions. Drawing on some ideas from Strawson (1964) and Bach & Harnish (1970), though not adopting their theories in whole, Wilkinson (2020) holds that what is essential to speech acts is that they express particular mental states. An assertion, for example, is simply an utterance which expresses a belief; a question is an utterance which expresses a desire to acquire certain information; etc. On this view, understanding someone else’s utterance is simply a matter of grasping its content and knowing what kind of mental state the relevant type of utterance expresses. Setting aside the question of whether one needs to interpret their own inner speech, it may be that inner speech episodes can be speech acts if one thinks of speech acts merely as expressions of particular mental states, rather than as actions which depend on conventions in the way that Austin and Searle suggest. For another analysis of inner speech in terms of speech act theory, see Geurts (2018), who emphasizes that inner speech episodes can operate to generate commitments in a way characteristic of speech acts; see also Frankish (2018) and Fernández Castro (2019).

An issue which sits just behind the question of whether inner speech episodes are speech acts is whether they are actions at all. Gregory (2020b) argues that, in the vast majority of cases, inner speech episodes are not actions, because we cannot give reasons for them (which is the criterion for actionhood on Davidson’s (1963) causal theory); they are not subject to our control (the criterion on Harry Frankfurt’s [1978] guidance theory); and we do not try to produce them (the criterion on O’Shaughnessy’s [1973] theory and Hornsby’s [1980] theory). If inner speech episodes are not actions, then they cannot be speech acts.

Tom Frankfort (2022) takes the opposite view. He observes that a great deal of inner speech is involved in deliberation, where this is an expansive category including “reflecting, reasoning, considering, evaluating” (2022: 52). He then applies Mele’s (2009) distinction between actions which involve “trying to bring it about that one x-s” (Mele 2009: 18) and actions which are done in order to bring it about that one x’s. Frankfort suggests that deliberating is an action in the first sense, insofar as it involves (for example) trying to make a decision, and inner speech episodes are actions in the second sense, insofar as they are produced in order to bring it about that one deliberates successfully and (for example) comes to a decision.

Jorba (forthcoming) also holds that inner speech episodes are typically actions, applying affordance theory. Affordances are opportunities for actions suggested by things in one’s environment. For example, an apple has the affordance of being edible; a cup has the affordance of being graspable. Some hold that affordances can also be things which suggest mental actions (Jorba cites McClelland 2020 and Jorba 2020). Jorba’s suggestion is that some mental states afford the production of inner speech episodes. For example, an inchoate thought affords being articulated clearly in inner speech, and an emotion can afford being labeled. Insofar as inner speech episodes are produced in response to affordances, they are actions and, specifically, speech acts. See Bar-On & Ochs (2018) for another account on which inner speech episodes can be “acts of innerly speaking our mind” (2018: 19, emphasis removed).

4.2 Inner Speech and Conversation
Closely related to the question of whether there can be speech acts in inner speech is the question of whether inner speech can involve a kind of dialogue or conversation. A theory which characterizes inner speech this way has been developed at length in psychology, primarily by Charles Fernyhough (e.g., 1996, 2008, 2009). However, the suggestion has been made in a variety of ways by philosophers as well, including by Machery (2018), Frankish (2018), Gauker (2018), and Wilkinson, in collaboration with Fernyhough (Wilkinson & Fernyhough 2018).

The idea that inner speech involves an internal dialogue or conversation clearly has intuitive appeal for some. One often finds inner speech described outside the philosophical context as the “inner dialogue”. But, if inner speech involves a kind of internal dialogue or conversation on more than a metaphorical level, then it is natural to wonder who the interlocutors are (Gregory 2020a). Machery (2018) and Frankish (2018) suggest that different parts of the brain communicate with one another via inner speech. Gauker (2018) suggests that inner speech involves conversing with oneself (see also the discussion of inner speech as a means for interaction between subsystems or modules in the mind in Section 2.2). One difficulty with both of these suggestions, however, is that philosophers of language generally (though not universally) think of conversation as fundamentally involving distinct human agents.

Gregory (2017) appeals to Grice’s (1975 [2013]) account of conversation to make this point. Grice argued that conversations are “characteristically … cooperative efforts” (p. 314). But cooperation requires multiple agents and there is only one agent in inner speech. That said, Gauker (2011, 2018) is working with an explicitly non-Gricean picture of conversation, motivated by an opposition to the doctrine that speech acts serve to express thoughts that are distinct from and precede the expressive utterance. He holds that speaking is,

in the first instance, something we do whenever there is no reason not to, because of the good it tends to do. (2018: 71)

In certain circumstances, where multiple individuals are present,

[a] conversation can be the occasion for each interlocutor to reflect on what he or she has experienced, … and on that basis to elicit a statement that is useful from the other. (2018: 72)

Insofar as we can generate inner speech episodes which cause us to reflect on some matter and then produce further inner speech episodes which are useful for us in the context, inner speech will be conversational. Gauker’s analysis here obviously reflects the expression-oriented approach to the question of whether there can be speech acts in inner speech.

In contrast to Gauker, Deamer (2021) argues that inner speech can be seen as being communicative in a Gricean sense. She holds that, to at least some extent, humans are “self-blind”: mental states such as our intentions are not always transparent to us. When we produce inner speech, we reveal our communicative intentions to ourselves, just as we reveal our communicative intentions to others when we converse with them.

While there is disagreement as to whether a series of inner speech episodes can be a dialogue in a literal sense, most agree that inner speech often closely resembles dialogue. As Gauker notes, one episode of inner speech will often prompt another, as happens in interpersonal dialogue. We can produce episodes of inner speech corresponding to different points of view, e.g., when thinking about the considerations for and against some course of action, in a way similar to two people with different opinions. Some participants in studies report that some of their inner speech episodes take place in the voices of others (McCarthy-Jones & Fernyhough 2011; Alderson-Day, Mitrenga, et al. 2018). This last consideration raises an important issue. We can certainly imagine conversing with others and we can certainly imagine others conversing. Such cases are usually taken to be distinct from inner speech (see Section 1). However, if inner speech can involve the voices of others, possibly expressing viewpoints other than our own, it becomes difficult to say how instances of inner speech with these characteristics differ from cases of imagining others speaking. How to delineate the extension of “inner speech” in a way that distinguishes inner speech acts from cases of (merely) imagining speech remains an underexplored issue.

5. Self-Knowledge and Metacognition
Inner speech plays an important role in a number of philosophical accounts of self-knowledge and metacognition. By “self-knowledge” we will mean knowledge of one’s own mental states, including both dispositional states—like beliefs, desires, and intentions—and occurrent states, such as thoughts, imaginings, decisions, and judgments. The notion of metacognition is somewhat broader, also encompassing judgments and non-cognitive assessments (e.g., “feelings of knowing”) concerning the validity of one’s own reasoning, the quality of one’s evidence, one’s degree of certainty, and so on (Proust 2013). While some theorists implicate inner speech in their accounts of both self-knowledge and metacognition (Jackendoff 1996; Clark 1998; Bermúdez 2003, 2018), others focus more narrowly on the question of how inner speech might facilitate self-knowledge (Byrne 2018; Carruthers 2011; Roessler 2016). A common thread among theorists who invoke inner speech in their accounts of metacognition or self-knowledge is the idea that certain others of our mental states—namely, those that our inner speech helps us to know about—are either less readily available to introspection or less well suited to serve a metacognitive role. Thus, these views all appear against a backdrop of broader commitments about the nature of mental states and our introspective access to them.

5.1 Metacognitive Approaches
One approach sees inner speech as especially well suited to aid in metacognition due to its linguistic structure, or its link to public language more generally. According to Andy Clark (1998), the fact that inner speech occurs in a language—where such language is seen as abstracting away from the particularities of perception—allows it to play a special role in “second-order cognitive dynamics” (see also Prinz 2011, 2012). This, he holds, is because the natural language sentences featured in inner speech are “context resistant” and “modality transcending” in ways that facilitate a more objective and reliable assessment of the soundness of one’s own thought processes (Clark 1998: 178). Bermúdez (2003, 2018) builds on Clark’s proposal, specifying that awareness of inner speech is essential for enabling humans to become conscious of their own propositional thought processes, which are otherwise amodal and inaccessible to introspection. According to Bermúdez,

all the propositional thoughts that we consciously introspect … take the form of sentences in a public language. (emphasis original, 2003: 159–160)

While he does not identify these public language sentences with our core thought processes themselves—these, he holds, occur in a subconscious language of thought—Bermúdez argues that the linguistic structure of inner speech is needed to adequately represent the relationships of entailment and rational support that may (or may not) exist among the subconscious thoughts the inner speech episodes serve to express. As he puts it,

we think about thoughts through thinking about the sentences through which those thoughts might be expressed. (2003: 164)

Jackendoff (1996, 2007, 2011, 2012) and Prinz (2011, 2012) likewise hold that there is a level of conceptual thought that is not directly available to introspection and that inner speech is well suited for making us aware of such thoughts. Yet, for Jackendoff and Prinz, inner speech is able to play this role primarily because, like other imagistic mental states, inner speech occurs at an “intermediate” level of representation, which, on their theories, is the only level of representation at which mental states are consciously available to the subject. Thus Jackendoff’s comment that “we are aware of our thinking because we hear the associated sounds in our heads” (2011: 613). Echoing Bermúdez and Clark, Prinz finds it

likely that we often come to know what we are thinking by hearing inner statements of the sentences that we would use to express our thoughts (2011:. 186)

and judges inner speech to be “a way of registering complex thoughts in consciousness” (2011: 186). (See also Machery 2005, 2018.)

5.2 Inferentialist Approaches
Several theorists, who we will term “inferentialists”, follow Ryle (1949 [2009]) in his claim that we often come to know what we are thinking by “overhear[ing]”, or “eavesdrop[ping] on … our own silent monologues” (1949 [2009: 165]). On these views, we come to know what we are thinking, or what we believe or desire, by drawing a kind of inference (the nature of which differs, depending on the theorist) from the fact that we “hear” ourselves say something in inner speech. The views of Clark, Bermúdez, Jackendoff, and Prinz, already reviewed, are inferentialist in nature. Yet there are other approaches that incorporate inner speech into a process that is even more explicitly inferential.

Carruthers (2009, 2010, 2011, 2018) is an inferentialist of this latter sort. While, in earlier work, he argued that thought itself occurs in inner speech (Carruthers 2002), Carruthers later abandoned that idea to hold that thoughts (including one’s beliefs) are always unconscious. On this view, inner speech episodes remain more or less directly available to introspection, yet only provide a kind of indirect evidence for what we are in fact judging or deciding (or believing, desiring, or intending) unconsciously. He emphasizes the fallible nature of such inferences, arguing on the basis of various empirical studies that many of the inferences people arrive at about their own beliefs and desires are in fact incorrect. Similarly to Jackendoff and Prinz, Carruthers holds that only sensory states are able to serve as inputs to the mental mechanism responsible for self- (and other-) directed mindreading. These inputs include visual and other forms of sensory imagery in addition to inner speech. However, in cases where we are having thoughts about abstract matters that are difficult to unambiguously represent with other forms of imagery—such as the thought that philosophy is a challenging subject—episodes of inner speech are held to provide an especially important source of information that one is having such thoughts. Carruthers emphasizes that the process becomes especially inferential in nature where other contextual information—such as that one sees oneself lingering over a choice of cereal box—combines with one’s inner speech to generate an all-things-considered appraisal of what one is currently judging or deciding. Cassam (2011, 2014) likewise implicates inner speech in a multi-faceted inferentialist account of self-knowledge, though not pitched in terms of “mindreading” mechanisms or other constructs from cognitive science.

Alex Byrne (2011, 2018) puts inner speech to somewhat different ends in his inferentialist account of how we know what we are thinking. For Byrne, there is no such thing as inner speech, strictly speaking, because there are no sounds (or voices) in the head. However, there are such things as auditory-phonological representations of voices. These give rise to an apparent perception of what we come to think of as the “inner voice”. By trying to attend to what the inner voice says, Byrne proposes, we can reliably form judgments about what we are thinking. The epistemic rule he proposes for doing so is:

THINK: If the inner voice speaks about x, believe that you are thinking about x.

As with Carruthers, a key motivation for Byrne’s account of how we know what we are thinking is a background view—motivated by the work of Shoemaker (1994), Dretske (2003), and others—that we have no other, more direct introspective method for knowing our own thoughts (i.e., we lack something like an “inner sense”). Note that Byrne’s approach is inferentialist in that he takes inner speech to be implicated in inferences that lead to knowledge of one’s own occurrent thoughts. Yet the sort of inference involved is quite different from that envisioned by Carruthers and Cassam, who both hold that inner speech episodes are just one kind of information among many that may be brought to bear in inferences about one’s standing and occurrent mental states. Importantly, the form of inference envisioned by Carruthers and Cassam is essentially the same in its first and third person applications, whereas Byrne’s THINK rule is of an inferential procedure that can only be used to reliably generate true beliefs about one’s own mental states. In Byrne’s view, this helps to explain the “peculiar” nature of introspection, where this peculiarity lies in the fact that our methods for knowing our own mental states are (intuitively) different from those we use to know others’ (Byrne 2011, 2018). Further, on Byrne’s version of inferentialism, the inferences we form by trying to follow THINK are extremely likely to amount to knowledge—thereby cohering with the intuition that knowledge of one’s own current thoughts is epistemically privileged. Whereas, the kinds of metacognitive inferences that Carruthers and Cassam envision to rely on inner speech are (by their own telling) epistemically on a par with our inferences about the mental states of others and far more susceptible to error.

5.3 Inferentialism’s Critics
Several philosophers object that inferentialist proposals leave us at too great an epistemic distance from our own thoughts (Bar-On & Ochs 2018; Roessler 2016) or have other unworkable features (Langland-Hassan 2014; Martínez-Manrique & Vicente 2010; Roessler 2016). Roessler (2016) pursues a non-observational account of the role of inner speech in generating self-knowledge. Rejecting the idea that we need to “eavesdrop on ourselves” by attending to our inner speech, Roessler suggests we follow remarks of Ryle (1949 [2009]) and Anscombe (1957) in understanding the knowledge gained through inner speech as a kind of “practical knowledge”, (or, for Ryle, “serial knowledge”), where knowing what one is thinking is understood as a special case of knowing what one is doing.

Bar-On & Ochs (2018) likewise take aim at what they term “Neo-Rylean” invocations of inner speech, arguing that Byrne’s THINK rule fails to identify a special role for inner speech in facilitating self-knowledge. Drawing on Bar-On’s (2004) broader expressivist approach to self-knowledge, Bar-On and Ochs hold that a proper account of inner speech’s role in self-knowledge should show how such knowledge is “distinctive and uniquely first-personal” in that it is

knowledge that one can be said to have in virtue of being in a privileged position to give direct voice to one’s thoughts. (2018: 20)

They do not, however, develop a positive account in detail.

Vicente & Martínez-Manrique (2005, 2008; Martínez-Manrique & Vicente 2010) have criticized Bermúdez’s and related inferentialist views on the grounds that the semantics of natural language sentences—and inner speech episodes, in particular—are underdetermined in ways incompatible with providing knowledge of one’s thoughts. For instance, the sentence “Jane’s cup is full”, is ambiguous in several ways, including the sense in which it is Jane’s cup (does she own it? is she just using it? is it the one she merely wants?) and the sense in which it is full (is it full of air? of liquid? of coins?). If the explicit meaning of a sentence is only extracted (and disambiguated) at the level of thought itself, they argue, it is unclear how awareness of semantically indeterminate inner speech utterances could suffice for awareness of one’s own—presumably explicit and unambiguous—propositional thoughts. Bermúdez replies in his 2018 paper.

Jorba & Vicente (2014) and Martínez-Manrique & Vicente (2015) criticize what they call the “format view” of inner speech (which they attribute to Jackendoff and others) which holds that we are conscious of our inner speech episodes only because of their sensory format (see also Fernández Castro 2016). If these criticisms succeed, they cast doubt on views, such as those of Carruthers (2010), Jackendoff (1996), and Prinz (2012), which link the metacognitive or introspective value of inner speech to its occurrence in a sensory format.

Langland-Hassan (2014) raises a different sort of challenge for inferentialist views. Recall that it is a common assumption of those views that propositional thought itself is amodal (i.e., non-sensory) and non-conscious. For theorists such as Carruthers, Prinz, Jackendoff, and Bermúdez, inner speech is a conscious mental process just because it has sensory features that render it the sort of state that is apt to be conscious. Langland-Hassan argues that there is a conflict in holding that an episode of inner speech is a single mental state with both sensory features (relating to the representation of phonemes) and semantic features (relating to the meanings of the corresponding words). If this criticism is correct, it creates problems for the proposal that inner speech is especially well suited (due to its sensory character) to serve as input to inferences about one’s non-conscious mental states. Bermúdez (2018), Carruthers (2018), and Munroe (2023) have articulated different ways of responding to this challenge (see also Prinz 2011 for relevant remarks).

6. Auditory Verbal Hallucinations and Inserted Thoughts
Inner speech features prominently in philosophical and cognitive scientific discussions of auditory verbal hallucinations (AVHs) and thought insertion. Both are common symptoms of schizophrenia but can occur in other contexts (e.g., brain injury, drug use) as well. AVHs are hallucinatory experiences of another’s speech, while thought insertion is understood either as a non-veridical experience of having someone else’s thoughts in one’s mind (Wing et al. 1990), or simply as the delusional belief that someone else’s thoughts are in one’s mind (Andreasen 1984). Two central questions explored by theorists are, first, whether (abnormal) inner speech is indeed the basis of AVHs or thought insertion, and, second, what might lead an episode of inner speech to be experienced as an AVH or inserted thought.

On the first question, an initially plausible approach to AVHs is to hold that they are more a matter of hallucinatory speech perception than of (unwitting) speech production, and thus not well conceived as episodes of inner speech. Wu (2012) and Cho & Wu (2013, 2014) advance a theory of this kind, holding that AVHs result from the spontaneous activation of speech perception areas in the brain. On their account, inner speech—and, in particular, the neural regions implicated in speech production—are not implicated in AVHs. Despite the attractive simplicity of this account, most researchers have pursued options that explicitly involve inner speech, for several reasons. First, in formal surveys, patients often report that the phenomenological characteristics of their AVHs are different from those of hearing speech, insofar as their AVHs are not as subjectively “loud” as cases of hearing speech, are not equally rich in sensory features, and do not always seem to emanate from outside the head (Stephens & Graham 2000; Hoffman et al. 2008; Laroi et al. 2012; Nayani & David 1996; Stephane 2019). It appears that an explanation of the seemingly “alien” nature of these episodes, as well as of thought insertion, will require some other apparatus than an appeal to perception-like phenomenology. Given the need for such an alternative, one may hope to extend it also to cases of AVHs that are reported as having rich, perception-like phenomenological features (Langland-Hassan 2008; Moseley & Wilkinson 2014).

Second, neuroimaging has shown activation in both language perception and language production areas when patients are experiencing AVHs (Allen, Aleman, & Mcguire 2007; Allen, Modinos, et al. 2012; Bohlken, Hugdahl, & Sommer 2017). Here as in other areas of the study of inner speech, it is important to recognize that the neural regions underlying speech production (such as Broca’s area, in the left inferior frontal gyrus) are distinct from those governing speech perception (such as Wernicke’s area, in the superior temporal gyrus). This is why damage to one area but not the other (as in some cases of stroke) can result in markedly different language impairments. The fact that the mechanisms governing speech production and perception are dissociable in these ways provides an important means for assessing whether AVHs are best viewed as productive or perceptual (or both) in nature.

Nevertheless, those who see abnormal inner speech episodes as the basis for AVHs or thought insertion face a difficult task in explaining what would lead a person to not identify their own inner speech as their own, or to not feel in control of their own inner speech. Some have offered content-based explanations, where it is some feature of the semantic content of the inner speech that leads a person to disown it. For instance, Stephens and Graham (2000) argue that a patient may disown inner speech episodes with contents that are “intentionally inexplicable”, in the sense that they are not easily accommodated within a coherent self-narrative (see also Roessler (2013), Sollberger (2014), Bortolotti & Broome (2009), and Fernández (2010) on the idea that AVHs or inserted thoughts are episodes with contents the patient is unwilling to endorse). Challenges for this approach are patient reports of voices that are helpful or encouraging. As the Swiss psychiatrist Eugen Bleuler notes in early work on people with schizophrenia, “besides their persecutors, the patients often hear the voice of some protector”, and, occasionally, the hallucinatory voices “represent sound criticism of the [patient’s] delusional thoughts and pathological drives” (1911 [1950: 98]).

A popular alternative approach—sometimes known as the “comparator” or “sensory feedback” approach—builds on work in cognitive neuroscience concerning the mechanisms by which bodily movements are determined to be one’s own (Feinberg 1978; Frith 1992; Miall et al. 1993; Wolpert, Miall & Kawato 1998). The basic idea behind these approaches is that, below the level of consciousness, the brain is continually generating predictions about the likely sensory consequences of planned actions, which are then compared with actual sensory feedback. When there is a mismatch between the prediction and sensory feedback, one may have the phenomenological sense of not being in control of one’s actions (Frith 2012). A number of authors have proposed that the generation of both inner and outer speech may be attended by the same kind of prediction and comparison mechanisms, and that the malfunctioning of these mechanisms could lead to one’s own inner speech seeming not to be in one’s control (Blakemore, Smith, et al. 2000; Campbell 1999; Langland-Hassan 2016; Proust 2006). These proposals derive some support from the fact that people with schizophrenia have been shown to have broader deficits in automatically anticipating and adjusting for the sensory consequences of their own actions (Blakemore, Smith et al. 2000; Blakemore, Wolpert, & Frith 1998).

Nevertheless, the comparator approach to AVHs and thought insertion has come in for criticism on several grounds (Synofzik, Vosgerau & Newen 2008; Vicente 2014; Vosgerau & Newen 2007). One complaint has been that the lack of sensory features associated with inserted thoughts, in particular, makes sensory-feedback approaches ill-suited to their explanation (Vosgerau & Newen 2007). In response, some defenders have shifted to pitching the thesis in terms of predictive processing models of perception and action (Gerrans 2015; Swiney 2018; Swiney & Sousa 2014; Wilkinson 2014; Wilkinson & Fernyhough 2017), while others have developed other alternatives (Langland-Hassan forthcoming). The matter of how best to characterize the phenomenology and underlying etiology of AVHs and thought insertion—and the relation of each to inner speech—together with the precise relationship between predictive processing models and the comparator approach, remain active areas of research. See Wilkinson & Alderson-Day (2016) for an introduction to an edited special-issue on the topic oriented at philosophers; see López-Silva & McClelland (forthcoming) for a philosophically-oriented anthology on thought insertion. (Note: Parts of this section draw on a more in-depth overview in Langland-Hassan 2021).

1. Varieties of Transformative Experience
Transformative experiences permeate our everyday lives—at least if we’re to believe the growing literature that has sprung up around this topic. To fully appreciate its significance, this section offers a brief, non-exhaustive sampling of various purported cases of transformative experience. It’s up to the reader to determine whether these examples qualify as transformative in the sense of the strict definition offered above. But perhaps more important than whether each of these qualifies, is the fact that considering whether they do raises important issues that help us better understand the myriad dimensions of our own lives.

1.1 Parenthood
Parenthood is Paul’s paradigm case of transformation (2014, 2015a). Prior to having a child, one cannot anticipate what it will be like to become a parent. Further, having a child changes the parent in a personally transformative way. Core preferences and life goals are often reshaped around a new priority: the child. The way the new parent sees the world and perceives terror and joy shifts. Zadie Smith (2013 [2018]) eloquently puts the previously unknown complexity of having a child thusly:

Occasionally the child, too, is a pleasure, though mostly she is a joy, which means in fact she gives us not much pleasure at all but rather that strange admixture of terror, pain, and delight that I have come to recognize as joy and now must find some way to live with daily. This is a new problem. (Smith 2013 [2018, 331])

And of course, the transformation associated with parenthood is not restricted to one’s first biological child. It extends to adopted children, and even can extend beyond humans to feline, canine, and other beings who depend on us and with whom we can bond.

1.2 Sense Modality and Sensory Experiences
Children who grow up in the United States rather than Australia generally don’t experience the distinctive taste of vegemite. People born with color blindness don’t see certain colors. Tasting vegemite and seeing color for the first time are radically new sensory experiences with distinctive phenomenal characters, and probably only involve epistemic transformation. Some people experience even more radical changes when they gain or lose a sense modality. Someone who has always been sighted or hearing cannot appreciate what it is like to be blind or deaf. Likewise, people who have always been blind or deaf cannot appreciate what it is like to be sighted or hearing. In addition to not knowing what gaining or losing a sense modality might be like, one cannot anticipate how that gain or loss might personally change them and the way they navigate the world. The fact that most of society is structured to accommodate sighted and hearing people increases the difference between a change in sense modality. And of course, appreciating the transformative nature of gaining a sense modality carries practical implications since many people are in a position to decide for themselves or others whether to gain a sense modality via surgical interventions.

1.3 Love and Relationships
Love has the power to transform us little by little. In fact, this incremental change is one of the fascinating features of love when put in the context of transformative experience (see Paul 2014). Smiling at a new acquaintance is not transformative, nor is grabbing coffee with them. Once you’ve had coffee, eating dinner together is not transformative either. On and on each step goes. Yet, by the end of things, when you look back at a relationship that’s decades long, you realize that you could not have imagined what it would be like to bond with another person in such an intimate way. The way you approached life, the preferences and life projects you developed, and the way love’s rose-tinted glasses filtered the way you see the world have radically changed you. On the flip side, ending this sort of relationship is also wildly transformative, especially if you’ve formed a sense of identity that revolves around your beloved. Furthermore, because it’s not clear that reason ever requires that you love someone in a romantic way, it’s difficult to explain how choosing love or rejecting it could be done rationally. Thus, opening oneself up to love or boldly ending it invites transformation and raises questions about whether doing so could ever be defended rationally.

1.4 Social Identity
All of us inhabit a place in society that’s determined in part by race, gender, sexual orientation, ability, religion, country of origin, education, socioeconomic status, political affiliation, and much more. Due to contingent but very real injustices, our place in society shapes our experiences. Sometimes, it’s possible to change our place in society (McKinnon 2015 discusses gender transitions and Barnes 2015 offers the fictional case of Pip from Great Expectations), and when we do so, that change is transformative. But the way in which these social changes are transformative underlines some troubling features these social divides have created. First, just as, for instance, Pip, cannot explain to his past self what social elevation is like, it is generally extremely difficult for people in one social group to communicate what it is like to be a member of that group to someone who is outside of it. This partially explains the phenomenon of situated knowledge and also gives rise to the possibility of testimonial epistemic injustice (see, e.g., Fricker 2007). Hermeneutical issues also arise. People’s self-conceptions aren’t developed in a vacuum, and shared norms and concepts contribute to the way in which one’s self-conception can develop, thus influencing the ways in which one can transform. For instance, “brave inspiration” is a readily available self-conception for disabled people while “thriving person in an unconventional body” is not—and this is an unjust state of affairs (Barnes 2015). Social identities and structures contribute an ethically rich dimension to the conversation on transformative experience.

1.5 Tragedy
Unfortunately, life also contains tragedies. The trauma of war leaves veterans and civilians physically and emotionally scarred in ways that can change their outlook on life forever. We aren’t morally perfect, and often fail in extremely regrettable ways. To top it all off, people die, sometimes after extended periods of pain and suffering. Experiences of negative valence are often epistemically surprising. There’s no way to predict what the death of a close loved one will feel like, even if the death is anticipated. Life’s tragedies also have the capacity to change who we are. Sometimes, this change can happen for the better. Cashman and Cushman (2020) suggest that although we don’t want to intentionally morally fail, moral failure can often teach incredibly valuable lessons and change how we act for the better. When it comes to death, dying creates a chasm of understanding between those who are dying and those who are not. Chung (2017 [Other Internet Resources]), a philosopher who wrote about his impending death, tells of the chasm that death opens up between those who are dying and those who are not. Truly acknowledging that one is dying changes your priorities and the way you experience the world in a way that can’t be explained to someone who isn’t dying. The same holds for someone forced to witness their beloved slowly fade away. Thompson (2020) offers an insightful meta-point, arguing that dying is an “ultimate” transformation because it forces us to adopt a perspective of our life as a whole that allows us to reconsider which of our prior experiences truly were transformative.

1.6 Ideology
Our beliefs shape who we are, and changes to our core beliefs have the potential to transform us. For instance, De Cruz (2018) and Chan (2016, 2019) argue that religious conversions are transformative. The mission statements of universities appear to acknowledge and strive for transformation among students (Paul & Quiggin 2020). Schwenkler (2020) and Stump (2020) both investigate the nuances of opening oneself up to ideological conversion in light of the potential for doxastic and philosophical transformation, respectively. Crucially, when ideological difference are too great, people lose the ability to adopt the perspective of others. This applies both intrapersonally, such as when we look back at our past selves and marvel at how we believed in Santa Claus, and interpersonally, which leads to the sort of breakdown we see in hyper-polarized political contexts. Speaking of politics, holding office or participating in politics in some deep way might also be transformative, both because they involve encountering people with different perspectives and also because they require representing them in a meaningful way (see Allen 2017). It’s tempting to think that changes in belief are merely epistemically transformative since they clearly change our epistemic states. But in the New Testament (Acts 9), Saul’s conversion on the road to Damascus into the Apostle Paul isn’t just a change in beliefs, it’s a deeper change that completely alters the way he lives his life. The scales falling off his eyes does not merely signify seeing the truth; it also represents a change to who he is.

1.7 Art and Fiction
Paul (2014) opens Transformative Experience with thought experiment about transforming into glamorous, slightly murderous, creatures of the night: vampires. Obviously, none of us actually face this choice. However, rhetorically, thinking about turning into a fictional creature helps motivate the idea that doing so would be both epistemically and personally transformative. After all, who can say for sure what becoming a vampire would really be like or how it would change a person? Furthermore, this case reveals something further about the connection between fiction, art, and transformative experience. It could be that art is transformative—or at least quasi-transformative—because it helps us understand things that we have not (or cannot) experience (Aumann 2022). Furthermore, art and fiction might be transformative from the perspective of the creator as well as the audience. For instance, the expression of oneself through art may be a transformative experience (Riggle 2020). Finally, art clearly involves our imaginations, and imagination may provide a way to gain knowledge about what a transformative is like prior to experiencing it. (More on this in §2.)

2. Epistemology: Can We Know What It’s Like?
Epistemically transformative experiences are experiences where one cannot know what they are like before having them. In the paradigm case of parenthood, the experience of becoming a parent for the first time has “an epistemically unique phenomenal character” (Paul 2015a, 157). One cannot know what these are experiences are like prior to having them.

Prior work, such as Jackson (1986), provides support for this epistemic claim. Jackson’s “What Mary Didn’t Know” invites us to engage in a thought experiment about Mary, a person who has lived in a black and white room her entire life. Prior to encountering color, can Mary know what it is like to see the color red? Does it matter whether Mary is a color scientist who has studied the physics of color and read extensive testimonies about what the color red is like? Jackson’s objective—to show that physicalism is false because it cannot give us knowledge of qualia—applies to transformative experience as well. In general, experiential, or “what it’s like”, knowledge cannot be obtained prior to experience. Thus, what transformative experiences are like cannot be known without having the relevant experience.

Many philosophers reject the claim that one cannot know what transformative experiences are like prior to having them. These rejections tend to center upon one of two strategies. First, one might turn to paradigm cases such parenthood and offer reasons to believe that one can in fact know quite a lot about what it’s like to be a parent prior to becoming one. For instance, Harman (2015) argues that caring for a significantly younger sibling in a quasi-paternal way or witnessing a close friend or family member become a parent provides at least some evidence regarding what becoming a parent is like. Krishnamurthy (2015, 180) offers a similar suggestion, arguing that “we can on the basis of experiences of similar types know what it is like to have a child”. For instance, babysitting or raising a cat shares common elements with parenting. Knowing what these elements are like allows one to know something about what being a parent is like.

Sharadin (2015) offers a variation of this type of strategy that focuses on non-phenomenal elements of parenthood. For instance, becoming a parent typically involves things like financial and sleep deprivation, and we can know that becoming a parent typically involves these things. Plausibly, there is a supervenience relation between these non-phenomenal elements and an agent’s phenomenal experience of them. Further, many people, such as philosophy graduate students, are intimately familiar with the phenomenal experience of financial and sleep deprivation. By building upon the non-phenomenal elements that parenthood shares with other experiences a person has had, that person can develop an idea of what parenthood is like prior to actually experiencing parenthood.

Some empirical research work focusing on how people model uncertainty suggests that people do in fact attempt to use this first strategy of building on what one knows to figure out what one does not know. Zimmerman and Ullman (2020, 73) model epistemic uncertainty and purportedly demonstrate that “people can make informed decisions about trying unfamiliar things”. For instance, suppose that someone encounters an unfamiliar yellow grape. Though they wouldn’t know what the yellow grape is like, they might appeal to their knowledge of what green and red grapes are like to form a judgment about what the yellow grape might be like. At the very least, it seems like they are justified in believing that the yellow grape will not wildly diverge from their other grape experiences. Based on this information, they can rationally choose to try the yellow grape. Even if they are completely unfamiliar with grapes, they might use their knowledge of other fruits to form an informed decision. In general, novel experiences fall into a taxonomy of the types of experiences one might have, and agents can use the next closest experiences to project what the novel one might be like.

Even if this strategy is successful, it’s unclear that it shows that we can know what transformative experiences are like prior to having them. Recall that transformative experiences are supposed to have “unique phenomenal character” (Paul 2015a, 157). If one knows enough about what the experience is like, then it’s not in fact transformative. For instance, Paul (2015b) responds to Harman’s case by suggesting that through having similar enough experiences, Harman might in fact have known what becoming a parent is like. Thus, becoming a parent for the first time would not have been transformative because the relevant transformative experience already occurred earlier. Whether a type of experience is transformative may be agent-relative. Furthermore, while this strategy is promising, some cases may still elude it. For instance, when it comes to gaining or losing a sense modality, it really does seem that the pre-transformed person cannot have any relevantly similar experiences.

The second strategy does not deny that we often don’t know what transformative experiences are like. Rather, it locates our experiential ignorance in a lack of imagination rather than an in principle difference in types of knowledge (i.e., propositional and experiential knowledge). Kind (2020), for instance, argues that the difference between projecting what transformative and non-transformative experiences amounts to a difference of degree rather than kind. Plausibly, it’s possible to imagine what it’s like to babysit for the first time. Further, imagining what it’s like to be a first-time babysitter might be easier than imagining what it’s like to become first-time parent. For someone with a sufficiently good imagination—and our imaginative abilities do also come in degrees—one can gradually scale up from the babysitting experience to the experience of becoming a parent. It may even be that we can augment our imaginations through aids such as art and thus approximate what foreign experiences are like (see Aumann 2022). The effectiveness of artistic aids as well as the understanding gained from them also plausibly admit of degrees. Thus, the imagination strategy can explain why it’s easier to figure out what some experiences are like than others, and why this can vary from individual to individual. Since paradigm transformative experiences tend to be among the most difficult to imagine, positing distinct “what it’s like” knowledge is tempting. However, the difficulty in imagining what paradigm transformative experiences are like merely generates the appearance of a distinct kind of knowledge. The upshot is that in principle, we can know what a transformative experience is like prior to experiencing it.

Arpaly (2020) offers a wrinkle on the imagination strategy, blaming our “crappy” imaginations for our inability to project what transformative experiences are like. Sometimes, what an experience is like is opaque because the “devilish details” of the experience simply haven’t occurred to us. For example, most people have not considered that if a giraffe were to drink coffee, the coffee would cold by the time it reaches the giraffe’s stomach. Other times, we overestimate our ability to imagine things, and our overconfidence prevents us from accepting testimony or other evidence that would be illuminating. These cases can be tragic, such as when a depressed person’s family doesn’t believe their reports of depression. The failure to correctly imagine what things would be like thus causes it to appear as if our lack of experience is the problem, since experience would quickly correct this misimpression. Crucially, there is nothing special about the “what it’s like” quality of these experiences. Though we are ignorant, we are not in principle ignorant and could theoretically figure out what the transformative experience would be like.

Like the first strategy, this second one is most vulnerable when it comes to extreme transformations in experience such as gaining or losing a sense modality. One might also wonder whether the second strategy significantly undermines the core epistemic claim: that one cannot know what transformative experiences are like prior to having them. Even if there is no in principle difference propositional and “what it’s like” knowledge, it does seem like imagination-based responses do acknowledge that some experiences elude our imaginative abilities.

Finally, Moss (2018) offers an interestingly different defense of the claim that we cannot know what a transformative experience is like prior to having it. Moss argues that we often have “probabilistic knowledge”. For instance, suppose that 50% of the people who experience childbirth report that the experience is miraculous. Based on that, it seems reasonable to conclude that there is a 50% chance that experiencing childbirth is miraculous. While an individual can’t know that the experience will be miraculous for them, it does seem that they can know that there’s a 50% chance that the experience will be miraculous for them. But crucially, before one knows that probabilistic claim, one must know that they aren’t exceptional. For instance, suppose it turns out that of the people who decline epidurals, only 10% of them report that the childbirth experience is miraculous. If one is going to decline an epidural, then they do not know that there’s a 50% chance the experience will be miraculous since they are part of a group—what Moss (2018, 173) calls “an alternative reference class”—for whom the probability does not apply. Furthermore, those who can’t rule out that they are in the alternative reference class (in this case, perhaps those who are unsure of whether they will have an epidural) also lack probabilistic knowledge. Plausibly in the case of parenthood and other transformative experiences, probabilistic claims can be formed based on testimony gathered from those who have had the experience. However, it could be that among those giving the testimony, there is significant variance that’s based on whether individuals belong to an alternative reference class. Given the nature of transformative experience, it may be unobvious whether a particular individual has a trait that places them into an alternative reference class. Thus, even if there’s ample data regarding how likely it is to have a particular parenting experience, that won’t result in probabilistic knowledge of what it’s like to be a parent. This defense also works even if it turns out that there isn’t a distinctive “what it’s like” knowledge and our imaginations can sometimes help us understand what foreign experiences are like.

3. Metaphysics: Can I Become Someone New?
Personally transformative experiences are ones that change who an agent is. Certainly, there are epistemic elements associated with personal transformation: agents may not know how an experience will personally transform them and they won’t know what it’s like to be transformed. There might also be de se knowledge, or self-locating knowledge of the kind that occurs when one knows who or where one is within a world (see Lewis 1979). Significantly for the context of transformative experience, de se knowledge can apply to a temporal part of a person, so it’s possible that someone who undergoes a transformative experience will “locate” themselves as being the person who results from the transformation, while their earlier self would have lacked this de se knowledge since they may not have taken the future, radically transformed person to be themselves. In any case, many of the considerations in the previous section apply to these epistemic elements. However, personal transformation also introduces interesting metaphysical issues, and this section focuses upon those.

Paul describes the situation as being one that “radically changes what it is like to be you, perhaps by replacing your core preferences with very different ones” (Paul 2015a, 156). Life goals, core preferences, or the way one experiences the world may constitute part of the change that occurs. Ullmann-Margalit (2006, 159) adds that because our beliefs and desires shape the core of who we are, changes to them turn us into a “different person”. There’s also a terrifying sense of finality since these personal transformations are “irrevocable” (Ullman-Margalit 2006, 160) or at least potentially irrevocable. This picture painted by Paul and Ullmann-Margalit is sometimes characterized as a “Replacement Model” (see Lambert & Schwenkler 2020b, § 5) because the agent contemplating undergoing transformation ends up “replaced” by the transformed person. There’s supposed to be a literal sense in which the pre-transformation agent ceases to exist.

Spelling out the sense in which the agent no longer exists is tricky. Focusing on core features is one natural way to explain the difference between the pre-transformed agent and future transformed person. Perhaps when enough core features are lost, the pre-transformed agent ceases to exist. (In essentialist language, perhaps some of these core features are essential, or such that the agent cannot survive the loss of them.) There’s an open question regarding which of our features count as core in this way, and some empirical studies suggest that we at least do regard some our features as being essential in this way. Molouki, Chen, Urminsky, and Bartels (2020) have done empirical work to see whether people exhibit semi-uniform views about which features are central to their selves. Their findings support earlier work by Strohminger and Nichols (2014) suggesting that features concerning morality (e.g., character traits) and personality are taken to be most central. Changes that are perceived as most drastic involve morality and personality, as well as features that are taken to be causally central. For instance, if someone takes “being a philosopher” to be causally central to how they navigate the world, then they tend to regard losing that feature as a drastic change. Valence and desires also matter: people take negative and undesired change to be more drastic. The explanation for asymmetric valence and desire perceptions rests upon the fact that people project their future selves to undergo positive development, so negative and undesired changes lie outside their self-conception. These finding cohere with many of the sorts of personal transformations that constitute personal transformations.

A second sort of claim that’s frequently made is that the pre-transformed agent cannot identify first-personally with the future transformed person, and vice versa. For instance, Velleman (1996) draws a distinction between imagining what Napoleon saw when looking out at Austerlitz and imagining oneself as Napoleon looking out at Austerlitz. The latter removes all first-personal traces of the imaginer (and is likely impossible to do). Paul (2017) makes a similar claim when distinguishing between affective and cognitive empathy. The former involves projecting our current selves into potential future scenarios, like if I imagine what it will be for me (a childless person) to have a child. It’s akin to the way we empathize with others. The latter is much richer, and it involves experiencing the potential future from the perspective of the future, rather than current self. To cognitively empathize with my future self who has a child, I would have to put myself into the first-personal experience of that person who now has the preferences and perspective of a parent. According to Paul, I lack the ability to cognitively empathize with my future parent self because that self is too unrelated to my current self. In general, we are not able to empathize with our distant future selves, even if those selves haven’t undergone a dramatic transformation. If Velleman and Paul are right, then the severing of the first-personal perspective and empathy that occurs after transformation is one way in which the pre-transformed agent ceases to exist.

Finally, it’s helpful to take a step back and consider the ways in which the future-transformed person is a different person. Suppose that losing central features and a disconnect in first-personal perspective are sufficient for replacing the pre-transformed agent with a new person. How do we explain the connection between the future and past person? On the replacement theory, transformative change results in a new person. Can we coherently say that the pre-transformed person has become the new person? Or does transformation annihilate and replace them?

The trick to explaining how one can become someone new without being annihilated involves articulating two different senses of “sameness”: one in which the past and future persons are the same and one in which they are not. For instance, Glazier (2020) notes that the type of explanation demanded mirrors a debate about whether contingentism is a coherent view. On contingentism, it’s possible that I (or anyone else) could be someone else. Philosophers who champion the necessity of identity tend to reject this claim as straightforwardly absurd. To explain how their account is coherent, the contingentist must identify two senses in which identity claims are necessary. Glazier’s suggestion rests on the claim that that no one’s perspective is impossible. Roughly, there’s a proprial, or perspectival, sense in which a claim like “I am Fred” is necessary. It’s necessary from “I’s” perspective that they are Fred because from their perspective the world is centered upon both the “I” and “Fred”. However, it’s possible that the world could have centered on someone else, say Georgia. In that case, there’s a non-proprial sense in which “I” should have been Georgia. This latter, non-proprial sense in which “I should have been Georgia” generates the contingency of identity.

Chan (2019) offers a different account on which the past and future persons might be the same metaphysically speaking, but different in terms of their practical identities. These practical identities are characterized by the traits that are changed in personal transformation: core preferences, life goals, ways of navigating the world, continuity of first-personal identity, and the like. Importantly, these traits form the person’s self, or at least the self that’s relevant for considerations of self-interest. This explains why ordinary decision-making procedures have difficulty when it comes to transformative experiences. (More on this in the next section.) Furthermore, distinguishing between metaphysical and practical senses of sameness explains the (practical) sense in which the person becomes someone new and the (metaphysical) sense in which they endure and are not annihilated.

4. Decision Theory: Is It Rational to Choose Transformative Experiences?
Transformative experiences present several challenges for traditional models of decision theory. First, the epistemically transformative component of the transformative experience involves a lack of “what it’s like” knowledge. Purportedly, this in turn involves a type of uncertainty that is different from the type of uncertainty decision theory is designed to handle. Second, the personally transformative component means that the post-transformation person may be extremely different from the pre-transformed person. Their preferences may radically change in unpredictable ways, and decision procedures must find a way to accommodate these changing preferences. Third, the personal transformation may be so extreme that the pre-transformed person considering whether to undergo the transformative experience can’t make the decision in the straightforwardly self-interested way that’s presupposed in standard decision-making models. Any of these challenges make using decision-making procedures impossible in the case of transformative experience. And if that’s the case, then it looks like one can’t rationally choose to undergo a transformative experience—the choice is either arational or irrational. Given that so many of our momentous choices in life involve potentially transformative outcomes, it would be disturbing if we discovered that these choices could not be made rationally.

4.1 “What It’s Like” Uncertainty
Standard decision models take probabilities and values as inputs and produce expected values as outputs. For instance, suppose ESPN’s outcome predictor projects the Kansas City Chiefs as having a 50% chance to win the Super Bowl, yet the moneyline, which is based on betting activity, is +105 (meaning that if you bet $100 on them and they win, you receive $105 in winning plus your initial $100 wager). By weighting the possible outcomes with their corresponding probabilities, we can calculate the expected value of betting $100 on the Chiefs:

.5
(
105
)
+
.5
(
−
100
)
=
2.5
If one uses a decision procedure where one maximizes expected value, it’s rational to bet on the Chiefs since betting $100 has an expected value of $2.50 while not betting has an expected value of 0 since there are no gains or losses. There are other decision procedures one might use as well. For instance, one might prefer a maximin procedure, in which one chooses the option with the best worst outcome. Since the worst outcome of betting on the Chiefs is losing money and the worst outcome of not betting is neither gaining nor losing money, not betting is the best worst outcome. Thus, a maximin procedure would recommend not betting. Crucially for our purposes, it doesn’t matter which decision procedure one utilizes. Rather, what matters is that values and probabilities (or at least possibilities) are required for any decision procedure to operate.

On the first challenge for decision theory, transformative experiences are epistemically transformative, and agents do not know what the experience will be like. What an experience is like determines the value associated with the experience. At the most basic level, part of what an experience is like involves the pain or pleasure of the experience. Pain detracts from the value of the experience while pleasure enhances it. More complex components of what the experience is like also affect the value of the experience. While some other factors—such as moral or social ones—may affect the value of the experience, what the experience itself is like clearly plays a large role in determining value. Without knowing what the experience is like, agents can’t reliably project its value. If the value of the experience is not known, then the value of any outcome involving transformative experiences also remains unknown. Thus, an agent choosing between options that may involve transformative experience cannot use standard decision procedures since those procedures require values as inputs.

This purported challenge is highly contested. Recall from §2 that many philosopher reject the claim that experiences like parenthood are epistemically transformative (e.g., Harman, Krishnamurthy, etc.). Denying that the experiences are epistemically transformative means that agents can know something about what the experiences are like prior to having them. For instance, the testimony of parents or the non-phenomenal elements of the experience might provide some sense of what becoming a parent is like. If that’s right, then perhaps at least rough values can be used in a decision procedure.

Alternatively, one might grant that we can’t know anything about what transformative experiences are like. Nevertheless, one might still be able to use standard decision procedures since we may know about the values associated with the experience even if we don’t know what the experience is like. For instance, Dougherty, Horowitz, and Sliwa (2015) invite us to consider a mystery box. Everyone who looks into the mystery box has a positive experience, though they cannot describe what the experience is like. On the basis of this information—that the value associated with the box is always positive—one can rationally choose to look in the box without knowing what that will be like.

Similarly, knowing the valence of outcomes can often provide rational grounds on which to make a decision even if what the outcome is like is unknown. Pascal’s Wager offers one such scenario: the infinite positive value of eternal happiness swamps any finite value. Thus, one is rationally justified—or perhaps even required!—to try to believe in God. McKinnon (2015) offers the opposite sort of case by inviting us to consider an individual considering transitioning. Prior to transitioning, many trans people suffer from severe depression and are at risk of suicide. Even if they do not know exactly what it will be like to transition, the alternative is sufficiently horrible, and thus the decision to transition can be rational.

Paul (2015b) suggests that all these responses miss the mark. First, people who choose transformative experience purely on the basis of values without knowing what the experience will be like are not choosing on the basis of what the experience is like. Of course, it can often be appropriate to make choices without considering what the outcomes will be like—cases involving moral stakes are one such scenario. However, in many paradigm cases such as parenthood, agents often do envision what their future lives will be like and base their decisions, at least partially, on that vision. Second, Paul emphasizes the importance of the values being subjective, or assigned by the agent. Because decisions involving transformative experience are personally significant, agents need to make the choice authentically. On Paul’s account, authenticity requires that the agents themselves ascribe value to the experience. (More on authenticity in §5.) Thus, testimony from others about the values they’ve ascribed to an experience won’t help an agent choose authentically for themselves.

4.2 Future Preference Uncertainty
Suppose that the approximate values of associated with outcomes can be known. The second challenge for standard decision theory procedures arises from the fact that transformative experiences have the potential to be personally transformative. Since personal transformation can involve extreme preference changes, the way outcomes are valued might not remain stable from before and after the transformation. For instance, a prospective parent might not value sleep, but once they become a parent confronted with a screaming infant that needs to be fed every few hours throughout the night, the way they value sleep may drastically shift. The values of outcomes used as inputs typically correspond to the preferences of the pre-transformed agent making the decision. If those preferences will shift unpredictably post-transformation, then knowing the values associated with the outcomes still may not be enough to allow an agent to make a rational decision.

In some sense, the challenge of changing preferences blends two familiar problems. First, preferences change over time. For instance, people with the means to save for retirement must balance their current preferences with what they believe will be their future ones. An extreme saver’s later self may look back and wish their earlier self had spent more on vacations. Transformative experiences add a further wrinkle by making the future preferences unknown. Second, changing preferences present a diachronic problem in which past, present, and future preferences must be balanced against each other. Presumably, this balancing involves aggregating all of these preferences, as well as deciding how to weigh them. For instance, many people are near-biased, and tend to weigh the preferences of their current and near-future selves far heavier than the preferences of their distant-future selves. The preferences of past selves rarely receive any attention at all. (Parfit [1984] has a series of thought experiments generating the intuition that it’s better for pain to be in the past, even if past pain is more severe than future pain. Sullivan [2018] and Boonin [2019] offer uncommonly held dissenting views: the former argues for temporal neutrality, or not engaging in any temporal discounting of the past or distant future, while the latter argues that the past preferences—even those belonging to people who are no longer alive—matter.)

Pettigrew (2019) offers a sophisticated account that has two components aimed at tackling both of these problems. The first, aimed at the uncertainty surrounding what the future preferences will be, bears similarity to responses to the challenge of assigning values given the “what it’s like” uncertainty. Basically, just as we can gather information about how people value transformative experiences, we can gather information about how people’s preferences change after undergoing transformative experiences. In an oversimplified example, if it turned out that 95% of new parents would prefer to be childless again, then given that one chooses to have a child, there would be a 95% chance that their future self would have the childless preference while there’d be a 5% chance that their future self would have a child-full preference. Then, just as decision procedures weigh the values of potential outcomes by their likelihood when we make decisions, they could include weighted preferences.

The second component, aimed at tackling the diachronic aspect of changing preferences, introduces a weighted general value function that aggregates the “local” value functions that correspond to the past, present, and future selves that make up the entire life of the agent. Further, the way in which the local value functions are aggregated can incorporate differences in the ways in which local selves handle probability assignments, decision procedures, and the weighing of, e.g., past versus future preferences. Aggregating the local value functions thus begins to resemble a social choice problem. Agents faced with choosing for changing selves ought to maximize the general value function, which aggregates the local value functions accounting for each temporally located local self.

Paul (2022) points out that Pettigrew’s account is vulnerable in two ways. First, the type of solution proposed by Pettigrew likens future selves to third parties. As noted, the weighted general value function closely resembles functions that aggregate individual preferences to group ones in social contexts. But it seems inappropriate to treat our future selves as third persons instead of fully integrated selves—and this is precisely the thrust of the problem that transformative experience presents! Second, it assumes that meaningful intrapersonal comparisons can be made. There’s some empirical work, especially regarding how people with disabilities judge their own welfare, that suggests these comparisons are difficult to make. Pettigrew (2019, § 8.6) attempts to address this issue with his “matching intervals solution”, which attempts to scale the different utility functions to each other. Briggs (2015) offers a prudence-inspired alternative that rests on privileging a person’s actual preferences (as opposed to their counterfactual preferences) without privileging their present preferences (as opposed to privileging present over future ones). Though success of any of these intrapersonal comparisons is an open question, there is widespread agreement that they are necessary to explain how future preferences can matter.

4.3 Self Uncertainty
Finally, the personally transformative aspect of transformative experiences creates the possibility of future selves who are so different from their pre-transformed selves that neither the earlier nor later selves regards the other as being “the same” person. As Ullmann-Margalit (2006, 158) puts it, “big” decisions are “core-affecting” and “transform one’s future self in a significant way” such that one emerges from the situation a different person. As we saw in §3, spelling out the exact sense of in which one can become a different person is tricky. However, examples illustrate how one might regard a temporally related self as a different person, and shed light on the exact nature of the problem for standard decision-making procedures.

Parfit (1984, 326) tells the story of a young Russian who holds his socialist ideals close to his heart. The young Russian also happens descend from the aristocracy, and stands to inherit a fortune when his relatives die. He realizes that when this happens, he may lose his socialist ideals. His instructions to his wife—“if I lose these ideals, I want you to think that I cease to exist”—reveals that he regards that potential future self as a different person. This type of example reinforces Paul’s (2017) claim that we cannot first-personally project into futures that are too distant or different. Agents who fully appreciate the personally transformative element of transformative experiences realize that these experiences may potentially transform them into someone different. Thus, from the perspective of the agent deciding whether to undergo a transformative experience, they must treat outcomes involving transformation as ones in which they may no longer exist.

The possibility of non-existence (or something regarded as equivalent to non-existence) means that even if an agent knows all the fact about value and future preferences, they cannot use standard decision-making procedures in a straightforward way—at least not if they’re self-interested. After all, even if a future transformed self would be incredibly happy and live a good, meaningful life, that doesn’t help the agent contemplating transformation if that future transformed self is not them in the relevant sense. Chan (2019) makes exactly this point in the context of Pascal’s Wager. The infinite happiness of the believer doesn’t benefit the non-believer precisely because becoming transformed by faith would change them into a different person (which in turn undermines the Wager’s appeal to self-interest). This point is closely related to the challenge raised by Paul for Pettigrew’s view in the previous subsection (§4.2). The future self is alien, and though there might be some decision procedure by which to make a rational decision to bring about that future self, that procedure is not the one related to the sense of self-interested that is under discussion.

A response to this challenge requires choosing in a way that bridges the gap between the pre-transformed agent and the future transformed self. Given the nature of transformative experience, it’s difficult to see how this could occur precisely since the pre-transformed agent lacks the ability to connect in the right way to the future transformed self. That connection goes beyond knowing the relevant values, probabilities, and value functions. It gets at the agent’s ability to choose authentically, to which §5 turns.

4.4 Reasonable, Not Rational
Finally, it’s worth considering the possibility that rational choice is simply not possible when it comes to transformative experience. Ullmann-Margalit and Morgenbesser (1977) discuss “picking,” which is characterized by indifference between alternatives, such as when one pick's between cans of the same flavor of Cambell's soup. By stipulation, picking can't appeal to values, preferences, or the sense of rationality discussed above—those things undertermine which alternative is optimal, which gives rise to the indifference in the first place. Importantly for Ullmann-Margalit and Morgenbesser, picking extends beyond trivial “Cambell's soup” choices to bigger ones, including transformative experiences. Even our values and preferences themselves (assuming we have control over them) may be subject to picking, since it's would be circular to appeal to them in order to explain why we hold them. Thus, many of our major life decisions, including potentially transformative ones, are subject to picking, rather than rational choice.

Continuing this line of thought, Ullmann-Margalit (2006) suggests that rather than focusing on acting rational in the sense of “optimizing” (as one does with standard decision-procedures), one ought to focus on “acting reasonably”. For instance, transformation involves both discontinuity in one’s life as well as a point of no return. A reasonable way of navigating choices that involve these two features involves attempting to minimize those features. For instance, a person contemplating a transformative decision like marriage might try to ease into it by first moving in with their potential spouse. Doing so minimizes the discontinuity and gives them an out, which makes the decision revocable. If Ullmann-Margalit is correct in suggesting that one might be able to build up to a transformative experience little by little, this raises an extremely interesting question for transformations that unfold gradually over time. Is it possible that each incremental step can be made rationally while a giant leap to transformation cannot be made rationally?

5. Existentialism: Choosing Authentically
Investigating decisions involving transformative experiences magnifies an existential problem as well. Recall from §4 that many of the strategies for making rational transformative decisions fail to also preserve authenticity. When transformation is on the table, who we are is at stake. And the choice of who we are is more fundamental than the other types of decisions we make. Who we are provides the framework from which we make other choices, so a choice that could change who we are is a choice between frameworks that itself lacks a framework from which to deliberate. As Ullmann-Margalit puts it:

At bottom, we make our most fundamental choices of the canons of morality, logic and rationality in total freedom and without appeal to reasons. They embody acts that this literature variously describes as nihilist, absurd, or leaps (of faith). (2006: 172)

On the flip side, what “this literature” does permit is authentic choice. For instance, deciding to transform without appealing to reason (perhaps because one cannot appeal to reason) coheres well to the Sartrean idea that persons do not antecedently have a particular telos. Rather, we are free to be our authentic selves precisely because are unconstrained and can choose who we want to be.

On this existentialist gloss, authenticity stands in tension with rationality when it comes to transformative experiences. On the one hand, we want to be able to rationally defend our big decisions to have a child, marry a particular person, or commit to a vocation. But on the other, these are the types of decisions that we also want to make authentically, and that doesn’t seem possible if we’re merely following what a decision procedure recommends. In fact, empirical research suggests that people do care deeply about authenticity. Furthermore, people approach decisions perceived to involve authenticity differently from more ordinary ones. Oktar and Lombrozo (2022) gave subjects vignettes in which deciding based on “deliberation” (which was akin to standard decision making) conflicted with deciding based on intuition. For instance, one scenario involved picking between two people with whom to pursue a romantic relationship. One person is a better “on paper” match, and it’s stipulated that you believe the method that determines them as such is accurate. The other person is one with whom you vibe with better in that sort of intangible, gut-feeling sort of way. Subjects leaned strongly toward pursuing a relationship with the latter person (the “intuition” choice) instead of the former (the “deliberation” choice). They also perceived this case as one that involves authenticity. In fact, when a choice was perceived to involve authenticity, subjects favored intuition-based decisions over deliberation-based ones. The preference of for intuition over deliberation raises the question of whether there are non-deliberative (in the sense of standard decision-making) procedures that can help us choose in transformative decisions in a way that preserves authenticity.

In fact, there are accounts that purport to preserve authenticity while also preserving rationality. Paul (2014) favors choosing on the basis of revelation. According to Paul, the decision should be reframed as one that asks whether the agent wants to discover what life will be like and who the agent will become, post-transformation. Essentially, the agent chooses transformation for its own sake. In doing so, the agent chooses rationally by choosing in accordance with the preference for discovery. The agent also chooses authentically by choosing based on the desire to know what the experience will be like for them and who they will become once transformed. The problem is that choosing based on revelation does not always seem appropriate given the import of many transformative experience. For instance, many transformative experiences involve other people, such as becoming a parent or marrying someone. Choosing these experiences on the basis of revelation fails to capture concern for the resulting child or the future spouse. Paul might respond that this objection to revelation is a moral one, and that a similar objection could be levied if the choice were made on the basis of self-interest. Thus, the objection might not count specifically against revelation. However, there’s a second worry, which is that revelation doesn’t help in cases where the decision lies between two transformative outcomes as opposed to a decision between the status quo and one transformative outcome.

Callard (2018) picks up on this last worry and points out that revelation for its own sake lacks a mechanism for valuing different revelations differently. Instead, Callard favors an account based on aspiration and proleptic reasons. For Callard, proleptic reasons are provisional ones aimed at a good to which one aspires but may only have an “inchoate, anticipatory, and indirect grasp”. For instance, someone who aspires to be a wine connoisseur initially lacks any conception of what they are trying to appreciate or experience when they take a sip of wine. Importantly, proleptic reasons allow the aspirant to act rationally when they start the process even though they lack knowledge of what the end goal is like. Interestingly, these types of cases typically lack the sharp discontinuity that are associated with paradigm transformative experiences like parenthood. In fact, Callard suggests that parenthood is not as discontinuous as assumed because potential parents often dedicate a lot of mental energy to the decision and learning all they can about parenthood. What appears to be a climactic “let’s go for it” is “embedded in a longer transformative journey” (Callard 2018, 63). Putting all of this together, transformative decisions can be made rationally via proleptic reasons and are authentic since they result from intentional deliberation about who the agent hopes to become.

Chang (2015) offers an interestingly different way of approaching transformative decision making. Chang starts by distinguishing between event-based and choice-based transformations. The former are the type that fit how transformative experiences are typically described. They involve experiences that are downstream from the choice—like becoming a parent—that transform the agent. The latter is where Chang’s interest lies. Choice-based transformation is one in which “the making of the choice itself transforms you” (Chang 2015, 240). Here, Chang has in mind cases in which one invokes voluntarist reasons when making a decision. Voluntarist reasons are reasons generated by the will that—on Chang’s account—are appropriate when all other existing reasons underdetermine what an agent ought to do. (Chang favors an account in which the will strengthens an existing reasons, but there are other voluntarists like Korsgaard (1996) who hold that the will can create reasons ex nihilo.) Crucially, in willing a voluntarist reason, one simultaneously reveals themself to be the type of person for whom that choice is rational. This type of account also appears to preserve authenticity (since what could be more authentic than one’s own will) and rationality (since adding the voluntarist reason to the mix tips the scales in favor of the choice that’s been made). Of course, voluntarist accounts are somewhat controversial, so Chang’s account of how to make transformative choices would inherit all the worries that voluntarism does.

Although these accounts—Paul’s, Callard’s, or Chang’s—all face worries, it is worth noting that if any of them work, then there is a way to preserve both authenticity and rationality even while respecting the original challenge of transformative experience to standard decision making procedures. None require knowing what the experience will be like or who will come out the other end. Nevertheless, one can still rationally and authentically plunge into the unknown.

6. Applied Ethics: In Light of Transformation, How Should We Treat Others?
Transformative experiences also demand that we revisit how we treat others in light of the fact that they potentially may undergo transformative experiences. As seen in §1, transformation may arise in many contexts, far too many to attempt to tackle here. Instead, this section will focus on three types of contexts in which the issue of how we should treat others given the possibility of transformation might arise: when we choose for others, when we make long-term decisions involving others, and when we create environments that (dis)favor transformation.

6.1 Choosing for Others
Plausibly, it’s wrong to interfere with the autonomy of others, especially when it comes to important personal decisions. As Akhlaghi (2022, 7) points out, interference is even less defensible when others are choosing to undergo transformative experiences because there is a

moral duty not to interfere with the autonomous self-making of others, through their choosing to undergo transformative experience to discover who they will become.

However, people often find themselves in situations in which they need to make decisions on behalf of others that may lead to transformative experiences. In fact, those who take the leap and become parents then find themselves in a position to make transformative decisions on behalf of their children. For instance, some parents of deaf children must decide whether to get cochlear implants for their child. Ideally, children receive these implants when they are extremely young, usually before the age of three. The early age at which the decision must be made forces parents to choose on behalf of their children. In addition to being a choice that affects how their children will perceive and navigate the world, the choice carries incredibly significant social consequences. Deaf communities offer distinctive goods that hearing communities cannot, and vice versa. Furthermore, as disability advocates point out, the difference between being deaf and non-deaf is “mere-difference” rather than “bad-difference” (see, e.g., Barnes 2014). This offers a further reason to believe that the decision to give a child a cochlear implant is a transformative one that must be made on the basis of the child’s future experiences as deaf or hearing as opposed to on the basis of value.

Put this way, parental choices, especially significant ones like deciding whether to get a child a cochlear implant, also resemble the non-identity problem. Parfit (1984) raises the non-identity problem as a puzzle for decisions that affect who will exist in the future. For instance, suppose a potential parent is choosing between implanting one of two embryos, and chooses one that has a genetic defect that causes monthly migraines that the other embryo lacks. Given that there are no other relevant differences between the two embryos, it appears that the parent has done something wrong by bringing into existence a person who will have a lower level of welfare than the other person who could have existed instead. However, it’s not obvious who the potential parent has harmed. Assuming the migraine-inflicted person prefers existing to never having existed, they have not been harmed since the alternative is non-existence. If that’s right, then perhaps the parents have done nothing wrong since no one has been harmed.

Similarly, the personally transformative aspect of transformative experiences affects who exists after undergoing the experience. Receiving a cochlear implant and growing up in a hearing community will transform the child into a radically different person from who the child would be if they did not receive an implant and grew up in a deaf community. The person who develops won’t have grounds to complain since wishing their parents had chosen otherwise would be like wishing they did not exist. But even if one does not believe that the cochlear implant is an existence-affecting decision point, the fact that the two potential futures are so foreign to each other means that a person situated in one of those futures cannot project what it would be like to have had the other life. If the earlier points about projecting value are correct, the person who has grown up in the deaf community cannot assign a subjective value to the alternate life in which they had the cochlear implant, and vice versa. Without those value assignments, it doesn’t appear that either person can claim that they would have been better off in the alternate scenario. Thus, whether the person receives the cochlear implant or not, articulating how that transformation harmed them will be challenging. Perhaps the parent can choose either option without harming or wronging anyone. The situation is also similar from the perspective of the parents and their preferences, for they will have grown to love their child and the particular person into whom they have developed.

Philosophers diverge on how parents should choose in these cases. (See, e.g., Harman (2015) for an interesting discussion on when “I’ll be glad I did it” reasoning is appropriate.) However, there’s a more interesting lesson to be drawn from these types of cases. Recall from §4.1 and §4.2 that Paul objects to certain types of decision-making strategies because they treat future selves as if they were third persons rather than integrated parts of the same self. These cases show that even in the third person case, standard decision-making procedures are not particularly helpful. Transformative experiences still create major challenges for decision-making.

At the other end of life, decisions must sometimes be made for people post-transformation. People suffering from dementia or Alzheimer’s transform in myriad ways, and their preferences often diverge from the preferences of their earlier selves. Sometimes, these preferences regard end of life care. Since the person with dementia or Alzheimer’s is not considered legally competent to change their advanced directives, others must make important medical decisions on their behalf. These people must decide whether to respect the preferences of the past self, or the current one. In some ways, this a questions about the weight that ought to be assigned to past preferences, and we might resolve in the way Pettigrew (2019) suggests by constructing a general value function that aggregates the past and current preferences. However, if the personal transformation is taken seriously, the current self is a different person. Binding them to the preferences of the past self is akin to binding them to the preferences of another person.

6.2 Long Term Decisions
In addition to transforming in the early and late stages of life, people transform throughout their lives, either via momentous “big” changes or via an accumulation of “small” changes. Long-term decisions must factor the potential for transformative change into account. For instance, Lackey (2020) and Chan (2020) independently address this issue in the context of punishment. Lackey’s argument demands that those with the power to issue long-term punishments, like judges, must consider the possibility of transformative change. Plausibly, punishment should be sensitive to the relevant evidence available at that time. We know that people change, often in transformative ways, and imprisonment seems like exactly the type of experience that would be transformative. Issuing strict, long-term prison sentences—such as life sentences without the possibility of parole—screens off the possibility of taking relevant future evidence into account. Thus, recognizing the possibility of transformation offers a powerful argument for sentencing reform.

Extended partnerships also provide another context in which transformative changes need to be accounted for when making long term decisions. For instance, marriage vows typically involve some type of life-long pledge. And, as anyone familiar with married people knows, people change in ways that disrupt the marriage. In a way, identifying these changes as transformative makes sense of an already common phenomenon. But it also raises a further question: how can one felicitously make a life-long promise to someone knowing that both they and their partner may transform in a way involving a radical shift of preferences and life goals? The centrality of transformation to this decision is doubled because the marriage itself is often transformative. It’s true that transformations connected with relationships tend to involve incremental changes because the relationship develops incrementally. But these incremental changes can lead people away from each other and won’t be noticeable until the larger schism develops due to their incremental nature.

These long-term decisions involving others suggest that the normative questions transformative experiences raise go beyond self-interested decision making. Furthermore, some of the proposed ways of making transformative decisions have interesting implications for these types of cases. For instance, Ullmann-Margalit suggests that there simply is not a rational way to make transformative decisions. Applying that to these cases gives the radical result that decision to marry or sentence someone to prison cannot be made rationally! Ullmann-Margalit’s further suggestion that perhaps these decisions can be made reasonably also has interesting implications. She suggests that minimizing the discontinuity of a big decision and backing off the point of no return might help, and includes moving in before marriage as one such way to ease reasonably into a big decision like marriage. The application for the prison case is even more interesting, for it suggests that life in prison should not be such a radical departure from life outside of it, and that there must be meaningful short term possibilities for parole.

6.3 Transformative Environments
Finally, special attention must be paid to our social environments since they shape the way in which members of society may transform. Education provides the most obvious instance of this. Fights over parental rights to control their children’s educations are so contentious precisely because early experiences shape who children grow up to become. Even higher education is taken to have a transformative goal (see Paul & Quiggin 2020). College students are typically in their early twenties—the last age at which people tend to undergo radical change before developing fairly stable preferences and goals that tend to endure through most of adulthood. In addition, the transformative environment of education shapes more than the individual students who experience it. Students go on to become members of society who in turn create an environment that will shape those who come after them. Morton (2021) points out that this tends to have a self-reinforcing effect because elite institutions like the Ivy League schools disproportionately influence social policy. Even if students enter these institutions without the goal of maintaining the status quo of the elite, by the time they graduate, they can be transformed into members of the elite who are now invested in safeguarding the interests of their newfound group. This, in turn, shapes social policies that reinforce which transformative experiences are most readily available to members of society.

This idea that social policies can shape individual choices and preferences creates both an opportunity and a responsibility to reconsider which policies ought to be adopted in light of the potential for transformative experience. For instance, Pettigrew (2023) examines the concept of nudging introduced by Thaler and Sunstein (2008). In a nutshell, nudging is a sort of intervention that pushes people toward making a particular choice while leaving open the possibility that they choose otherwise. Opt-out retirement programs offer a paradigm case of nudging since they increase the likelihood that people will put money away for retirement while still allowing people the ability to opt-out. Thaler and Sunstein label nudging policies as “libertarian paternalism” because while these interventions look paternalistic, they purportedly help people make the decision that their future idealized selves will deem to be best “as judged by themselves” (Thaler and Sunstein 2008, 4). Of course, if the decisions are transformative, or incremental parts of multiple decisions that become transformative, simply looking at the judgment of the future self does not seem appropriate at all! (And Pettigrew makes precisely this argument before proposing a modification to the “as judged by themselves” test that’s based on his weighted general value function.)

There are at least two bigger-picture issues that come out of this discussion of nudging people, potentially toward transformation. First, the norms regarding nudging people toward potential transformation requires further examination. Most policies, nudging or otherwise, exhibit some degree of interventionism. In addition to which transformations might be preferable for society as a whole, there’s also the question of whether we should adopt policies that maximize individual autonomy. Second, we might wonder why nudging works in the first place, and if it really does work for transformative experiences. Recall that part of the nature of transformative experiences is that one cannot know what they will be like or how they will change prior to having the experience. Nudging, on the other hand, only works if these things are somewhat predictable. Of course, unpredictability with respect to an individual is compatible with predictability with respect to overall social trends. But, if nudging really works, it does lend credence to the idea certain elements of transformative experience are predictable and perhaps strengthens the case of those from §4 who believe that one can make rational choices with respect to transformative experiences.

Finally, we’ve structured our society in many unfortunate ways. This goes beyond the discrimination that people suffer on the basis of race, sex, ability, socioeconomic status, and the like. More subtle conceptual structures shape and limit the way we form our self-identities. These injustices are obviously bad in themselves, and they also interact with transformative experience in a way that furthers the injustice. Barnes (2015) argues that one’s “self-conception and self-identity aren’t developed in cultural isolation” and that “social norms and structures make certain ways of interpreting or thinking about ourselves readily available” (185). For example, society makes it easy for women to “re-shape their self-conception to cohere with the image of a dutiful, submissive wife” (186). Similarly, “brave inspiration” is a readily available self-conception for disabled people while “thriving person in an unconventional body” is not (185–186). These states of affairs are bad for women and disabled people. Since personal transformation involves changes to one’s self-conception, society plays an outsized role in the types of transformations that are available to us.

Higher-order evidence is evidence which bears on a believer’s rational capacities, epistemic performance, or evidential situation. Many epistemologists hold that this kind of evidence can rationally affect our “first-order” beliefs as well: that is, those beliefs about the world that we form using the relevant rational capacities, or in the relevant evidential situation. It is easiest to get a grip on this phenomenon by looking at examples. Here is a paradigmatic case (paraphrased from Schoenfield 2018: 690, based on similar cases put forth by Adam Elga [2013 and 2008—see Other Internet Resources], Lasonen-Aarnio [2014], Christensen [2010a], and others):

Hypoxia: Aisha is out flying her small, unpressurized airplane, wondering whether she has enough fuel to make it to Hawaii. She looks at the gauges, dials, and maps, and obtains some evidence, E, which she knows strongly supports (say to degree .99) either the proposition that she has enough gas (G) or that she does not (~G). Thinking it over and performing the necessary calculations, Aisha concludes G; in fact, this is what E supports. But then she checks her altitude and notices that she’s at great risk for hypoxia, a condition which impairs one’s reasoning while leaving the reasoner feeling perfectly cogent and clear-headed. Aisha knows that at this altitude, pilots performing the kinds of calculations she just did only reach the correct conclusion 50% of the time.

Aisha’s “first-order” evidence is her evidence bearing directly on her beliefs about G: that is, the evidence she receives by consulting her dials, gauges, and maps. Her “higher-order” evidence is her evidence suggesting that she’s at risk for hypoxia. Higher-order evidence bears directly on Aisha’s epistemic situation in various ways, but does not bear directly on G. The primary question that this case raises, for the higher-order evidence literature, is: does Aisha’s higher-order evidence also rationally affect her beliefs about G? (That is, does it bear on G in some indirect way?)

Some say yes. It would be reckless for Aisha to head out over the Pacific after realizing that there is such a serious chance that she’s rationally impaired, which surely shows (some argue) that she should not be very confident of G. Others say no. As the case stipulates, Aisha’s first-order evidence strongly supports G; whether Aisha is hypoxic has absolutely nothing to do with whether she has enough gas to make it to Hawaii. (Why would her total evidence prompt her to revise confidence in G, when the new evidence she has gained is irrelevant to G?) Answering “yes” raises questions about exactly how and why this level-interaction works. Answering “no” raises questions about how to explain the intuitive unreasonableness of Aisha’s maintaining high confidence in G.

Higher-order evidence thus raises a puzzle. Two apparent features of Hypoxia are in tension with one another: it seems that Aisha is required to reduce her confidence in G, and yet it also seems that her evidence still strongly supports G. Some see this as a conflict between the belief state that seems intuitively rational (reduced confidence or suspension of judgment about G) and the belief state that seems strongly supported by her evidence (high confidence in G). Others see it as a conflict within her beliefs. If Aisha maintains high confidence in G, but also takes seriously the possibility that she could be hypoxic, she will be in a state of epistemic akrasia: she will have a belief state (her high confidence in G) which she also judges likely to be irrational, or unsupported by her evidence.

In what follows we will see these issues crop up in several different forms. This article will be organized around a few core questions about higher-order evidence, which will give us different ways to approach these central puzzles.

Is higher-order evidence different from ordinary evidence? If so, how?
Why might we deny that higher-order evidence has a rational effect on first-order beliefs? And if we take that approach, which problems and questions remain?
If higher-order evidence rationally affects first-order beliefs, how does this work? What sort of principle might govern that interaction?
Is there a way to split the difference, embracing both sides of the puzzle? For example, might there be different, incompatible epistemic norms at work in cases like Hypoxia, one telling Aisha to believe G and another telling her to suspend judgment?
A few quick notes before moving on. Following most of the literature, the term “higher-order evidence” is used here, although it would be more accurate to speak of higher-order evidential effects or higher-order evidential import (since one piece of evidence may be relevant to a person’s beliefs about many different subject matters, in a number of different ways). And like most of the literature, the focus is on higher-order defeat, rather than higher-order confirmation, even though these possibilities go hand in hand. Some of the issues discussed in this article are discussed in more detail in the entry on epistemic self-doubt. Finally, although the higher-order evidence debate has its roots in the literature on disagreement, this entry focuses on the simpler, single-person case introduced above and mostly omits disagreement.

1. What is Distinctive About Higher-Order Evidence?
Higher-order evidence was introduced above by example. We can come across higher-order evidence in a variety of ways: brain-altering conditions like hypoxia, or drugs, but also more mundane sources like bias and fatigue. Many epistemologists have discussed disagreement as a source of higher-order evidence: if an equally well-informed and thoughtful person looks at the evidence and draws a different conclusion from yours, this arguably gives you reason to worry that you’ve made a rational error (see, e.g., Kelly 2005, Feldman 2006, Christensen 2007b, Elga 2008 and much following literature). And some have argued that “irrelevant influences” on belief, such as one’s religious upbringing, can be a source of higher-order evidence as well: the realization that you would have had different religious beliefs if you had been raised in a different community, for example, might give you reason to doubt the rationality of those beliefs (see Elga 2008—see Other Internet Resources, White 2010, and Vavova 2018). It is hard to find an uncontroversial definition of higher-order evidence, as different authors understand it in different ways. But even without a general definition, we can look at cases like Hypoxia to see how higher-order evidence is importantly distinctive. (This section assumes that higher-order evidence has some first-order rational import, as this is where the distinctive features arise.)

At first glance, one might think that Hypoxia is simply a case of undercutting defeat, and Aisha’s justification for believing G is defeated just as one’s perceptual beliefs might be defeated by, for instance, evidence of tricky lighting. But as Feldman (2005) argues, higher-order defeat and undercutting defeat are importantly different. Compare Hypoxia to a case in which you find out that a certain wall, which appears to be red, is illuminated by a red light. In the latter case, you might recognize that your experience as of a red wall generally supports the belief that the wall is red, and also recognize that you responded appropriately to that evidence before finding out about the tricky lighting. But in Hypoxia it seems that Aisha is not in a position to recognize either of these things. If she takes her higher-order evidence seriously, she will come to doubt whether her first-order evidence ever supported G in the first place. And she will also doubt whether she evaluated it correctly. (See Coates 2012 and Christensen 2010a for similar discussion.) So higher-order defeat is not simply undercutting defeat.

Joshua DiPaolo (2018) argues that higher-order defeat is also distinctive in that it is “object-independent”. For instance, learning that there is a red light on the wall will undercut your belief that the wall is red, but will have no effect if you believe that the wall is not red. Higher-order evidence, on the other hand, typically does not discriminate based on the contents of the beliefs it targets. Extending DiPaolo’s argument to our case above, Aisha’s higher-order evidence targeted her belief about G, but could have easily targeted a belief with different contents if she had been reasoning about a different matter while flying at that altitude.

Christensen (2010a) argues that higher-order evidence is distinctive because its import is agent-relative. While Aisha's information about hypoxia gives Aisha reason to doubt her beliefs about whether she will make it to Hawaii, it would have no such effect on another person looking at the same charts and dials from the safety of the ground. However, merely treating higher-order evidence as indexical does not seem to make it less puzzling; see Schoenfield 2018 for further discussion.

Perhaps the most puzzling feature of higher-order evidence is that it seems to obligate agents to ignore or set aside parts of their total evidence. (See Christensen 2010a for an early defense of this idea; others, including Elga (2007), also defend it in the context of disagreement.) Even as Aisha comes to doubt her conclusion about G, her first-order evidence and reasoning is still plainly before her. But she cannot rationally appeal to it in forming her beliefs. If she could, Aisha might argue:

although I’m at an altitude that renders me susceptible to hypoxia, I must be immune. After all, my first-order evidence in fact supports the conclusion that I have enough fuel to make it to Hawaii, and that’s the very same conclusion I reached!

To a supporter of higher-order defeat, such reasoning looks irrational and dogmatic. (Furthermore, if she could reason this way, Aisha could arguably keep her high confidence in G—which his just to say, her higher-order evidence wouldn’t have a rational effect after all.) In order to rule out the rationality of such reasoning, while acknowledging that Aisha’s first-order evidence has not vanished, some epistemologists say that Aisha must set aside the targeted first-order evidence and reasoning once her higher-order evidence comes in. This thought is often called “Independence”. Section 3.1 discusses it in more detail.

Finally, related to this last observation, Horowitz (2019) and Schoenfield (2015b, 2018) both argue that higher-order evidence is predictably misleading: if it has first-order effects, we can predict a priori that it will lead ideally rational thinkers away from the truth. We expect first-order evidence to generally make us more accurate, provided that we respond to it rationally. And we expect higher-order evidence to lead us away from what our first-order evidence supports. So when we accommodate all of that evidence rationally, we’ll tend to end up with a less accurate belief state than we would if we had ignored the higher-order evidence.

In all of these ways, higher-order evidence presents distinctive problems for epistemology. (Though distinctive does not necessarily mean rare: Hedden and Dorst [forthcoming] argue that almost all evidence has higher-order import.) As we will see in the next section, the difficulties presented by higher-order evidence have prompted some epistemologists to deny that it has first-order import altogether.

2. Denying the Import of Higher-Order Evidence
Higher-order evidence raises special problems. One very general problem is that it is hard to see how we could make sense of higher-order evidence within a consistent, total picture of rationality. Maria Lasonen-Aarnio (2014) brings out this point especially forcefully and comprehensively, so this next section will largely follow her presentation. (See also Schechter 2013 for discussion of many similar concerns.) We will then look at a slightly different objection to theories that accommodate higher-order evidence: the charge that they are self-defeating. The section will conclude with some options for theories according to which higher-order evidence does not rationally affect first-order beliefs.

2.1 Structural problems for higher-order evidence
Lasonen-Aarnio begins with the observation that respecting higher-order evidence can compel a rational agent to violate genuine epistemic rules. (This is very similar to the idea presented in the introduction: that after Aisha receives her higher-order evidence, her total evidence still supports G.) Since this thought is common to much of the higher-order evidence literature, it will be worth spelling out in detail the reasoning behind it. One simple way to make the thought plausible is to focus on a case of entailment—so, let’s suppose Aisha’s first-order evidence entails G. Then we can argue as follows:

P1.
Aisha’s first-order evidence entails G.
P2.
After Aisha receives her higher-order evidence, her total evidence entails G.
P3.
It is a rational requirement to believe what our evidence entails.
P4.
After Aisha receives her higher-order evidence, she is rationally required to believe G.
P5.
After Aisha receives her higher-order evidence, she is rationally required to suspend judgment on G.
C.
After receiving her higher-order evidence, Aisha is rationally required to violate a rational requirement.
P1 is built into (this version of) our case. P2 follows from P1, assuming that Aisha’s body of total evidence grows monotonically over the course of the story. P3 is plausible, and would nicely explain our verdict at the beginning of the story: that, before she receives her higher-order evidence, Aisha should believe G. P4 follows from P2 and P3. And P5 is the intuitive verdict that many epistemologists share about cases like Hypoxia. (Though see Henderson forthcoming, Staffel forthcoming, and Steglich-Peterson 2019 for alternative views on which higher-order evidence does not require suspension of judgment, but still has a rational effect.) So if P5 is right, this means that Aisha is required to disobey an epistemic rule which applies to her current situation: she must suspend judgment in a proposition that is entailed by her evidence, rather than believe it.

Though focusing on entailment makes the argument above particularly clear, it’s not essential. The same problem can, plausibly, arise with non-entailing evidence as well. Lasonen-Aarnio focuses on a perceptual case, and Christensen (2010a) argues that cases involving inductive reasoning can lead to the same conclusion. (Both argue for versions of P2 in non-entailing contexts: they argue, respectively, that the perceptual or inductive support remains even in the face of higher-order undermining.)

How can we make sense of Aisha’s situation, in light of this apparent conflict? Lasonen-Aarnio (2014) surveys several possible ways to make room for the conflict within our overall epistemological theory. One strategy we might try is to say that epistemic rules have built-in exceptions for higher-order defeat. That doesn’t solve the problem, Lasonen-Aarnio argues, but just pushes it back: if any rule can be defeated, then so can rules with built-in exceptions. A second strategy is to say that epistemic rules are hierarchical, with some taking precedence over others; but again, the higher-level rules must themselves be defeasible, leading to an infinite hierarchy. The rules must also be ordered by a “meta-rule” which determines which rule governs one’s current situation; what if the meta-rule itself is defeasible? It seems that we are either left with an infinite regress, or that we must accept a stopping point—a rule which itself cannot be rationally defeated. Another strategy is to posit an “Über-rule” which specifies the rational response for each unique situation. This fails, Lasonen-Aarnio argues, because it is too complex for us to grasp, too different from the epistemic rules we ordinarily take ourselves to follow, and endorsing it leaves us with an unsatisfying kind of particularism about rationality. This proposal also runs into the same problem we saw above. If the Über-Rule is always correct, we must say that it cannot be rationally defeated. If we are willing to accept indefeasible rules, why should we think that higher-order defeat happens at all? (Why not just accept the rules governing Aisha’s belief in G as themselves indefeasible by higher-order doubt?) Lasonen-Aarnio concludes that in light of these problems, we should reject higher-order defeat. (See Bradley 2019 for response to Lasonen-Aarnio, and a defense of the Über-rule.)

2.2 Higher-order defeat and self-undermining
Another route to doubt about higher-order defeat is what’s sometimes called the “self-undermining” objection. As several epistemologists have pointed out, there are strange consequences for anyone who believes a theory on which higher-order evidence has first-order effects: it seems that this belief is liable to undercut its own justification. Let’s consider a candidate principle on which higher-order evidence can defeat first-order beliefs; call it “HOD” (for “higher-order defeat”). Now consider a person, Sam, who believes that HOD is a true principle of rationality. What happens if Sam’s belief in HOD is itself a target of higher-order defeat? This might happen through peer disagreement (which is the focus of most of the literature on this objection) or other means. Afterwards, according to HOD, Sam cannot rationally believe HOD.

This might already seem like a problem to some: a true theory of rationality should not (arguably) undermine our justification for believing it. And taking it a step further, it can look like the theory is either paradoxical or incoherent. If HOD can call for its own rejection (in the cases where belief in HOD is itself undermined), how can it give us coherent directions? Suppose Sam’s higher-order evidence targets two beliefs simultaneously: his belief about some proposition P, and his belief about HOD itself. HOD tells him to reduce confidence in P. But since HOD is undermined as well, it is arguably also telling him not to reduce confidence (or to reduce confidence to a lesser degree). These recommendations are incompatible, yielding the worry that HOD is internally inconsistent. On the other hand, the worry about paradox arises when we consider what happens when Sam begins to revise his beliefs. Once HOD is undermined, suppose Sam no longer believes it, and goes back to revise the beliefs that he formed on its basis. But his last application of HOD was what led to his doubting HOD—so if he “undoes” that step, he’ll believe HOD again! But then his belief in HOD will be undermined by his higher-order evidence, and the loop will start over. (For further discussion see Elga 2010, Weatherson 2013, Christensen 2013 and 2021a, and Bradley 2019. See Roush 2009 for discussion of a related phenomenon.)

Advocates of higher-order defeat have offered a few different responses to this class of objections. One option, proposed by Elga (2010), is to say that principles like HOD are exempt from undermining. (Elga’s view draws on an argument found in Lewis 1971 and H. Field 2000, for the conclusion that our most fundamental belief-forming methods must be self-recommending.) Another option is to say that our attitude towards principles like HOD is not one of belief, but some other type of attitude. (See Goldberg 2013, Barnett 2019, and Fleisher 2021 for examples of this approach.) Finally, one might simply deny that Sam is obligated to enter the paradoxical loop once his belief in HOD is undermined. Christensen (2013, 2021a, 2021b) argues along these lines. The loop gets started if we think that once Sam rationally doubts HOD, he is rationally required to stop adopting the beliefs that HOD recommends, and instead adopt whichever beliefs he now regards as most rational. But this thought is not part of HOD, and we are free to deny it—we can maintain that HOD is true, and rationally binding even for those who rationally doubt it. (This is different from saying that HOD must be self-recommending; on Elga’s proposal, one should believe that one should always follow HOD, and also always follow it. On Christensen’s, one should always follow HOD, regardless of what one should believe one should do.) This response would bypass the paradox. But it comes at what some defenders of HOD see as a cost: it means we must accept some instances of rational epistemic akrasia. If Sam revises his belief in HOD, but continues to follow it, as this suggestion would have him do, he will end up with a belief state whose rationality he doubts.

In the face of these difficulties, some epistemologists conclude that higher-order defeat is simply not a genuine phenomenon. These views are discussed next. In sections 3 and 4, we will come back to the options for accommodating higher-order defeat.

2.3 Consequences of denying the import of higher-order evidence
If we hold that higher-order evidence does not have first-order rational effects, what should we say about cases like Hypoxia? There are two mainstream options defended in the literature. “Level-Splitters” suggest that Aisha’s first-order belief (about G) should follow her first-order evidence, so she should be highly confident of G. But her higher-order belief (about her own rationality, or about what her first-order evidence supports) should follow her higher-order evidence. “Steadfasters” argue that Aisha should just dismiss the higher-order evidence altogether—believe G, and believe that her evidence supports it. (See Alexander 2013, however, for an argument that no response is justified in Aisha’s case, and Leonard 2020 for an argument that it is indeterminate what Aisha should believe.)

Defenders of the Level-Splitting view include Lasonen-Aarnio (2014), Coates (2012), Weatherson (ms–see Other Internet Resources), Williamson (2014), and Wedgwood (2012). The obvious advantage is that this view straightforwardly takes all of Aisha’s evidence into account: her evidence about G affects her beliefs about G, and her evidence about her epistemic situation affects her beliefs about her epistemic situation. An obvious upshot of this view is that epistemic akrasia can be rational: in particular, in Hypoxia, Aisha should end up believing G, while also believing that her evidence likely doesn’t support G.

But admitting rational epistemic akrasia in this case incurs a large intuitive cost. As Horowitz (2014) argues, if epistemic akrasia is rational in cases like Aisha’s, then so is bootstrapping: if Aisha finds herself in this situation a number of times in a row, or regarding a number of different beliefs, she can use her first-order beliefs to establish a fantastic track record of success, ultimately dismissing the possibility that she was ever rationally impaired. This reasoning looks absurd—because, presumably, there is a tension between strongly holding a belief while also believing one’s evidence doesn’t support it. So why allow this tension in even one case? Horowitz also illustrates other examples of irrational reasoning and action that seem warranted by epistemic akrasia; see also Brown 2018, Littlejohn 2018, and Silva 2018 for further discussion of intuitively irrational reasoning and action licensed by epistemic akrasia in these cases, as well as Feldman 2005 for an earlier rejection of epistemic akrasia in similar circumstances.

The second possibility is to say that higher-order evidence simply has no effect on first-order or higher-order beliefs. (Following the peer disagreement literature, we could call this a “steadfast” view; Smithies [2019] calls it “upward push”.) Kelly (2005) seems to tentatively support this view in the context of peer disagreement (though his later work defends a more moderate “total evidence” view; see, for example, Kelly 2010). Titelbaum (2015) argues for the nearby position that a rational agent can never be mistaken about the rational requirements that apply to her situation (although she might be rationally uncertain as to which situation she is in); he writes that “mistakes about rationality are mistakes of rationality”. Titelbaum’s argument for this rests on the assumption that epistemic akrasia is irrational. (See also Titelbaum 2019. See C. Field 2019 for criticism of this position.) Tal (2021) also defends the steadfast view, in part appealing to the irrationality of epistemic akrasia.

Smithies (2019; see especially ch. 10) gives an extended defense of a steadfast view. He argues that ideal rationality requires rational omniscience—that is, omniscience both about what the rational requirements are and which requirements apply to one at all times. This means that misleading higher-order evidence is, in an important sense, impossible to come by. While non-ideal agents like Aisha may be mistaken about what evidence they have or what it supports, these mistakes are themselves departures from ideal rationality. (Smithies also supplements this with a view about non-ideal rationality, which is discussed below.)

One of the primary objections to the steadfast view is that ignoring higher-order evidence appears to be blatantly dogmatic: it is hard to see how it could be rational for Aisha to continue believing G with no reduction in confidence, after hearing that her altitude puts her at risk of hypoxia. (Though Tom Kelly has argued [see Kelly 2013, for example] that dogmatism in such cases is not inherently irrational.) Additionally, acting on her belief that G—say, setting off for Hawaii with a plane full of passengers—would be shockingly irresponsible, suggesting that something is wrong with the belief that G. (See Christensen 2010a, for example.)

Cases like Hypoxia therefore leave us with three choices. If we say that Aisha should maintain confidence in G, but reduce confidence that it’s rational for her to belief G, we must explain why epistemic akrasia can be rational. If we say she should maintain confidence in G and dismiss the possibility of hypoxia, we must explain why dogmatism can be rational. And if we say she should reduce confidence in G, we must explain how this type of defeat works, and how it fits into our broader theory of rationality. Let us now return to that last question.

3. Accommodating the Import of Higher-Order Evidence
In this section we will look more closely at the possibilities for accommodating higher-order defeat. Even setting aside questions about how such defeat fits into the rest of our epistemological theory, there are several more local questions about how higher-order defeat works. What sort of principle could explain the intuitive verdicts in cases like Hypoxia? Which evidence and reasoning can agents like Aisha rely on in forming their beliefs, and under what circumstances? What determines which attitude, exactly, Aisha should have towards G after taking both her first-order and her higher-order evidence into account?

There are a couple of different ideas that epistemologists sympathetic to higher-order evidence typically aim to capture. One is the thought that higher-order evidence requires us to “bracket” or set aside some of our first-order evidence and reasoning. This is often called “Independence”. The second is the thought that, in accommodating one’s higher-order evidence, one should somehow adjust one’s first-order belief to match what one has learned from the higher-order evidence: either to match what one believes or has reason to believe would be rational, to match one’s expected level of reliability, or some variation on one of these. Principles dictating how one should calibrate one’s first-order beliefs in light of higher-order evidence are often called “level-bridging principles” or “calibration principles”.

Many specific proposals for how to accommodate higher-order evidence (often focusing on the case of disagreement, which we can think of as a variety of higher-order defeat) combine both of these ideas. For example, here is Elga’s (2007: 490) formulation of the “Equal Weight View” of disagreement:

Equal weight view Upon finding out that an advisor disagrees, your probability that you are right should equal your prior conditional probability that you would be right. Prior to what? Prior to your thinking through the disputed issue, and finding out what the advisor thinks of it. Conditional on what? On whatever you have learned about the circumstances of the disagreement.

Calibrating your confidence to the probability that “you would be right” is a way of matching your confidence in P to your expected reliability about P, so the Equal Weight View is in part a level-bridging principle. And the “prior” and “conditional” clauses commit Elga to an Independence principle as well: he is saying that we must set aside the specific first-order evidence and reasoning about the relevant matter, and consider only the surrounding “circumstances”. In the very next paragraph Elga clarifies that “whatever you have learned about the circumstances of the disagreement” must be independent from the reasoning leading to the disagreement itself. Instead, it should include facts about the situation that would affect your or your peer’s reliability, such as how much coffee you have each had, how absurd you find the other person’s answer, and whether the reasoning invites a type of mistake that you or your friend is especially likely to make.

The next two subsections discuss Independence and level-bridging separately. But many authors who endorse one of these (in one form or another) also endorse the other.

3.1 Independence principles
Independence principles say, roughly, that higher-order evidence calls for us to set aside some of our evidence, and not rely on it in our reasoning. This thought is required to rule out the kind of dogmatic response to higher-order evidence discussed above: if we did not have to set aside our first-order evidence and reasoning, it would be rational to rely on it to dismiss any higher-order doubt. Independence raises a number of questions. How can it be rational to ignore evidence? What, exactly, do we have to ignore? And does Independence open the door to skepticism?

Some balk at Independence because it simply seems irrational to ignore evidence (see Kelly 2005, 2010, for example). Kelly (2010) presents the objection roughly like this: if higher-order evidence requires us to ignore our first-order evidence, he asks, doesn’t that make rationality far too easy to come by? It appears that someone could botch their first-order reasoning completely, adjust their confidence in the face of higher-order evidence, and (since they are now obligated to ignore the first-order considerations) have all of their earlier rational mistakes forgiven. Christensen (2011) disagrees, arguing that while someone in this situation may have responded to part of her evidence correctly, we can still distinguish between her final belief state and the belief state of someone who didn’t make the initial mistake: someone who did every step properly is more rational than someone who did not. (See Sliwa & Horowitz 2015 for further discussion; see Schoenfield 2015a for an objection.)

If Independence is right, there are remaining questions about exactly what needs to be set aside—evidence? Reasoning? Something else?—and under what circumstances. As several authors have brought out, it is not quite right to simply say that our assessment must be independent of our first-order reasoning; often, facts about that reasoning, sometimes involving very specific aspects of our evidence, are highly relevant and it would be irrational to ignore them. (See Arsenault & Irving 2012, Kelly 2013, and Lord 2014 for versions of this objection; see Christensen 2018 and 2019 for replies.) It is also not quite right to say that our assessment must be independent of our first-order evidence; often, a single piece of evidence has several different effects, some of which should be set aside and others of which should be taken into account. See Christensen 2019 for detailed discussion of these complexities and others.

A different sort of question concerns how much evidence, information, or background beliefs we must set aside, and whether there are any limits on this. Intuitively, the scope of what we must set aside depends on the scope of higher-order undermining we receive, and which instances or types of reasoning are called into question. But how far can it go? What if everything is called into question? Considering this possibility leads to paradox. On the one hand, reason to universally doubt our reasoning seems to justify skepticism across the board. On the other hand, the way we would arrive at that skeptical state would be by using our reasoning… which has been, by hypothesis, called into question. Some epistemologists have suggested that since there is no stable and consistent response to such cases, we ought to conclude that universal defeat is impossible. But this response is hard to reconcile with the fact that defeat comes on a spectrum; if the extreme cases are impossible, what about the intermediate cases? (For further discussion, see Egan & Elga 2005, Enoch 2010, Sliwa & Horowitz 2015, Schoenfield 2015a, Christensen 2010a, 2019. See also the entry on epistemic self-doubt for further discussion.)

Even if we restrict our attention to more moderate cases of undermining, one still might wonder whether rationality can ask us to doubt so much that we end up skeptics about large and important domains (even if we are not skeptics across the board). Could it be rational for us to come to doubt, for example, all of our moral or religious beliefs on the basis of higher-order undermining? Elga (2007) argues (again in the context of peer disagreement) that we should not worry about this possibility. In order to doubt all of our moral beliefs, for example, we must have independent grounds to judge these beliefs to be unreliable. But if we set aside all of our moral beliefs, Elga argues, we won’t have enough left over to make any sort of reliability judgment—and therefore, won’t have rational grounds for doubt. So undermining can only happen locally. (And even then, he argues, many of our religious and moral beliefs will be safe, since on any particular occasion, the targeted religious or moral belief will be supported by our other moral and religious beliefs—the ones that aren’t called into question.) See Vavova 2018 and Christensen 2011 for further discussion of this point. Vavova and Christensen both differentiate between two possible ways to formulate Independence: one on which you must revise your beliefs insofar as you fail to have good independent reason to trust them, and one on which you must revise insofar as you have good independent reason to think that you’re mistaken. They argue that the first formulation has skeptical results, while the second avoids them.

3.2 Level-bridging principles
While Independence principles tell us what to set aside, level-bridging principles specify how our first-order beliefs should cohere with our higher-order beliefs. (As mentioned above, however, these principles aren’t always presented separately. Level-bridging principles also often include some element of Independence, or are meant to apply alongside an Independence principle.)

Some epistemologists argue that our first-order beliefs should line up somehow with our beliefs about rationality. (See Smithies 2019 and Titelbaum 2015, 2019, for example.) Others argue that our first-order beliefs should line up somehow with our beliefs about reliability. And still others incorporate elements of both. Some literature discusses both notions together and other literature distinguishes explicitly between the two. (See Christensen 2016b, Sliwa & Horowitz 2015, and Schoenfield 2015a for a few examples of more explicit discussions. See also Dorst [forthcoming] for a comprehensive overview of some of the principles proposed in the literature and the relationship between them, and the entry on epistemic self-doubt for discussion of some other level-bridging principles in greater detail.)

I will highlight the choice by first describing an intuitively plausible level-bridging principle that focuses on rationality, and a problem case for this principle which has motivated some epistemologists to move towards reliability instead. Although the second principle, too, has come under criticism, the case is a useful illustration of some of the complications that arise in this choice.

3.2.1 Rationality-focused principles
The general thought behind rationality-focused level-bridging principles is that your beliefs about the world should line up with your beliefs about what’s rational for you to believe. If you think it’s rational to believe P (or, if it’s rational for you to think that’s rational…) you should believe P. If you think it’s rational to believe ~P, you should believe ~P. This line of thought involves deferring to rationality as you would defer to an expert.

What if you’re uncertain about what’s rational? Arguably, this is Aisha’s situation: she’s unsure whether her evidence rationally supports G, as she initially thought it did, or whether hypoxia has confused her and her evidence doesn’t support G after all. One initially plausible response to this sort of situation is to say that when we’re uncertain, our beliefs should reflect a kind of weighted average of the responses we take to be possibly rational. This yields the result that if we’re about equally confident that we should believe P and that we should believe ~P, the thing to do is to suspend judgment.

The principle Rational Reflection makes this thought more precise in a degreed-belief, or “credence” setting. (Christensen [2010b] introduces and discusses the principle at length. Salow [2018] and Skipper [2021] are proponents of the principle. Elga [2013] and Dorst [2020] amend it, as we’ll see later.) Roughly, according to Rational Reflection, one’s credences (“Cr” in the formulation below) should align with those that one regards as rational (“Pr”):

Rational Reflection: Cr(A∣Pr(A)=n)=n

If this principle were a true rational requirement, then rational agents in situations like Aisha’s would end up with a strong coherence between their first-order beliefs and their beliefs about what is rational. Rational Reflection says, for instance, that it cannot be rational for Aisha to be rationally certain that it is rational to have .9 confidence in G, without also having .9 confidence in G. And it cannot be rational for Aisha to be uncertain, without also adopting a weighted average of the credences that she regards as possibly rational (weighted by her credence, in each, that it is rational). In the version of the case discussed in the introduction, one might interpret Aisha’s higher-order evidence as indicating that her high confidence in G is only 50% likely to be rational, given her first-order evidence. If it is 50% likely that high confidence is rational, and 50% likely that low confidence is rational, Aisha should plausibly adopt the weighted average of these possibilities and arrive at a middling level of credence. Rational Reflection supports this explanation of the story.

However, Rational Reflection has counterintuitive consequences in some cases, such as the “Unmarked Clock” case, introduced in Williamson (2014). Here is that case (based on the presentation in Christensen 2010b; see also Elga 2013; see Horowitz 2014 for a similar case, discussed in connection with epistemic akrasia, and see also Sliwa & Horowitz 2015 for a non-perceptual case with similar features):

The Unmarked Clock: Chloe is looking at an unmarked clock with just a minute hand, which jumps discretely between its positions. The hand is pointing somewhere around where the 4 would be, if it were marked, which of course it isn’t. Chloe is wondering: is the hand pointing to the 19? The 20? The 21? (call those propositions “P19”, “P20”, and “P21”).

Williamson, Christensen, and Elga (among others) all agree on the following about this case:

(1)
Chloe shouldn’t be certain of any of P19, P20, or P21.
(2)
Chloe’s credence in whichever of these propositions is actually her evidence should be highest, and should taper off as possibilities become more remote. (In other words, if the hand is really at 20 minutes after the hour, she should have highest credence in P20, a bit lower credence in P19 and P21, and lower credence still in P18 and P22.)
And finally,

(3)
Chloe can figure out all of these facts about her epistemic situation simply by thinking about the setup of the case, as we just have.
The problem is that (1), (2), and (3) together entail that Chloe should violate Rational Reflection.

Here is why: suppose the hand is at 20 minutes after the hour, and Chloe’s credence is in fact distributed as it should be, with P20 receiving the highest value. Since Chloe is rational, then by (2) above, she should also give significant credence to P19 and P21. Now consider the implications for what Chloe thinks her credence should be. In P20, Chloe’s current credence is rational. But in P19 and P21 (which we have just said she gives significant credence to), her current credence in P20 is too high. So she is in a position to conclude the following about her credence in P20: it’s definitely not too low, but it may well be too high. This unbalanced state violates Rational Reflection, and also looks like an instance of epistemic akrasia.

Adam Elga (2013) argues that this sort of situation motivates a different principle, which he calls “New Rational Reflection” (following Ned Hall’s “New Principal Principle”, and the argument in favor of it; see Hall 1994). Elga argues that just as we should not in general defer (directly) to experts when we know more than they do, we should not in general defer to rationality in cases where it is rational to doubt one’s rationality. If we use “Cr” for an agent’s credence, and “Pr” for a candidate ideally rational credence, we can express Elga’s principle as follows:

New Rational Reflection: Cr(A∣Pr is ideal)=Pr(A∣Pr is ideal)

Both Rational Reflection and New Rational Reflection have us defer to rationality as we would defer to an expert. But whereas Rational Reflection has us defer to rationality as an expert with exactly our evidence, New Rational Reflection has us defer to rationality as an expert who has our evidence and is certain that it is an expert. Elga argues that this is the right way to defer to experts more generally, making New Rational Reflection (on his view) simply a more carefully-formulated expert deference principle. (See Pettigrew & Titelbaum 2014 for a concurrent view.)

In the clock case, New Rational Reflection also allows for epistemic akrasia: Chloe’s beliefs about the clock come apart from her estimate of what’s rational for her to believe about the clock. But New Rational Reflection offers us an explanation for why this is unproblematic. In normal cases, what’s rational is a good guide to what’s true: if it’s rational to believe it will rain, it’s also likely to be true that it will rain. But in the clock case, this generality doesn’t hold. We can predict that rationality and truth will come apart. So when Chloe’s belief matches her best estimate of what’s true, it will diverge from her best estimate of what’s rational. Furthermore, this divergence comes about because of uncertainty about what’s rational. So by eliminating that uncertainty—by deferring to rationality only on the condition that rationality is not uncertain about its own expertise—New Rational Reflection aims to eliminate that gap between rationality and truth. (See Elga 2013, as well as Horowitz 2014, for further discussion of this feature of the case.)

Several authors agree with this line of thought, accepting both the setup of the clock case and Elga’s general line of thought regarding how it should be treated. These authors take the clock case to be one in which epistemic akrasia is rationally permissible after all, showing that any anti-akrasia norms must be formulated carefully. For similar discussion, see Horowitz’s (2014) discussion of the dartboard case (which is modeled after the unmarked clock). There, Horowitz argues that epistemic akrasia is rationally permissible when we expect the evidence to be “falsity-guiding”; though see Weatherson (2019: ch. 10), and Hawthorne, Isaacs, and Lasonen-Aarnio (2021) for arguments that this condition is too narrow. Sliwa and Horowitz (2015) present an alternative level-bridging principle, “Evidential Calibration”, and argue that, like New Rational Reflection, it can help differentiate between rational and irrational cases of epistemic akrasia, as well as rule out bootstrapping. Christensen (2016a) proposes what he calls the “Idealized Thermometer Model”, and makes similar points in its favor. Dorst (2020; see also his 2019) proposes another principle, “Trust”, which is a weakening of Rational Reflection. Dorst argues that Trust allows us to be uncertain about rationality, while still treating rationality as an expert; this vindicates the idea that we should defer to our evidence, and (following I. J. Good) that more evidence is always epistemically beneficial. All of these level-bridging principles take higher-order evidence into account, but also allow some instances of epistemic akrasia.

If we agree with this line of thought, we might draw two lessons. First: treating rationality as an expert is a complicated job, and any rational expert deference principle must be formulated carefully. If we can predict that rationality and truth will come apart, we should not defer unrestrictedly to rationality. And relatedly, we might take cases like this to show that epistemic akrasia can be rational: it can crop up even on some views according to which higher-order evidence is epistemically significant.

Some epistemologists disagree with these lessons, and moreover, with the entire setup of the clock case. One camp of detractors objects to claims (1), (2), and (3) as set out above. These epistemologists argue that we cannot be rationally uncertain about what our evidence is (as Chloe is) or about what it supports. See, for example, Stalnaker (2009), Smithies (2019: ch. 11), and Skipper (2021). Salow (2018) argues that the conception of evidence required to get the puzzle going can be used to allow “biased inquiry”. Cases like the unmarked clock thus present a choice point for epistemologists who want to accommodate higher-order defeat: accept that such cases are possible and reject Rational Reflection, or reject such cases and adopt a strong transparency requirement about evidence and rationality.

Others disagree from the opposite side: Maria Lasonen-Aarnio (2015) argues that even the modified principle, New Rational Reflection, presupposes too much self-knowledge. She advocates rejecting all level-bridging principles, at least as far as our theory of evidential support is concerned (though see section 4 for discussion of her view on cases like Aisha’s).)

Finally, Christensen (2021a) argues that New Rational Reflection doesn’t go far enough. New Rational Reflection says we should defer, to some extent, to any theory of rationality we think might possibly be right. But what if we think it’s possible that rationality can come apart from the truth—as it does in the clock case, or even more broadly, as it does on views that allow moral encroachment? (On the extreme end, consider views on which rationality is about believing what makes you happy.) Surely we should not defer to them, even a little bit. (If one of them is right, of course, we should follow it—but the present question is just about whether we should treat different candidates for rationality as experts.) So Christensen argues we should reject New Rational Reflection, and focus on attaining beliefs we take to be accurate, rather than beliefs we take to be rational. This may mean moving away entirely from rationality-focused level-bridging principles.

3.2.2 Reliability-focused principles
So far we have focused on Rational Reflection and New Rational Reflection, which are motivated by the thought that in accommodating higher-order evidence, we should calibrate our first-order beliefs to our higher-order beliefs about rationality. Another way to approach the question begins with reliability. The thought here is that higher-order evidence affects our first-order beliefs because of its bearing on our reliability—that is, our propensity to get to the truth, under the relevant circumstances. Examples of this approach include Elga’s “Equal Weight View”, quoted above; Christensen (2007a)’s “Integration”; the “Calibration Rule”, discussed by White (2009); Weatherson’s (ms—see Other Internet Resources) “Judgments Screen Evidence” (which he argues against); “Guess Calibration”, discussed in Sliwa and Horowitz 2015; “Calibration”, discussed in Schoenfield 2015a; and the “Simple Thermometer Model” discussed in Christensen 2016a. As a representative example, here is White’s “Calibration Rule”, which he presents as a consequence of the Equal Weight View:

Calibration Rule: If I draw the conclusion p on the basis of any evidence e, my credence in p should equal my prior expected reliability with respect to p.

There are various complications involved in interpreting this rule (for instance, it refers to “drawing a conclusion”, which is an all-or-nothing judgment, as well as credences). But notice that, unlike Rational Reflection, the Calibration Rule makes no reference to rationality. (It does specify that the conclusion is drawn on the basis of some evidence, but as White points out in his discussion of the rule, the evidence plays no part in determining what we should believe.)

Reliability-based level-bridging principles must also be formulated carefully in order to navigate worries in the vicinity of the generality problem. (Among other things, one’s reliability estimate on a particular occasion must take base rates into account; see Isaacs 2021.) But just as we saw before, such principles are always put forth in conjunction with—or incorporate some element of—Independence principles. If we can answer the question of how to circumscribe Independence, presumably that will answer the generality problem in this domain as well.

Focusing on reliability, rather than rationality, has advantages and disadvantages. An important advantage is that this approach allows us to accommodate cases like the unmarked clock, discussed in the previous section. But the disadvantage is that reliability-based level-bridging principles do not answer certain questions which, for many epistemologists, lie at the heart of the higher-order evidence debate: can epistemic akrasia be rational? And should we in some sense treat rationality as an expert to which we should defer? If our level-bridging principle does not mention rationality, it will not have immediate consequences for these questions, which may seem unsatisfying to some.

Distinguishing between rationality-focused and reliability-focused level-bridging principles highlights another choice point for epistemologists. Some take questions about akrasia to be central, and defend rationality-based level-bridging principles for that reason (Smithies 2019 is a paradigmatic example; see also Neta 2019). Others—even those who support level-bridging—take cases like the unmarked clock to show that these questions aren’t so central after all, and that perhaps epistemic akrasia is not so significant (Christensen 2016a and 2021a are paradigmatic examples of this approach). A third strategy is to say that anti-akrasia, or level-coherence principles, have a special sort of normative status that differs from other rational requirements. Some of the proposals discussed in the next section defend this view.

4. Dilemmas and Two-Norm Views
We began by discussing a puzzle raised by higher-order evidence: it seems that agents in situations like Hypoxia should reduce confidence, but also that if they do, they will be ignoring evidence in a problematic way. We have seen some arguments against reducing confidence, and some proposals for how Aisha should reduce confidence. But some epistemologists think that neither of these possibilities gives us the full story. Maybe level-bridging principles are genuine rational requirements, but there is still something wrong with Aisha if she reduces confidence. Or maybe they are not genuine rational requirements, yet there is something else wrong with Aisha if she does not reduce confidence. Maybe they are both rational requirements, and Aisha is facing an epistemic dilemma. (An alternative way to frame the puzzle focuses on epistemic akrasia: maybe Aisha is rationally required to be epistemically akratic in her situation, but there is something else wrong with her if she is epistemically akratic, and so forth.)

This section discusses two strategies which acknowledge the remaining puzzle and attempt to solve it. One, defended most prominently by David Christensen, holds that higher-order evidence gives rise to epistemic dilemmas, where there is no fully rational response available (though there may be a rationally best response). So Aisha is both required to believe G and to doubt G, and she is just unfortunately unable to do both. Another family of responses, here called “two-norm views”, aim to separate different modes of epistemic evaluation, and argue that Aisha’s conflicting requirements somehow issue from different normative realms. The common goal of all these strategies is to explain the apparent conflict of norms in cases like Hypoxia, without denying the legitimacy of any of these conflicting norms.

4.1 Dilemmas
Christensen takes the puzzles surrounding higher-order evidence to show that the requirements of rationality sometimes conflict with one another, putting agents like Aisha in an epistemic bind. This proposal differs from the two-norm views discussed below, in that there is just one notion of epistemic rationality at work. According to the dilemma view, in some circumstances, it is impossible to satisfy all the rational requirements at once.(see Christensen 2007a, 2010a, 2013, 2016b, and 2021c). In his more recent work (see Christensen 2021c), Christensen sees the norms in conflict, in Aisha’s case, as one requiring us to believe what our evidence entails, and another requiring us to revise in light of higher-order evidence. (An alternative possibility, which Christensen suggests in earlier work [see his 2013], is that the second norm is explicitly an anti-akratic norm.)

An important feature of Christensen’s view is that, although Aisha is subject to conflicting requirements, there is still a best epistemic response in her situation. (Christensen holds that the best response is to reduce confidence.) This raises a question: what determines which response is best? See Leonard 2020 for arguments against the dilemma view; Leonard defends a nearby view according to which there are conflicting norms, but it’s indeterminate (among a restricted set of possibilities) what Aisha should believe. Knoks (2021) defends a view along similar lines, arguing that Aisha’s situation is permissive (again, among a similarly-restricted set of possibilities). The possibility of dilemmas in epistemology raises several questions: how can epistemic requirements relate (or not) to notions of epistemic blame, and how can they guide our beliefs? See Hughes 2019 and 2021, e.g., for further discussion of these issues (though mostly focused on a different putative source of conflicting requirements); Hughes defends the position that we should accept epistemic dilemmas.

4.2 Ideal vs. non-ideal modes of evaluation
A few authors have suggested that while higher-order evidence has genuine normative significance, this significance belongs only to some non-ideal normative realm. So while a rationally ideal agent’s higher-order evidence would have no effect on her first-order beliefs, a non-ideal agent’s evidence should have such an effect—precisely because she is non-ideal.

Joshua DiPaolo (2019) develops one version of this view. Drawing on work in political philosophy, he argues that we need an epistemological “theory of the second best”. On his proposed view, the norms that apply to ideal agents are different from the norms that apply to non-ideal agents. While the ideal norms define a standard of perfection for all of us, non-ideal norms tell us how to approach that standard, taking our imperfections into account. DiPaolo argues that this approach allows us to resolve the apparent tensions involved in accommodating higher-order evidence: ideal rationality requires ignoring higher-order evidence, but non-ideal rationality requires respecting it.

While non-ideal agents are limited in their reasoning abilities, they are also limited in their abilities to double-check and “police” themselves. Appealing to this consideration, Joshua Schechter (2013) makes a suggestion that cuts in the opposite direction from DiPaolo’s: he argues that perhaps our epistemic imperfections cap our responsibility to respond to higher-order evidence. This means that while our available evidence may call for extensive belief revision—and while a more ideal agent would revise her beliefs in response to higher-order evidence—non-ideal believers like us are permitted to stop when we’ve done what we can.

Declan Smithies (2019) also defends a view on which the ideal/non-ideal distinction comes into play. This is discussed in more detail below.

4.3 Best plans to follow vs. best plans to make
Another kind of two-norm view comes from Miriam Schoenfield (see her 2015b and 2018). Schoenfield interprets judgments about rationality, in cases like Aisha’s, as plans. She points out that we can evaluate plans in (at least) two different ways: by looking at what will happen if they are followed perfectly, and by looking at what will happen if they are made. If you need to leave the house at 10:30, but are habitually running late, “leave the house at 10” might be the best plan to make, even if “leave the house at 10:30” is the best plan to follow. This is similar to DiPaolo’s suggestion in that the difference between the best plan to make and the best plan to follow depends on a person’s (predicted) rational shortcomings: the best plan to make is one that takes these shortcomings into account in a particular way. However, Schoenfield’s view is not that higher-order evidence only has rational import for non-ideal agents; rather, it has the import it has for anyone who rationally believes that they are non-ideal.

An advantage of this approach is that it allows us to focus on accuracy as the primary target of epistemic rationality. Schoenfield frames both modes of evaluation in terms of accuracy: specifically, the accuracy-related consequences of the plan. So if she is right that the best-plan-to-make/best-plan-to-follow distinction can explain higher-order evidence, we would end up with a relatively uniform two-norm view. See Horowitz 2019 for two objections: first, that focusing on consequences seems to open the door to non-epistemic plans, such as “have a sandwich before reasoning”; second, that the best plan to make might differ among different believers, in which case this strategy would not yield anything like a general defense of revising in response to higher-order evidence. This second worry also raises questions about DiPaolo’s proposal and how universal we can expect a non-ideal rationality to be.

4.4 Reasons vs. rationality
Alex Worsnip (2018) argues that we can explain the oddness of higher-order evidence by distinguishing between two kinds of epistemic requirements: evidence responsiveness and coherence. If Aisha maintains her belief that G, and believes that her evidence may well not support this belief, she will believe everything her evidence supports. If she revises her belief that she has enough fuel (aligning it with her estimate of what the evidence supports) she will be coherent. This view is one that explicitly appeals to epistemic akrasia, as Worsnip’s coherence norms are effectively anti-akrasia norms.

4.5 Evidence vs. dispositions
Maria Lasonen-Aarnio (2020) argues that the conflict comes from two different modes of evaluation which we can apply to Aisha’s case. In addition to evaluating whether believers have correctly followed the epistemic requirements that apply to them, or have correctly accommodated their evidence, we can also evaluate their belief-forming dispositions. If Aisha holds onto her belief about G, while recognizing the danger of hypoxia in her own case, she is responding appropriately to her evidence and is (if her belief is formed in the right way) following the requirements that apply to her. But she is also manifesting a disposition that is unlikely to serve her well in the long term: ignoring what appears to be a conclusive reason for belief (her belief that she’s likely to be hypoxic, and therefore likely to be responding inappropriately to her evidence) will often involve actual conclusive reasons for belief. We can criticize Aisha for manifesting this disposition, even if this particular case is not one of the situations in which it goes wrong. (A relevant comparison here is Rule versus Act Utilitarianism: a good rule might occasionally lead to imperfect outcomes, whereas a good outcome might occasionally be the result of a bad rule. See Coates [2012] for a similar suggestion about rules in this context.)

Smithies (2019) defends a similar view, discussed in more detail in the next subsection.

4.5 Propositional justification vs. doxastic justification
Finally, Paul Silva (2017) and Declan Smithies (2019) each argue—though in different ways—that we can resolve the conflict by distinguishing between propositional and doxastic justification. (Also see Ye 2020 for objections to the move to doxastic justification in this context.) Let us consider Silva’s proposal first. An agent like Aisha, he argues, is propositionally justified in believing G, and in believing that her evidence may well not support G. But she cannot come to rationally hold the belief that G: in other words, she cannot be doxastically justified in believing G. Silva’s argument for this claim is in part an inference to the best explanation: although Aisha’s evidence supports G, it seems irrational for Aisha to act on that belief, suggesting that Aisha lacks knowledge of G. If Aisha’s belief is propositionally justified but not known, this in turn suggests that the belief is not doxastically justified. (See also van Wietmarschen 2013 for a similar proposal in the case of peer disagreement. Van Wietmarschen’s argument does not appeal to knowledge; rather, he argues directly that an agent’s belief is not well-grounded, or doxastically justified, if her basis for holding it does not respond to her higher-order evidence.)

Smithies (2019) invokes this distinction to a slightly different end. As mentioned above, he argues that we can never be propositionally justified in believing falsehoods about what our evidence supports—so, Aisha is propositionally justified in believing G, and propositionally justified in believing that her evidence supports this. But assuming that Aisha is a normal, non-ideal believer, her own doxastic dispositions won’t be sensitive enough to the evidence to safely track her propositional justification. This means that she can’t be doxastically justified in believing that her evidence supports G. Interestingly, Smithies argues that in this case a non-ideal agent like Aisha should be epistemically akratic; the ideal, non-akratic state isn’t available to her, and an akratic state is, he argues, the best she can do.

5. Conclusion
We began by noting that higher-order evidence gives rise to a puzzle. It seems that “higher-order evidence”—information about our own irrationality or unreliability—should prompt us to revise our beliefs about the world, but if we do so, we must ignore evidence and reasoning that is directly relevant to the truth of those beliefs. Much of the literature on higher-order evidence revolves around this puzzle: arguing that we should reject one side of the puzzle or the other, or finding ways to hold onto both.

As of this writing, two related questions emerge as central to the debate going forward. First: is higher-order evidence significant because it gives us information about our own rationality? Or because it gives us information about our own reliability? And second: are there genuine norms prohibiting epistemic akrasia? (So, should our beliefs about what’s rational line up with our beliefs about the world?) Or does the appearance of these norms merely arise because of nearby norms regarding reliability—or, perhaps, because there are multiple, conflicting modes of epistemic normativity? Untangling the puzzles surrounding higher-order evidence will ultimately involve answering these questions as well, as well as broader questions about the relationship between rationality and truth.

1. A Caveat About Theories
A theory of development should explain the core phenomena of growth, cell differentiation, and morphogenesis, which together transform an egg into a mature organism. However, beyond this rough consensus uncertainty abounds. Exactly what entities undergo development, and what are the process’ temporal, spatial, and functional boundaries? These questions are debated in biology and philosophy (Bonner 1974; Pradeu et al. 2011). Also unsettled are the nature and significance of scientific theories. Whether a general theory of development is possible or desirable hinges in part on how “theory” is defined. Yet there is no philosophical consensus to fall back on. Furthermore, developmental biology is not a traditionally theoretical field (in contrast to, say, evolutionary biology; see the entry on developmental biology). A recent edited collection, Towards a Theory of Development, reveals a variety of viewpoints and frameworks, ranging from skepticism about any such theory, to specific proposals influenced by physics, mathematics, biochemistry, systems biology, and more (Minelli & Pradeu 2014a). Broadly speaking, however,

most developmental biologists have not been strongly interested in constructing an overarching theory of development and… developmental biology has not been a focal topic for philosophers of biology. (Burian 2014: xii)

The subject has received little focused attention in biology or philosophy.

The term “theory”, for the purpose of this entry, refers to broad conceptual frameworks about the nature of the developmental process as a whole. This is more inclusive and less demanding than traditional philosophical notions of theory; “big picture” views offering an overall characterization of and/or basic principles for understanding development. Epigenesis and preformation are alternative theories in this sense: two persistent ways of describing and seeking to explain the development of individual organic form.

2. The Problem
The core question underlying the existence of these two competing philosophical traditions is the extent to which something is formed or organized from “the beginning” or whether organization and form arise only over time. Nineteenth-century uses of the term “evolution” included a sense of unfolding of preexisting form, a sort of preformationism in contrast to the epigenesis of the day. Discussions of “evolution” and “epigenesis” can therefore be misleading in retrospect since the former term has assumed a meaning closer to the older meaning of epigenesis (Bowler 1975). Making things even more complicated, by the late nineteenth century “preformationism” really was more about various versions of predetermination or predelineation than preexistence of form as such. Furthermore some authors saw epigenesis or preformation as entirely internally directed, while others in each case allowed responses to the environment. In the background lie debates about the relative significance of predestination and free will, for persons, for organic beings, or even for the inorganic. In each case, it is important to keep in mind what the particular writer was saying and the arguments presented. Thus, discussions of epigenesis and preformation often bring in other ancillary questions and are difficult to separate from their contexts. This entry is an effort to extract what is centrally at issue and to focus on key contributions to the discussion.

The terms of debate can in principle apply to the inorganic world; e.g., solar systems can “evolve” and could develop epigenetically. Yet they are not thought of as doing so, typically, and so epigenesis and preformation are primarily applied to the organic world. Species can evolve or develop more or less gradually, with more or less form already physically existing or programmed in from the beginning. Yet typically discussions of epigenesis and preformation have focused on individual organisms and their development rather than on species. The emphasis is on different interpretations of the actual developmental process as it plays out in time, in individual organisms. Therefore, this entry focuses on individual organisms and understandings of their development processes. Even more specifically, this means looking at the development of their form and to a lesser extent also function. Epigenesis and preformation offer two competing interpretations of what is involved, with a range of alternatives in between. The two approaches draw on different metaphysical and different epistemological sets of assumptions. We can get at the central issues by looking most closely at a series of focused episodes.

3. Aristotle and Aristotelianism
Aristotle was a keen observer of many things, including embryos. Looking at chicks, for example, and drawing on his interpretations developed earlier for the physical sciences, he saw material, final, formal, and efficient causes at work in the generation of individual organisms. The early egg was not formed; it did not already contain a little chick (or whatever the species). Instead, an individual animal only gradually acquired a heart that began beating; likewise for the other parts that make it a chick. The material may be there from the beginning, but the formal cause only gradually plays out along with the efficient cause of embryonic development.

Thus, Aristotle could fit his observations of embryos into his larger theoretical interpretations of the world. In sexual generation, individual organisms begin when the fluids from the mother and the father come together. This combines the essential causes and initiates the developmental process. The maternal contribution is the material cause, which resides in the menstrual blood. After “the discharge is over and most of it has passed off, then what remains begins to take shape as a fetus” (Aristotle De Generatione Animalium [GA], 1.727b17–18). Yet the menstrual blood, or female semen, is only that out of which it generates and must be acted upon by the male semen which is that which generates. Together, consistent with the essential nature of the species and telos (or final cause) in question, the formal cause and efficient causal process act to bring a formed individual organism from potential into actual being. Gradually, over time, an individual organism’s form begins to emerge from the unformed. The male and female parents serve as the “principles of generation” for each individual organism (in sexually-generating species).

For Aristotle, an individual life begins when the male and female semen are brought together. This is an external action, which starts the individual formative process. From that point on, the process is internal, initially driven by causes internal to the combined fluids. The process then leads to formation of the individual’s type, since “once a thing has been formed, it must of necessity grow” (Aristotle GA 1.735a18–19). (See Lennox 2001 for discussion of Aristotle’s predecessors on these points; see Van Speybroeck et al. 2002; Vinci & Robert 2005; Connell 2016, 2020; Falcon & Lefebvre 2017; Henry 2017; Hopwood et al. 2018; on Aristotle’s theory of generation and subsequent scientific development of these ideas.)

An individual organic life requires an internal source of motion, or “soul”, which resides in the material body from the outset. This soul guides the gradual epigenetic process of development. This is the Aristotelian and not the Christian soul. Soul consists of the vegetative (for all organisms), locomotory (for animals), and rational (for humans). The soul, consisting of one to three parts depending on the kind of living being, resides in the combination of male and female semen. The living differs from the dead because of the action of the soul. Therefore, it is the teleological drive of the potential that actualizes the individual and its form and function, epigenetically, gradually, and internally.

Aristotelians followed Aristotle and without much further study of embryos interpreted the process of generation, including human development, as gradual and epigenetic. Traditional Catholicism agreed. St. Augustine and St. Thomas Aquinas both held that hominization, or the coming into being of the human, occurs only gradually. Quickening was thought to occur around 40 days, and to be the point at which the merely animal mix of material fluids was ensouled. Until 1859, when Pope Pius IX decreed that life begins at “conception”, the Church was epigenetic along with the Aristotelians (see Maienschein 2003).

4. Eighteenth-Century Debates
Shirley Roe’s discussion of the eighteenth-century debates is an excellent examination of the context. Enthusiasm for scientific study of natural phenomena of all sorts was combined with particular interest in natural history and changes over time and with newly available microscopic methods to stimulate interest in development (Roe 1981). Aristotelian epigenesis still provided the background assumptions about individual development as the eighteenth century began, and researchers sought to observe the gradual emergence of form from non-form. Yet Aristotelian accounts called for the efficacy of the causes, acting through the process of ensoulment. In effect, this interpretation of epigenesis depended on a life force within the organism driving its emergence of form. Those who accepted epigenesis also accepted a form of vitalism (see Detlefsen 2006, Zammito 2018 for more on early modern vitalism debates).

Matter in motion, by itself, would not seem to have the capacity to produce these results. How could unformed matter become formed? How could the emerging form acquire capacity to function without some vital force or factor that was not strictly material? This was the problem for materialists. Those who began with a materialist metaphysics, assuming that all that can exist is matter in motion, could not see how gradual epigenetic emergence of form could occur. The early modern period brought debates between those who started from metaphysical assumptions of materialism and those who started from epistemological assumptions that empirical observation should provide the basis for scientific knowledge.

One popular representation of the alternative, preformationist view was the homunculus. Whether initially intended seriously or as a way to capture alternative ideas, the idea of a tiny preformed little person did capture attention. Nicolaas von Hartsoeker gave us the image in 1694 of a tiny man in the sperm, which became the starting point for spermists. Others, ovists, accepted the idea of a preformed organism—but in the egg rather than sperm. Both views are preformationism taken quite literally. The form that the individual adult organism would assume was, physically and materially, preformed from the earliest stages of development. The subsequent process was just growth.

Not all preformationists took their preformationism quite so literally or graphically. But that view did present a competing alternative to Aristotelian epigenesis by the eighteenth century (see Bowler 1971, Pinto-Correia 1997). As Iris Fry has argued in her study of origins of life debates, only with preformation could a materialistic mechanist be a good Christian in the eighteenth century (Fry 2000: 26, citing Farley 1977: 29). This debate played out, for example, in the work of Caspar Friedrich Wolff and Charles Bonnet, both looking at chick development (Detlefsen 2006). They looked at the same thing and even fundamentally agreed about what they saw, but their conclusions were quite different. This story can be seen as a debate about scientific theory. Wolff was an epigenesist, maintaining that form emerges only gradually. Bonnet was a preformationist, insisting that form exists from the beginning of each individual organism and only experiences growth over time. In addition to these theoretical and epistemological issues, there is also a story about metaphysics. The eighteenth century brought debates between metaphysical materialists who were forced into preformationism, and epistemological epigenesists who observed form emerging only gradually and who were willing to accept vitalism as the only apparent causal explanation for the emergence of form from the not-formed (Roe 1981; Maienschein 2000; Nicoglou & Wolfe 2018 [and references therein]; Wolfe 2021).

5. Evolution and Embryos: A New Preformationism
In 1859, Darwin focused on embryos and their usefulness for understanding evolutionary relationships. Ernst Haeckel brought the study of embryos to popular attention. And histologists and embryologists, especially in Germany and the United States, used rapidly improving microscopic techniques to observe far more than had been possible before. These observations, in the context of evolutionary interpretations, raised new questions and provoked new answers. The understanding of both epigenesis and preformation underwent transformation so that the debates brought new questions along with the traditional differences.

Darwin pointed to embryology as fundamental for interpreting historical relationships. In Chapter 13 of the Origin he asked

How, then, can we explain these several facts in embryology,—namely the very general, but not universal difference in structure between the embryo and the adult;—of parts in the same individual embryo, which ultimately become very unlike and serve for diverse purposes, being at this early period of growth alike;—of embryos of different species within the same class, generally, but not universally, resembling each other;—of the structure of the embryo not being closely related to its conditions of existence, except when the embryo becomes at any period of life active and has to provide for itself;—of the embryo apparently having sometimes a higher organisation than the mature animal, into which it is developed. (1859: 442–443)

But we know that this was a rhetorical question, and sure enough he concluded that

I believe that all these facts can be explained, as follows, on the view of descent with modification. (1859: 443)

And that furthermore,

the leading facts in embryology, which are second in importance to none in natural history, are explained on the principle of slight modifications not appearing, in the many descendants from some one ancient progenitor, at a very early period in the life of each, though perhaps caused at the earliest, and being inherited at a corresponding not early period. Embryology rises greatly in interest, when we thus look at the embryo as a picture, more or less obscured, of the common parent-form of each great class of animals. (Darwin 1859: 450)

Haeckel saw ontogeny as the brief and rapid recapitulation of phylogeny and saw each individual’s development as following the sequence of, and indeed caused by, the evolutionary history of that individual organism’s species. In his highly popular books, widely translated and widely read, Haeckel offered pictures of comparative embryology. See, he seemed to suggest, the human form emerges following the evolutionary development and adaptations of its ancestors. Form comes from form of the ancestors, and it unfolds following pre-scripted stages (Haeckel 1866).

Darwin was not an embryologist, and he did not contribute to our understanding of embryogenesis as such. Nor did Haeckel, really. But while Darwin’s use of the embryo in supporting evolutionary theory and in helping to interpret evolutionary relationships was consistent with various versions of either epigenetic or preformationist development, Haeckel’s view was decidedly preformationist. Here, then, was a preformationist interpretation based not on additional embryological observations but on adherence to Haeckel’s own metaphysical view—monistic materialism—and to his desire to provide evidence for evolution. The Haeckelian approach reflected the context in which those studying cells and embryos worked at the end of the nineteenth century.

6. Late Nineteenth-Century Debates: Weismann and Hertwig
In 1899, American biologist William Morton Wheeler suggested that there are just two different kinds of thinkers. Some see change and process, while others see stability. Heraclitus, Aristotle, physiology, and epigenesis characterize one way of looking at the world, while Parmenides, Plato, morphology, and preformationism characterizes another. These are, Wheeler felt, stable and persistent classes, with just the nature and details of their differences changing over time. Yet by the end of the nineteenth century, he argued, neither a strict preformationist nor a strict epigeneticist should prevail. Rather he called for a middle ground, for:

The pronounced “epigenecist” of to-day who postulates little or no pre-determination in the germ must gird himself to perform Herculean labors in explaining how the complex heterogeneity of the adult organism can arise from chemical enzymes, while the pronounced “preformationist” of to-day is bound to elucidate the elaborate morphological structure which he insists must be present in the germ.

Furthermore, it is not to philosophy but to science that we must look to resolve the relative contributions of each, for “Both tendencies will find their correctives in investigation” (Wheeler 1899: 284).

Wheeler was stimulated by recent late nineteenth-century debates, themselves provoked by a flood of new discoveries. August Weismann and Oscar Hertwig provided particularly strong and contrasting positions. Weismann had begun from an epigenetic viewpoint and initially rejected the idea that individual form emerges through the unfolding, or evolution, of pre-existent form in the inherited germ. But by the time his Das Keimplasm appeared in 1892 (translated into English in 1893), Weismann had changed his mind. As Weismann wrote:

My doubts as to the validity of Darwin’s theory were for a long time not confined to this point alone: the assumption of the existence of preformed constituents of all parts of the body seemed to me far too easy a solution of the difficult, besides entailing an impossibility in the shape of an absolutely inconceivable aggregation of primary constituents. I therefore endeavoured to see if it were not possible to imagine that the germ-plasm, though of complex structure, was not composed of such an immense number of particles, and that its further complication arose subsequently in the course of development. In other words, what I sought was a substance from which the whole organism might arise by epigenesis, and not by evolution. After repeated attempts in which I more than once imagined myself successful, but all of which broke down when further tested by facts. I finally became convinced that an epigenetic development is an impossibility. Moreover, I found an actual proof of the reality of evolution, which … is so simple that I can scarcely understand how it was possible that it should have escaped my notice so long. (Weismann 1892 [1893: xiii–xiv])

His “proof” provided an account of how, within the context of cell theory and given that the entire body begins in one fertilized cell, all the diverse body parts can become so diversely differentiated. The key is in the special material of the germ cells, Weismann decided. Within these cells lies all the determinants necessary to direct development. Inheritance, that is, causes development and differentiation.

Weismann’s theory postulated the existence of several levels of hypothetical units. By the 1890s, it was agreed that individuals begin as cells, those cells contain nuclei, and that nuclei contain chromosomes. The chromosomes are the material of heredity, Weismann postulated, and they consist of a string of determinants, correlated with characters in the organism. Each determinant consisted of a number of material particles called biophores, inherited from both parents. These biophores compete with each other and some prevail, which then determines the character of the determinant, which in turn determines the character of the organism. During each cell division, the original whole chromosomal material is divided up, so that the effect is like a mosaic. Each cell becomes the right type just because of the action of the determinants distributed to it. As Weismann put it,

Ontogeny, or the development of the individual, depends therefore on a series of gradual qualitative changes in the nuclear substance of the egg-cell.

Cells are self-differentiating

that is to say, the fate of the cells is determined by forces situated within them, and not by external influences. (Weismann 1892 [1893: 32, 134])

Conditions external to the cell itself cannot guide development, but rather the causes lie within. And cell differentiations that make up complex organisms are predetermined. Frederick Churchill’s magnificent biography of Weismann discusses these ideas in depth (Churchill 2015).

Oscar Hertwig disagreed. He felt that Weismann made too many assumptions and actually provided no real explanation of development and differentiation at all. In his work of 1894, Präformation oder Epigenese, Hertwig complained that Weismann’s theory:

merely transfers to an invisible region the solution of a problem that we are trying to solve, at least partially, by investigation of visible characters; and in the invisible region it is impossible to apply the methods of science. So, by its very nature, it is barren to investigation, as there is no means by which investigation may be put to the proof. In this respect it is like its predecessor, the theory of preformation of the eighteenth century. (Hertwig 1894 [1900: 140])

In contrast to Weismann’s preformationism, Hertwig pointed to the interactions of cells and to the differences among cells for the source of differentiation. Complexity is not built in from the beginning, but emerges over time, dynamically, and interactively. A cytologist himself, Hertwig saw the intricate structures already part of the unfertilized egg, and the changes that occur with fertilization. The egg is not a completely unstructured blob, but rather a complex of different materials that can respond to influences both within the egg and from the external environment. Cells behave like small organisms, and it is the interactions of these separate organisms that makes the whole. As Hertwig put it:

I shall explain the gradual, progressive organization of the whole organism as due to the influences upon each other of these numerous elementary organisms in each stage of the development. I cannot regard the development of any creature as a mosaic work. I hold that all the parts develop in connection with each other, the development of each part always being dependent upon the development of the whole.

Furthermore,

during the course of development, there are forces external to the cells that bid them assume the individual characters appropriate to their individual relations to the whole; the determining forces are not within the cells, as the doctrine of determinants supposed. (Hertwig 1894 [1900: 105–106, 138])

Hertwig and Weismann continued to argue, as did others, both about the metaphysical nature of the organism as well as about the epistemological demands for gaining knowledge about it, with no generally accepted way to resolve the issues. Given the information at hand, it seemed that Wheeler was right. There were just two different types of people, drawing on two different sets of values and emphases. Both relied on assumptions, and only new evidence could move the discussion forward.

7. Late Nineteenth-Century Debates: Roux and Driesch
Wilhelm Roux adopted much the same approach as Weismann’s and so, at first, did Hans Driesch. Yet their experiments ultimately led to new approaches and revised interpretations of what was at issue with epigenesist and preformationist accounts of development (Maienschein 1991b and Weber 2022). In 1888, Roux published results of his experiments on frog eggs. Working on the assumption of a mosaic type preformationism, Roux was persuaded that starting from the very first cell division, each cell would be different because it was already predetermined to be different.

Roux proposed an experiment, a simple and elegant experiment on the face of it. He proposed to take a developing frog egg, after the first cell division, and to separate the two cells. Finding it impossible to separate the two cells, however, he simply killed one by inserting a hot needle. That cell just hung there like a blob of material and no longer differentiated. The other half organism, or single cell proceeded to develop, in Roux’s interpretation, as it normally would have developed (Roux 1888). The half became a half, just as it should if it were already preformed or predetermined as to its fate in the organism. Roux had, it seemed, confirmed the mosaic hypothesis.

A few years later, Driesch was working at Naples and had access to sea urchin eggs. Fortunately, because of Oscar and his brother Richard Hertwig’s study of these eggs, Driesch knew that if he shook the two cells they would separate completely. Driesch reported agreeing with Roux and intending to confirm Roux’s results. But since the sea urchin eggs could actually be separated, he felt that his results would be even more convincing. Imagine his surprise when he looked the next morning after separating the eggs and found not two half embryos but two smaller sized urchin larvae. As he noted,

I must confess that the idea of a free-swimming hemisphere or a half gastrula open lengthwise seemed rather extraordinary. I thought the formations would probably die.

Not so.

Instead, the next morning I found in their respective dishes typical, actively swimming blastulae of half size. (Driesch 1892 [1964: 46])

In later experiments they developed even further, into apparently perfectly normal pluteus larvae, and even the four cell stage could do the same.

Driesch concluded with an epigenetic account, but an epigenesis relying strictly on materialistic factors (at least that was his initial response; Driesch did turn later to a version of vitalism). The early embryo retains its totipotency, he concluded. The fertilized egg clearly has the capacity to become a whole organism and so, apparently, do the cells after the early cell divisions. Not a mosaic of cells already predetermined by their inherited determinants in the nucleus, the early embryonic stages are instead a population of separate totipotent organisms, each capable of becoming a whole. It is only the interactions among them under normal conditions that lead to a complex, organized, integrated differentiated organism.

It might seem that Roux would have had to acknowledge the superiority of Driesch’s approach, since Driesch had actually separated the cells. But no. Instead Roux countered with an additional hypothesis. The nucleus retains the capacity to adapt, especially in simpler organisms. They need the capacity to regenerate when injured, and therefore the mosaic determination simply has not occurred yet. Each cell retains a “reserve idioplasm”, he argued, and this provides the necessary backup determination needed to form a whole organism (see Churchill 1966, 1973).

It seems that Wheeler was right. Roux, Weismann, and others had decided that development must be guided by predetermined mosaic differences. Preformation, stability, and predictability stood on one side, with epigenesis, dynamic process, and change on the other. And, as Wheeler noted, by 1899 the way forward lay between the extremes of strict preformation or epigenesis. Wheeler’s dissertation director Charles Otis Whitman agreed. Whitman felt that what biology needed was a clear statement of the alternative views, and then movement to a new standpoint examining how much depends on the organism’s developmental response to external conditions drawing on preformation, rather than on programmed internal unfolding alone.

Whitman, Edmund Beecher Wilson, and others at the Marine Biological Laboratory in Woods Hole, Massachusetts, dedicated considerable energy to discovering the nature of each cell and its internal organization and relationships, in an attempt to discover the relative contributions of preformation and epigenetic development to a materialistic explanation of development. By the early twentieth century, they had moved toward an understanding that included a fertilized egg that was to some extent preorganized and differentiated, including in the nuclear chromosomes, and also a capacity of the individual organism to respond to changes in its environment or to self-regulate. This was epigenesis allowing some minimal predeterminism.

8. Regulative Theories of Development
This “epigenesis-first” view of development set the stage for a strand of theorizing that continued well into the twentieth century. The main theoretical tension in twentieth- and twenty-first-century studies of development is not between classic preformation and epigenesis, but between different views about control of developmental processes. If genes are the primary source of control, then organismal development is preformationist in an important sense: it is genetically determined. But if control is more distributed or holistic, such that developing organisms are (in some sense) self-organizing, then the process is regulated in a way recalling classic theories of epigenesis. Several influential theories of morphogenesis and pattern formation take the latter view. Gene-based accounts of development take the former. In this way, the classic theoretical opposition between preformation and epigenesis is transformed and carried forward into the twentieth and twenty-first centuries. In the first half of the twentieth century, theoretical concepts associated with epigenesis played a significant role in studies of development. This section surveys the main theoretical efforts along these lines.

8.1 Organicism, gradients, and fields
Driesch’s experiments (see Section 7) demonstrated regulative development: the developing embryo compensated for experimental intervention rather than following a pre-determined plan. To account for this phenomenon without resorting to vitalism, a new theoretical approach was needed. One such was organicism, which Donna Haraway (1976) casts as a new Kuhnian paradigm for embryology in the first half of the twentieth century. Its tenets included:

the organism is a unified whole, with multiple connections between levels of complexity/organization;
development is a goal-directed process, regulated throughout rather than pre-determined; and
organismal shape and structure should be understood in terms of principles for achieving form.
Lenoir (1982) traces these ideas to Kant’s Critique of Judgment, notably reciprocal determination of parts and the whole organism during the process of development. A more explicit influence was von Bertalanffy’s systems theory of development (1928 [1933, trans. Woodger]; see the entries on levels of organization in biology and systems and synthetic biology). Another influence was D’Arcy Thompson’s seminal On Growth and Form (1917; see the entry on developmental biology). A key idea was that organismal form emerges from a self-organizing system, not the unfolding of a pre-existing program.

Haraway (1976) identifies four main elements of organicism:

the goal of explaining organismal form;
concepts of symmetry, polarity, and pattern;
field-particle duality (analogous to physics); and
links to structuralism in philosophy (i.e., a structure as a self-regulating, complex system involving multiple interacting levels of organization and spatio-temporal scales).
She examines these elements in the work of the paradigm’s principal architects in twentieth-century developmental biology: Ross Harrison, Joseph Needham, and Paul Weiss. Organicists sought mathematical yet autonomously biological laws to account for emergent order in developmental processes. Although such laws did not materialize, Haraway argues that metaphors (principally those of crystals and fields) played significant theoretical roles in their stead. More abstract theoretical concepts—of polarity, gradients, and fields—were also used to explain organismal form in the first half of the twentieth century. For example, Hans Spemann (1936 [1938]) proposed that

the body of many, if not all animals, at least in the embryonic state, possesses one or several axes with unequal poles along which there exists a gradient of some sort. The course of development depends upon these gradients to a high degree. (1936 [1938: 318]).

Similarly, Charles Manning Child hypothesized that organismal development is based on “activity gradients” grounded in metabolism. Others objected that these concepts are unclear, metaphysically murky, and unscientifically vitalist (see Gilbert, Opitz, & Raff 1996).

An important spur to gradient and field theories was the phenomenon of “the organizer”, demonstrated by Hilde Mangold’s experiments transplanting newt tissue. She moved a small piece from the dorsal lip of a developing Triton cristatus embryo into the early gastrula of another newt species (Triton taeniatus). Donor tissue thus came in contact with undifferentiated ectoderm of another species. The result: two conjoined embryos with different body axes. This indicated that dorsal lip tissue somehow “organized” host cells and tissues into another embryonic body. Spemann designated the dorsal lip of the embryo “the organization-center” or “organizer”. But how did this work? The proposed answer suggested that body axes result from a gradient of some chemical substance emanating from cells of the organizer. This was the starting-point for “field theories”; e.g.,

…the egg and early embryo consist of fields—gradients or differentiation centers in which the specific properties drop off in intensity as the distance from the field center increases…. (Harrison 1969: 258)

In discussions with other members of Cambridge’s Theoretical Biology Club, Joseph Needham sought a theory of the chemical nature of the “organizer”. Building on D’Arcy Thompson’s theories of biological form and insights from biochemistry, he conceptualized fields as spatial regions of a developing embryo, which determine for all points within a region a specific quality, direction, and intensity. The field as a whole exhibits (in)stability and equilibrium positions. Organismal development is thus defined as

a progressive restriction of potencies by determination of the parts to pursue fixed fates…this state of affairs can best be pictured in the manner of a series of equilibrium states. (Needham 1936: 58)

The overall process is to be explained by probabilistic “field laws” describing a sequence of equilibrium positions for a field, extending from proteins and fibers to cell shape and organismal morphology. Although Needham did not flesh out his theoretical ideas in detail, they show clear parallels with Waddington’s view of development, as well as recent systems approaches (see Section 9.1 and section 10.2).

Working in the US, Paul Weiss also elaborated field and gradient concepts to sketch a theory of development that anticipated key ideas of systems biology today (see the entry on systems and synthetic biology). His mature theory (“molecular ecology”) posited an array of molecular species in a cell, distributed, arranged, grouped in ways determined by their sterically-mediated interactions and physical environment (1968). Steric interactions are based on molecules’ shape and charge; biochemical features such as bonding and repulsion. Weiss theorized that these molecular interactions are organized by higher-level fields so as to produce patterns of cell differentiation, growth, and morphogenesis according to the principle of “gradual determination”. There is no pre-existing “seat” of embryonic organization in the egg or early embryo—instead, organization emerges in the process itself, through a physiological gradient. Weiss’s theory was based on extensive research on limb regeneration, neural development, grafting, and cell culture. A regenerated amphibian limb, for example, shows the correct orientation and organization of parts, even if derived from different cell types in another body part. How do the new parts acquire a “sense of direction” yielding correct morphological organization? Weiss’s answer is that some physiological gradient in the body, tells the cells “where they are and what to do”.

Weiss theorized this idea in terms of fields:

factors which cause the originally indefinite course of the individual parts of a germ to become definite and specific, and, furthermore, cause this to occur in compliance with a typical pattern. (1939: 290)

A field is organized from center to periphery, with a focal point of maximal intensity and gradual decrease from this center. This organization entails a “physiological gradient”: a robust distribution of (molecular) properties, which vary along the three spatial dimensions and along one or more axes (polarity). Its causal activity is holistic, determining cell behavior, which in turn produces growth, differentiation, and morphogenesis. Haraway (1976), Keller (2002), and Vecchi and Hernández (2014) examine the complex and uneven history of gradient and field concepts in developmental biology. Haraway, as discussed above, is concerned primarily with these concepts as metaphors structuring the organicist paradigm via the work of Harrison, Needham, and Weiss. Evelyn Fox Keller considers these concepts as part of the (so far largely unsuccessful) tradition of mathematicizing biology to understand development. Davide Vecchi and Isaac Hernández elaborate on Keller’s view, arguing that the concept of “morphogenetic field” was supplanted by Wolpert’s concept of “positional information”, part of the mid-twentieth-century theoretical shift from organicist ideas to genetic control of development (see Section 8.3).

8.2 Turing’s reaction-diffusion model
Eschewing genetics, Turing’s theory of morphogenesis (1952) sought to explain how patterns first emerge in an early embryo. His answer was a simple model consisting of two reaction-diffusion equations, representing chemical “morphogens” X and Y diffusing through a tissue at rates determined by constants 
D
x
 and 
D
y
,
 coupled to chemical reactions with effects represented by functions f and g:

X
t
=
f
(
X
,
Y
)
+
D
x
∇
2
X
Y
t
=
g
(
X
,
Y
)
+
D
y
∇
2
Y
(These equations follow Keller’s 2002 presentation, which is more streamlined than Turing’s original.) One morphogen is an activator, the other an inhibitor. Both are made and destroyed at constant rates. Initially, the tissue is homogeneous, lacking any spatial organization. Crucially, for stable patterns to emerge X and Y must diffuse at different rates, the inhibitor having the larger diffusion coefficient. Under these parameter values, random fluctuations in the system lead to instability resulting in pattern-formation. That is, from an initially stable, homogeneous system of cells/tissue, interaction between two diffusing chemicals (morphogens) leads to emergence of a stable chemical pattern. Turing assumes that steady-state chemical patterns determine patterns at the cell/tissue level (through mechanisms wholly unspecified). Given that assumption, the model accounts for pattern formation in a group of cells or a tissue.

Turing’s model of morphogenesis has several striking features. First, it is based on physics and chemistry rather than biology: reaction-diffusion equations incorporating Fourier series and the law of mass action. Reaction-diffusion equations are a class of non-linear partial differential equations. (Hodgkin and Huxley’s model of neural propagation is also of this class—at the time, one of the few applications of these equations to biology; see the entry on mechanisms in science.) Turing’s use of these equations to model the transition from homogeneity to spatial patterning is rather counterintuitive, as diffusion is a characteristically homogenizing process. So his model was a theoretical advance, extending the insight that reaction-diffusion equations can model transitions and “waves of advance” (e.g., in neurons) to morphogenesis (Berestycki 2013). Second, the model is strikingly abstract—“…a simplification and an idealization, and consequently a falsification” (Turing 1952: 37). Yet it has many biological applications. Turing (1952) explored mainly simple cases of chemical diffusion through a tissue of fixed size. But he also applied the model to chemical waves on spheres to represent gastrulation. That more complex case, with three interacting morphogens, can produce traveling waves and out-of-phase oscillations. Turing also applied his model to plant development, specifically phyllotaxis (arrangement of leaves on a stem; see S. B. Cooper & van Leeuwen 2013). Subsequent generalizations of Turing’s equations have been used to model a wide variety of developmental phenomena, including fish pigmentation patterns, human mesenchymal cell differentiation, butterfly wing patterns, mouse hair follicles/coat color patterns, limb and tooth development, and bacterial colony growth dynamics (Meinhardt 1982, Murray 1989). However, its explanatory role is controversial, primarily because it is hard to show that Turing’s model describes how development actually proceeds in real organisms.

Keller (2002) discusses this issue, as well as major features of Turing’s model. One key problem (noted by Waddington at the time) is that “pure homogeneity” as a starting point for development is unrealistic; the egg or early embryo is never a “blank slate” as Turing assumed. She argues that Turing’s was a premature attempt at mathematical biology, noting as well the challenge it posed to prevalent ideas about causality: organismal form as emergent, self-organizing; holistic, arising from the system rather than driven by genes. Vecchi and Hernández (2014) build on Keller’s view, diagnosing “a clash of causal ideologies” in the different possible interpretations of initiating cause in Turing’s model. They are more optimistic about its biological relevance and influence. Scientists continue to apply and reflect on Turing’s model of morphogenesis (e.g., Kondo & Miura 2010). As the latter scholars note, Francis Crick’s source-sink model of embryonic development (1970) can be considered the simplest form of a reaction-diffusion model, with the reaction term removed. However, Crick’s model is mechanistically simpler, with morphogenesis controlled by a single morphogen diffusing along a line of cells:

At one end of a line of cells one postulates a source—a cell that produces a chemical (which I shall call a morphogen) and maintains it at a constant level. At the other end the extreme cell acts as a sink: that is, it destroys the molecule, holding the concentration at that point to a fixed low level. The morphogen can diffuse from one cell to another along a line of cells. (Crick 1970: 420)

Unlike Turing’s more holistic model, in which patterns emerge from initial random instability due to interaction of multiple morphogens, Crick’s model grounds morphogenesis in simple chemical diffusion. Agutter, Malone, and Wheatley (2000) and Vecchi and Hernández (2014) argue that Crick’s model lacks explanatory power. However, Minelli (2009) suggests an updated source-sink model, informed by advances in molecular and cell biology.

8.3 Positional information
More influential for mainstream developmental biology was the concept of positional information. Though originally a contribution to regulative theories of development, the concept soon transformed to support theories of genetic control. This epitomizes the shift in biological thought that followed breakthroughs on DNA structure, protein coding, and other phenomena of molecular genetics (see the entry on molecular genetics). Lewis Wolpert (1969) introduced the concept of positional information to solve (like Turing)

the problem of assigning specific states to an ensemble of identical cells, whose initial states are relatively similar, such that the resulting ensemble of states forms a well-defined spatial pattern. (1969: 4)

Wolpert’s answer was that each cell in a developing system has a unique value reflecting its position in that system, encoded by the spatial gradient of a diffusible molecule across the system. Specification of a cell’s position in the system is relative to one or more points in the system: the source(s) of the diffusible molecule or cell property. Cells that share the same set of points relative to which their position is specified make up a field. Wolpert used this model to explain a range of experimental results and observations of development in various species (as well as the toy “French flag” example). In 1969, Wolpert saw the next task as discovering and articulating rules (and underlying mechanisms) for specification of positional information and polarity, the nature of points and boundaries, and “new meaning to classical concepts such as induction, dominance and field” (1969: 1).

Wolpert’s theoretical approach differed from predecessors in its relation to genetic information. Positional information was proposed as a “universal mechanism” for “translation of genetic information into spatial patterns of differentiation” (Wolpert 1969: 1). The concept was designed to integrate gene-based and organicist approaches to development. Cells “interpret” changes in their positional information, so as to change the pattern of gene activation in a cell. Changing patterns of gene expression drive cell differentiation in a developing organism. This in turn effects spatial distribution of cell forces (e.g., contraction, motility, cell-cell contact), which drives organism-level morphogenesis. However, by 1975, Wolpert’s thinking about development had undergone a conceptual shift (Keller 2002). Between 1971 and 1975, Wolpert’s ideas were “geneticized”, after which he accepted the idea of a genetic program for development and the embryo as “computable” from an egg. In this way, the idea of a morphogen gradient establishing positional information for cells was put under genetic control (see Section 9).

Wolpert and Lewis (1975) proposed a research program of computational embryology aimed at a

theory of development [that] would effectively enable one to compute the adult organism from the genetic information in the egg. The problem may be approached by viewing the egg as containing a program for development. (1975: 14)

Philosopher Alexander Rosenberg (1997) endorses this version of Wolpert’s theory as vindication of strong molecular reductionism in developmental biology. Manfred Laubichler and Günter Wagner (2001), alongside other biological theorists, reject this version of reductionism (see Section 10). Jaeger, Irons, and Monk (2008) propose to reverse Wolpert’s conceptual shift with their “relativistic theory of positional information”, adding a role for regulative feedback by responding cells. Vecchi and Hernández (2014) criticize Wolpert’s and Rosenberg’s reductionist computational embryology as classically preformationist and note explanatory lacunae of the idea of a genetic program pre-established in the egg. This follows Keller (2002), who argues that the twentieth-century consensus on development is essentially preformationist. This brings us to

the widespread reductionist and deterministic view of development as programmed in genes…with the implicit idea that the final form of the organism is “already there” in the instructions contained in its genome as early as the egg stage. (Minelli & Pradeu 2014b: 4)

9. Twentieth-Century Genetics: A New Predeterminism
Early twentieth-century embryology highlighted epigenesis. But a new twist on preformationism soon arose in the form of genetics. This pointed to the nuclear chromosomes as loci for the causes of differentiation. Yet unlike Weismann and Roux, new geneticists did not see the genetic material as divided up into a mosaic to explain ensuing cell and tissue differences. Rather, the inherited nuclear material was the same in every cell, but it acted differently according to an internal program. This interpretation appealed to some scientists for metaphysical reasons since it focused on the material units of heredity and apparently of causation. Epistemologically, it was more difficult to point to evidence that inherited genes explain development.

This is not the place for a history of genetics, which has been offered many times elsewhere. The important point here is that genetics brought a new form of preformationism. Instead of a dynamically acting organism taking its cues from the environmental conditions and from the way that cells interact with each cell division, the twentieth century brought a dominant and popular view that has often emphasized genes as programmed to carry the information of heredity, which was also the information necessary to construct an individual. Of course, there have been calls for alternatives or interactionist models where heredity and development, epigenesis and preformation, work together, but these have often been offered as alternatives than as central interpretations (see Section 10).

In the beginning of the twentieth century, at first Thomas Hunt Morgan resisted the Mendelian-chromosome theory of inheritance that saw inherited units of heredity carried on chromosomes as determinants of developed characters. If all the cells contain the same chromosomes, then how can their inheritance explain anything, he asked. Instead, he insisted that “We have two factors determining characters: heredity and the modification during development” (Morgan 1910a: 477). Morgan wrote to a friend that “my field is experimental embryology” and not the genetics with which he became associated (Morgan 1908). Like his Woods Hole colleagues at the Marine Biological Laboratory, Morgan did not see how inherited chromosomes could explain development of form from non-form. He had rejected Weismann’s interpretations and continued to reject the idea of inherited determinants.

Also in 1910, however, he was studying many different kinds of organisms in pursuit of explanations of heredity as well as differentiation. A white-eyed male Drosophila fly famously caught his attention, and led him to the conclusion that some inherited factors must, indeed, cause expression in the emerging organism (Morgan 1910b). It is not that Morgan changed his mind about how to do science, but rather that the evidence carried him in new directions (Maienschein 1991a).

The fertilized egg cell contains a nucleus made up of chromosomes inherited from both parents. Along these chromosomes are lined up units of heredity that serve like Weismann’s determinants, now called genes. These genes correlate with some characters in the resulting organism, and therefore in some sense the resulting form was predetermined in the egg. Yet it was not already formed. And, indeed, the mere correlation of genes and characters tells us virtually nothing about how the differentiation occurs nor about how form becomes formed (the problem of morphogenesis). Therefore, yes, genetics brings a sort of new preformation or more accurately predeterminism. But that in itself brings a description and a correlation but no explanation. Or so Morgan initially felt, as did his embryologist colleagues. Advances in genetics soon changed the theoretical landscape. In 1934, Morgan posited differential gene activity as the key to understanding organismal development. On his view, genes are inherited, their activity controlled by cytoplasmic factors. The latter are originally heterogeneously distributed in the egg. Differential gene activity so-driven leads in turn to differential cytoplasmic factor distribution, and the cycle continues, influenced by signals from a cell’s environment (primarily neighboring cells). Ideas of preformation and epigenesis are combined in pre-determined genes acting in response to diverse environmental factors. Burian (2005) argues that the old theoretical opposition was reinscribed in the disciplinary separation of embryology and genetics, particularly in the US. In that context, studies of development emphasizing the nucleus endorsed preformationism, while those focusing on cytoplasm and cell lineage differentiation tended to epigenesis. This theoretical rift was healed when research focus shifted from “cytoplasm vs. nucleus” to mechanisms of gene expression (Burian 2005). Theoretical concepts grounded in genetics and molecular biology thereafter increasingly dominated thinking about development.

By mid-twentieth century, and especially after the discovery of DNA’s structure (which apparently also explained its function), researchers began to forget or at least ignore questions about morphogenesis and epigenesis (see, for example, Olby 1974, Judson 1979). Instead they asked how, actually, genes give rise to differentiated form? Somehow that works, seemed to be the answer. Genetics predominated over what C.H. Waddington referred to as the epigenetics of development (Waddington 1942). Of course not everyone ignored development, but it became a seriously neglected field and even professional societies and journals that had focused on “embryology” shifted to “developmental genetics” (Oppenheimer 1967). When Robert Briggs and Thomas King cloned frogs in the 1950s and John Gurdon extended the research in the 1960s, it seemed that nuclear transfer could come from only early stages of development. Furthermore, the resulting clones were like their donors from whom the nuclei came rather than like the mothers from whom the eggs came (Briggs & King 1952; Gurdon & Colman 1999; McLaren 2000). Apparently development brings differentiation that is unidirectional. Preformationist/ predeterminist thinking prevailed. Epigenetic development and regulatory response to environmental conditions seemed to have strict limits for those adopting the mid-twentieth-century predeterminist emphasis.

9.1 Waddington’s landscape
In this context, Waddington’s theoretical approach was distinctive, aiming to integrate genetics and epigenetic development. His main device for doing so was “the epigenetic landscape”, first articulated in 1939 and iconically diagrammed in The Strategy of the Genes (1957). Waddington’s landscape model represents developmental potential as

a more or less flat, or rather undulating surface, which is tilted so that points representing later states are lower than those representing earlier ones … Then if something, such as a ball, were placed on the surface, it would run down toward some final end state at the bottom edge. (1957: 29).

The model visualizes three “essentially formal” properties of development: unidirectionality in time (via the landscape’s tilt), multiple discrete termini from a single undifferentiated start (via branching tracks), and robustness of developmental processes (via steepness of valley walls).

These topographic features reflect generalizations about animal development, based mainly on experiments on chick and Drosophila. A rolling ball’s path down the incline corresponds to the development of some cell or tissue from an early undifferentiated state to a mature differentiated state.

What controls the path taken by a cell or piece of developing tissue—a pre-determined genetic program or ongoing orchestration of stimuli? Waddington (1939, 1940, 1957) identified genes as the determinants of epigenetic landscape topography. This is depicted in a companion diagram showing the landscape’s “underside” as a network of interacting biochemical products “which are ultimately controlled by genes” (1957: 36). Waddington first articulated the landscape analogy in 1939, as a generalization of time- and dose-effect curves representing the role of genes in producing specific phenotypic effects. The landscape model results from including interactive effects of the entire genome on a particular pathway:

[o]ne might roughly say that all these genes correspond to the geological structure which moulds the form of the valley. (1939: 182)

Although he featured genetic control, Waddington’s designation of the landscape as “epigenetic” suggests a view of development allowing more of a role for epigenesis than more gene-focused contemporaries. Scott Gilbert (1991) argues that the branching-track lineage structure unifies development and genetics, visualizing a formal analogy between cellular, genetic, and organismal development. Fagan (2012, 2013a) extends this argument, focusing on Waddington’s unification of two complementary landscape images: robust pathways above, and interacting gene products below, with genes at the bottom, metaphorically “pulling the strings”. Nicoglou and Merlin (2017) and Nicoglou (2018) discuss this unifying, integrative feature of Waddington’s landscape model as one strand of twentieth-century epigenetics.

Waddington’s own later theorizing took a mathematical turn, interpreting the notion of a field in terms of spatial relations and using Réné Thom’s topology to theorize developmental pathways as an epigenetic system (1968). This work emphasized the concept of “chreod”, a trajectory (directed path) of normal development within multidimensional space, with axes for time, three spatial dimensions, and concentrations of chemicals. Although not fruitful in biology at the time, Waddington’s mathematical approach anticipated twenty-first-century alternatives to the idea of genetic control (see Section 10). In that context, the landscape model has experienced a renaissance. The underside image is replaced by complex gene regulatory networks, topside surfaces explicated in terms of systems biology and/or stem cell concepts (Fagan 2012, 2013a). Fusco and colleagues (2014) discuss recent theoretical proposals (e.g., Wang, Wang, & Huang 2010) to “rehabilitate” Waddington’s landscape as a dynamical systems model, which require significant changes from the original. They conclude that landscape models (updated or not) are good for visualizing cell differentiation but not other important developmental processes—and so not well-suited for a comprehensive theory of development. As a metaphorical aid to understanding, however, Waddington’s landscape remains influential. Jan Baedke (2013) examines its broader impact across the life sciences, extending beyond organismal development to developmental psychology and cultural anthropology.

9.2 The genetic program
In his influential book What is Life (1944)? Erwin Schrödinger speculated that development is controlled by “a code-script structure” localized to chromosomes, information-patterns

instrumental in bringing about the development they foreshadow…architect’s plan and builder’s craft all in one. (1944: 18–19)

Twentieth-century triumphs in genetics bolstered this idea. The main challenge for such theories is how invariant genes, the same in every cell of an organism, can control the process of diversification of those cells, their temporally-orchestrated movements and organization into tissues, bodily structures, and complex organs. Frank Lillie (1927) put the point starkly (discussed in Burian 2005):

The essential problem of development is precisely that differentiation in relation to space and time within the life-history of the individual which genetics appears implicitly to ignore… Those who desire to make genetics the basis of physiology of development will have to explain how an unchanging complex can direct the course of an ordered developmental stream. (1927: 365–367)

Responses to what Burian has labelled “Lillie’s paradox” hinge on differences in gene expression among cells and tissues. Chromosomal DNA is a linear template for an mRNA transcript, which is in turn a template for a sequence of amino acids making up a protein. Cell phenotype depends on which genes are transcribed and then translated. But DNA does not express itself. The challenge then is to account for gene expression in a way that preserves genetic control of development. The concept of a “genetic program for development” responds to this challenge.

The idea was forcefully articulated by François Jacob and Jacques Monod:

During embryonic development, the instructions contained in the chromosomes of the egg are gradually translated and executed… The whole plan of growth, the whole series of operations to be carried out, the order and the site of syntheses and their coordination are all written down in the nucleic-acid message. (Jacob 1970 [1973: 313])

Jacob and Monod’s view was grounded on their pioneering work on bacterial gene expression (1961a, 1961b). Their key result, the operon model, explains how gene expression in E. coli bacteria is regulated by environmental signals. Briefly, the model represents interactions among various components: protein-encoding DNA sequences, regulatory DNA sequences, the “operator region” of DNA located near the start of protein-encoding genes, repressor protein, and small molecules (e.g., allolactose). If a repressor binds the operator region, this blocks protein synthesis at nearby coding sequences. Small molecules like allolactose bind the repressor, inhibiting its inhibition, so the protein-encoding genes associated with the “de-repressed” operator are expressed. Those genes encode enzymes involved in metabolizing the small molecules, neatly closing the regulatory loop. Jacob and Monod singled out DNA as the controlling molecule of this regulatory system. Furthermore, as Michael Morange (2000) discusses, they extrapolated the E. coli operon model to gene regulation in general, positing that all organismal development is controlled by a small set of regulatory genes.

Jacob and Monod’s subsequent work emphasized molecular genetic reductionism and the idea of a genetic program for development. For example, Jacob began The Logic of Life (1970 [1973]) with reflections on “The Programme”:

… the structure of macromolecules is determined down to the last detail by sequences of four chemical radicals contained in the genetic heritage. What are transmitted from generation to generation are the “instructions” specifying the molecular structures: the architectural plans of the future organism. They are also the means of executing those plans and of coordinating the activities of the system. In the chromosomes received from its parents, each egg therefore contains its entire future: the stages of its development, the shape and the properties of the living being which will emerge. The organism thus becomes the realization of a programme prescribed by its heredity. (1970 [1973: 1–2])

However, extrapolation from bacterial gene regulation to development in multicellular organisms proved unfounded. Limitations of the operon model soon became evident. In eukaryotic, multicellular organisms, gene expression is far more complex. Fifty years of molecular biology have revealed a menagerie of mechanisms implicated in the complex cellular machinery of gene expression (see the entry on molecular biology). And this is not to mention interactions among cells and tissues, about which classic molecular biology was silent. Brian Goodwin, a student of Waddington’s, charted an alternative theoretical path that skirted these limitations. In the 1960s, he developed equations to model genetic oscillation, building on Jacob and Monod’s operon model (Goodwin 1965). But his subsequent theorizing about development emphasized self-organization due to chemical gradients and mechanical strain in cytoplasm, presaging dynamic and physical theories that gained prominence around the turn of the millennium (Goodwin & Trainor 1985, see Section 10.2 and the entry on systems and synthetic biology).

The next experimental milestone for theories of genetic control of development was Christiane Nüsslein-Volhard and collaborators’ painstaking characterization of mechanisms of body patterning and polarity in Drosophila (e.g., Driever & Nüsslein-Volhard 1988). They distinguished three regions along the early embryo’s anteroposterior body axis (anterior, posterior, and terminal), the basic patterns and structures of which are controlled by distinct sets of maternal genes. A few such genes have long-range “organizing” effects. Notably, Driever and Nüsslein-Volhard (1988) showed that bicoid protein acts as a morphogen, controlling formation of a fly’s anterior (including head and thorax) in accordance with its concentration gradient. Significantly, their experimental manipulations were DNA sequence mutations (known to effect anterior body plan development or bicoid copy number). The experiments thereby charted a causal pathway from DNA to mRNA to protein to cell differentiation to morphogenesis. This demonstration of changes in body-plan correlated with maternal genetic mutations was powerful vindication of the idea that genes control development. Moreover, central concepts of the organicist alternative (gradients and positional information) were brought under the rubric of that theory. Nüsslein-Volhard’s gene-based approach remains influential in developmental biology (see the entry on developmental biology).

9.3 The regulatory genome
The above and other experimental successes underpin Eric Davidson’s theory of “the regulatory genome” (2006), which combines new experimental data (mainly from Drosophila and sea urchin) with systems and network concepts—in effect, updating Jacob and Monod’s notion of the genetic program. On this view, development is controlled by a DNA-encoded program made up of short sequences that specifically bind transcription factor proteins and thereby make a difference to gene expression. The first step of gene expression in higher organisms is typically the binding of one or more protein factors to a regulatory region of DNA located near the sequence to be transcribed (“read” into mRNA and thence to protein). Davidson terms these DNA sequences “cis-regulatory modules”. Each module’s effect is represented as a conditional rule of the form: “If protein X is present, then gene Y is expressed at level Z”. Each gene has a set of such modules associated with it, which collectively specify its expression pattern under various conditions. That expression pattern, in turn, determines a cell’s phenotype and developmental fate. Control of development is therefore attributed entirely to the DNA components of molecular complexes that make a difference to gene expression. Transcription factor proteins and other components are conceived as “inputs” to the information-processing modules, and effects on gene expression as “outputs”.

These basic “cis-regulatory” units are organized into systems of interacting modules. Because transcription factor proteins are products of gene expression, the regulatory modules that control their expression are sites of “primary core control” for development. These core control modules form an interconnected network, reflecting the influences of transcription factor proteins on one another’s expression. All organisms have a genetic regulatory network composed of DNA sequences distributed throughout its genome, which constitutes a stable underlying program for development. Collectively, DNA modules act as “a vast, delocalized computational device” that processes regulatory states of a cell (Davidson 2006: 185). Furthermore, regulatory DNA sequences are (for the most part) invariant across cells of an organism, and organisms of a species, with a relatively small set of “hub” transcription factors conserved throughout much of the animal kingdom. The regulatory genome therefore offers a unified explanation of animal evolution and development. However, there are good reasons to think the role of DNA sequences in gene expression is not distinctive, causally or informationally (see the entries on gene, genetics, and reductionism in biology). Other recent theoretical approaches tend toward more inclusive, less gene-centric explanations of development.

10. Twenty-First-Century Alternatives: A New Epigenesis?
The end of the twentieth century brought discoveries that challenged prevailing genetic determinism, and also began to replace the extreme forms of either preformationism or epigenesis with the sorts of interactionist models that were only offered as outlying alternatives in earlier decades. A modified form of epigenesis, in which the organism is seen as beginning from an inherited egg and sperm that do include genes, seems to be on the rise again. Research on cell development, stem cells, and tissue engineering shows that the identity of any particular cell is not predetermined, but also depends on interactions with its neighbors and context. Ian Wilmut’s team’s success in cloning Dolly, reported in 1997, and John Gearhart and James Thomson’s successes with developing human stem cell lines, both reported in 1998, challenged prevailing assumptions (Wilmut et al 1997, Wilmut, Campbell, & Tudge 2000; Thomson et al. 1998; Shamblott et al. 1998; Gearhart 1998). Both suggested that development is a good deal more flexible, plastic, and interactive than preformationist interpretations allow. These experimental results, alongside conceptual issues, spur alternative theories of development. Gilbert (2004) notes increased emphasis on interaction, change, emergence, and reciprocal “determination” relations between whole and component parts. His own work emphasizes the need for multiple perspectives in understanding development; notably diversification in the location of causal control beyond genes alone (see the entry on evolution and development). This section focuses on philosophical efforts along these lines.

10.1 Developmental systems and cycles
Susan Oyama’s monograph The Ontogeny of Information (1985 [2000a]) critiques gene-based theories of development. She argues that genetic information for development is causally derivative, existing as such only in the context of an ongoing developmental process. That process, in all its contingency and historical specificity, is causally primary. Neither DNA nor environmental factors are causes of development outside the interactive context that makes features of the physical world an organism’s environment and induces patterns of gene activation within cells. Genetic information emerges from the interactions of heterogeneous, dispersed, developmental resources. Central to Oyama’s view is the

conception of a developmental system, not as the reading off of a preexisting code, but as a complex of interacting influences, some inside the organism’s skin, some external to it, and including its ecological niche in all its spatial and temporal aspects. (1985 [2000a: 39])

As in earlier organicism, patterns and form emerge from ongoing interaction, within and among multiple levels of organization, on multiple time-scales. But unlike the organicists, Oyama has an established theoretical alternative to contend with. Much of her argument is negative, rejecting the gene/environment dichotomy, primacy of genes as causes, and lingering preformationism of the idea of a genetic program for development. Her theoretical perspective aims to overcome entrenched (and often unrecognized) dichotomies in biological thought. Although criticized for their complexity, apparent incompatibility with scientific generalization, and lack of connection to experimental practices, Oyama’s ideas about developmental systems have been influential in twenty-first-century philosophy of biology.

One impact is further articulation of developmental systems theory (DST; see the entries on inheritance systems and replication and reproduction). In the introduction to their 2001 edited volume, Cycles of Contingency, Oyama, Paul Griffiths, and Russell Gray set out DST’s major themes and commitments: joint determination by multiple causes (causal parity), context sensitivity and contingency, extended inheritance, development as construction, distributed control, and evolution as construction. Another core tenet is rejection of opposed dualities such as nature/nurture, gene/environment, and biology/culture—not arguing that an adequate theory of development must include both sides of opposition, but that the oppositions themselves have no place in an adequate theory of development. Relatedly, genes are not privileged causes of development (Griffiths & Knight 1998). This “parity thesis” is sometimes misunderstood as a theoretical claim that all causes of development are equally important. But it is better understood as a constraint on theories of development (and evolution): to not presuppose any fundamental distinction between genes and all other causes (Oyama et al. 2001: 3). DST’s other themes are similarly arrayed against twentieth-century predeterminism. In this way, DST entails a conceptual reorientation in thinking about inheritance, development, and evolution, and a point of departure for philosophical exploration of alternatives to gene-centrism and entrenched dichotomies. Much of this research focuses on integrating development and evolution—i.e., evo-devo theories (see the entry on evolution and development). DST-affiliated projects that focus on organismal development are discussed here.

A developmental system is

a heterogeneous and causally complex mix of interacting entities and influences that produces the life cycle of an organism. (Oyama 2000b: 1)

James Griesemer (2000a, 2000b, 2014a, 2014b) further articulates this idea by conceptualizing development as part of a more general theory of reproduction (see the entry on replication and reproduction). In this theory,

development is the acquisition of the capacity to reproduce, where reproduction involves material propagation of developmental capacities from parents to offspring. (2014b: 199)

If development is so conceived,

…then it turns out all traditional life cycles are complex…[i.e.] there is typically at least one substantial change of developmental context or niche, with multiple generations of progenerants, before a life cycle is completed. (2014b: 191–192)

Complex life cycles of parasites and viruses, then, are not idiosyncratic but rather exemplars of complex, context-dependent developmental processes. Griesemer’s theoretical reorientation departs from the traditional idea of development as proceeding linearly from egg to embryo to adult. Instead, developmental capacities are properties of life cycles involving multiple organismal forms. This motivates a new theoretical concept: scaffolding interactions that bring a developing entity and aspects of the environment into such close association as to qualify as a new “hybrid” entity with new developmental potentialities (Griesemer 2014a). The original entity and environment are as “parents” to the new “hybrid” developmental system (e.g., HIV integrated into host genome vs. free virus and uninfected human cell/genome). Genes are demoted to “a special kind of evolved class of scaffolding developmental mechanisms” (2014b: 198).

Biologist Alessandro Minelli (2009, 2014) endorses a similar view of development, arguing that the first step toward a satisfactory theory is characterizing the full range of developmental processes, beyond the traditional “adultocentric perspective” tracing the formation of a mature organism from an egg cell. Although Minelli does not theorize development in terms of reproducers, he does conceptualize the process in terms of life cycles (see also Bonner 1974). Life cycles can be multigenerational, multigenomic, unicellular—and so developmental processes include these too, implicating haploid stages in sexually-reproducing organisms, alternation of generations, mixed sexual/asexual reproduction as in colonial tunicates and plants, etc. Minelli proposes to use this expanded view of “developmental disparity”, encompassing the full range of diversity of life cycles of living things, alongside “traditional, or naïve, concepts of development” to arrive at a satisfactory general framework (2014: 228).

Jason Scott Robert (2004) extends Oyama’s critique of the prevailing view that

development is now standardly construed as the epigenesis of something preformed in the DNA. (2004: 35)

This combination of old theoretical opposites, he argues, is unbalanced in favor of preformationism. Robert proposes instead “creative development”:

the organism’s semi-autonomous self-constitution from a range of ontogenetic raw materials,

co-constructed with its environment (2004: 87). Burian (2005) similarly challenges the adequacy of genetic determinism for understanding development, arguing that experimental results better support multilevel causation. Although grounded in experimental practices and associated concepts rather than abstract theory, Burian’s arguments motivate search for new theories to account for robustness of developmental processes and outcomes.

10.2 Physical and dynamic systems
Another strand of theorizing development draws on physics of materials. Stuart Newman (2003) argues that physical factors played a major role in the early evolutionary history of multicellular organisms. Living tissues undergoing development have properties of liquid-like “soft matter”, such as viscous flow, elasticity, surface tension. They are also “excitable”,

simultaneously hav[ing] chemical, mechanical, and electrical properties, they behave in a multiscale fashion, continuously and simultaneously changing their composition and organizational properties on several temporal and spatial scales. (2003: 96)

These material properties allow living tissues to be analyzed in terms of physical theories and constraints. Although developmental processes in organisms today appear to follow pre-determined genetic programs, physical forces and constraints are at the origin of developmental systems and still play a vital role within them.

Newman’s theoretical approach “link[s] the modern physics of materials with contemporary knowledge of genetic determinants” (2014: 107; see also Newman 2003; Forgacs & Newman 2005). A core thesis of this theoretical approach is that excitable soft matter can exhibit self-organization in the absence of any pre-existing program; e.g., synchronized oscillations, local diffusion gradients, compartment-formation via cell adhesion. (This theoretical approach is anticipated in the work of Brian Goodwin, see Section 9.2.) Newman posits that the earliest multicellular organisms underwent development spurred by these physical processes, together yielding a basic body plan. Over long evolutionary timescales, gene regulatory networks are overlaid upon physics-driven self-organizing processes. The result is a highly-conserved set of dynamical patterning modules (DPMs) that make basic shapes in a developing embryo: layers, lumens, folds, tubes, segments, etc. Importantly, DPMs are not predetermined genetic programs, but more inclusive systems capable of self-organization. Newman and colleagues use computer simulation to study the possible patterns generated by dynamical gene network models representing DPMs (Salazar-Ciudad, Newman, & Solé 2001). This method brings in dynamical systems theory, which has recently become central to systems biology (see the entry on systems and synthetic biology).

Dynamical systems approaches to development, being committed to holism and temporal unfolding, echo classic epigenesis and early twentieth-century organicism. These earlier ideas are brought to bear on new high-throughput quantitative datasets using simulation technology—updating and revitalizing the earlier systems theoretic approaches of D’Arcy Thompson and von Bertalanffy. Although most work in systems biology focuses on single-cell organisms and intracellular networks, some researchers look to dynamical systems theory to construct a general theory of development. Following Goodwin’s theories, Johannes Jaeger and colleagues seek to identify a finite core set of basic developmental processes implemented by genetic-epigenetic-cellular regulatory systems (e.g., Jaeger & Sharpe 2014). They use computer simulation of regulatory network models to identify classes of geometrically similar networks that perform specific functions (such as producing stripe patterns). The goal is a rational classification scheme for functionally-characterized developmental mechanisms, which can in turn serve as groundwork for a general theory of development. It remains unclear, however, if biological functions in development can be characterized in a context-independent (modular) way, allowing for a tractable theory. Relatedly, Jonathan Bard (2011, 2013) posits a relatively small set of developmental networks driving “patterning, signaling, proliferation, differentiation, and morphogenesis”, “themes used over and over again” in networks of signaling pathways. Bard’s graphical network approach is distinctive in cutting across spatial scales and levels of hierarchical organization. Core processes (as networks) are distributed across levels; there is no preferred level of developmental activity, but all involved simultaneously. The resulting network structures are quite complex.

10.3 Stem cells and lineages
Results of stem cell experiments prompt re-examination of now-standard assumptions about the nature of development. At early stages of mammalian development when embryonic stem cells are most plentiful, in the blastocyst stage just before implantation, stem cells can be harvested and cultured to become a large number of different kinds of cells (Thomson et al. 1998). In theory, they have the capacity to become any kind of differentiated cell, but it is impossible to prove that conclusively (Fagan 2013b). Position in the organism and with respect to other cells seems to be decisive in directing differentiation. Although genetics provides information about the range of possibilities, regulation of gene expression involves diverse factors—and stem cells’ plasticity and context-dependence fits a more epigenetic view. Cell reprogramming, for example, is a method of producing stem cells (induced pluripotent stem cells) from more differentiated cells, effectively reversing normal development (Takahashi & Yamanaka 2006). This contradicts any strict principle of development as irreversible and internally-directed, undermining the notion of a fixed program for development (Brandt 2010). Melinda Cooper (2003) examines how central concepts of stem cell research (potency, differentiation, form, and regeneration) fit within the long tradition of theorizing about epigenesis and self-organization, dating from seventeenth-century revivals of Aristotelian embryology.

Ariane Dröscher (2014) traces the history of conceptual change concerning stem cells via lineage tree diagrams, a form of visual representation common to studies of development and of evolution. Lineage diagrams track relations between generations of reproducing entities. From Haeckel’s speculative image of the Tree of Life and Weismann’s introduction of “cytogenetic tree diagrams”, Dröscher examines this cell-centric way of understanding development from the mid-nineteenth century onward. Scott Gilbert (1991) shows that branching tracks have been used to represent cell development since the late nineteenth century, most prominently in cell lineage diagrams that track cell pedigrees and division events. In these models, branch-points represent cell division events and branching tracks represent genealogical relations among cells. Other cell characteristics are also represented, such as position within the developing embryo, morphology, and developmental fate. Waddington’s landscape is a model of this type (see Section 8.1). Fagan (2013a) uses this modeling approach to characterize cell development in general. Any process of cell development produces a cell lineage tree with a specific topology, representing developmental and reproductive relations between cells. Different stem cell concepts correspond to models that differentially constrain the space of possible topologies for cell lineage trees. This framework provides a systematic representation of the many different varieties of stem cell.

Fagan (2013a, 2017) extends this cell lineage framework to cell-molecular and cell-organism relations, yielding a cell-centric multi-level model of development. Her view of the cell-molecular relation is that of systems biology: a cell state is a pattern of gene expression and molecular interactions that determines a cell’s structural and functional characteristics. The cell-organism relation is “enkaptic”—that is, cells reproduce and differentiate (the two defining stem cell abilities) and are collected or encapsulated into a higher-level system: gastrula, tissue, organ, or an experimentally-produced organoid or embryo-like structure. The higher-level system emerges via formation of a boundary separating it from its environment. So different levels or scales of a developmental process are related by “boundary-formation”. On this view, development is a process comprised of multi-layered interactive networks, arranged in strata (layers) related by an encapsulating boundary. Each network is related to the one below by boundary-formation, conceived as emerging out of (and imposing constraints on) smaller-scale interactions such that an encapsulating system is distinguished from its environment.

Jane Maienschien and Kate MacCord offer a suggestive look at regeneration as a response of complex systems to injury through repair. (Maienschein and MacCord, 2022) The repair draws on inherited and in some ways predelineated organization, as well as on responses to changing environments. Both Fagan’s stem cell-based alternatives to predetermined development and Maienschein and MacCord’s suggestions about regeneration across all scales of life hark back to Morgan’s suggestion that

a process of pure epigenetic development, as generally understood nowadays, may also be predetermined in the egg. (Morgan 1901: 968)

The nowadays of the twenty-first century may take us back to some of the understanding and insights of the early twentieth, a time when a balance of epigenesis and preformation seemed likely.


1. Rules, Meaning, and Content
What does the notion of rule-following have to do with the notions of linguistic meaning and mental content? For our purposes, the important point is that meaning something by a linguistic expression is analogous to following a rule. Suppose I write out the beginning of an arithmetical series

2
,
4
,
6
,
8
,
10
,
…
If the rule I’m following is add 2, the continuation

12
,
14
,
16
,
…
is correct, in that it accords with the rule I’m following, while the continuation

13
,
19
,
20
,
…
is incorrect, in that it fails to accord with the rule I’m following.

We have here an analogy with my meaning something by a linguistic expression. Say that I mean blue by ‘blue’. Then, ‘blue’ is correctly applicable to, for example, a US postbox but not to a ripe (Roma) tomato. We can express this point by saying that the former application accords with the predicate’s meaning while the latter application fails to do so. Given this analogy, arguments about rule-following have consequences for our conception of linguistic meaning: if an argument shows that there are no facts about which rule an agent is following, it may also show that there are no facts about what a speaker means by a linguistic expression.

Note that the notion of accord in play in the case of following a rule is also in play in our conception of mental states with intentional content generally. Say that one intends to attend the performance of Sartre’s play No Exit at the Hopewell Theatre on Wednesday. Then, one’s attending the performance at the Hopewell on Wednesday accords with one’s intention (in the sense that it fulfils it), while one’s staying at home to grade logic exams fails to accord with it. Say that one believes that the cat is on the mat. Then, the state of affairs in which the cat is on the mat accords with one’s belief (in the sense that it renders it true), while the state of affairs in which the cat is on the roof does not. Say that one desires to smoke a Bolivar Number 3. Then, one’s smoking a Bolivar Number 3 accords with one’s desire (in the sense that it satisfies it), while one’s smoking a Café Crème does not accord with it. Given this, arguments about rule-following have consequences for our conception of mental content: if an argument shows that there are no facts about what rule an agent is following, it may also show that there are no facts about the contents of a thinker’s mental states.

Before considering the arguments themselves, we’ll pause to reflect on views about the relative priority of linguistic meaning and mental content, and on what presuppositions are required in order for the arguments to be run.

In his influential 1989 survey, Paul Boghossian distinguishes between two broad types of view:

The Sellarsian View: the notion of linguistic meaning is explanatorily prior to the notion of mental content (Sellars 1956).
The Gricean View: the notion of mental content is explanatorily prior to the notion of linguistic meaning (Grice 1989).
Boghossian suggests that, irrespective of which of these views is adopted, it will not be possible to develop a sceptical argument that exclusively targets linguistic meaning. On the Sellarsian View, the conclusion that there are no facts about linguistic meaning will ensure that there are no facts about mental content, since on that view it is from the former sort of fact that the latter sort of fact would have to be derived. On the Gricean view, raising a sceptical doubt about linguistic meaning cannot be done without raising a sceptical doubt about mental content.

We would add a third possible view:

The Davidsonian View: the notions of mental content and linguistic meaning are explanatorily interdependent; neither takes explanatory priority over the other (Davidson 1984, 2001).
Clearly, on the Davidsonian view, one cannot pose a sceptical threat to the existence of facts about the meanings of linguistic expressions without also threatening the existence of facts about mental content, and vice versa. And we can add Boghossian’s further observation:

If [the sceptical arguments are] effective at all, they should be as effective against linguistic content as they are against mental content. This is evident from the fact that the arguments construct their skeptical case by exploiting features of content properties, but without exploiting any facts about the putative bearers of those properties. Thus, they would apply to anything said to possess content, whether it was mental or not. (1990 [2008: 62])

In what follows, then, we’ll move freely between considering arguments about rule-following, linguistic meaning, and mental content.[2]

2. The Sceptical Argument
We’ll begin with a brief outline of the argument of Kripke’s sceptic. Suppose that I’ve never dealt with numbers larger than 57.[3] (Given our finite nature and the infinitude of the natural number series, there will always in fact be such a number.) I’m asked to perform the computation ‘
68
+
57
’, and I arrive at the answer ‘125’, which I take to be right. However, a “bizarre skeptic” (Kripke 1982: 8) questions my certainty. She suggests that in the past I used ‘plus’ and ‘+’ to mean a different function, which she calls “quaddition”. Quaddition yields the same result as addition if the numbers are lower than 57, and 5 otherwise, so the correct result of the aforementioned computation is ‘5’, not ‘125’. I should answer ‘5’ if I intend to use ‘plus’ in the same way in which I have been using it in the past, or so the sceptic suggests.

Kripke allows that the sceptic’s proposal is “absolutely wild”, and that she is “crazy” if she “proposes [her] hypothesis sincerely”. He grants, however, that it is not logically impossible, and so “there must be some fact about my past usage that can be cited to refute” that hypothesis (1982: 9). That is, there must be some fact about my past usage that determines that I meant addition by ‘plus’ in the past, and thus that (again, assuming that I intend to use the expression in the same way I have been using it so far) I should answer ‘125’ rather than ‘5’. Importantly, the sceptic does not question my memory concerning past use; indeed, she goes as far as to allow that the exercise of my cognitive powers is faultless, and that I have access to all the facts about my mind and behaviour that are potentially constitutive of my meaning one thing rather than another (1982: 14). Her thought is that if I am not able, even in such cognitively ideal conditions, to provide the fact in virtue of which I mean addition, a fact that properly singles out the function of addition rather than the function of quaddition, it is because there is no such fact. Furthermore, the focus is on past use because “if I use language at all, I cannot doubt coherently that ‘plus’, as I now use it, denotes plus” (1982: 13). But, if the sceptic’s challenge succeeds, it can be generalized, for “if there was no such thing as my meaning plus rather than quus in the past, neither can there be any such thing in the present” (1982: 21). (The fact that the sceptic grants the idealisation of our cognitive powers in the way that she does shows that her argument is not of a piece with the argument of the epistemological sceptic, who is concerned with whether our actual cognitive capacities can lead to knowledge. See Boghossian 1989 [2002: 150]. For dissent over this point, see Ginsborg 2018. Martin Kusch takes the argument to be metaphysical [2006: xiv], but, in contrast with Boghossian, he takes the dialogic setting to play an essential role in it.)

As we’ll see, the search for a fact fails, and the sceptic concludes that “the entire idea of meaning vanishes into thin air” (Kripke 1982: 22). Kripke rejects this paradoxical conclusion as “insane and intolerable” (1982: 60) and “incredible and self-defeating” (1982: 71), and goes on to develop, on behalf of Wittgenstein, a sceptical solution, which he takes to be similar in some respects to David Hume’s solution to the sceptical problem about causation (1982: 4; 62–69), and which purports to conceive of meaning in a way that does not lead to paradox. We discuss the sceptical solution in section 3. (George Wilson was the first to insist on the significance of the distinction between the parts of the sceptic’s position Kripke’s Wittgenstein accepts and the parts he rejects—between the basic sceptical conclusion, according to which there are no facts about a speaker of the sort that the sceptic is seeking that constitute her meaning something by an expression, and the radical sceptical conclusion, according to which no one means anything by an expression [Wilson 1994, 1998]. We will return to Wilson’s view in section 3.3.)

Why does Kripke take the search for candidate meaning facts to fail? Recall that all my previous uses of ‘+’ are compatible with my meaning quaddition, which is what enables the sceptic to say that I meant that all along. One might complain that the challenge operates from a “ridiculous model of instruction” (1982: 15), which fails to take into account that to be a competent adder is to have internalized a general instruction or rule that is now “engraved on my mind as on a slate” and which “justifies and determines my present response” (1982: 15–16). But the sceptic will reply that the worry can be raised again with respect to the general instruction or rule, which is just as susceptible to being interpreted in a deviant way as the initial expression. Kripke then considers a variety of other candidates, which are the kernel of various philosophical theories, and argues, on behalf of the sceptic, that none of them fit the bill. Among the facts considered are my being disposed to produce the sum (1982: 22–32), my instantiating a machine whose operations embody the function of addition (1982: 32–35), the simplicity of the addition hypothesis (1982: 37–39), my having a distinctive experience “with its own special quale, known directly” through introspection (1982: 41), my having an image in mind that supposedly singles out addition (1982: 42), my being in a primitive, irreducible state of meaning addition (1982: 51–53), and my grasping an abstract entity, such as a Fregean sense, which singles out addition (1982: 53–54). None of them, Kripke argues, is successful in ruling out the skeptic’s hypothesis that I meant quaddition rather than addition.

As mentioned above, dispositionalism and non-reductionism are the most prominently discussed proposals, and we’ll consider them more carefully in section 4 and section 5, respectively. At this stage, we should ask the following question: what are the conditions that a candidate meaning fact must meet? There is controversy in the literature about their nature and plausibility.

2.1 The Extensionality Condition
Here is how Kripke first lays out the two conditions:

An answer to the skeptic must satisfy two conditions. First, it must give an account of what fact it is (about my mental state) that constitutes my meaning plus, not quus. But further, there is a condition that any putative candidate for such a fact must satisfy. It must, in some sense, show how I am justified in giving the answer ‘125’ to ‘
68
+
57
’. The ‘directions’ … that determine what I should do in each instance, must somehow be ‘contained’ in any candidate for the fact as to what I meant. Otherwise, the skeptic has not been answered when he holds that my present response is arbitrary. (1982: 11)

To begin with, Kripke claims that whatever fact makes it the case that a speaker means addition by ‘+’ must single out the addition function, as opposed to the quaddition function, as what is meant. It follows from this that the putative meaning-constituting fact must account for the conditions of correct application of ‘+’. In other words, the fact in which my meaning addition by ‘+’ consists must single out ‘4’ as the correct response to ‘
2
+
2
’, ‘110’ as the correct response to ‘
55
+
55
’, ‘125’ as the correct response to the query ‘
68
+
57
’, and so on. Meaning facts render the applications of expressions correct or incorrect, and so a fact cannot count as a meaning-constituting fact unless it does this. This is an uncontroversial claim, which most philosophers accept. As Simon Blackburn notes, this

distinguishes the production of terms from mere noise, and turns utterance into assertion—into the making of judgement,

and so

it is not seriously open to a philosopher to deny that, in this minimal sense, there is such a thing as correctness and incorrectness. (1984 [2002: 29]; see also Wikforss 2001: 206; Hattiangadi 2006, 222; Glüer & Wikforss 2009: 35; see Travis 2006 for a dissenting view)

Moreover, this is something on which those who seek to offer a reductive account of meaning (e.g., Fodor 1990; Millikan 1984) and those who are sceptical about the prospects of reduction (e.g., Boghossian 1989; Verheggen 2011; Bridges 2014) seem to agree.

We’ll call this first condition the extensionality condition. In the case of a predicate like ‘green’, for example, it requires that the fact which constitutes its meaning determines the appropriate class of things to which ‘green’ is correctly applicable. This will be the class of green things as opposed, say, to the class of grue things (where an object is grue if and only if it is green before some specified time t and blue thereafter), and in the arithmetical case on which we have focussed so far, the extension of ‘+’ will contain the triple 
⟨
57
,
68
,
125
⟩
 (and not the triple 
⟨
57
,
68
,
5
⟩
).

To see how a candidate meaning-constituting fact might fail the extensionality condition, consider a simple form of dispositional theory of meaning which proposes as constitutive of my meaning addition the fact that I’m disposed to answer with the sum (as opposed, say, to the quum) when faced with arithmetical queries of the form ‘
x
+
y
’. The sceptic argues that this fact doesn’t single out the addition function:

Let ‘quaddition’ be redefined so as to be a function which agrees with addition for all pairs of numbers small enough for me to have any disposition to add them, and let it diverge from addition thereafter (say, it is 5). Then, just as the skeptic previously proposed the hypothesis that I meant quaddition in the old sense, now he proposes quaddition in the new sense. A dispositional account will be impotent to refute him. As before, there are infinitely many candidates the skeptic can propose for the role of quaddition. (Kripke 1982: 27)

We’ll consider whether dispositionalism can muster resources to deal plausibly with this problem concerning the satisfaction of the extensionality condition below (in section 4).

2.2 The Normativity Condition
According to a prominent line of thought, the notion of correctness involved in the seemingly platitudinous claim that meaningful expressions have conditions of correct application is intrinsically normative. On this reading, meaning facts are normative facts—they not only sort the applications of expressions into correct or incorrect, but also prescribe how expressions ought to be applied. They issue semantic categorical obligations that bind speakers in determinate ways; the justified applications are precisely those that fulfil these semantic obligations. (The kind of normativity at stake is meaning engendered, rather than meaning determining; it is grounded in meaning, rather than grounding meaning. See Glüer and Wikforss 2009 for this helpful distinction.)

To illustrate how the second condition, thus construed, constrains accounts of meaning, let us again consider Kripke’s discussion of dispositionalism. He thinks that the dispositionalist offers “a descriptive account” of the relation between what one means by an expression and one’s uses of that expression, but that “this is not the proper account of the relation, which is normative, not descriptive” (1982: 37). More generally, Kripke says, “the relation of meaning and intention to future action is normative, not descriptive” (1982: 37). Among the commentators who read the second condition in this way are Wikforss 2001, Glüer and Wikforss 2009, Hattiangadi 2006 and 2007, and Miller 2011, 2012. Thus construed, the sceptical argument can be compared to arguments in metaethics that purport to establish, by drawing on J. L. Mackie’s (1977) argument from queerness concerning the seemingly problematic metaphysical and epistemological status of moral properties, an error-theory of moral judgment (Miller 2010a, 2020). (See the entry on moral anti-realism.)[4]

Kripke’s discussion has resulted in a vigorous debate about whether meaning really is normative, as well as about how the normativity of meaning is best understood. For a defence of the claim that meaning is normative, see Whiting 2007, 2009, 2016 (note that Whiting focuses on the idea that meaning facts engender permissions to apply words correctly and obligations not to apply them incorrectly, though both the permissions and the obligations are defeasible). For criticism of the view that meaning is normative, see Fodor 1990, Glüer and Pagin 1998, Glüer 1999, Wikforss 2001, Boghossian 2005, Miller 2006, Hattiangadi 2006, 2007, and Glüer and Wikforss 2009. (See also the entry on the normativity of meaning.) Some philosophers seek to carve a middle ground between the normativist and the anti-normativist positions—for instance, by claiming that meaning facts are essentially justificatory (Gampel 1997), or that they have hypothetical implications that are essential to them, thus being fundamentally unlike natural facts, which may be hypothetically normative only accidentally (Verheggen 2011; Chapter 2 of Myers and Verheggen 2016). Hannah Ginsborg proposes a novel conception of normativity as more basic than rules (Ginsborg 2011b, 2012, forthcoming), which we shall briefly discuss in the last section.

Some commentators take the normativity condition to amount to an agential requirement, one that primarily concerns the applications or uses of expressions. The thought is that meaningful uses of expressions are not arbitrary—they are not unjustified leaps in the dark. An adequate conception of meaning must be able to account for this. This view of the normativity condition claims to shed light on Kripke’s numerous appeals to the metaphor of blindness (1982: 10, 15, 17, 23, 87). Kusch thinks that the requirement of non-blindness is best understood as falling under the purview of semantic normativity (which, contra the normativist interpreters, he does not take to involve categorical obligations), and that it is best understood as indicating that the speaker’s “meaning-constituting mental state guides and instructs” her on how to apply the expression, that the speaker “can refer to this mental state in order to justify her use” of the expression, and that this state

not only justifies certain applications—in the sense that meaning addition justifies ‘125’ in answer to ‘
68
+
57
=
?
’—it also justifies the way in which the answer is usually produced. (Kusch 2006: 8–9, italics added)

Along similar lines, it has been suggested that the meaning-constituting facts be able to accommodate the idea that “the meaningful use of words must be revealed as intentional” (Sultanescu and Verheggen 2019, 13; Sultanescu forthcoming). The paradox has also been interpreted as belonging

to the philosophy of rational explanation, of explanations that account for what people do or think by citing their reasons for doing or thinking so. (Bridges 2014: 249; see also Bridges 2016)

Some interpreters take the sceptical argument to involve the imposition of an epistemological constraint—a constraint related to the epistemic justification of semantic judgments, rather than to the rationality of the applications of expressions. Warren Goldfarb notes that Kripke “does seem to mean that the justifications must in some sense be transparent” (1985 [2002: 98]). José Zalabardo takes Kripke to be demanding that the meaning-constituting facts provide speakers with justification for their judgments about the correctness of the applications of their predicates. Justification is construed in an internalist sense: speakers possess the relevant justification if the procedure through which they decide whether predicates apply to objects involved “conscious engagement with the facts that determine how these questions should be answered” (1997 [2002: 286]). (See also Jackman 2003, Guardo 2012, and Merino-Rajme 2015). Crispin Wright proposes a more specific epistemic constraint, namely, that of accounting for the seemingly puzzling fact that the epistemology of meaning is first-person authoritative even though meaning something by an expression is in crucial respects akin to having a dispositional trait. In Wright’s words, the constraint is to explain

how it is possible to be effortlessly, non-inferentially and generally reliably authoritative about psychological states which have no distinctive occurrent phenomenology and which have to answer, after the fashion of dispositions, to what one says and does in situations so far unconsidered. (2001: 150)

Note that all the construals of the second condition appear to put pressure on dispositionalism over and above that exerted by the extensionality condition. Prima facie, dispositional facts are facts about what we will or would do, not about what we ought to do; dispositional facts appear not to be essentially justificatory or hypothetically prescriptive; dispositions do not justify or rationalise their manifestations, and in making semantic judgements we do not typically engage with facts about our linguistic dispositions; lastly, it is unclear how a dispositional account of meaning could be rendered consistent with its intuitive first-person epistemology. See section 4 for further discussion of dispositionalism.

3. The Sceptical Solution
If the sceptical argument is cogent, it seems to follow that there are no meaning-constituting facts, no facts in virtue of which linguistic expressions mean one thing rather than another. As noted above, this appears to imply the paradoxical conclusion that “the entire idea of meaning vanishes into thin air” (1982: 22). Kripke distinguishes between two broad ways in which one might attempt to avoid this conclusion (1982: 66–7). On the one hand, one might provide a straight response, by identifying some meaning-constituting fact of the sort called into question by the sceptic. The various proposals discussed briefly in section 2 above are instances of straight responses. The two most prominent types of straight response in the literature—reductive dispositionalism and non-reductionism—are discussed in more detail in section 4 and section 5 below. On the other hand, one might provide a sceptical response. That is, one might concede that there are no meaning-constituting facts of the sort demanded by the sceptic but deny that this leads to a paradoxical conclusion. In this section, we shall focus on this strategy.

The proponent of the sceptical solution can be understood as rejecting eliminativism about our practices of ascribing meaning. Mirroring parallel discussions in metaethics, the two most obvious paths available to her involve providing either an error-theoretic account or a non-factualist account of ascriptions of meaning. We shall follow Boghossian in viewing these paths as forms of irrealism about meaning, content and rules (Boghossian 1989, 1990). A prominent general line of argument in the recent literature suggests that irrealist views of any area make presuppositions that irrealist views of meaning and content are bound to deny, so that irrealism about meaning and content is ultimately incoherent (Boghossian 1989, 1990; Hattiangadi 2007, 2017, 2018; Miller 2011, 2015a, 2020). We’ll illustrate this general line of attack by sketching an argument to the effect that, regardless of whether one pursues an error-theoretic or a non-factualist approach, adopting irrealism leads inexorably to an “insane and intolerable” and “incredible and self-defeating” form of eliminativism on which the notions of meaning and content do turn out to “vanish into thin air”. We’ll then briefly consider an alternative way of providing a sceptical response, which aims to revise the conception of meaning fact that is at work in the sceptic’s mindset.

3.1 Error Theories
Suppose we adopt an error theory: the view that all atomic, positive statements ascribing meaning, content, or the following of a rule, are false. While some error theories are eliminativist (e.g., Churchland 1981 on propositional attitudes), the error theorist need not subscribe to eliminativism. For instance, J.L. Mackie (1977) argues that although moral judgements are uniformly false, eliminativism can be avoided given that some moral judgements are such that their acceptance facilitates securing the benefits of social cooperation in circumstances where “the limitation of men’s sympathies” (1977: 108) threaten their attainment.[5] On this view, even though our practice of making moral judgments results in falsehoods, it meets a subsidiary norm (or norms) in terms of whose satisfaction its pragmatic utility can be secured.[6] Might an error theorist about meaning, content and rule-following attempt to avoid eliminativism by following a similar strategy?

It might seem that there is room for this approach. In the case of meaning, the subsidiary norm might be something like the following: one ought to assert “Jones means addition by ‘+’” only when Jones’s

particular responses to arithmetical queries agree with those of the community in enough cases, especially the simple ones (and if his “wrong” answers are not often bizarrely wrong, as is ‘5’ for ‘
68
+
57
’, but seem to agree with ours in procedure, even when he makes a “computational mistake”). (Kripke 1982: 92)

This norm would thus be cashed out in terms of agreement with respect to inclinations “to go on” in certain ways, and the utility of our complying with it would be that it enables us to make helpful discriminations—for example, when seeking to buy five apples—between grocers whose inclinations match ours and grocers with “bizarre” quus-like inclinations.[7]

While this strategy might seem to some to be promising in the moral case, it faces special problems in the case of meaning, content and rules (Boghossian 1989, 1990; Miller 2015a). In order for the strategy to be able so much as to be pursued, there has to be such a thing as complying or failing to comply with a subsidiary norm—and so, a fortiori, such a thing as complying or failing to comply with a norm as such. An error theorist about rule-following, however, denies precisely that there are facts about norm-compliance and non-compliance. Having argued that all statements about rule-compliance are false, the error theorist apparently lacks the resources for telling a story about the pragmatic utility of our continuing to engage in the practice of making judgements about rule-following. The upshot seems to be that, if we accept that there are no facts about speakers in virtue of which expressions have meaning, embracing an error theory will not prevent the notion of meaning from “vanishing into thin air”.

3.2 Non-Factualist Theories
One might attempt to avoid eliminativism about meaning by embracing a different type of irrealism, namely, non-factualism. A non-factualist about a domain maintains that judgments and claims made within that domain are not in the business of stating facts. Indeed, the standard view in the secondary literature is that Kripke’s Wittgenstein himself is proposing a form of semantic non-factualism in the sceptical solution outlined in chapter 3 of Kripke (1982). See, e.g., McGinn (1984), Wright (1984), Boghossian (1989), and Hale (2017). Might semantic non-factualism afford us a way to embrace the conclusion of the sceptical argument while avoiding eliminativism?

This move faces difficulties parallel to those faced by error theories (Boghossian 1989, 1990; Hattiangadi 2007: chapter 4, 2018; Miller 2011, 2020). The non-factualist about meaning proposes that we construe ascriptions of meaning as having a purpose or function different from that of stating facts. But, insofar as a sentence is regarded as having a function, there is an intelligible distinction between correct and incorrect uses of that sentence; in other words, the sentence is rule-governed. That the notion of correctness in these cases cannot be identified with truth or warranted assertibility makes no difference to the applicability of a generalised version of the extensionality condition, which we outlined in section 2. Thus, suppose that ‘
S
’ is a sentence that has a non-descriptive semantic function. Consider these two specifications of the conditions in which uttering ‘
S
’ is correct, where 
R
1
 and 
R
2
 would confer different correctness-values on utterances of ‘
S
’:

(a)
Uttering ‘
S
’ is correct iff the conditions in which it is uttered accord with 
R
1
;
(b)
Uttering ‘
S
’ is correct iff the conditions in which it is uttered accord with 
R
2
.
Whatever makes it the case that (a) provides the correctness conditions for utterances of ‘
S
’ must rule out (b) as providing those conditions.

Now, let’s consider the case of plans, which are expressed in sentences that wear their non-descriptive semantic function on their sleeves. (We choose the case of plans deliberately here, as a view of this kind is mooted in Gibbard 2012.) Take the sentence ‘Let’s write a fugue!’. Consider two possible correctness conditions for it:

(a*)
‘Let’s write a fugue!’, as uttered by Glenn, is correct iff Glenn plans to write a fugue
and

(b*)
‘Let’s write a fugue!’, as uttered by Glenn, is correct iff either (a) it is time t earlier than t* and Glenn plans to write a fugue or (b) it is time t later than or equal to t* and Glenn plans to write a novel.
Glenn’s finite nature together with the infinitude of the temporal sequence ensures that the sceptic will always be able to argue that no fact about Glenn is capable of ruling in something like (a*) and ruling out something like (b*) as the relevant correctness condition. The non-factualist is entitled to regard “Let’s write a fugue!” as having a determinate meaning only if she can provide some fact about Glenn or his speech community that determines that that sentence is governed by (a*) rather than (b*). The same argument can be pressed against the suggestion that “Jones means addition by ‘+’” should be regarded as having some non-descriptive semantic function. The non-factualist will be able to regard “Jones means addition by ‘+’” as having a determinate meaning only if she can provide some fact about Jones or his speech community that determines that that sentence is governed by one rule or correctness condition rather than another.

So, a non-factualist account of any region of thought and talk, which is committed to the claim that there are no facts of the relevant sort, would seem to presupposes a realist account of meaning, content and rules according to which there are semantic facts, intentional facts, and facts about normative accord. So, a non-factualist account of meaning, content and rules, which is committed to the claim that there are no semantic facts, intentional facts, or facts about normative accord that our semantic, intentional, or normative discourse purports to capture, presupposes a realist account of meaning, content and rules according to which there are semantic facts, intentional facts, and facts about normative accord. It thus faces a charge of incoherence.

As noted above, we chose “plans” as our stalking horse here in order to make explicit the problem this poses for Allan Gibbard’s (2012) account of meaning (it makes no difference to the argument whether “plans” are taken to be linguistic items possessing meaning or mental states possessing intentional content). A Gibbard-style expressivist approach to an area such as morality denies that there are moral facts, but presupposes that there are facts about meaning, content and normative accord (facts that determine what accords and fails to accord with a plan). A Gibbard-style approach to meaning, content and rules thus, on the one hand, denies that there are semantic facts, intentional facts and facts about normative accord (facts that determine what accords and fails to accord with a plan), and, on the other, presupposes that there are such facts. It thus faces a charge of incoherence.

A similar objection to Gibbard’s view is outlined in Hattiangadi (2018). According to Hattiangadi, a Gibbard-style expressivist account of moral claims, for example, aims to give an “oblique” explanation of them in terms of the states of mind they express (rather than a “straight” explanation in terms of (moral) states of affairs which potentially render them true). But such an oblique explanation in the moral case presupposes a straight explanation of intentionality. In parallel, an oblique explanation of meaning and intentionality would presuppose a straight explanation of meaning and intentionality, again threatening the view with incoherence. In a reply to Hattiangadi, Gibbard reflects on the strategy of the metaethical expressivist and attempts to use it to counter Hattiangadi’s worry. He writes:

A parallel can be found in ethics: Suppose we claim that being good consists in being pleasurable. The concept of being pleasurable can be completely non-ethical and naturalistic, but the claim “Being good consists in being pleasurable” is ethical—and so, if Moore and others are right, nonnaturalistic. Is there, then, “a straight or substantive explanation of intentionality”? The correct answer will parallel that for the question, “Is there a straight substantive explanation of being good?” If ethical hedonists are right and being good consists in being pleasurable, then there’s a straight, substantive explanation of being good in the sense of a naturalistic explanation of the property that being good consists in. But the claim “Being good is being pleasurable” isn’t itself naturalistic. If Ayer was right, it amounts to “Hurrah for all and only what”s pleasurable. (Gibbard 2018: 770)

We leave assessment of Gibbard’s reply as an exercise for readers.[8]

3.3 An Alternate Form of Factualism
Wilson takes the lesson of the sceptical argument to be not that there are no meaning facts, but rather that a certain conception of such facts, which he calls classical realism, is hopeless, and conceives of the sceptical solution as accommodating meaning facts when conceived in a different way (Wilson 1994; see also Wright 1992: chapter 6). Classical realism is sometimes referred to as semantic platonism, the view that “the meanings of our words are guaranteed by the pre-existing structure of reality” (Pears 1988: 363; cf. Child 2001, Verheggen 2003, Zalabardo 2003, Hanks 2017). What is essential to classical realism or semantic platonism is that the properties that guarantee meaningfulness must be antecedently singled out by individuals (or communities) in order to endow their words with semantic standards (Wilson 1994 [2002: 251]). As Zalabardo puts it, what is required is

a conscious act in which I decide to pair the predicate with the property in such a way that the satisfaction conditions of the predicate, as I mean it, are determined by the instantiation conditions of the property. (2003: 314)

Wilson takes the sceptical challenge to reveal that no sense can be made of this idea, for it is not possible for an individual (or community) non-linguistically to single out properties as “the de re subject of her meaning-constituting intentions” (1998: 105). But, to repeat, what this allegedly shows is not that there are no meaning facts, but rather that we must reform our conception of them.

The alternative picture of meaning that Wilson fleshes out conceives of expressions as not connected to properties that serve as “pre-established” standards of correctness” (2003: 181–182), and suggests that “what we mean by [an expression] is something that gets settled only over the course of time” (2003: 186). In response to Wilson’s proposal, it has been argued that it is susceptible to collapsing into a form of subjectivism (Kremer 2000), and that it is untenable, for it falls prey to the sceptical challenge that it purports to bypass (Miller 2010b). It has also been argued, contra Wilson, that classical realism is merely an instance of a more general conception of meaning that takes standards of correctness to be determined by entities—whether abstract properties or real features of the world around us—that are considered independently of how we might describe them linguistically; it is this conception that must be rejected, as it is ultimately responsible for generating the paradox (Verheggen 2003).[9]

4. Reductive Dispositionalism
The most widely discussed attempt at a straight solution to the sceptical challenge is reductive dispositionalism. According to a simple version of reductive dispositionalism, the fact that Jones has the concept of addition rather than of quaddition is to be identified with (or is constituted by) his disposition to produce the result of adding (and not quadding) the numbers x and y in response to arithmetical queries of the form ‘
x
+
y
=
?
’, and the fact that he means cat by ‘cat’ is to be identified with (or is constituted by) his disposition to apply ‘cat’ to cats. (See Horwich 1998, 2010, 2012 for a systematic development of dispositionalism; an answer to Kripke’s challenge is articulated in Horwich 2015.)

As Boghossian notes (1989 [2002: 164–165]), the general form of dispositionalism targeted by the sceptic covers both conceptual role theories and causal/informational theories. In both cases, the account is intended to be reductive, insofar as the content-determining dispositions are to be characterized in wholly non-semantic and non-intentional terms. The sceptic’s attack on reductive dispositionalist theories is thus an attack on two of the most popular accounts of the determination of content in contemporary philosophy of mind and language.

The sceptic argues that dispositionalist theories face three problems. The first problem—the finitude problem—is that there is a sense in which, much like the totality of our previous linguistic behaviour, our dispositions are finite. Given that the extension of the addition function is infinite, containing a denumerably infinite number of triples 
⟨
x
,
y
,
z
⟩
 such that x plus y is identical to z, Jones’s meaning addition by ‘+’ cannot be identified with her dispositions to respond to arithmetical queries since it is simply false that she is disposed to answer with the sum when faced with the query ‘
x
+
y
=
?
’. In some (indeed, most) cases, the numbers involved will be so large that Jones’s brain’s capacity for computation is far exceeded, and Jones may even die long before she is able to grasp the relevant numbers. We might follow Boghossian in dubbing such numbers “inaccessible” (2015: 335), and we might define quaddition to be a function that diverges from addition over only inaccessible numbers. In this case, the problem is that, given Jones’s dispositions, it is indeterminate whether he means plus or quus.

The second problem—the error problem—is that someone might be systematically disposed to make mistakes. Take Smith, who is systematically disposed to miscarry when responding to ‘
x
+
y
=
?
’ queries. When Smith produces ‘28’ in response to ‘
19
+
19
=
?
’, we want to be able to say that her answer is incorrect in the light of what she means by ‘+’. However, if what she means is determined by her dispositions, we are forced to say that she actually means some non-standard function (one that corresponds to addition with the carrying operation removed), so that her answer ‘28’ is correct.

The third problem—the normativity problem—is that the dispositionalist view seems unable to capture the normativity of meaning. Given what she means by ‘+’, Jones ought to respond to arithmetical queries of the form ‘
x
+
y
=
?
’ by producing the sum of x and y, but the meaning-constituting fact proposed by the dispositionalist is at most a fact about how she would respond to queries of the relevant form:

Suppose I do mean addition by ‘+’. What is the relation of this supposition to the question how I will respond to the problem ‘
68
+
57
’? The dispositionalist gives a descriptive account of this relation: if ‘+’ meant addition, then I will answer ‘125’. But this is not the proper account of the relation, which is normative, not descriptive. The point is not that, if I meant addition by ‘+’, I will answer ‘125’, but that, if I intend to accord with my past meaning of ‘+’, I should answer ‘125’. Computational error, finiteness of my capacity, and other disturbing factors may lead me not to be disposed to respond as I should, but if so, I have not acted in accordance with my intentions. The relation of meaning and intention to future action is normative, not descriptive. (Kripke 1982: 37)

In section 2, we outlined a number of ways in which a normativity condition might be thought to impose a constraint on accounts of meaning. We suggested that in all of these ways this condition puts at least prima facie pressure on dispositionalist theories of meaning. We will limit ourselves in the remainder of this section to some remarks on the finitude problem and the error problem. These two problems indicate two obstacles that the dispositionalist must overcome in order to meet the extensionality condition.

Blackburn responds to the finitude problem by pointing out that familiar dispositional properties (such as fragility) are in a sense infinitary: “there is an infinite number of places and times and strikings and surfaces on which it could be displayed” (1984 [2002: 35]). If a glass has infinitary dispositions, perhaps a human does too, and perhaps this will yield an extended disposition that covers the case of queries involving inaccessible numbers. Even though we have no way of getting an ordinary glass to Alpha Centauri (it would decay long before it got there), we can think of it as possessing an extended disposition to break there: breaking is what the glass would be disposed to do were its dispositions on earth allowed to manifest themselves on Alpha Centauri. Likewise, even though Jones has no disposition to answer queries involving inaccessible numbers, responding with the sum is what Jones would be disposed to do were her dispositions in accessible cases allowed to manifest themselves in inaccessible cases. This would in turn allow us to say that the answer that she would accept in those cases is “the one that would be given by reiterating procedures [Jones is] disposed to use, a number of times” (1984 [2002: 35]).

Blackburn’s response to the finitude problem is open to criticism. First, Blackburn’s talk of procedures Jones is disposed to use is illegitimate in this context: to “use” a “procedure” is to follow a rule, and we cannot help ourselves to the idea that Jones is following the rule for addition here (or any rule, for that matter), as it is Jones’s status as a rule-follower that we are hoping to recover from facts about her dispositions. What we can say is that as far as the accessible cases go, the answers Jones is disposed to give conform to the rule for addition. But, of course, they also conform to the rule for quaddition. What makes Jones an adder, and not a quadder, according to Blackburn’s suggestion, is that were Jones’s dispositions in the accessible cases allowed to manifest themselves in the inaccessible cases, she would respond with the sum, and not the quum.

However, Boghossian (2015: 341) points out that there is a crucial disanalogy between this case and the extended disposition to break on Alpha Centauri plausibly ascribed to the glass. To think of the dispositions the glass has on earth as manifesting themselves on Alpha Centauri, we don’t need to think of the glass in any way that is inconsistent with its nature as a physical object. It can be regarded as having the same intrinsic physical characteristics on Alpha Centauri as it has on earth, and if it is true that, given those characteristics, it would break if struck on Alpha Centauri, that suffices for the attribution of the extended disposition to break on Alpha Centauri. Matters stand differently with Jones. In order to think of Jones’s dispositions to respond in accessible cases as manifesting themselves in inaccessible cases, we would have to think of her in a way that is inconsistent with her nature as a finite biological being. This is because responding to queries involving inaccessible numbers would require, let’s suppose, a brain the size of the universe. But the fact that with a brain the size of the universe the sum would be produced no more warrants the attribution of the relevant extended disposition to Jones than does the fact that with a brain the size of the universe she would outplay Magnus Carlsen warrant the attribution to her of the potential to win the world chess championship. Jones has no extended disposition of the sort adumbrated by Blackburn.[10] The upshot, then, is that Jones’s dispositions do not determine whether she means plus rather than some quus-like function by ‘+’, where quus diverges from plus for inaccessible numbers.[11]

We’ve followed Boghossian (2015) in setting up the finitude problem as fundamentally a problem about determinacy. In a recent paper, Jared Warren admits that solving the finitude problem, thus construed, turns on solving the error problem (2020: 268), and proceeds to offer an attempted solution to that problem. Consider the following proposal: the fact which constitutes Jones’s meaning addition by ‘+’ is the fact that, when faced with arithmetical queries involving the ‘+’ sign, Jones is stably disposed to reply with the sum in the overwhelming majority of normal situations.[12] What are normal situations, and what is it for a disposition to be stable? Normal situations are those in which neither external nor internal factors are interfering with Jones’s general cognitive functioning. More specifically, the normal situations are those in which Jones is clearheaded—situations in which the air is not permeated with mind-bending chemicals, in which Jones is not drunk, exhausted, or badly hungover, so that neither external causes nor internal causes are interfering with her cognitive performance. Furthermore, to say that Jones’s disposition to respond with the sum is stable is to say that, as the number of arithmetical queries she has faced increases, the ratio of answers that give something other than the sum to answers that give the sum tends towards zero. And to keep the bar relatively low, we don’t require that in normal conditions it is metaphysically impossible for Jones to answer with something other than the sum. We only require that, when such conditions obtain, it is rational to be nearly certain that she will answer with the sum. Call the disposition which we have described here disp. disp corresponds to the meaning-constituting dispositions that Warren proposes as offering a solution to the error problem. The proposal is intended to be reductive. Warren notes that “normalcy”, defined as he defines it, “isn’t semantic or intentional or otherwise problematically question-begging” (2020: 271).

However, Warren’s attempt to solve the error problem can be questioned. The error problem arises as a result of the fact that the following two possibilities are consistent with Jones’s possession of disp. First, Jones means addition by ‘+’ and is responding correctly to the relevant queries. Second, Jones means some quus-like function and is responding incorrectly. What Warren thus needs is a characterisation of normal situations such that the latter possibility is ruled out. Thus, what is required is a characterisation of normal situations such that, when those situations obtain, we are entitled to be nearly certain that Jones will answer with the sum, and that in answering with the sum Jones is responding correctly. The trouble is that there is an infinite range of functions 
F
1
,…, 
F
n
 that have different extensions from the addition function. If Jones means some function 
F
i
 among them, and if she answers with the sum, she would be answering incorrectly. Thus, the normal situations have to be such that their obtaining ensures that Jones means by ‘+’ none of the functions in this open-ended and infinite set. The question that drives Kripke’s Wittgenstein’s objection is: how could this be achieved other than through the inclusion of a clause in the characterisation of normal situations to the effect that Jones means addition by ‘+’ (or at least, that Jones means a function with the same extension as addition)? How could the obtaining of a non-semantically characterised set of situations have the effect of excluding every member of an open-ended and infinite set of semantically or intentionally characterised states of affairs (Jones means 
F
1
 by ‘+’, Jones means 
F
2
 by ‘+’, and so on ad infinitum)?[13]

Thus, it can be argued that the dispositionalist account offered by Warren either fails to resolve the indeterminacy problem or does so only at the expense of deploying semantic and intentional notions, which is inconsistent with its reductive aspirations.[14]

Postscript to section 4: Lewis on Natural Properties
A reductionist position that has been somewhat neglected in the rule-following literature is suggested by David Lewis in his “New Work for a Theory of Universals” (1983). Lewis writes:

The naive solution is that adding means going on in the same way as before when the numbers get big, whereas quadding means doing something different; there is nothing present in the subject that constitutes an intention to do different things in different cases; therefore he intends addition, not quaddition. We should not scoff at this naive response. It is the correct solution to the puzzle. But we must pay to regain our naiveté. Our theory of properties must have adequate resources to somehow ratify the judgement that instances of adding are all alike in a way that instances of quadding are not. The property of adding is not perfectly natural, of course, not on a par with unit charge or sphericality. And the property of quadding is not perfectly unnatural. But quadding is worse by a disjunction. So quaddition is to that extent less of a way to go on doing the same, and therefore it is to that extent less of an eligible thing to intend to do. (1983: 376)

Take a predicate like ‘green’. The totality of facts about our previous use and dispositions to use ‘green’ are consistent with it referring to the property green but also with it referring to the property grue. So, what might ground the claim that the property green is somehow privileged as the referent of ‘green’? Lewis can be taken to advocate a form of “interpretationism” according to which semantic facts are constitutively determined by the best theory of the data (J. R. G. Williams 2007). Among the a priori constitutive constraints governing what counts as the best theory is a principle requiring that the referents assigned to expressions be the most natural of those consistent with the data. Since green is more natural than grue, it is more “eligible” than grue to be assigned to ‘green’ as its referent. Likewise for adding and quadding. In this way, the indeterminacy left open by facts about use is fended off, Lewis thinks.

Lewis’s proposal is not ad hoc, as the notion of a natural property that it utilises is required, for example, by his account of laws of nature (see the entry on David Lewis, section 4.6). However, its application to the rule-following problem faces a number of challenges. First, it is not obvious how it extends to the mathematical examples that are the focus of Kripke’s Wittgenstein. Boghossian writes,

I see no obvious notion of naturalness that will cover both the notion of a natural property, as it might figure in an account of similarity or lawlikeness, and that of a natural function. (2015: 355)

It has also been argued that even if Lewis’s proposal might meet the extensionality condition, it cannot meet the normativity condition (Merino-Rajme 2015).

Lewis’s proposal is also likely to be challenged on epistemological grounds similar to those used by Kripke and Wright in dismissing the suggestion that quaddition can be ruled out in light of the fact the hypothesis that Jones meant quaddition is less simple than the hypothesis that he meant addition. A speaker can know that in response to the query ‘
68
+
57
’, ‘125’ is the answer that accords with what she meant by ‘+’, without having to infer this from facts about her previous linguistic behaviour. That is to say, in recognising that the answer ‘125’ fits what we mean by ‘+’, we do not proceed “by inference to the best semantic explanation of [our] previous uses of that expression” (Wright 2001: 109; see also Kripke 1982: 40). But this is apparently what we would have to do if the “simplicity” suggestion were correct: the best explanation would be yielded by the simplest of the hypotheses consistent with our previous linguistic behavior. The “simplicity” suggestion thus apparently makes a mystery of our (generally) non-inferential semantic knowledge. Lewis’s suggestion will be challenged on similar grounds. We do not infer what we mean by ‘+’ from facts about naturalness together with constitutive principles governing interpretation. Again, the account appears to make a mystery of the non-inferential nature of much of our semantic knowledge. Moreover, it faces difficulties in accommodating the authority normally credited to self-ascriptions of meaning. For Lewis, in virtue of the role they play in his account of scientific laws, simplicity and naturalness are objective notions. However, a speaker’s opinions about what she means, unlike, say, her opinions about the structure of the world or of our hypotheses about it, are generally authoritative, unless there are special reasons to doubt them. What might the basis for this default authority be, if what she means is determined by facts about simplicity and naturalness?

Moreover, the Lewisian view seems to be a form of semantic platonism (Child 2011: 126), in so far as it upholds the idea that our meaning what we do by our words is somehow guaranteed by the structure of reality. But it might be taken to be a radical form of semantic platonism, in so far as it seems to leave no room for the speaker’s contribution to the singling out of properties (see section 3.3). Unlike other versions of semantic platonism, it is vulnerable to a complaint to the effect that the subjective perspective of the thinker or speaker is entirely annihilated.

For a lucid exposition and critique of Lewis’s position, see J.R.G. Williams (2007). For rare examples of treatments of Lewis’s views in the context of the rule-following literature, see Merino-Rajme (2015), Glüer (2017), and Azzouni (2017).

5. Non-Reductionism
The apparently very serious problems we outlined for the dispositionalist conception of meaning have been taken by a number of philosophers to show that we ought to resist the temptation to explain meaning and content in more basic terms. How might one formulate a non-reductionist position? On Stroud’s view, it amounts to denying that we can explain

the phenomena of meaning and understanding “from outside” them, as it were, without attributing intentional attitudes or supposing that anything means anything or is understood in a certain way to those whose understanding is being accounted for. (Stroud 2000: viii)

More generally, we might say that the facts constitutive of the semantic domain cannot be characterised or explained in non-semantic terms, that is, without employing the notions of meaning or understanding; the facts constitutive of rule-following cannot be characterised or explained without employing the notion of rule-following. Some philosophers who embrace non-reductionism also defend the view according to which semantic facts do not supervene on anything; they are metaphysically fundamental. Boghossian relies on the finitude problem to argue that, if meaning facts are determinate, then they cannot supervene on non-semantic facts (Boghossian 2015). However, the denial of supervenience is not essential to non-reductionism (cf. Child 2019b): at the core of the position is the idea that any attempt to account for meaning in more basic terms is hopeless or philosophically confused.

Kripke briefly considers the possibility that the states of meaning or understanding, or the facts about meaning and understanding, are primitive or sui generis, which he cashes out as the idea that

meaning addition by “plus” … is simply a primitive state, not to be assimilated to sensations or headaches or any “qualitative” states, nor to be assimilated to dispositions, but a state of a unique kind of its own. (1982: 51)

He raises two complaints against this approach. First, he characterizes it as desperate, insofar as “it leaves the nature of this postulated primitive state … completely mysterious” (1982: 51), for such an approach does not provide an account of what makes it possible for one to “be confident that [one] does, at present” mean what one does (1982: 51). Second, he thinks that a non-reductionist account does not address the “logical difficulty implicit in Wittgenstein’s sceptical argument” (1982: 51), which is that it would seem that we could not “conceive of a finite state which could not be interpreted in a quus-like way” (1982: 52).

Some philosophers claim that Kripke’s treatment of the non-reductionist position is unsatisfactory. McGinn, who appears to ignore Kripke’s brief discussion of non-reductionism, thinks that there is an

undefended and undisclosed premise [in the sceptic’s argument], namely that semantic discourse cannot be regarded as irreducible. (1984: 82)[15]

McGinn also notes that Kripke has no qualms with adopting a non-reductionist view of meaning in other works—see, for instance, Kripke 1972: 94–97. Goldfarb thinks that “the conception Kripke exploits is basically physicalistic” (1985 [2002: 95]), and thus that pursuing a non-physicalist approach hasn’t been ruled out. Boghossian thinks that what Kripke needs for his treatment of non-reductionism to succeed is an argument from queerness aiming to show that there is something inherently queer about meaning properties, which he fails to provide (1989 [2002: 180]; cf. Hattiangadi 2007: 47–50). Ultimately, Boghossian is sympathetic to the non-reductionist approach, though he thinks that “it really is not plausible” that such a conception might be true of linguistic meaning (1989 [2002: 179]); on his view, it is facts about mental content that are irreducible.

Before exploring several of the non-reductionist positions proposed in recent years, we should note that some of the proponents of non-reductionism think that Kripke’s sceptical challenge is based on confusion, and that our task is to unearth that confusion. Thus, on their view, the proper response is not to solve the sceptical problem by showing that the sceptic failed properly to acknowledge some set of facts (or some features of some such facts), but to dissolve it by showing that there is, in fact, no problem. McDowell, for instance, argues that Kripke misunderstands the dialectic pursued by Wittgenstein in Philosophical Investigations. On his view,

the right response to the paradox, Wittgenstein in effect tells us, is not to accept it but to correct the misunderstanding on which it depends, (1984 [1998: 229])

which puts us in a position to dissolve the paradox and, with it, the problem of how meaning is possible. This involves renouncing the problematic assumption that understanding an expression requires interpreting that expression. McDowell’s diagnosis isn’t confined to linguistic expressions. What we ought to resist is the thought that,

whatever is in a person’s mind at any time, it needs interpretation if it is to sort items outside the mind into those that are in accord with it and those that are not. (1992 [1998: 268])

Similarly, Stroud thinks that the paradox is “an expression of an unsatisfiable demand” (1990 [2000: 88]), namely, the demand for

some facts, the recognition of which would not require that we already speak and understand a language, and some rules, which would tell us what, given those facts, it was correct to say.

Such facts and such rules would have to be such as to “serve to get us into language in the first place” (Stroud 1990b [2000: 94]). The demand is most strongly manifested in Kripke’s assumption that there must be an item that instructs or tells the speaker what to do with her expressions. Stroud claims that proper engagement with Wittgenstein’s remarks reveals this assumption to be misguided, for it embarks us on a regress (Stroud 1996 [2000: 180–185]). Once we recognize the misguidedness of the picture that Kripke assumes, we will no longer feel the force of the sceptical challenge, Stroud thinks. However, contra Stroud, it seems that the extensionality condition is all we need in order to pose a stripped-down version of the question that the sceptic is raising, namely, the question of what makes the standards of correctness that govern our uses of expressions and our deployments of concepts possible.

It might be argued that the urgency of this question, or even its very intelligibility, is merely a symptom of a frame of mind from within which meaning seems impossible, and that our proper task is to leave this confused frame of mind behind (e.g., McDowell 1992 [1998: 272, 274]; 1998a: 57–58). However, this line of reasoning might be taken to presume that a question is urgent or intelligible only if it is in principle possible to offer a reductive answer to it, that constructive philosophy is necessarily reductive philosophy. Verheggen argues that the rejection of reductionism does not commit one to quietism. As she sees it, non-reductionism can be constructive; it can revolve around advancing and defending positive claims (Verheggen 2000, 2003). Even though the project of providing necessary and sufficient conditions for meaning is hopeless, the non-reductionist can still aspire to articulate necessary conditions that aren’t “even remotely trivial” (Myers and Verheggen 2016: 3), and to draw illuminating connections between meaning and other irreducible phenomena. Through a creative reconstruction of Davidson’s triangulation argument, Verheggen argues that interaction with a second individual and aspects of the shared world is a necessary condition for one’s having a language and thoughts (see chapter 1 of Myers and Verheggen 2016). The constitution of the standards of correctness that govern language and thought necessitates that the individual be aware of the possibility of being mistaken, an awareness that can only be grounded in linguistic interactions with another individual and features of the world. Thus, the triangulation argument is taken by Verheggen to reveal the hopelessness of the reductive ambition, insofar as it shows that we cannot offer an account of the constitution of the standards of correctness that govern language and thought without presupposing that a commitment to those standards is already in place. (See also Sultanescu and Verheggen 2019 for an account of the Davidsonian answer to Kripke’s sceptical challenge and Verheggen 2017a for an account of the Davidsonian answer to Wittgenstein’s paradox.) William Child also defends a variety of non-reductionism, one that “does not give merely pleonastic answers but aims to say something genuinely informative” (Child 2019a: 97). He does so by relying on Wittgenstein’s remarks on meaning and rule-following.

According to Wright, “it is an important methodological precept that we do not despair of giving answers to constitutive questions too soon” (2001: 191). He goes on to propose a non-reductionist view that is sensitive to the difficulty of accounting for our knowledge of what we mean. (As we noted in section 2, Wright takes Kripke’s sceptic to impose a legitimate epistemological constraint on answers to the skeptical challenge.) He offers a “judgment-dependent” account of intention, according to which what one intends is determined by one’s best judgment about what one intends. Insofar as the concepts of intention and meaning are “relevantly similar” (2001: 206), this account can also claim to shed light on the nature of meaning. Thus, we might say, on Wright’s behalf, that what one means by an expression is determined by one’s best judgment about what one means. The notion of judgment is taken by Wright as primitive. Still, the authoritative nature of first-personal avowals is allegedly vindicated. See especially essays 5–7 in Wright 2001.[16]

Wright and Boghossian recently offered independent arguments to the effect that the adoption of a non-reductionist view of meaning does not secure the intelligibility of the idea of guidance by a rule. According to Wright, the only way in which rule-following can be understood is if it conforms to what he calls “the modus ponens model” (2007: 491). The model states that an act is a genuine instance of rule-following if it can be rationalized by, on the one hand, citing the rule and, on the other, indicating that the circumstances, which must be specifiable without appealing to the rule, call for its application. Wright investigates basic cases of language use, and argues that if we assume that the modus ponens model applies to these cases, we are saddled with an Augustinian picture, according to which conceptual capacities are necessarily prior to capacities to use language. At the same time, he accepts that Wittgenstein has revealed the bankruptcy of the Augustinian picture in Philosophical Investigations; so, the idea of antecedent conceptual capacities is unintelligible. This is taken to show that the modus ponens model cannot apply to basic cases. Wright calls this “the minor premise problem”, and argues that it compels us to accept that “in the basic case we do not really follow—are not really guided by—anything” (2007: 497).

Boghossian also relies on the modus ponens model to argue that a non-reductionist position does not allow us to make sense of the intelligibility of rule-following. He offers “an intuitive characterization” of the phenomenon of rule-following, according to which it has the following structure:

a state that can play the role of rule-acceptance; and some non-deviant causal chain leading from that state to a piece of behavior that would allow us to say that the rule explains and (in the personal-level case) rationalizes the behavior in question. (2012: 31)

What allows us to say that the rule explains and rationalizes the behaviour is an act of inference from the rule to what it requires in particular contexts. But inference is, according to Boghossian, “an example of rule-following par excellence” (2012: 40), which indicates that the act of inference must fit the intuitive characterization above, thus requiring a further act. A regress is unavoidable for the proponent of non-reductionism, according to Boghossian. This is the inference problem.

Arguably, the two problems are anticipated in Kripke’s line of reasoning, especially in his remark, mentioned earlier in this section, to the effect that the non-reductionist view faces a logical difficulty (1982: 51–52). The difficulty seems to arise from three claims that seem uncontroversial but are inconsistent:

the state of meaning plus by ‘+’ must guide the speaker in her applications of the expression ‘+’;
a state of meaning can be interpreted in more than one way;
something that can be interpreted in more than one way cannot guide.
We might think that one’s state of meaning something by an expression is not the sort of thing that one can interpret (thus denying (ii)), or that whether something can be interpreted in more than one way is irrelevant for the question of whether it can guide (thus denying (iii)). But neither of these options entitles us to reject (i); the non-reductionist still owes us an account of what it is to be guided by a rule (or by one’s understanding of an expression).

Miller offers an account of guidance by drawing on McDowell’s writings on Wittgenstein. He argues that the inference problem and the minor premise problem are not genuine difficulties for the non-reductionist. On his view, the upshot of Wittgenstein’s reflections on rule-following is that

in applying a rule R in a particular case there need be no further inferential step—over and above that involving R itself—mediating between acceptance of R and that particular application. (2015b: 405)

This is just what it is for rule-following not to be a matter of interpretation: the rule is applied immediately, as it were—without the mediation of a further rule, such as an inference rule, in the manner suggested by Boghossian, or a rule for the deployment of a prior concept, in the manner suggested by Wright. What puts an agent in a position to follow a rule is her having been trained into a practice or custom of following rules of that sort (2015b: 407), where the notions of training, practice, and custom are semantically characterized and cannot receive further philosophical illumination.

Thus, according to some defenders of non-reductionism, rule-following has an essentially social character. One dispute that is intramural to the non-reductionist approach concerns the precise way in which this social character should be understood. When it comes to meaning, Verheggen distinguishes between communitarian views, according to which

having a (first) language essentially depends on meaning by one’s words what members of some community mean by them,

and interpersonalist views, according to which

having a (first) language essentially depends on having used (at least some of) one’s words to communicate with others, (Myers and Verheggen 2016: 84; see also Verheggen 2006 for the initial articulation of the distinction)

and goes on to defend the interpersonalist view. Relatedly, there is the question of how we should understand the notions of practice and custom and the role that they play in a correct conception of intentionality, broadly construed. It might be thought, as Wittgenstein seems to suggest in Philosophical Investigations (e.g., #198; #201–202), that it is essential to thinking and speaking that one be trained into practices or customs, and thus that our conception should reflect the centrality of these notions (McDowell 1984, M. Williams 1999, Stroud 2000, M. Williams 2010, Miller 2015b); at least initially, this appears to favour the communitarian view. (See also Section 4 of Haase 2018 for a different kind of attempt to flesh out the Wittgensteinian notion of practice, and Pettit 1990 for a form of non-reductionism on which communal interaction is required in at least some cases of rule-following). But on the Davidsonian conception, at the centre of which is disagreement and the need to settle it rationally against the constraints of the shared world, the idea of practice might not serve any explanatory purpose; even though shared beliefs may be essential for thought, shared standards of correctness are not essential for language. The Davidsonian conception is a variety of interpersonalism. This intramural debate is very much ongoing.

Some philosophers have explored the possibility of a middle path between reductive dispositionalism and non-reductionism. Thus, in a paper in which she discusses Stroud’s view, Ginsborg distinguishes between austere forms of non-reductionism, which she takes to be incompatible with constructive philosophising about meaning, and “less austere and partly reductionist” approaches, which allow that “we could account for meaning in terms of a more basic idea of goal-directed human activity” (2011a: 153), but without allowing that such activity can be captured in purely dispositionalist or physicalist terms. She goes on to articulate a less austere view, which explains meaning in terms of a notion of normativity that she takes to be primitive. On this view, for someone to mean something by an expression is for her to have a disposition to apply it in particular contexts and, crucially, to take the manifestations of that disposition to be appropriate. Taking one’s responses to be appropriate

does not depend on the antecedent grasp of a rule or standard determining that response as correct rather than incorrect, or even on the awareness that there is such a rule or standard; (2011a: 169)

this establishes the primitive status of the notion of appropriateness. Thus, Ginsborg provides a dispositionalist account of meaning, albeit with a crucial proviso to the effect that the relevant dispositions are to be characterized in normative terms. She thinks that the account can serve as a straight solution to the sceptical challenge. On the one hand, it purports to vindicate the normativity of meaning, and thus to meet the normativity condition; on the other hand, it purports to account for the distinction between correct and incorrect applications of expressions, and thus to meet the extensionality condition. For Ginsborg, the set of correct applications of an expression are the applications that one is disposed to regard as appropriate—the applications that ought, in the primitive sense, to be made (see Ginsborg 2011b for a more detailed account of her solution to Kripke’s problem).

Ginsborg’s view is in some respects similar to Robert Brandom’s. Brandom seeks to explain meaning in terms of use, where use is specified in a way that is

neither so generous as to permit semantic or intentional vocabulary, nor so parsimonious as to insist on purely naturalistic vocabulary. (1994: xiii)

Thus, his approach to meaning might also be viewed as less austere and partly reductionist. We do not have room to explain the details of Brandom’s intricate view; suffice it to say that, on that view, the proper specification of the use that determines meaning essentially involves normative vocabulary. The facts that determine meaning are facts about the entitlements and commitments that are implicit in the performances of speech acts. Thus, what a speaker means by an utterance is to be understood as consisting, roughly, in the performances that she is committed to in virtue of the utterance as well as in the performances that entitle her to make it. Ultimately, these facts are “products of human activity” (xiv), being a matter of our adopting normative attitudes toward one another--of taking one another to be committed or entitled, in light of our performances, to various other performances. However, although there are similarities, there are also important differences between Brandom’s approach and Ginsborg’s. While for Brandom the norms that are constitutive of meaning are socially instituted, for Ginsborg they are natural. Moreover, the notion of appropriateness that Ginsborg fleshes out is more basic than the notion of reason, and thus more basic than the notions of entitlement and commitment that Brandom takes to be constitutive of meaning (Ginsborg 2011a: 172fn21). Still, Ginsborg does think that “expressions have meanings only in virtue of there being ways in which they ought to be applied” (2012: 132). So, to put it crudely, on both accounts, meaning facts are reduced to facts or considerations about what ought to be the case. The question that the austere non-reductionist will raise is whether the latter kinds of fact are apt to solve the indeterminacy problem, and thus to meet the extensionality condition.

The challenge of the sceptic makes perspicuous the fact that a non-semantically described pattern is compatible with indefinitely many interpretations. Does the appeal to the normative domain help us rule out the sceptic’s alternative hypotheses? Given that, arguably, on a partly reductionist picture of the sort that Brandom proposes, utterances are, ultimately, nothing more than “normatively constrained noise- or mark-makings” (Whiting 2006: 11), that is, non-semantically described performances that stand in normative relations to other non-semantically described performances, it does not seem that we have the resources to single out as privileged a particular interpretation or standard of correctness. Similarly, a normative pattern that instantiates how one ought, in the primitive sense proposed by Ginsborg, to go on with respect to an expression seems to be consistent with more than one semantic interpretation of that expression. It might be thought that Ginsborg could appeal to the non-semantically characterized disposition in order to fix the meanings of the relevant expression. However, we have already shown in section 4 that dispositionalist accounts face very serious obstacles (see Verheggen 2015; Chapter II of Myers and Verheggen 2016, and Miller 2019 for more discussion of the failure of dispositionalism in relation to Ginsborg’s view). So, the proponent of the less austere approach to meaning owes the austere non-reductionist an account of how the extensionality condition might be met. (See Haddock 2012 and Sultanescu 2021 for more discussion of Ginsborg’s view, and Rosen 1997, McDowell 2002, Hattiangadi 2003, and Whiting 2006 for more discussion of Brandom’s view.)

1. History
From the birth of the theory of quantum mechanics in 1925/6 to the outbreak of war in Europe, a clear orthodoxy emerged in the conceptual and ontological framework for understanding quantum theory. Now known as the Copenhagen interpretation, this framework embodied the positivistic tendencies of Heisenberg and Bohr, and was set opposed to the more realist tendencies of de Broglie, Einstein, and Schrödinger. It was not until Bell’s theorem in the 1960s, and its experimental tests in the 1970s and 1980s, that new energy was breathed into this interpretational debate. However, beginning in the mid-1940s, the first suggestions of retrocausality as part of the conceptual and ontological framework in quantum theory had already materialized.

There are two key ideas that punctuate the historical development of the notion of retrocausality in quantum mechanics. The first proposal of retroactive influence in quantum mechanics comes from a suggestion made by Wheeler and Feynman (1945, 1949). They were led to this idea while considering the potentially classical origins of some of the difficulties of quantum theory. Consider the following problem from classical electrodynamics: an accelerating electron emits electromagnetic radiation and, through this process, the acceleration of the electron is damped. Various attempts to account for this phenomenon in terms of the classical theory of electrodynamics lacked either empirical adequacy or a coherent physical interpretation. Wheeler and Feynman attempted to remedy this situation by reinterpreting Dirac’s (1938) theory of radiating electrons.

The core of Wheeler and Feynman’s proposed “absorber theory of radiation” is a suggestion that the process of electromagnetic radiation emission and absorption should be thought of as an interaction between a source and an absorber rather than as an independent elementary process. (This idea has its roots as far back as Tetrode 1922 and G. Lewis 1926.) Wheeler and Feynman imagine an accelerated point charge located within an absorbing system and consider the nature of the electromagnetic field associated with the acceleration. An electromagnetic disturbance can be imagined “initially” to travel outwards from the source to perturb each particle of the absorber. The particles of the absorber then generate together a subsequent field. According to the Wheeler-Feynman view, this new field is comprised of half the sum of the retarded (forward-in-time) and advanced (backward-in-time) solutions to Maxwell’s equations. The sum of the advanced effects of all the particles of the absorber then yields an advanced incoming field that is present at the source simultaneous with the moment of emission (although see §5 for more on how one should understand this “process”). The claim is that this advanced field exerts a finite force on the source which has exactly the required magnitude and direction to account for the observed energy transferred from source to absorber; this is Dirac’s radiative damping field. In addition, when this advanced field is combined with the equivalent half-retarded, half-advanced field of the source, the total observed disturbance is the full retarded field known empirically to be emitted by accelerated point charges.

The crucial point to note about the Wheeler-Feynman schema is that due to the advanced field of the absorber, the radiative damping field is present at the source at exactly the time of the initial acceleration. This schema of advanced and retarded waves now forms the basis for the most fully-formed retrocausal model of quantum mechanics, the transactional interpretation (see §5).

The second key idea in the historical development of retrocausality in quantum mechanics occurs around the same time as Wheeler and Feynman’s absorber theory. French physicist Costa de Beauregard, a student of de Broglie, noticed a potential objection to the reasoning found in Einstein, Podolsky, and Rosen’s famous paper (1935) on the completeness of quantum mechanics (see the entry on the Einstein-Podolsky-Rosen argument in quantum theory), now widely known as the EPR argument. Einstein et al. argue that quantum mechanics must be incomplete on the basis of the following assumption: no reasonable definition of reality could be expected to permit the reality of some system being dependent upon the process of measurement carried out on some other distant system which does not in any way disturb the first system. The key condition that Einstein et al. suggest any reasonable definition of reality should satisfy is that “there is no longer any interaction between the two parts”. (Later, Einstein 1948 accounted for this feature with an explicit assumption of “locality”, see §2.2). Costa de Beauregard, however, was alert to a particular kind of unorthodox alternative to this condition which upended its role in the EPR argument. His proposal was that two distant systems could “remain correlated by means of a successively advanced and retarded wave” (Costa de Beauregard 1953: 1634); that is, one system could influence, via an advanced wave, the state of the combined systems in their common past, which then, via a retarded wave, could influence the state of the distant system in a kind of “zigzag” through spacetime. This way, there could be a dependence between the two distant systems without any “spooky action-at-a-distance”. Thus, as Costa de Beauregard (1987b: 252) puts it,

Einstein of course is right in seeing an incompatibility between his special relativity theory and the distant quantal correlations, but only under the assumption that advanced actions are excluded.

When Costa de Beauregard in 1947 suggested this response to the EPR argument to his then supervisor de Broglie, de Broglie was “far from willing to accept” the proposal (1987b: 252) and forbade Costa de Beauregard to publish his unorthodox idea (Price & Wharton 2015). However, in 1948 Feynman had developed his eponymous diagrams in which antiparticles were to be interpreted as particles moving backward-in-time along the particle trajectories, and so by 1953 de Broglie had endorsed the publication of Costa de Beauregard’s response. On the seeming craziness of the proposal, Costa de Beauregard claims, “[t]oday, as the phenomenon of the EPR correlations is very well validated experimentally, and is in itself a ‘crazy phenomenon’, any explanation of it must be ‘crazy’” (1987b: 252; see also Costa de Beauregard 1976, 1977b, 1987a).

2. Metaphysical Preliminaries
Before addressing two of the main motivations for adopting the hypothesis of retrocausality in the foundations of quantum theory, it will be worthwhile to provide a few comments on two key notions that play a significant role in the following discussion: causality and locality. This will help to pin down what exactly is meant, and not meant, by retrocausality.

2.1 Causality
There is a tradition that stretches back at least as far as Russell (1913) that denies that there is any place for causal notions in the fundamental sciences, including physics: the notion serves no purpose, and simply does not appear, in the fundamental sciences. The argument goes that, since at least the nineteenth century, the laws that govern physical behavior in fundamental sciences such as physics are almost always differential equations. Such equations are notable for specifying, given some initial conditions, exact properties of systems for all time. And thus if everything is specified for all time, there is no place left for causality. Thus Russell advocates that “causality” should be eliminated from the philosophers lexicon, because it is certainly not a part of the scientific lexicon.

In contrast to Russell’s position, Cartwright (1979: 420) claims that we do have a need and use for a causal vocabulary in science: “causal laws cannot be done away with, for they are needed to ground the distinction between effective strategies and ineffective ones”. One of the main contemporary accounts of causation, the interventionist account of causation (Woodward 2003; see also the entry on causation and manipulability), is an embodiment of Cartwright’s dictum. In a nutshell, the interventionist account claims that A is a cause of B if and only if manipulating A is an effective means of (indirectly) manipulating B. Causality in the present entry, unless specified otherwise, should be understood along broadly interventionist lines. According to accounts of quantum theory that hypothesize retrocausality, manipulating the setting of a measurement apparatus can be an effective means of manipulating aspects of the past. A broadly interventionist view of causality indeed underlies most contemporary attempts to harness the tool kit of causal modeling (see the entry on causal models; Spirtes, Glymour, & Scheines 2000; Pearl 2009) in the foundations of quantum theory (Leifer & Spekkens 2013; Cavalcanti & Lal 2014; Costa & Shrapnel 2016; Allen et al. 2017).

Using the notion of causality along broadly interventionist lines in the foundations of quantum theory does not commit one to realism (or anti-realism) about the causal relations at issue. Woodward combines interventionism with realism about causality while acknowledging

important differences between, on the one hand, the way in which causal notions figure in common sense and the special sciences and the empirical assumptions that underlie their application and, on the other hand, the ways in which these notions figure in physics. (Woodward 2007: 67; although see Frisch 2014: chs. 4 and 5 for a response)

Another suggested strategy to take into account Russell’s worry while continuing to apply causal notions in physics in a consistent manner is to understand interventionism in “perspectival” terms (Price 2007; Price & Corry 2007; Price & Weslake 2010; Ismael 2016). Perspectivalism is usually staged, as seems natural in the setting of modern physics (although more will be said on this below), in the framework of a block universe view where the past, present, and future are equally real. In this framework, causality cannot have anything to do with changing the future or the past because both are—from an “external” perspective—completely “fixed”. But one can understand causation in the block universe from an “internal” perspective, according to which causal correlations are precisely those that are stable under interventions on those variables that we refer to as the “causes”.

The important difference between the two viewpoints—internal and external to the block—is that there is a discrepancy between the parts of the spacetime block that are epistemically accessible from each perspective. The spatiotemporally constrained perspective by which we are bound permits us only limited epistemic accessibility to other spatiotemporal regions. This is the perspective in which, according to causal perspectivalism, causal notions are perfectly serviceable. Once, on the other hand, we imagine ourselves to be omniscient beings that have epistemic access to the whole spatiotemporal block, it should not come as a surprise that our causal intuitions get confused when we attempt to consider how a spatiotemporally bound agent can deliberate about whether or not to affect a particular event that is already determined from our imagined omniscient perspective. It is because we do not know which events are determined to occur and are ignorant about many others that we can be deliberative agents at all. Again, these considerations are relevant just as much to ordinary forward-in-time causation as they are to backward-in-time causation.

Many of the retrocausal approaches to quantum theory considered in §6 are best understood with some type of perspectival interventionist account of causality in mind. A notable exception is the transactional interpretation (§5), in which causality might be best understood in terms of processes underscored by conserved quantities. The possibilist extension of the transactional interpretation, defended by Kastner (2006, 2013), moreover eschews the block universe picture.

2.2 Locality
According to Bell’s theorem (Bell 1964; Clauser et al. 1969; see also the entry on Bell’s theorem) and its descendants (e.g., Greenberger, Horne, & Zeilinger 1989; see also the entry on Bell’s theorem, §6; Goldstein et al. 2011; Brunner et al. 2014 for overviews), any theory that reproduces all the correlations of measurement outcomes predicted by quantum theory must violate a principle that Bell calls local causality (Bell 1976, 1990; see also Norsen 2011; Wiseman & Cavalcanti 2017). In a locally causal theory, probabilities of spatiotemporally localized events occurring in some region 1 are independent of what occurs in a region 2 that is spacelike separated from region 1, given a complete specification of what occurs in a spacetime region 3 in region 1’s backward light cone that completely shields off region 1 from the backward light cone of region 2. (See, for instance, Figs. 4 and 6 in Bell 1990 or Fig. 2 in the entry on Bell’s theorem.)

In a relativistic setting, then, the notion of locality involves prohibiting conditional dependences between spacelike separated events, provided that the region upon which these spacelike separated events are conditioned constitutes their common causal (Minkowski) past. This characterization of locality explicitly assumes causal asymmetry. Thus locality is the idea that there are no causal relations between spacelike separated events.

There is another sense of “local” that is worth explicitly noting for the purposes of avoiding ambiguity. This is the idea that causal influences are mediated continuously along timelike trajectories. Thus, given Costa de Beauregard’s suggestion of “zigzag” causal influences, it is perfectly possible for a retrocausal model of quantum phenomena to be nonlocal in the sense that causal relations exist between spacelike separated events, but “local” in the sense that these causal influences are constrained to timelike trajectories. For clarity, this latter notion is best understood as set opposed to action-at-a-distance, and is variously delineated as “action-by-contact” (Evans, Price, & Wharton 2013) or “continuous action” (Wharton & Argaman 2020; Adlam 2022).

3. Motivation I: Exploiting Loopholes in the “No-Go Theorems”
The first of two main motivating considerations for invoking retrocausality in the foundations of quantum mechanics derives from the exploitation of what is essentially the same loophole in a range of theorems collectively known as “no-go theorems”. According to these theorems, any theory or model that is able to account for the empirically confirmed consequences of quantum theory must be unavoidably nonlocal, contextual, and 
ψ
-ontic (i.e., ascribe reality to the quantum states 
ψ
).

One way to understand the role that retrocausality plays in circumventing the results of the no-go theorems is to consider each theorem to be underpinned by what is known as the ontological models framework (Harrigan & Spekkens 2010; Leifer 2014; Ringbauer 2017). This is a general framework that can be applied to a wide variety of “realist” models, including theories of classical physics as well as local hidden variable approaches to quantum mechanics. The framework consists of an operational description of a “process” which describes observed statistics for outcomes of measurements given both preparations and transformations, along with an ontological model (or “ontic extension”) accounting for the observed statistics. In the quantum context, when a preparation procedures corresponds to a quantum state 
ψ
, a quantum system subjected to this procedure actually ends up in an “ontic” state 
λ
, chosen from a set of states 
Λ
, which completely specifies the system’s properties. The framework leaves open (and is ultimately used to define) whether the quantum state 
ψ
 is itself an ontic or epistemic state (if 
ψ
 is ontic, 
λ
 either includes additional ontic degrees of freedom, or is in one-to-one correspondence with 
ψ
; see §3.3). Each preparation is assumed to result in some 
λ
 via a classical probability density over 
Λ
, and a set of measurement procedures that determine conditional probabilities for outcomes dependent upon 
λ
 (which thus screens off the preparation procedure 
ψ
); explicitly, 
λ
 does not causally depend on any future measurement setting 
α
. Finally, the operational statistics must reproduce the quantum statistics.

Important for our purposes here is the qualification that, in the ontological models framework, 
λ
 is assumed to be “conditionally independent” of 
α
 (“measurement independence”). This assumption effectively rules out, among other things, that the future measurement setting 
α
 causally influences the earlier state 
λ
. Thus, in so far as the no-go theorems are underpinned by the ontological models framework, the no-go theorems are not applicable to models that do allow retrocausality from 
α
 to 
λ
. And in so far as there is motivation to avoid the consequences of the no-go theorems for quantum theory, retrocausality is well placed to provide such a model (or so the argument goes). Notably, it has been argued that admitting retrocausality (i) makes it possible to account for the correlations entailed by quantum theory using action-by-contact causal influences (and so ensures Lorentz invariance); (ii) undermines as implausible the assumption of (certain types of) noncontextuality from the outset; and (iii) may enable an independently attractive 
ψ
-epistemic interpretation of the wavefunction underpinned by local hidden variables. These arguments are addressed in turn.

3.1 Nonlocality Theorems
The principle of local causality, according to Bell, is meant to spell out the idea that

[t]he direct causes (and effects) of events are near by, and even the indirect causes (and effects) are no further away than permitted by the velocity of light. (1990: 105)

Violation of this principle, according to some researchers in the foundations of quantum theory, indicates a fundamental incompatibility between quantum theory and the spirit, perhaps even the letter, of relativity theory (Maudlin 2011). That the correlations entailed by quantum theory which violate local causality actually occur in nature has been experimentally documented many times (for example, by Freedman & Clauser 1972; Aspect, Dalibard, & Roger 1982; and Aspect, Grangier, & Roger 1982; see the entry on Bell’s theorem, §4 for an overview on early experiments).

Bell’s result crucially depends not only on the assumption of local causality, but also on the assumption that whatever variables 
λ
 describes in some spacetime region, which Bell calls “local beables”, do not depend probabilistically on which measurement setting 
α
 some experimenters choose in the future of that region:

(1)
  
P
(
λ
∣
α
)
=
P
(
λ
)
.
 
This is the aforementioned assumption of measurement independence. It is also sometimes referred to as “no superdeterminism” because it is incompatible with a particularly strong form of determinism (“superdeterminism”) according to which the joint past of the measurement setting 
α
 and the measured system state 
λ
 determines them both completely and induces a correlation between them. But, as pointed out in the first instance by Costa de Beauregard (1977a) and then by Price (1994, 1996), superdeterminism is not the only way in which Eq. (
1
) can be violated: if there is retrocausality (understood along interventionist lines as outlined in §2.1), the choice of measurement setting 
α
 may causally influence the physical state 
λ
 at an earlier time and thereby also render Eq. (
1
) incorrect. In this picture, as pointed out by Price and Wharton (2021), it might be possible to interpret the local causality-violating correlations between distant events as reflecting a type of retrocausality-induced “collider bias”.

Without Eq. (
1
), in turn, Bell’s theorem can no longer be derived. Thus, admitting the possibility of retrocausality in principle reopens the possibility of giving a causal account of the nonlocal correlations entailed by quantum theory as mediated by purely action-by-contact, spatiotemporally contiguous, Lorentz invariant causal influences (of the type envisaged by Costa de Beauregard) acting between systems described by local beables. Concrete steps towards a model that might fulfill this promise will be reviewed in §6.

Contrary to this narrative, Adlam (2022) argues that the attempt to rescue continuous-action-type locality (of the sort discussed in §2.2) is not a good motivation for retrocausality. According to Adlam, to the extent that the independently most attractive picture of causality is an interventionist one in combination with a block universe view, there is no principled reason for assuming that causal influences are confined to continuous action. Adlam provides her own motivation for retrocausality, based on an argument that “accepting the existence of genuine, unmediated nonlocality in and of itself leads us to accept retrocausality” (2022: 422).

3.2 Contextuality Theorems
A wealth of theoretical results establish that models and theories which reproduce the predictions of quantum theory must be in some sense “contextual”. A model or theory is noncontextual when the properties attributed to the system (e.g., the value of some dynamical variable that the system is found to have) are independent of the manner in which those properties are measured or observed (the context), beyond the actual observation itself (for instance, the other properties that are measured in conjunction with the measurement). In classical mechanics, the properties that systems are found to have and that are attributed to them as a consequence of measurement do not in principle depend on the measurement context, so classical mechanics is noncontextual. The first contextuality theorems for quantum theory go back to Bell (1966) and Kochen and Specker (1967). They demonstrate that if one were to consider quantum measurements as deterministically uncovering the values of arbitrary pre-existing dynamical variables of quantum systems, then such a model would have to be contextual (that is, measured values would have to depend upon the context of measurement). Thus, no noncontextual deterministic local hidden variable model can reproduce the observed statistics of quantum theory.

A new way of understanding contextuality operationally was pioneered by Spekkens (2005). Employing the ontological models framework, an ontological model of an operational theory is noncontextual when operationally equivalent experimental procedures have equivalent representations in the ontological model. This understanding of noncontextuality is then a principle of parsimony akin to Leibniz’ law of Identity of Indiscernibles: no ontological difference without operational difference. Using this operational understanding, Spekkens expands the class of ontological models to which contextuality applies beyond deterministic local hidden variable models. But the story is essentially the same: hypothesizing underlying ontic properties for quantum systems that are distinct only if there are corresponding operational differences cannot account for the correlations entailed by quantum theory. Thus, no noncontextual ontological model can reproduce the observed statistics of quantum theory. (For an extended criticism of Spekkens’ operational understanding of contextuality see Hermens 2011.)

Hypothesizing retrocausal influences alleviates both of these worries. Retrocausality renders Kochen-Specker-type contextuality potentially explainable as a form of “causal contextuality” (see the entry on the Kochen-Specker theorem, §5.3). If there is a backward-directed influence of the chosen measurement setting (and context) on the pre-measurement ontic state, it is no longer to be expected that the measurement process is simply uncovering an independently existing definite value for some property of the system, rather the measurement process can play a causal role in bringing about such values (the measurement process is retrocausal rather than retrodictive). Indeed, one might argue contextuality of measured values is just what one might expect when admitting retrocausal influences. As Wharton (2014: 203) puts it, “Kochen-Specker contextuality is the failure of the Independence Assumption”, i.e., the failure of measurement independence.

With respect to Spekkens’ more general understanding of contextuality, recall that it is an explicit assumption of the ontological models framework that the ontic state is independent of the measurement procedure. Thus, hypothesizing retrocausality is an unequivocal rejection of the ontological models framework. But one might wonder whether Spekkens’ principle of parsimony might be recast to apply more generally to retrocausal models. §7.4 considers a result due to Shrapnel and Costa (2018) that indicates that retrocausal accounts must indeed accept Spekkens-type contextuality.

3.3 Psi-ontology Theorems
In some models staged in the ontological models framework, an ontic state 
λ
 is only compatible with preparation procedures associated with one specific quantum state 
ψ
. In that case, 
ψ
 can be seen as part of 
λ
 and, therefore, as an element of reality itself. Models of this type are referred to as “
ψ
-ontic”. In other models, an ontic state 
λ
 can be the result of preparation procedures associated with different quantum states 
ψ
. In these models, 
ψ
 is not an aspect of reality and is often more naturally seen as reflecting an agent’s incomplete knowledge about the underlying ontic state 
λ
. Models of this type are referred to as “
ψ
-epistemic”. Spekkens (2007) motivates the search for attractive 
ψ
-epistemic models by pointing out various parallels between quantum mechanics and a toy model in which the analogue of the quantum state is epistemic in that it reflects incomplete information about an underlying ontic state.

However, so-called “
ψ
-ontology theorems” (Pusey, Barrett, & Rudolph 2012; Hardy 2013; Colbeck & Renner 2012; see Leifer 2014 for an overview), establish that, given certain plausible assumptions, only 
ψ
-ontic models can reproduce the empirical consequences of quantum theory. The specific assumptions used to derive this conclusion differ for the various theorems. All of them, however, rely on the ontological models framework which, as noted a number of times already, explicitly incorporates an assumption of measurement independence (Eq. (
1
)). Since, as shown above, measurement independence implicitly rules out retrocausality, these theorems apply only inasmuch as retrocausality is assumed to be absent.

Moreover, the theorem due to Pusey, Barrett, and Rudolph (2012)—which according to Leifer (2014) uses the least contestable assumptions of all—relies on an additional independence assumption according to which the ontic states of two or more distinct, randomly prepared, systems are uncorrelated before undergoing joint measurement. Wharton (2014: 203) points out that in a framework that is open to retrocausality this is a problematic assumption because one would then expect “past correlations [to] arise […] for exactly the same reason that future correlations arise in entanglement experiments”. Exploring the prospects for retrocausal accounts is therefore one—perhaps the—important open route for developing an attractive 
ψ
-epistemic model that may be able to explain the quantum correlations.

3.4 Classical Ontology?
It is worth pausing at this point to consider the metaphysical motivation for taking a retrocausal approach to quantum theory, especially in light of circumventing these no-go theorems. The orthodox reading of the no-go theorems is that, whatever is said about the ultimate conceptual and ontological framework for understanding quantum theory, it cannot be completely classical: it must be nonlocal and/or contextual and/or ascribe reality to indeterminate states. In short, quantum theory cannot be about local hidden variables. Part of the appeal of hypothesizing retrocausality in the face of these no-go theorems is to regain (either partial or complete) classicality in these senses (albeit, with—perhaps nonclassical—symmetric causal influences). That is, retrocausality holds the potential to allow a metaphysical framework for quantum mechanics that contains causally action-by-contact, noncontextual (or where any contextuality is underpinned by noncontextual epistemic constraints), counterfactually definite, determinate (although possibly indeterministic), spatiotemporally located properties for physical systems—in other words, a classical ontology.

A nice to way to consider this is in terms of Quine’s (1951) distinction between the “ontology” and the “ideology” of a scientific theory, where the ideology of a theory consists of the ideas that can be expressed in that theory. Ideological economy is then a measure of the economy of primitive undefined statements employed to reproduce this ideology. The claim here would then be that the ideology of symmetric causal influences is more economical than rejecting a classical ontology. Thus in so far as quantum mechanics is telling us something profound about the fundamental nature of reality, the hypothesis of retrocausality shows that the lesson of quantum mechanics is not necessarily that the quantum ontology can no longer be classical. Some might see this as a virtue of retrocausal approaches. (Although the Shrapnel-Costa no-go theorem reviewed in §7.4 significantly jeopardizes this view.)

4. Motivation II: Time-Symmetry
4.1 Deriving Retrocausality from Time-Symmetry
The laws of nature at the most fundamental level at which they are currently known are combined in the Standard Model of elementary particle physics. These laws are CPT-invariant, i.e., they remain the same under the combined operations of charge-reversal C (replacing all particles by their anti-particles), parity P (flipping the signs of all spatial coordinates), and time-reversal T. The asymmetries in time which are pervasive in our everyday lives are a consequence not of any temporal asymmetry in these laws but, instead, of the boundary conditions of the universe, notably in its very early stages. It seems natural to assume that the time-symmetry of the laws (modulo the combined operation of C and P) extends to causal dependences at the fundamental “ontic” level that underlies the empirical success of quantum theory. If so, there may be backward-in-time no less than forward-in-time causal influences at that ontic level.

Price (2012) turns these sketchy considerations into a rigorous argument. He shows that, when combined with two assumptions concerning quantum ontology, time-symmetry implies retrocausality (understood along broadly interventionist lines). The ontological assumptions are (i) that at least some aspects of the quantum state 
ψ
 are real (notably, in Price’s example, there is a “beable” encoding photon polarization angle), and (ii) that inputs and outputs of quantum experiments are discrete emission and detection events. Moreover, it is important to Price’s argument that dynamical time-symmetry (that the dynamical laws of the theory are time-symmetric) be understood as implying that operational time-symmetry (that the set of all possible combinations of preparation and measurement procedures in a theory, with associated probabilities for outputs given inputs, is closed under interchange of preparation and measurement) translates into ontic time-symmetry (operational time-symmetry plus a suitable map between the ontic state spaces of the symmetric combinations). Given these conditions, any foundational account that reproduces the empirical verdicts of quantum theory must be retrocausal.

Leifer and Pusey (2017) (see also Leifer 2017 in Other Internet Resources) strengthen Price’s argument by showing that his assumption about the reality of (aspects of) the quantum state 
ψ
 can be relaxed. As they demonstrate, if measurement outcomes depend only on a system’s ontic state 
λ
, i.e., if that state completely mediates any correlations between preparation procedures and measurement outcomes (“
λ
-mediation”), this suffices for operational time-symmetry to entail the existence of retrocausality. Foundational accounts which like Bohmian mechanics (Bohm 1952a,b) or GRW-theory (Ghirardi, Rimini, & Weber 1986) avoid postulating retrocausality do so by violating time-symmetry in some way. The GRW-theory does so by introducing explicitly time-asymmetric dynamics. In Bohmian mechanics the dynamics is time-symmetric, but the theory is applied in a time-asymmetric manner when assessing which quantum states are actually realized. Notably, one assumes that the quantum states of a measured system and a measurement device connected to it are uncorrelated prior to measurement, whereas they are in general correlated after measurement (Leifer & Pusey 2017: §X.).

4.2 The Action Duality Principle
The more advanced relativistic quantum theories that underlie modern particle physics are typically formulated in the Lagrangian, path integral-based, formalism, where information about the symmetries and interactions of the theory are encoded in the action, S. Wharton, Miller, and Price (2011) use this formalism as a foundation to suggest that action symmetries must be reflected as ontological symmetries. In particular, Wharton et al. claim that for any two experimental arrangements related by a spacetime transformation (say, reflection in time) that leaves the action unchanged, the ontologies must also remain unchanged across the same spacetime transformation. This principle, referred to by Wharton et al. as action duality, imposes non-trivial constraints on realist accounts.

Notably, Evans, Price, & Wharton (2013) argue that there is such an action symmetry between a pair of entangled photons passing through separate polarizers and a single photon passing sequentially through two polarizers. Thus, if action duality is well-founded, the action symmetry should be reflected in identical ontologies for the action-dual experiments. Short of rejecting action duality, this implies one of two things: either the usual causal explanation for the behavior of the single photon must be reflected in a causal explanation for the typically-quantum behavior of the pair of entangled photons, and so there must be retrocausality at the level of the ontic state 
λ
, or the nonlocality ascribed to the typically-quantum behavior of the pair of entangled photons must be similarly ascribed to the behavior of the single photon, and so nonlocality is even more dramatically widespread than usually assumed, and indeed is not unique to entangled bipartite quantum systems. In so far as there is a strong case for the behavior of a single photon passing sequentially through two polarizers having a perfectly good causal explanation based on spatiotemporally localized properties, the argument of Evans et al. is that this amounts to an equally strong case for retrocausality in quantum theory.

5. The Transactional Interpretation
This entry so far has considered the two most significant motivating arguments in favor of adopting retrocausality as a hypothesis for dealing with the interpretational challenges of quantum theory. But these motivations do not by themselves amount to an interpretation or model of quantum theory. §6 consists of a survey of a range of retrocausal models, but this section first considers perhaps the most prominent retrocausal model, the transactional interpretation. Developed by Cramer in the 1980s (Cramer 1980, 1986, 1988), the transactional interpretation is heavily influenced by the framework of the Wheeler-Feynman absorber approach to electrodynamics (see §1); the Wheeler-Feynman schema can be adopted to describe the microscopic exchange of a single quantum of energy, momentum, etc., between and within quantum systems.

At the heart of the transactional interpretation is the “transaction”: real physical events are identified with so-called “handshakes” between forward-evolving quantum states 
ψ
 and backward-evolving complex-conjugates 
ψ
∗
. When a quantum emitter (such as a vibrating electron or atom in an excited state) is to emit a single quantum (a photon, in these cases), the source produces a radiative field—the “offer” wave. Analogously to the Wheeler-Feynman description, this field propagates outwards both forward and backward in time (as well as across space). When this field encounters an absorber, a new field is generated—the “confirmation” wave—that likewise propagates both forward and backward in time, and so is present as an advanced incident wave at the emitter at the instant of emission. Both the retarded field produced by the absorber and the advanced field produced by the emitter exactly cancel with the retarded field produced by the emitter and advanced field produced by the absorber for all times before the emission and after the absorption of the photon; only between the emitter and the absorber is there a radiative field. Thus the transaction is completed with this “handshake”: a cycle of offer and confirmation waves

repeats until the response of the emitter and absorber is sufficient to satisfy all of the quantum boundary conditions…at which point the transaction is completed. (Cramer 1986: 662)

Many confirmation waves from potential absorbers may converge on the emitter at the time of emission but the quantum boundary conditions can usually only permit a single transaction to form. Any observer who witnesses this process would perceive only the completed transaction, which would be interpreted as the passage of a particle (e.g., a photon) between emitter and absorber.

The transactional interpretation takes the wave function to be a real physical wave with spatial extent. The wave function of the quantum mechanical formalism is identical with the initial offer wave of the transaction mechanism and the collapsed wave function is identical with the completed transaction. Quantum particles are thus not to be thought of as represented by the wave function but rather by the completed transaction, of which the wave function is only the initial phase. As Cramer explains:

The transaction may involve a single emitter and absorber or multiple emitters and absorbers, but it is only complete when appropriate boundary conditions are satisfied at all loci of emission and absorption. Particles transferred have no separate identity independent from the satisfaction of these boundary conditions. (1986: 666)

The amplitude of the confirmation wave which is produced by the absorber is proportional to the local amplitude of the incident wave that stimulated it and this, in turn, is dependent on the attenuation it received as it propagated from the source. Thus, the total amplitude of the confirmation wave is just the absolute square of the initial offer wave (evaluated at the absorber), which yields the Born rule. Since the Born rule arises as a product of the transaction mechanism, there is no special significance attached to the role of the observer in the act of measurement. The “collapse of the wave function” is interpreted as the completion of the transaction.

The transactional interpretation explicitly interprets the quantum state 
ψ
 as real, and so does not constitute an attempt to exploit the retrocausality loopholes to the theorems that rule out 
ψ
-epistemic accounts. Additionally, the transactional interpretation subverts the dilemma at the core of the EPR argument (Einstein, et al. 1935) by permitting incompatible observables to take on definite values simultaneously: the wavefunction, according to the transactional interpretation,

brings to each potential absorber the full range of possible outcomes, and all have “simultaneous reality” in the EPR sense. The absorber interacts so as to cause one of these outcomes to emerge in the transaction, so that the collapsed [wavefunction] manifests only one of these outcomes. (Cramer 1986: 668).

Most importantly, however, the transactional interpretation employs both retarded and advanced waves, and in doing so admits the possibility of providing a “zigzag” explanation of the nonlocality associated with entangled quantum systems.

Before turning to one of the more significant objections to the transactional interpretation, and to retrocausality in general, it is instructive to tease apart here two complementary descriptions of this transaction process. On the one hand there is a description of the real physical process, consisting of the passage of a particle between emitter and absorber, that a temporally bound experimenter would observe; and on the other hand there is a description of a dynamical process of offer and confirmation waves that is instrumental in establishing the transaction. This latter process simply cannot occur in an ordinary time sequence, not least because any temporally bound observer by construction cannot detect any offer or confirmation waves. Cramer suggests that the “dynamical process” be understood as occurring in a “pseudotime” sequence:

The account of an emitter-absorber transaction presented here employs the semantic device of describing a process extending across a lightlike or a timelike interval of space-time as if it occurred in a time sequence external to the process. The reader is reminded that this is only a pedagogical convention for the purposes of description. The process is atemporal and the only observables come from the superposition of all “steps” to form the final transaction. (Cramer 1986: 661, fn.14)

These steps are of course the cyclically repeated exchange of offer and confirmation waves which continue “until the net exchange of energy and other conserved quantities satisfies the quantum boundary conditions of the system” (1986: 662). There is a strong sense here that any process described as occurring in pseudotime is not a process at all but, as Cramer reminds, merely a “pedagogical convention for the purposes of description”. Whether it is best to understand causality according to the transactional interpretation in terms of processes underscored by conserved quantities is closely tied to how one should best understand this pseudotemporal process.

Maudlin (2011) outlines a selection of problems that arise in Cramer’s theory as a result of the pseudotemporal account of the transaction mechanism: processes important to the completion of a transaction take place in pseudotime only (rather than in real time) and thus cannot be said to have taken place at all. Since a temporally bound observer can only ever perceive a completed transaction, i.e., a collapsed wavefunction, the uncollapsed wavefunction never actually exists. Since the initial offer wave is identical to the wavefunction of the quantum formalism, any ensuing exchange of advanced and retarded waves required to provide the quantum mechanical probabilities, according to Maudlin, also do not exist. Moreover, Cramer’s exposition of the transaction mechanism seems to suggest that the stimulation of sequential offer and confirmation waves occurs deterministically, leaving a gaping hole in any explanation the transactional interpretation might provide of the stochastic nature of quantum mechanics. Although these problems are significant, Maudlin admits that they may indeed be peculiar to Cramer’s theory. Maudlin also sets out a more general objection to retrocausal models of quantum mechanics which he claims to pose a problem for “any theory in which both backwards and forwards influences conspire to shape events” (2011: 184).

Maudlin’s main objection to the transactional interpretation hinges upon the fact that the transaction process depends crucially on the fixity of the absorbers “just sitting out there in the future, waiting to absorb” (2011: 182); one cannot presume that present events are unable to influence the future disposition of the absorbers. Maudlin offers a thought experiment to illustrate this objection. A radioactive source is constrained to emit a 
β
-particle either to the left or to the right. To the right sits absorber A at a distance of 1 unit. Absorber B is also located to the right but at a distance of 2 units and is built on pivots so that it can be swung around to the left on command. A 
β
-particle emitted at time 
t
0
 to the right will be absorbed by absorber A at time 
t
1
. If after time 
t
1
 the 
β
-particle is not detected at absorber A, absorber B is quickly swung around to the left to detect the 
β
-particle after time 
2
t
1
.

According to the transactional interpretation, since there are two possible outcomes (detection at absorber A or detection at absorber B), there will be two confirmation waves sent back from the future, one for each absorber. Furthermore, since it is equally probable that the 
β
-particle be detected at either absorber, the amplitudes of these confirmation waves should be equal. However, a confirmation wave from absorber B can only be sent back to the emitter if absorber B is located on the left. For this to be the case, absorber A must not have detected the 
β
-particle and thus the outcome of the experiment must already have been decided. The incidence of a confirmation wave from absorber B at the emitter ensures that the 
β
-particle is to be sent to the left, even though the amplitude of this wave implies a probability of a half of this being the case. As Maudlin (2011: 184) states so succinctly, “Cramer’s theory collapses”.

The key challenge from Maudlin is that any retrocausal mechanism must ensure that the future behavior of the system transpires consistently with the spatiotemporal structure dictated by any potential future causes: “stochastic outcomes at a particular point in time may influence the future, but that future itself is supposed to play a role in producing the outcomes” (2011: 181). In the transactional interpretation the existence of the confirmation wave itself presupposes some determined future state of the system with retrocausal influence. However, with standard (i.e., forward-in-time) stochastic causal influences affecting the future from the present, a determined future may not necessarily be guaranteed in every such case, as shown by Maudlin’s experiment.

Maudlin’s challenge to the transactional interpretation has been met with a range of responses (see P. Lewis 2013 and the entry on action at a distance in quantum mechanics for more discussion of possible responses). The responses generally fall into two types (P. Lewis 2013). The first type of response attempts to accommodate Maudlin’s example within the transactional interpretation. Berkovitz (2002) defends the transactional interpretation by showing that causal loops of the type found in Maudlin’s experiment need not obey the assumptions about probabilities that are common in linear causal situations. Marchildon (2006) proposes considering the absorption properties of the long distance boundary conditions: if the universe is a perfect absorber of all radiation then a confirmation wave from the left will always be received by the radioactive source at the time of emission and it will encode the correct probabilistic information. Kastner (2006) proposes differentiating between competing initial states of the radioactive source, corresponding to the two emission possibilities, that together characterize an unstable bifurcation point between distinct worlds, where the seemingly problematic probabilities reflect a probabilistic structure across both possible worlds.

The second type of response is to modify the transactional interpretation. For instance, Cramer (2016) introduces the idea of a hierarchy of advanced-wave echoes dependent upon the magnitude of the spatiotemporal interval from which they originate. Kastner (2013) surmises that the source of the problem that Maudlin has exposed, however, is the idea that quantum processes take place in the “block world”, and rejects this conception of processes in her own development of the transactional interpretation. According to her “possibilist” transactional interpretation, all the potential transactions exist in a real space of possibilities, which amounts at once to a kind of modal realism and an indeterminacy regarding future states of the system (hence Kastner’s rejection of the block universe view). The possibilist transactional interpretation arguably handles multi-particle scenarios more naturally, and presents the most modern sustained development of the transactional interpretation (although see P. Lewis 2013 for criticisms of the possibilist transactional interpretation specific to Maudlin’s challenge).

6. Developments Towards a Retrocausal Model
The transactional interpretation might be seen as the most prominent—and historically significant—retrocausal model on the market, but it is not the only one. While retrocausality in quantum mechanics has been the subject of considerable analysis and critique over the years (Rietdijk 1978; Sutherland 1983, 1985, 1989; Price 1984, 2001; Hokkyo 1988, 2008; Miller 1996, 1997; Atkinson 2000; Argaman 2010; Evans 2015), the focus of this section is a review of some of the more concrete proposals for retrocausal models.

6.1 The Two-State Vector Formalism
What is now known as the two-state vector formalism was first proposed by Watanabe (1955), and then rediscovered by Aharonov, Bergmann, and Lebowitz (1964). The proposal is that the usual forward evolving quantum state contains insufficient information to completely specify a quantum system; rather the forward evolving state must be supplemented by a backward evolving state to provide a complete specification. Thus, according to the two-state vector formalism, the complete quantum description contains a state vector that evolves forward in time from the initial boundary condition towards the future, and a state vector that evolves backward in time from the future boundary condition towards the past. It is only a combination of complete measurements at both initial and final boundaries that can provide a complete specification of a quantum system. The two-state vector formalism is empirically equivalent to standard quantum mechanics (Aharonov & Vaidman 1991, 2008).

The emphasis of the two-state vector formalism is on the operational elements of the theory, and there are very few ontological prescriptions, including how best to understand causality. It is in principle compatible with a variety of supplemented retrocausal ontologies, e.g., the causally symmetric Bohm model (§6.3).

6.2 Toy Models
Toy models have been employed to illustrate how retrocausality could be possibly realized. Price (2008) suggests a simple toy model featuring linked nodes that can assume different values, which he dubs the “Helsinki model”. If one interprets the nodes as partially ordered in time and the values of the exogenous boundary nodes as controllable, the dynamics specified by Price entails causal bi-directionality, i.e., both ordinary forward causality and retrocausality, understood in an interventionist sense. Although the model does indeed display particular behavior that can be naturally interpreted as retrocausal, a full-blown analogy with standard quantum mechanics is limited.

The Helsinki model consists of three primitive endogenous nodes, each node comprising a meeting point of three edges, with two “internal” edges linking the three nodes and five “external” edges. Each edge has one of three “flavors”, A, B, or C. The system is temporally oriented with three exogenous nodes, each joined to a single edge, representing system “inputs” (preparations/interventions), and two system “outputs” (measurement outcomes/observations) joined to the remaining two edges. The two internal edges represent hidden flavors that cannot be directly controlled or observed. There are two basic rules that govern the dynamics of this toy system: (i) each node must be strictly inhomogeneous—i.e., comprising three edges of different flavors—or strictly homogeneous—i.e., three edges of the same flavor, and (ii) successive homogeneous nodes are prohibited.

The retrocausal behavior of the model arises as a result of the heavy constraints that the two basic rules place on the possible flavors of the hidden edges, which establishes correlations between the input states and the hidden states. Thus interventions on the left or right exogenous variables influence the complete set of possible hidden states of the system. Assuming that the hidden states are in the past of these variable choices, the hidden state depends “retrocausally” on the left and right input settings. Moreover, under specific node variables, some interventions on the left or right exogenous variables amount to interventions on the distant output variable, displaying a kind of nonlocality (but violating no-signaling).

More ambitiously, Corry (2015) proposes three toy models, also using nodes and links, which exhibit Bell-type correlations and account for them in a purely local manner in that the constraints governing nodes make reference only to information available at the respective nodes. The models do not in general specify values for unobserved nodes, however. As a way out, Corry suggests, one may either postulate such values at the price of accepting “retrofinkish dispositions” (dispositions which, if they were triggered, would not have been there in the first place) or simply deny the existence of such values outright.

6.3 The Causally Symmetric Bohm Model
A model that hypothesizes retrocausality and reproduces the consequences of standard quantum theory without violating Lorentz invariance is Sutherland’s (2008, 2015, 2017) causally symmetric version of Bohmian mechanics. This model adds to the standard quantum state 
ψ
i
 of ordinary Bohmian mechanics, which is fixed by an initial boundary condition, an additional quantum state 
ψ
f
, which is fixed by some final boundary condition. An analogue to the “guiding equation” for particle motion in ordinary Bohmian mechanics is derived by Sutherland that is symmetric with respect to these states. The zero-component of the probability current, which is directly related to the probability density, is computed as

(2)
  
ρ
(
x
,
t
)
=
R
e
(
ψ
ψ
∗
f
ψ
i
a
)
 
where

(3)
  
a
=
∫
ψ
∗
f
(
x
,
t
)
ψ
i
(
x
,
t
)
d
3
x
.
 
Finally, for consistency, the model also requires that the conditional probability of the final state being 
ψ
f
, given the initial state 
ψ
i
, is

(4)
  
ρ
(
ψ
f
∣
ψ
i
)
=
|
a
|
2
.
 
Berkovitz (2008) criticizes the use of the additional assumption Eq. (
4
) and the need for it in Sutherland’s model, arguing that it leads to an undesirable form of causal loops and has an ad hoc character because there is no independent reason to think that 
ψ
i
 and 
ψ
f
 should be correlated in this way.

Sutherland’s model is explicitly retrocausal in that particle dynamics are influenced by 
ψ
f
, which in turn depends on the future measurement setting. It also contains action-by-contact causal influences in that Bell-type correlations are accounted for in the “zigzag” manner envisaged by Costa de Beauregard, as outlined in §1.

6.4 The Relational Blockworld Interpretation
Silberstein, Stuckey, and McDevitt (2018), based on earlier work together with Cifone (Stuckey, Silberstein, & Cifone 2008; Silberstein, Cifone, & Stuckey. 2008), suggest a realist interpretation that they call the “relational blockworld view”. The ontology of this interpretation consists of so-called “spacetimesource elements”, which are characterized as “amalgams of space, time, and sources” (Silberstein, Stuckey, & McDevitt 2018: 153).

Technically, the relational blockworld approach is set up as a modification of lattice gauge theory, with the Feynman path integral functioning as an “adynamical global constraint”. While adynamical and acausal rather than retrocausal in spirit, on the authors’ view this interpretation exploits the retrocausality loopholes of the no-go theorems. They conceive of the relational blockworld view as 
ψ
-epistemic. In more recent work (2018: Ch. 6), Silberstein, Stuckey and McDevitt have developed this approach into an ambitious overarching programme in fundamental physics, aiming at field-theoretic unification as well as a novel account of quantum gravity.

6.5 The Two-Time Boundary Value Model
Schulman (1997, 2012) proposes a solution to the quantum measurement problem based on the possibility of future conditioning, which originates from his analysis of the thermodynamic arrow of time. Beginning with Loschmidt’s challenge to Boltzmann—that it should not be possible to derive irreversible dynamical behavior from time-symmetric dynamics (see the entry on thermodynamic asymmetry in time)—Schulman notes that successful “retrodiction” of past macroscopic states of some thermodynamic system is indeed asymmetric to successful “prediction” of future macroscopic states. For successful retrodiction, rather than evolving each of the microscopic states of some macroscopic state according to the dynamical laws (which is identical to the process of prediction, and is the basis of Loschmidt’s challenge), one instead hypothesizes a prior macroscopic state to which the prediction process can be applied such that the current macroscopic state of the system obtains with high likelihood given the dynamical evolution of the prior microscopic states. With respect to the set of possible microscopic states for the current macroscopic state, since the evolution of the vast majority (on Liouville measure) of these states according to the dynamical laws result in trajectories that conflict with the retrodiction hypothesis, these states are effectively rejected in the process of retrodiction in favor of those special few microscopic states that correspond to the dynamical evolution of acceptable hypothetical initial conditions.

Schulman’s proposal in response to this asymmetry is that, just as the set of possible final microscopic states must be restricted for successful retrodiction, so should the permissible initial microscopic states be restricted for the purposes of prediction. Thus, since final microscopic states are subject to conditioning from the past state of the system, the initial microscopic states will be subject to conditioning from the future state of the system—a conditioning that is hidden in thermodynamic processes where the microscopic states of the system are indistinguishable macroscopically. This future conditioning is a central feature of Schulman’s two-time boundary condition proposal and the hidden nature of this conditioning Schulman calls “cryptic constraints”.

Regarding quantum theory, Schulman claims that quantum superpositions of macroscopically distinct states generated by quantum evolution, which are at the heart of many of the nonclassical elements of quantum theory, are what he calls “grotesque” states, and proposes that these states are avoided in quantum systems due to future conditioning and cryptic constraints. Just like there are special microscopic states of thermodynamical systems that evolve “against” the second law of thermodynamics (which are identified in the process of retrodiction), so too must there be “special” microscopic states of a quantum system which do not lead to grotesque states when evolved according to the quantum dynamical laws, rather these states will lead to one particular definite state of the superposition. Schulman’s solution to the quantum measurement problem is that, in every performed experiment, the initial conditions of the quantum system are among these special states which, through pure unitary quantum evolution, yield a single outcome to the experiment (Schulman 1997: 214). Grotesque states, the problematic states of the quantum measurement problem, are thus avoided.

Schulman’s proposal implicitly assumes that, in the preparation of an experiment, it is only the macroscopic state of the system which is under the control of the experimenter; it is impossible to control the precise microscopic state. It is this initial microscopic state that Schulman suggests is always a special state. Schulman envisages the special-state constraint as correlated with future conditions and, since these constraints are not apparent to the experimenter until the future conditions are “measured” at the end of the experiment, these constraints are cryptic. As a result of the future conditioning of initial states, Schulman’s proposal is a kind of retrocausal mechanism, understood in an interventionist sense. (For an extension of Schulman’s model into the Lagrangian schema (§6.6) see Almada et al. 2016 and Wharton 2014, 2018.)

6.6 “All-at-once” Lagrangian Models
Wharton (2010a; see also Wharton 2007, 2010b, 2013, 2016, 2018; Wharton, Miller, & Price 2011; Evans, Price, & Wharton 2013) proposes a “novel interpretation of the Klein-Gordon equation” for a neutral, spinless relativistic particle. The account is a retrocausal picture based on Hamilton’s principle and the symmetric constraint of both initial and final boundary conditions to construct equations of motion from a Lagrangian, and is a natural setting for a perspectival interventionist account of causality. Wharton treats external measurements as physical constraints imposed on a system in the same way that boundary constraints are imposed on the action integral of Hamilton’s principle; the final measurement does not simply reveal preexisting values of the parameters, but constrains those values (just as the initial boundary condition would). Wharton’s model has been described as an “all-at-once” approach, since the dynamics of physical systems between an initial and final boundary emerges en bloc as the solution to a two-time boundary value problem.

On this interpretation, one considers reality exclusively between two temporal boundaries as being described by a classical field 
ϕ
 that is a solution to the Klein-Gordon equation: specification of field values at both an initial and final boundary (as opposed to field values and their rate of change at only the initial boundary) constrains the field solutions between the boundaries. Wharton argues that constraining such fields at both an initial and a final boundary (or a closed hypersurface in spacetime) generates two strikingly quantum features: quantization of certain field properties and contextuality of the unknown parameters characterizing the field between the boundaries. (That there are unknown parameters before the imposition of the final condition is ensured due to the underdetermination of the classical field by specifying only the field values, and not their rate of change, in the initial data.)

From within Wharton’s picture, an invariant joint probability distribution associated with each possible pair of initial and final conditions can be constructed, and the usual conditional probabilities can be formed by conditioning on any chosen portion of the boundary (Wharton 2010a,b). Probability is then a manifestation of our ignorance: if one knew only the initial boundary, one would only be able to describe the subsequent field probabilistically (due to the future constraint); given the final boundary as well, one would then be able to retrodict the field values between the two boundaries. (See Evans, Gryb, and Thébault 2016 for a proposed extension of this schema to the cosmological context.)

In more recent work (Wharton 2016), Wharton explores the prospects for a realist retrocausal interpretation of quantum theory based on the Feynman path integral formalism (Feynman 1942). In that formalism as applied to a single particle undergoing position measurements at spacetime points 
(
x
0
,
t
0
)
 and 
(
x
1
,
t
1
)
, the joint probability distribution for all pairs of points and given times 
t
0
 and 
t
1
 is given by

(5)
  
P
(
x
0
,
x
1
)
=
∣
∣
∣
∣
∑
x
0
↦
x
1
 
exp
(
i
S
/
ℏ
)
∣
∣
∣
∣
2
.
 
The sum in this formula is to be understood as the infinitesimal limit of a discretized set of spacetime trajectories connecting 
(
x
0
,
t
0
)
 and 
(
x
1
,
t
1
)
. S is the classical action of the particle along the respective trajectory.

A straightforward but naive interpretation of this equation according to which the probability reflects ignorance concerning the path taken does not work because the right hand side of Eq. (
5
) is not a sum of positive numbers (interpretable as probabilities of trajectories) but rather a positive number obtained by taking the modulus squared of a sum of complex numbers. Wharton explores the prospects for giving an ignorance interpretation of the path integral along less straightforward lines, noting that Eq. (
5
) can be brought into the form

(6)
  
P
(
x
0
,
x
1
)
=
∑
c
i
 
∣
∣
∣
∣
∑
A
∈
c
i
 
exp
(
i
S
A
/
ℏ
)
∣
∣
∣
∣
2
,
 
where the 
|
c
i
|
 are distinct groups of trajectories A. The form Eq. (
6
), according to Wharton, invites an interpretation of the probability in terms of ignorance concerning the actual group of trajectories 
c
i
, and he tentatively proposes a field interpretation of the 
c
i
. The interpretation is retrocausal because the probabilities over groups of trajectories are influenced by the future measurement time and setting. Open questions for this approach concern the grouping of trajectories, which is so far inherently ambiguous, the details of the suggested field interpretation, as well as generalizations to many-particle and other more general settings.

6.7 The Q-based interpretation
The Husimi Q-function (Husimi 1940) is a non-negative distribution function on phase space with a wide applicability, e.g. in quantum optics. It is obtained from the better known Wigner function (Wigner 1932) by smoothening with a Gaussian filter. The Q-based interpretation (Drumond and Reid 2020; Friederich 2021) assumes that any quantum system has a precise phase space location, and that phase space locations are distributed according to the Q-function. As a consequence, all dynamical variables of all quantum systems have definite values in this interpretation, and the measurement problem is avoided.

Drummond and Reid (2020) argue that this interpretation avoids the no-go theorems discussed in §3 via the retrocausality loophole. In support of this claim, they point to a result by Drummond (2021), according to which, for a wide class of quantum field theories, the Q-function evolves via diffusion backward in time for half of all degrees of freedom (and forward for the other half). Friederich (2021) suggests that failure of temporal locality, independently motivated by Adlam (2018, 2022), could also make those theorems inapplicable to the Q-based interpretation.

It is not immediately obvious that the Q-based interpretation is empirically adequate since it does not exactly reproduce the quantum probabilities derived from the Born rule. However, as argued by Drummond and Reid (2020), for various measurement setups and at the level of macroscopic measurement devices, the discrepancy with standard quantum mechanics based on the Born rule may not be detectable. Friederich (2021) provides a general argument that the Q-based interpretation is practically indistinguishable from standard quantum mechanics at the level of measurement devices, parallelling the standard argument for the empirical adequacy of Bohmian mechanics, as sketched in the entry on Bohmian mechanics, §10. Interestingly, a version of Bohmian mechanics that also treats the Husimi function as the actual phase space probability distribution was earlier suggested by de Polavieja (1996).

7. Objections Against Retrocausality in Quantum Mechanics
This final section reviews some of the most common, and then two of the most significant, objections against the proposal of retrocausality in quantum mechanics.

7.1 General Arguments Against Retrocausality
There is a tradition in philosophy for regarding the very idea of retrocausality as incoherent. The most prominent worry (Flew 1954, Black 1956), is the so-called “bilking argument” (see the entry on time travel). Imagine a pair of events, a cause, C, and an effect, E, which we believe to be retrocausally connected (E occurs earlier in time than C). It seems possible to devise an experiment which could confirm whether our belief in the retrocausal connection is correct or not. Namely, once we had observed that E had occurred, we could then set about ensuring that C does not occur, thereby breaking any retrocausal connection that could have existed between them. If we were successful in doing this, then the effect would have been “bilked” of its cause.

The bilking argument drives one towards the claim that any belief an agent might hold in the positive retrocausal correlation between event C and event E is simply false. However, Dummett (1964) disputes that giving up this belief is the only solution to the bilking argument. Rather, according to Dummett, what the bilking argument actually shows is that a set of three conditions concerning the two events, and the agent’s relationship to them, is incoherent:

There exists a positive correlation between an event C and an event E.
Event C is within the power of an agent to perform.
The agent has epistemic access to the occurrence of event E independently of any intention to bring it about.
It is interesting to note that these conditions do not specify in which order events C and E occur. On simple reflection, there is a perfectly natural reason why it is not possible to bilk future effects of their causes, since condition (iii) fails to hold for future events: we simply have no access to which future events occur independently of the role we play as causal agents to bring the events about. When we lack that epistemic access to past events, the same route out of the bilking argument becomes available.

Dummett’s defense against the bilking argument is especially relevant to quantum mechanics. In fact, once a suitable specification is made of how condition (iii) can be violated, we find that there exists a strong parallel between the conditions which need to hold to justify a belief in bringing about the past and the structure of quantum mechanics. Price (1996: 174) points out that bilking is impossible in the following circumstances: rather than suppose that a violation of condition (iii) entails that the relevant agent has no epistemic access to the relevant past events independently of any intention to bring them about, suppose that the means by which knowledge of these past events is gathered breaks the claimed correlation between the agent’s action and those past events. Such a condition can be stated as follows:

The agent can gain epistemic access to the occurrence of event E independently of any intention to bring it about and without altering event E from what it would have been had no epistemic access been gained.
The significance of this weakened violation of condition (iii) is that it is just the sort of condition one would expect to hold if the system in question were a quantum system. The very nature of quantum mechanics ensures that any claimed positive correlation between the future measurement settings and the hidden variables characterizing a quantum system cannot possibly be bilked of their causes because condition (iv) is perennially violated. Moreover, so long as we subscribe to the epistemic interpretation of the wavefunction, we lack epistemic access to the “hidden” variables of the system and we lack this access in principle as a result of the structure of quantum theory.

Another prominent challenge against the very idea of retrocausality is that it inevitably would give rise to vicious causal loops (Mellor 1998). (See Faye 1994 for a response and the entry on backward causation for a more detailed review of the objections raised against the idea of retrocausality.)

7.2 Retrocausality Just Is Superdeterminism
Recall (§3.1) that retrocausality can be motivated as an explicit violation of the assumption of measurement independence (Eq. (
1
)) as a means of circumventing Bell’s theorem. But there is another possible mechanism that might underpin violations of measurement independence, namely, superdeterminism. This is the idea that, in the terminology of §3, the joint past of (i) the measurement setting 
α
 and (ii) the hidden state of the measured system 
λ
 determines both of them completely and induces the relevant quantum correlations between them (see the entry on Bell’s Theorem, §8.1.1, and references therein). Hossenfelder (2020) argues against referring to violations of measurement independence as ‘retrocausality’, preferring to consider such violations as exclusively instances of ‘superdeterminism’, since “the idea of a cause propagating back in time is meaningless” (2020:10; see also Hossenfelder and Palmer (2020)). The essential point of contention here, and Hossenfelder points this out explicitly, is that each of retrocausality and superdeterminism invokes a different understanding of the nature of causality.

The characterisation of causality that Hossenfelder (2020: 10) takes to undermine the proposal of retrocausality is that A is a cause of B if and only if A and B are correlated and B is in the forward lightcone of A: “If you think you have a situation where B ”retrocauses“ A, then this merely means A causes B”. In this way, such correlations between events should never be understood as retrocausal, and should always be understood as superdeterministic. This characterization of causality is reminiscent of Hume’s conventionalism about cause and effect, according to which it is simply a matter of terminology that causes must precede their effects (see the entry on Backward Causation, §2.3). As noted in the metaphysical preliminaries set out in §2.1, the conception of causality that most naturally coheres with the proposal of retrocausality is an interventionist one. Hossenfelder acknowledges this, and argues that the reason the interventionist account of causation is inappropriate as a proposal in the quantum context “is that ”agents“ and their ”interventions“ are macroscopic terms that do not appear in quantum mechanics”.

What Hossenfelder’s critique emphasizes is that retrocausality requires a certain package of metaphysical views to be a viable proposal. Hossenfelder’s analysis relies on a conception of causality that is at odds with the interventionist account, especially as understood along perspectival lines, as outlined in §2.1. As a result, a defence of retrocausality against Hossenfelder’s objection would need to defend the fruitfulness of this account of causality.

7.3 Retrocausality Requires Fine Tuning
Causal modeling (Spirtes, Glymour, & Scheines 2000; Pearl 2009) is a practice that has arisen from the field of machine learning that consists in the development of algorithms that can automate the discovery of causes from correlations in large data sets. The causal discovery algorithms permit an inference from given statistical dependences and independences between distinct measurable elements of some system to a causal model for that system. As part of the algorithms, a series of constraints must be placed on the resulting models that capture general features that we take to be characteristic of causality. Two of the more significant assumptions are (i) the causal Markov condition, which ensures that every statistical dependence in the data results in a causal dependence in the model—essentially a formalization of Reichenbach’s common cause principle—and (ii) faithfulness, which ensures that every statistical independence implies a causal independence, or no causal independence is the result of a fine-tuning of the model.

It has long been recognized (Butterfield 1992; Hausman 1999; Hausman & Woodward 1999) that quantum correlations force one to give up at least one of the assumptions usually made in the causal modeling framework. Wood and Spekkens (2015) argue that any causal model purporting to causally explain the observed quantum correlations must be fine-tuned (i.e., must violate the faithfulness assumption). More precisely, according to them, since the observed statistical independences in an entangled bipartite quantum system imply no signaling between the parties, when it is then assumed that every statistical independence implies a causal independence (which is what faithfulness dictates), it must be inferred that there can be no (direct or mediated) causal link between the parties. Since there is an observed statistical dependence between the outcomes of measurements on the bipartite system, we can no longer account for this dependence with a causal link unless this link is fine tuned to ensure that the no-signaling independences still hold. There is thus a fundamental tension between the observed quantum correlations and the no-signaling requirement, the faithfulness assumption and the possibility of a causal explanation.

Formally, Wood and Spekkens argue that the following three assumptions form an inconsistent set: (i) the predictions of quantum theory concerning the observed statistical dependences and independences are correct; (ii) the observed statistical dependences and independences can be given a causal explanation; (iii) the faithfulness assumption holds. Wood and Spekkens conclude that, since the faithfulness assumption is an indispensable element of causal discovery, the second assumption must yield. The contrapositive of this is that any purported causal explanation of the observed correlations in an entangled bipartite quantum system falls afoul of the tension between the no-signaling constraint and no fine tuning and, thus, must violate the assumption of faithfulness. Such causal explanations, so the argument goes, including retrocausal explanations, should therefore be ruled out as viable explanations.

As a brief aside, this fine-tuning worry for retrocausality in the quantum context arises in a more straightforward way. There is no good evidence to suggest that signaling towards the past is possible; that is, there is no retrocausality at the operational level. (Pegg 2006, 2008 argues that this can be explained formally as a result of the completeness condition on the measurement operators, introducing an asymmetry in normalization conditions for preparation and measurement.) Yet, despite there being no signaling towards the past, retrocausal accounts assume causal influences towards past. That these causal influences do not show up as statistical dependences exploitable for signaling purposes raises exactly the same fine-tuning worry as Wood and Spekkens raise.

An obvious response to the challenge set by Wood and Spekkens is to simply reject the assumption of faithfulness. But this should not be taken lightly; the intuition behind the faithfulness assumption is basic and compelling. When no statistical correlation exists between the occurrences of a pair of events, there is no reason for supposing there to be a causal connection between them. Conversely, if we were to allow the possibility of a causal connection between statistically uncorrelated events, we would have a particularly hard task determining which of these uncorrelated sets could be harboring a conspiratorial causal connection that hides the correlation. The faithfulness assumption is thus a principle of parsimony—the simplest explanation for a pair of statistically uncorrelated events is that they are causally independent—much the same way that Spekkens’ (2005) definition of contextuality is, too (see §3.2); indeed, Cavalcanti (2018) argues that contextuality can be construed as a form of fine-tuning.

There are, however, well-known examples of systems that potentially show a misapplication of the faithfulness assumption. One such example, originating in Hesslow (1976), involves a contraceptive pill that can cause thrombosis while simultaneously lowering the chance of pregnancy, which can also cause thrombosis. As Cartwright (2001: 246) points out, given the right weight for these process, it is conceivable that the net effect of the pills on the frequency of thrombosis be zero. This is a case of “cancelling paths”, where the effect of two or more causal routes between a pair of variables cancels to achieve statistical independence. In a case such as this, since we can have independent knowledge of the separate causal mechanisms involved here, there are grounds for arguing that there really is a causal connection between the variables despite their statistical independence. Thus, it is certainly possible to imagine a scenario in which the faithfulness assumption could lead us astray. However, in defense of the general principle, an example such as this clearly contains what Wood and Spekkens refer to as fine tuning; the specific weights for these processes would need to match precisely to erase the statistical dependence, and such a balance would generally be thought as unstable (any change in background conditions, etc. would reveal the causal connection in the form of a statistical dependence).

Näger (2016) raises the possibility that unfaithfulness can occur without conspiratorial fine tuning if the unfaithfulness arises in a stable way. In the quantum context, Näger suggests that the fine-tuning mechanism is what he calls “internal cancelling paths”. This mechanism is analogous to the usual cancelling paths scenario, but the path-cancelling mechanism does not manifest at the level of variables, but at the level of values. On this view, such fine tuning would occur as a result of the particular causal and/or nomological process that governs the system, and it is in this sense that the cancelling paths mechanism is internal, and it is the fact that the mechanism is internal that renders the associated fine tuning stable to external disturbances. Thus

if the laws of nature are such that disturbances always alter the different paths in a balanced way, then it is physically impossible to unbalance the paths. (Näger 2016: 26)

The possibility raised by Näger would circumvent the problem that violations of faithfulness ultimately undermine our ability to make suitable inferences of causal independence based on statistical independence by allowing only a specific kind of unfaithfulness—a principled or law-based unfaithfulness that is “internal” and is thus stable to background conditions—which is much less conspiratorial, as the fine-tuning is a function of the specific process involved. Evans (2018) argues that a basic retrocausal model of the sort envisaged by Costa de Beauregard (see §1) employs just such an internal cancelling paths explanation to account for the unfaithful (no signaling) causal channels. See also Almada et al. (2016) for an argument that fine tuning in the quantum context is robust and arises as a result of symmetry considerations. Furthermore, Evans (2021) argues that, to the letter of Wood and Spekkens’ analysis, cases of fine tuning may be more ubiquitous than we suspect, and so we should not be so worried about such quantum cases.

7.4 Contextuality for Exotic Causal Structures
Recall (§3.2) that Spekkens’ (2005) claim that no noncontextual ontological model can reproduce the observed statistics of quantum theory based on his principle of parsimony (that there can be no ontological difference without operational difference) was sidestepped by retrocausal approaches due to the explicit assumption of the ontological models framework that the ontic state is independent of the measurement procedure (i.e., that there is no retrocausality). It was noted there the possibility that Spekkens’ principle of parsimony might be recast to apply more generally to retrocausal models. Shrapnel and Costa (2018) achieve just this in a no-go theorem that applies to any exotic causal structure used to sidestep the ontological models framework, including retrocausal accounts, rendering such models contextual after all.

Shrapnel and Costa’s result is based on a generalization of the ontological models framework which replaces the operational preparation, transformation, and measurement procedures with the temporally and causally neutral notions of local controllables and environmental processes that mediate correlations between different local systems, and generate the joint statistics for a set of events. “These include any global properties, initial states, connecting mechanisms, causal influence, or global dynamics” (2018: 5). Furthermore, they replace the ontic state 
λ
 with the ontic “process” 
ω
:

our ontic process captures the physical properties of the world that remain invariant under our local operations. That is, although we allow local properties to change under specific operations, we wish our ontic process to capture those aspects of reality that are independent of this probing. (2018: 8)

As a result, the notion of 
λ
-mediation (encountered in §4.1) is replaced by the notion of 
ω
-mediation, in which the ontic process 
ω
 completely specifies the properties of the environment that mediate correlations between regions, and screens off outcomes produced by local controllables from the rest of the environment. Shrapnel and Costa (2018: 9) define the notion of “instrument noncontextuality” as a law of parsimony (along the lines of Spekkens’ own definition of noncontextuality): “Operationally indistinguishable pairs of outcomes and local controllables should remain indistinguishable at the ontological level”. They then show that no instrument noncontextual model can reproduce the quantum statistical predictions.

Crucially, what is contextual is not just the traditional notion of “state”, but any supposedly objective feature of the theory, such as a dynamical law or boundary condition. (2018: 2)

Since preparations, transformations, and measurements have been replaced by local controllables, there is no extra assumption in Shrapnel and Costa’s framework that 
ω
 is correlated with some controllables but independent of others. Thus the usual route out of the ontological models framework, and so the no-go theorems of §3, open to retrocausal approaches—that the framework assumes no retrocausality—is closed off in the Shrapnel-Costa theorem, rendering retrocausal approaches contextual along with the rest of the models captured by the ontological models framework.

This presents a significant worry for retrocausal approaches to quantum theory. If the main motivation for pursing the hypothesis of retrocausality is to recapture in some sense a classical ontology for quantum theory (see §3.4), then the Shrapnel-Costa theorem has made this task either impossible, or beholden to the possibility of some further story explaining how the contextual features of the model arise from some noncontextual footing. On this latter point, it is difficult to see how this story might be told without significantly reducing the ideological economy of the conceptual framework of retrocausality, again jeopardizing a potential virtue of retrocausality (see Evans 2020 for further discussion of this point).

As mentioned above (§7.3), contextuality can be construed as a form of fine tuning (Cavalcanti 2018; Adlam 2021), especially when the demand for noncontextuality is understood as a requirement of parsimony, as above. The worries raised in this section and the last underline the fact that the challenge to account for various types of fine tuning is the most serious principled obstacle that retrocausal accounts continue to face.

1. Terminology
The language here is highly contentious. There are exceptions, but in a long history mental disorders or illnesses have been characterized as “evil”, “sinful”, and “willful error” or, at the very least, regarded as unwelcome misfortune.[1] With some regularity, conditions listed in the “Diagnostic and Statistical Manual of Mental Disorders” (DSM) of the American Psychiatric Association (APA 2013) and the “International Classification of Disease” (ICD) of the World Health Organization (WHO 2020) have provided new classificatory titles and terminology, such revisions often solely aimed at reducing negative and stigmatizing associations. Authors cited in what follows use “mental disorder”, “psychiatric disability”, “psychiatric disorder”, “mental illness”, “madness”, “psychopathology”, and “neuro-atypicality”. Controversy attaches to these terms, as it does to particular diagnostic labels (such as “schizophrenia”). Because some would question whether these mental differences are forms of illness or disorder at all, the more neutral but rarely used, “mental difference” perhaps better accommodates each side of this controversy, so the choice of “disorder” here is for its greater familiarity, and not intended to promote a disorder or illness view.

Three changes of language require special attention. With increasing frequency, the term “illness” in “mental illness” has been replaced by “disorder”, apparently without a consistent rationale beyond avoiding explicitly medical associations. In a parallel recent trend “the cognitive” and “cognition” are sometimes introduced as equivalents or replacements for “the mental”. This new language around “cognition” collapses the earlier faculty psychology divisions of affection and cognition: as much as doxastic states, emotions are “cognitive”.[2] Finally, increasing use of “mental and behavioral”, sometimes shortened to “behavioral” (as in “behavioral health”), reflects substantive changes, such as the inclusion of addictions in the class of disorders and a preference for precisely measurable symptoms over subjective report.

Unless otherwise indicated, the expression “mental disorder” replaces “mental illness” in what follows, and refers not only to more “mental” conditions like psychoses and affective disorders, but also to “behavioral” conditions such as addictions and personality disorders. Frequently, the shift from “mental” to “cognitive” also indicates allegiance to substantive theoretical tenets. Here, however, “cognitive” and “cognition” are used only as terms of art within particular theoretical analyses.

2. Folk Psychology, Conceptual Analysis, and Science
Concepts of mental disorder are understood differently in the perspectives of folk psychology (which privilege common-sense understandings) and medical psychiatry (which privilege scientific understandings). Inconsistencies arising at the boundaries, where mental disorders meet other kinds of disorder, add ambiguity. Rather than traditionally mental symptoms, for example, “hysterical” (“psychosomatic”, “somatoform”, “functional” or “conversion”) syndromes exhibit bodily maladies and dysfunction (Scull 2009). Yet they remain mental disorders in common understanding, and have long found a place in standard psychiatric classifications.[3]

There are different views about the conceptual relationship between everyday and more clinical language about mental disorder, and philosophers and others have approached this matter according to varying foundational assumptions. Both commonsense psychology and conceptual analysis reflecting it, are part of what Rachel Cooper calls a broadly “descriptive” project, which engages linguistic intuitions (Cooper 2020). Opinions vary as to the value and importance of the resulting characterizations. Some insist that the concept of mental disorder employed in psychiatry’s conception and classification of disorders is too closely allied to the parallel concepts in folk psychology. Dominic Murphy (2006) argues that folk psychology is inadequate to the scientific taxonomical task of discovering the “hidden causal structure” of mental disorders, since there is no assurance that common sense understandings correspond to scientifically tractable concepts. Without a principled and systematic way to identify the class of mental disorders, these concerns suggest that any taxonomy that is employed will likely prove inaccurate and the outmoded, folk psychological category of mental disorder will eventually be rendered obsolete.

More conservatively, others have urged the practical importance of maintaining the category of mental disorder (Brülde & Radovic 2006). Everyday language and the traditional classifications built around it have provided a common framework for research and clinical practice; and with any further blurring of the boundaries between mental disorders and the brain damage and disease treated by neurologists, demarcations of professional competence would be lost. Conversely, the scientific authority of medical psychiatry has been challenged by those who express fears of overdiagnosis, granting too much power to psychiatry and the pharmacology industry, and inappropriate deference to ‘expert opinions’ on mental health and eudaimonia that may be better addressed by non-scientific perspectives (see §10).

It is not only for such considerations of practicality and custom that common sense concepts have been supported. Some analyses adhere to an account of mind and mental processing employing mentalist terms and normative presuppositions inapplicable within an exclusively neuro-physical framework (see §4, §5, and §8). Others regard mental disorders as socially constructed entities, the existence and classification of which are inextricably tied to societal and interpersonal features of the world (see §10).

A taxonomy of these varying foundational assumptions includes intersecting issues: what mental disorders are, how much we presently know about them, and different approaches to their analysis. In one set of contrasts, naturalist (or objectivist) accounts hold that—as empirically discoverable entities—mental disorders can be provided value-free description, while normative (or evaluativist) analyses deny the possibility of such description (discussed in §8.1). Revisionists, prepared to relinquish all current concepts, disagree with conservatives favoring the retention of (at least some) traditional categories. And, in a final sorting, the nature of mental disorder will be sought either through a posteriori scientific research based in neurocognitive science, or through conceptual analysis derived in part or whole from social and cultural norms.

3. The Mental in Mental Disorder
In a once-common practice, mental or “functional” disorders were diagnosed just when no somatic traits were evident. Such language is now explicitly disavowed, eclipsed by a growing recognition that all disorders involve bodily states (APA 2013: 309; O’Leary 2021). Still, the “mental” in mental disorder is variously construed.

3.1 Internal Causes and External Symptoms
On traditional, two-part models from cell pathology, dysfunctional organic processes internal to the individual are manifested in, and causally responsible for, more readily observable external symptoms. Applied to mental disorder, certain underlying processes have been delimited as mental by appeal to the traditional categories of faculty psychology (perception, affection, cognition, memory, and so on). For example, hallucinations represent dysfunctional perceptual capabilities, mania and depression disturbed affect regulation, and delusions defective cognitive processing. A disorder is thus determined to be mental (as distinct from physical) if its internal causes involve psychological faculties (Wakefield 1997). Other accounts ascribe disordered mentality—not to underlying features but—to effects on the subject’s social and personal functioning (Rashed & Bingham 2014). For example, it is because her states of sadness and self-doubt result in absenteeism, that the person with depression seeks medical help (see §4.2). More holistic and “biopsychosocial” accounts combine these features (Nordenfelt 1995; Davies & Roache 2017; Bolton & Gillett 2019; O’Leary 2021).

On two-stage accounts both internal and external features form integral parts (Graham [2013] argues that this holds for prototypical disorders). Internal and external features are each included in the DSM definition of mental disorder:

a syndrome characterized by clinically significant disturbance in an individual’s cognition, emotion regulation, or behavior, that reflects a dysfunction in the psychological, biological or developmental processes underlying mental functioning. (APA 2013: 20, emphasis added)

The different positions on mental disorder just sketched—emphasizing internal conditions, observable manifestations (“symptoms”), and both—are discussed in Section 4. Each position exhibits vulnerabilities. Accounts stressing inherent features regularly rely on hypothetical entities or processes, expecting that future discoveries will reveal knowledge of causal mechanisms presently hidden from view (This position has a long history; see Murphy 2006, Tabb 2015). Often accounted for by its status as a new science, this faith has been sorely tested, thus far, by confused classifications, apparently ill-grounded research, and other liabilities, as well as incomplete models of mental dysfunction (see §4 and §6). If these impediments can be overcome, emphasis on internal causes may be expected to yield powerful explanatory models, laying the ground for targeted interventions and effective prevention and treatment (see the entry on Philosophy of Psychiatry). Placing emphasis on disabling or dysfunctional observable symptoms has comparable vulnerabilities. One setting’s dysfunctional mental symptom may be another’s normal, admired, or useful trait; and mental disorder must be distinguished conceptually from deviance, as well as from normal responses to the normal losses and setbacks that are common in human experience (see §4, §8, and §10).

3.2 The Mark of the Mental
In some philosophical accounts (including those stemming from phenomenological traditions), the mental is distinguished by particular features: it bears a special relationship to conscious awareness and to persons, for example, or may be taken to exhibit the distinctive “aboutness” or intentionality exclusive to mental attitudes (see §5). Similarly, some theorizing emphasizes the reasons-responsiveness of all human thought and action, by which disorder can alone be explained and understood (Campbell 2013; Thornton 2007; Summers & Sinnott-Armstrong 2019).

Explanations in cognitive psychology have taken several different forms over the years: information processing models, connectionist networks, and neuroscientific approaches. Moreover, philosophical reconstructions of cognitive psychology and cognitive science must be distinguished from the cognitive psychology practiced by psychologists—although little discussion of “the mental” occurs in either. Instead, focus is on the cognitive when, as was pointed out earlier, the “cognitive” subsumes capacities, states, and processes that used to be considered non-cognitive, such as sensations and emotions. Widespread acceptance of these shifts in much theoretical and research writing on mental disorder has gone some way toward eclipsing philosophical concepts of mind and the mental, although commonsense cognitive capacities (which are assumed in philosophical accounts of intentionality) remain the starting point of the research program of cognitive science, and cognitive studies of traditional “mental states”, such as reasoning and consciousness.

The focus of cognitive psychology usually lies with computation and representation. Mental/cognitive states (representations) depict features of the outside world (as well as other mental states and abstract entities) and mental/cognitive processes operate on those inner symbols, transforming and manipulating them (see Von Eckardt 1993; Friedenberg & Silverman 2011; Cratsley & Samuels 2013, and the entry on Cognitive Science). Although demarcated by the faculties known as “mental”, the realm of the cognitive is typically construed as properties or processes with a causal role in determining behavior, or behavioral capacities, that offer no resistance to naturalistic characterization (Chalmers 1996). Candidates for a distinctive “mark of the cognitive” are debated—but so is the need for one (Varga 2018; Allen 2017).

3.3 Metaphysical Implications
Mental disorders are conditions or states attributed to persons, but this need entail neither that they are entirely non-physical in nature, nor that they must (or even can), be explained in solely neuro-scientific terms. Maintaining the separation between mental and physical disorders is compatible with some forms of weak physicalism, allowing that mental or psychological processing involved in functions such as perception, reasoning and memory, are realized in the workings of the brain (see Schaffner 2016; Jefferson 2021 and the entry on Health). Problems of supervenience and emergence have led some to defend a holistic “naturalistic dualism” entailed in a biopsychosocial model (Bolton & Gillett 2019; O’Leary 2021).

4. The Disorder in Mental Disorder
Schizophrenia, depression, and obsessions, bipolar disorder are core instances of mental disorder, but psychiatric classification recognizes many other conditions as well. From such a large and heterogeneous collection, this broad category may be regarded as a family resemblance one (Lilienfeld & Marino 1995). Indeed, through a different historical or cultural lens, the assembled variations known today as mental disorders would likely appear incoherent and arbitrary. Yet, spurred by essentialist expectations (and out of concern about the unwarranted “medicalization” of normal states and behavior), the quest for a unifying conception of mental disorder (illness, or disease) has persisted within philosophical research. Characteristic features have been identified, including disunity, irrationality, the presence of suffering and disability, several forms of dysfunction, and even adaptive function. Proposed formal analytic definitions are illustrated in Section 4.4.

4.1 Disunity and Irrationality
Works of ancient philosophy are focused more on the psyche’s health (or eudaimonia) than its illness. Nonetheless, there are hints that just as a unified soul is one that is healthy (as well as rational and virtuous), a soul lacking unity will be disturbed or mad. Offering an account of the harmonious soul, whose rational and non-rational elements achieve unity, Aristotle leaves us a picture of the warring and fractured state of an unhealthy soul, for example.[4] The emphasis on disunity is here tied to vice and irrationality: a fully unified soul is virtuous and rational, a disunified one vicious and irrational in its unhealthy divisions. This view of vices and virtues is also characteristic of the subsequent Stoic analyses (Irwin 2013), although Aristotle adhered to a different account of the passions and a more Platonic analysis of vice. A conception of mental illness as psychic disunity (as well as an association between health, rationality and virtue) reoccurs in later philosophy (in Spinoza, for example), and in psychoanalytic traditions. Within present-day disorder descriptions, some symptom clusters readily fit the classical emphasis on disunity (addictions, and bipolarity, for example); others, including most personality disorders, are less easily depicted in such terms (Worrell & Denham 2016).

Mental disorder has been understood as irrationality (or “Unreason”) after the “Age of Reason” that prized order and logic (Foucault 1965). Together with the emergence of empirical science, this emphasis is seen to have laid the foundation for our contemporary psychiatric categories and theories.[5] In the present day, cultural norms and intuitive folk psychology assign the boundaries of mental disorder, and these intuitions conflict about some particular conditions (e.g., addictions, personality disorders). Yet disturbed or disabled doxastic states and capabilities remain core examples of disorder, over which intuitive agreement is strong. Characterized by incomprehensibly disordered thought, failure to adjust beliefs in response to new evidence, inconsistencies between thought and action, and delusional convictions, psychosis and psychotic thought patterns are regularly judged prototypical features of mental disorder. So the rationalistic analysis of disorder corresponds—but only to a reduced version of the presently sprawling overall category.

Forms of doxastic irrationality are still the mainstay of much policy and legal analysis about mental disorder. Assessments of criminal responsibility, of fitness to stand trial, and of the capacity to undertake binding contracts, for example, are expressed in terms of the defendant’s ability to know and understand (Reznek 1987; Robinson 1996, 2013; Adshead 2008). Ostensibly, construing mental disorder as a want of rationality has been weakened by evidence from behavioral economics showing that holding and acting on well-grounded and reasons-responsive beliefs occurs rarely in the general population, and common prejudices and superstitions seem barely distinguishable from clinical delusions with respect not only to their prevalence but to the way they are adopted and maintained (Bortolotti 2009, 2013, 2020).

Confidence that irrationality defines mental disorder is similarly eroded if, understood as effective social function and personal flourishing, mental health lies in traits such as unwarranted optimism, and the distorting tendency to remember successes over failures in “positive illusions”(Taylor & Brown 1988; McKay & Dennett 2009; Jefferson et al. 2017). Along these lines, some illusions, delusions, and hallucinations have recently been acknowledged to be “perfectly acceptable, sometimes praiseworthy ways of being hopeful, committed to imagining and enacting a better world for oneself and others…making moral and meaningful lives” (Flanagan & Graham 2017: 309). Whether disorder is usefully characterized as a want of reason also depends on guiding, normative conceptions of mental health or eudaimonia, and on the role of reason in those conceptions—not merely on facts of the matter, or on consequentialist reasoning.

4.2 Suffering and Disability
Other depictions of disorder rely on one or both of the groups of traits around harm, suffering, and distress, on the one hand, and disability, incapacity and personal or behavioral dysfunction, on the other. These are the features noted in a series of influential prefatory remarks in the diagnostic and statistical manuals (the DSMs and ICDs). The wording of the fifth edition of the DSM introduces a disjunction:

Mental disorders are usually associated with significant distress or disability in social, occupational, or other important activities. (APA 2013 emphasis added)

A very similar passage from the ICD-11 is comparably qualified:

“Disorder”…is…a clinically recognizable set of symptoms or behavior associated in most cases with distress and with interference with personal functions. (WHO 2020, emphasis added)

Psychodynamic or psychoanalytic presuppositions may posit underlying distresses that are masked or submerged within the psyche; and the elusive phenomenology of some conditions suggests the presence of nameless existential anxieties hidden from awareness (Ratcliffe 2008, 2017). But such explanations aside, distress has been widely regarded as a ubiquitous feature of disorder. In symptom-focused accounts laying stress on the consequences of the syndrome, distress becomes prominent as a form of disabling dysfunction (Stein et al. 2010). Instead of separate criteria (and either singly or jointly sufficient for disorder, as in the respective DSM and ICD definitions above), suffering and dysfunction are conjoined on a “distress-impairment” analysis, where disorder status is assigned with (and defined by) distress that is “unmanageable or disabling” (Bolton 2013). The plausibility of this analysis increases with what have been called “distress related conditions”, such as depression and anxiety, that are “more constitutive of the illness” (Bolton 2012: 10; also see §4).

To accommodate exceptions that seem neither distressing nor disabling (such as manic states), mental disorder is sometimes characterized not by distress and dysfunction but by raised risk of such outcomes (Gert & Culver 2004). But risk of disorder is not disorder, and risk language invites troubling ethical issues around over-diagnosis and false positives (Schwartz 2008; Stein et al. 2010; Bolton 2013; Broome, Fugar-Poli, & Wuyts 2013; Radden 2018).

Loosely understood, moreover, distresses are an inescapable part of the human condition and normal responses to life’s vicissitudes. When and whether normal (and even appropriate) suffering reflects pathology has long been the source of philosophical—and societal—disagreement (Wilkinson 2000; Horwitz & Wakefield 2007). In the discussions of “normal sadness” that accompanied the revision of the fifth edition of the DSM, the grief exclusion that had (temporarily) exempted from diagnosis the suffering around mourning and grief, was challenged, its proposed elimination charged with “medicalizing” or “pathologizing” normal and appropriate human feelings (Zachar 2014; Wakefield 2012). The separation of normal from pathological distress will be indicated by distress emanating from the disorder itself, rather than from other contingencies. But presently, distresses resulting from the stigma and discrimination that follow diagnosis and treatment, as well as a host of other, frequently negative, consequences in jarring and alarming disruptions to personal lives, selves, and relationships, prove difficult to disentangle (Tekin 2011).

Some predict that biological markers will eventually allow us to distinguish distress that is a symptom of depression, for example, from that which is a normal response to external contingencies (Horwitz & Wakefield 2007). Such biomarkers may be welcomed by those decrying over-diagnosis (Stegenga 2008, ch. 6), although an evaluative interpretation as to whether, and when, such biomarkers occur in healthy and unhealthy form will be required.

Some argue that the subjective experience of distress and the extent of impairment of the person’s day-to-day functioning are intrinsic properties of disorders like depression: conceptually, disorder attributions are made on the basis of “consequences of the syndrome as they manifest for the subject” (Rashed & Bingham 2014: 245). Psychological symptoms may constitute a mental disorder, even as it is caused by biological or social factors. In the absence of known biomarkers, depression is attributed based on psychological symptoms alone; and were known biomarkers present without evidence of any psychological symptoms, our intuitions suggest, disorder attribution would be withheld. These intuitions may shift with time, it is recognized, depending on how most people and most psychiatrists now understand, define, diagnose, and treat, depression. In current practices, attributions of depression are made without biomarkers (Cooper 2020).

Analyses characterizing felt distress as a property constitutive of some given psychiatric condition (e.g., depression) are also compatible with recent models focused on the causally interconnected statistical networks making up symptom clusters. These clusters are depicted as reinforced through feedback loops that serve to link together assorted symptoms independent of any underlying, antecedent, common, cause. In the case of depression, a range of symptoms arise from diverse sources and, through their looping interactions, form, worsen, and maintain the disorder as a relatively stable entity and conceptual whole (Kendler, Zachar, & Craver 2011; Borsboom & Cramer 2013; Borsboom 2017).

Symptom-focused accounts may combine suffering with disability. But a conception in terms of what the affected person is prevented from doing, or unable to do as well as others, captured in the ideas of disability, impairment, incapacity and personal or behavioral dysfunction, offers an alternative characterization that can acknowledge disorders without apparent personal suffering (notably, mania and narcissistic personality disorder).

Dysfunction and disability have been allied or treated as rough equivalents; but sometimes disability is placed in opposition to dysfunction. Instead of being construed as internal to the person, disabilities are often represented as conditional impairments, dependent on context (including physical and social arrangements). They impose limitations on the person’s ability to perform everyday activities and participate as more typically-abled people do and call for appropriate accommodation analogous to ramps for those using wheelchairs (Oliver 2004; Polvora 2011). The analogies linking psychiatric with other disabilities is incomplete, however, nor can accommodations be achieved as easily as installing ramps (Amundson & Tresky 2007; Rashed 2019).

Like disability, the deviance eliciting societal censure and condemnation is also placed in contrast to dysfunction, although efforts to further characterize that contrast have thus far been incomplete (Aftab & Rashed 2021).

4.3 Dysfunction in Two Stage Analyses
Dysfunction forms a central element of the most widely discussed analytic definition of mental disorder, introduced in §3. The notion of dysfunction applies in two distinct ways in Wakefield’s harmful dysfunction analysis, one way avowedly objective and the other not (see §4.4). In the first, dysfunction occurs in some part or parts of a bodily or neural system. That dysfunction in turn causes dysfunction in some part of the individual’s social and personal system (grounding normative judgments of harmfulness). The first kind of dysfunction allegedly permits factual description.

The characteristic dysfunction of mental disorder is here part of a standard, idiopathic model, as we saw, with disabling traits understood as symptoms or manifestations of an underlying pathological process. The suitability of this model for psychiatric conditions has received persistent critique (see §10.1). Recent challenges rest on the persuasiveness of network models (introduced in §4.2), where symptomatic dysfunction does not emanate from some disabled inner mechanism, but instead emerges piecemeal from interacting experiences that cumulatively build clusters of disabling symptoms out of feedback loops (Kendler, Zachar, & Craver 2011; Borsboom & Cramer 2013). Support for this alternative model stems from evidence that a range of factors combine to bring about disorder: individualistic risk factors, but also aspects of the broader context in which the individual finds herself (Bolton 2010; Kirmayer, Lemelson, & Cummings 2015). A more fundamental critique rejects the dysfunction analysis of disorder, favoring instead a madness-as-strategy account, which draws from adaptationism (Garson 2022; see §4.4 and the entry on Adaptationism).

4.4 Formal Definitions
Eschewing a more formal definition, analyses such as the “distress-impairment” one introduced earlier rely on prototypical cases (Graham 2013), or point to intrinsic vagueness that must thwart such efforts (Keil, Keuck & Hauswald 2017). Others are more ambitious, proposing analytic definitions in terms of necessary and sufficient conditions and even encompassing other medical conditions as well as mental disorders (for those stressing the inseparability and interdependence of mental and bodily disorder, no important distinction is acknowledged between mental and physical disorders [Pârvan 2015]). Definitions (i)–(vi) below are a sample of these efforts. More recent definitions reflect increasing recognition that the diversity of the category must frustrate efforts at a covering definition.

A disease is the interference of a normal biological function that detracts from the person’s survival or reproduction (Boorse 1977). More recent elaborations on this early version of the definition emphasize biological function and statistical normality, so that on a bio-statistical theory, diseases are internal states that depress a functional ability below species-typical levels (relative to age and sex) (Boorse 1997). Critiques of this definition have challenged its aspiration to be value free; its introduction of an arbitrarily selected reference class; and its failure to honor the accepted distinction between “disease” (with its implied defectiveness) and mere difference (Bolton 2008).
A condition is a mental disorder if and only if (a) the condition causes some harm or deprivation of benefit to the person as judged by the standards of the person’s culture, and (b) the condition results from the inability of some internal mechanism to perform its natural function, wherein a natural function is an effect that is part of the evolutionary explanation of the existence and structure of the mechanism (Wakefield 1992, 1997). Critiques of this definition occur later in this section and in Section 5. In addition, definitions in evolutionary theoretic terms introduce a category of innate risk factors that is belied by the way natural, social, and individual factors are inextricably interwoven in disorder (Bolton 2008). And the formulation relies on unsubstantiated, empirical assumptions about the way natural selection underlies natural function (Lilienfeld & Marino 1995; Murphy & Stich 2000). The cultural relativism in (a) has also been challenged (Gert & Culver 2004: 421; Bolton 2008). And rather than exhibiting dysfunction, at least some mental disorders may be explained relationally, by traits that are mismatched in the person’s context, due to their developmental or evolutionary features (Garson 2015).
A mental malady is a condition of a person, other than his rational beliefs and desires, such that he is suffering, or at increased risk of suffering, an evil (death, pain, disability, loss of freedom or opportunity, or loss of pleasure), in the absence of a distinct sustaining cause (Gert & Culver 2004). The concept of a sustaining cause is unacceptably vague and inclusive, permitting conditions to count as disorders that are not, intuitively, disorders at all (Murphy 2006). For example, some disorders leave permanent, non-pathological alterations in the character that outlast any immediate stressors.
A condition is pathological if and only if it is an abnormal bodily/mental condition that requires medical intervention and that harms standard members of the species in standard conditions (Reznek 1987: 163–4). For criticisms of this definition’s appeal to baseline population norms, and to medical intervention, see comments on (i), (ii) and (iv) above. Reference to required medical intervention fails to acknowledge risks of over-medicalization and over-diagnosis and invokes concerns over enhancement (Savulescu, ter Meulen, & Kahane 2011)
Diseases involve deprivation, but a disease is a depriving relation rather than a depriving entity, depending on the patient for its existence…the person is not conceived as ontologically diminished or defective because it suffers the deprivation. Drawing on Augustine’s ontology of disease, bodily integrity, and the human person, Alexandra Pârvan (2015, 2016) argues that disease stands in ontologically necessary connection with the patient as person (from this she derives a treatment approach based on how the person relates to the disease, and a goal of reconfiguring the person as deprived but not diminished). This account is limited in its required adherence to its Augustinian ontology.
Mental disorders are biological kinds whose effects lead to harmful consequences … more natural kinds of mental disorders (e.g. schizophrenia, bipolar disorder) are biological kinds primarily underwritten by biological mechanisms. More artificial kinds (e.g., hysteria, voyeuristic disorder) are social kinds primarily underwritten by social mechanisms (Tsou 2021: 2–3).
… at least some of the forms (of madness) … are strategies for solving problems, coping with aspects of the environment, regulating one’s mental economy … the creative problem-solving activity of the human mind, or God’s stern but benevolent hand, or the healing impetus of nature, or an evolutionary adaptation, a purpose-driven process, a well-operated machine … (Garson 2022: 10). If neuropsychiatry ever succeeds in identifying the defective mechanisms it seeks, Garson’s analysis must be weakened. Moreover, it seems vulnerable to some of the accusations of complexity-defying oversimplification that have dogged other adaptationist just-so stories.
5. Phenomenological Approaches
The symptoms of mental disorder are primarily, if not exclusively, states about which their subject can claim a sort of authority. Since subjects can intentionally or unintentionally misreport symptom states, such phenomenological reports—however necessary—are epistemically limited as data (Kontos 2016). Psychology can provide reliable behavioral assessments of disorder and indicate its presence through laboratory performance tests. But no mental disorder is thus far independently verifiable (though blood tests or scans, for example). Hence, first person reports play a special part in understanding mental disorders, for clinicians, researchers, and philosophers alike (Flanagan 2011; Varga 2015). Karl Jaspers’ General Psychopathology, which combines detailed clinical description with the existential and phenomenological methods of Husserl and Heidegger, has been widely discussed. This pairing of clinical and philosophical knowledge makes Jaspers (1913[1963]) one of the undisputed originators of the research field known as the philosophy of psychiatry and psychopathology. The “phenomenological” clinical approaches following this broadly Jasperian tradition, however, vary in their adherence to the tenets of phenomenology (Parnas & Sass 2008).

The phenomenological strand of philosophical analysis influenced by thinkers like Husserl and Heidegger focuses on immediate, first person reports. Analyses have examined self-experience in psychosis (Parnas & Sass 2008; Madeira, Pienkos, et al. 2019), disordered temporal experience (Fuchs 2005, 2013), delusional states (Parnas & Sass 2008; Gallagher 2005, 2013), and affective disturbances (Ratcliffe 2008; Ratcliffe & Stephan 2014; Jacobs et. al. 2014). In these traditions neither psychology nor psychopathology are empirical sciences in the usual sense because they involve distinctive forms of explanation. Arising within nineteenth century social science, the hermeneutical approach involving meanings calls for Verstehen (understanding), a distinctive, interpretive way of apprehending human action (Jaspers 1913[1963]; Phillips 2013, Wiggins & Schwartz 2011; Spitzer & Uehlein 1992). These differences of approach bring differing orientations towards fundamentals, and approaches following German and French traditions have been contrasted with the “Anglo-empiricist” approaches, which display a greater emphasis on objectivity and empirical science (Mullen 2011; Gergel 2012).

These differences bring contrasting theories about psychology as science. Some argue that the subjective life of the patient should be the main or even sole locus of attention (Stanghellini 2004). Others argue that the experiences associated with psychosis must be categorically divorced from more typical psychological processes (Sass 2001; Parnas & Sass 2008). Emphasizing the unique challenges imposed by interpretation in psychiatry, Somogy Varga (2015) argues for a hermeneutics distinctive to psychiatry that is grounded in ideas about the self-interpreting aspect of human beings, “mental disorder” thus standing in an asymmetrical relation that supervenes on our self identities.

There is disagreement over the correct application of phenomenological method (Mishara 2007; Sass, Parnas, & Zahavi 2011). But psychopathology likely offers a challenge so great as to call for a range of approaches (Ratcliffe 2011; Wiggins and Schwartz 2011; Gallagher 2013). Attempts have also been made to combine phenomenological with empirical approaches: Matthew Ratcliffe’s work on affective states employs social research methods (Ratcliffe 2008; Ratcliffe & Stephan 2014). And efforts to tie in phenomenological theorizing with findings in neuroscience have yielded the hybrid methodology of phenomenological clinical neuroscience advocating an initial study of subjective experience to only then be probed for its underlying neurobiology (Mishara 2007: 34).

The merging of empirical and phenomenological methodologies is represented by the fields of embodied and enactive cognition. Conceptions of the embodied, embedded, and sense-making enactive mind bring emphasis on the way, shaped by perceptual experience, consciousness and the first person perspective form the basis of all mental processing (Varela, Thompson, & Rosch 1991; Durt, Fuchs, & Tewes 2017; Di Paolo & De Jaegher 2017). Applied to mental disorder, this departure from classical cognitivist assumptions and analogies suggests that at least some disorder grows out of disturbances in embodied interaction with the environment, and not from dysfunctions occurring in high-level cognitive mechanisms (Drayson 2009; Stanghellini 2004, 2016; Maiese 2016).[6]

6. Classification
While Section 3 focused on what might separate mental from non-mental disorders, and Section 4 was concerned with how to separate disordered from non-disordered states, this section addresses controversies over how different types of putative mental disorders should be distinguished from one another. These controversies, like so many about psychiatry, span the disciplines of medicine, science (including neuroscience and psychology), and philosophy.

The DSM and ICD share broad features in providing categorical taxonomies: each disorder is idiopathic in arising at least in part from morbid factors within the person, and each is identified “descriptively”, using polythetic (disjunctive) criteria identified with clinical observation (including patients’ self-reports). Aside from serving the institutions providing services, their uniformity is aimed to enhance inter-diagnostician reliability; and research based on these reliable classifications, it had been hoped, should eventually allow validation of the categories, although failure to formulate valid diagnostic categories has been conspicuous and spurned the creation of alternative classification systems (e.g., RDoC, HiTOP).

Following early work by Carl Hempel (1961) that depicted psychiatry’s claim to scientific status as depending on the empirical testability of classificatory concepts, much of the subsequent philosophical discussion of classification has been critical. These criticisms concede little usefulness to psychiatric classification, are skeptical of the promise of validity, doubtful of its methodology and claims to scientific authority, unpersuaded by the categorical system employed, skeptical about its individualistic and idiopathic assumptions, and dubious over its claims to value-freedom. Philosophical analysis has often focused on particular symptom descriptions, disregarding or disavowing the diagnostic categories of which they are presumed to be clinical manifestations, in some cases introducing and employing revised categories such as “distress related conditions” (Bolton 2012), “body image disorders” (Morris 2013), and “real hallucinations” (Ratcliffe 2017). Others have accepted the entities so classified (Sass et al. 2011).

Criticisms of the DSM and the ICD question their research purposes and usefulness, categorical approach to taxonomy, and supposed value-neutrality (see §8). These criticisms emphasize the presence of multiple overarching values, including the methodological values intended to facilitate reliability and validity. Unsupportable values (e.g., homophobia, misogyny) have also been identified.

6.1 Research Purposes and Usefulness
Even by those within psychiatry, it has been widely concluded that as tools for research, the prevailing classifications are flawed, producing findings that tend to be inconsistent, non-replicable, non-specific, or ambiguous, with the categories involved exhibiting problems of construct and predictive validity, as well as imprecise phenotypic definitions, widespread heterogeneity, and extensive comorbidity (Cuthbert & Insel 2013; Poland 2014; Poland & Von Eckardt 2013; Tsou 2021). In partial defense of DSM-type classifications, Elizabeth Lalumera (2016) points out that mental disorders may correspond to theoretically informed, albeit incompletely understood, concepts, in contrast to descriptive conceptions sufficient for identification practices in diagnosis and care.

In response to the DSM’s failure to formulate valid categories, the Research Domain Criteria (RDoC) defines constructs at lower levels of analysis than the DSM’s favored level of “mental disorders”. Separate units of analysis (genes, cells, circuits, self reports, etc.) are each employed in specific research domains (e.g., positive and negative valence systems, cognitive systems, systems for social processes, and arousal/regulatory systems), and the intersections of units of analysis with research domains produce segments of a spectrum linking normal and atypical features. Whether RDoC’s goals are compatible has been questioned, but its aim is to promote both more accurate research and more effective treatments (Cuthbert & Insel 2013; Tabb 2015, 2019; Perring 2016; Morris et. al. 2022). RDoC has in turn been criticized, e.g., for assigning disorder to individuals rather than social context, neglecting personal agency, and assuming an outdated individualistic model of the self (e.g., see Poland & Tekin 2017; Tabb 2019).

6.2 Categorical and Dimensional Approaches
The DSM and ICD have largely followed a nineteenth century, Kraepelinian model, where each disease is a discretely bounded entity, made up of a symptom cluster emanating from underlying organic states or processes within the individual patient. But the applicability of this model to mental disorder has been challenged. Some suggest replacing the broad ideal of validity (involving a relation between classificatory name and underlying disease) with the narrower concept of predictive or prognostic validity (Schaffner 2012; Tsou 2015, 2021). Rather than being classified as discrete diseases, some argue that disorders should be classified dimensionally, e.g., defining depression by severity levels (Zachar 2014; Poland & Tekin 2017; Machery 2017).

Some diagnostic conditions (e.g., PTSD) apparently arise from their subject’s surrounding social, economic, and cultural context. Even those with more claim to idiopathic genetic, neurological, or biological causes as predisposing factors are recognized to exhibit a course more strongly influenced by environmental and epigenetic than any fixed inherent factors, thereby putting further pressure on the “common cause” hypothesis, whereby a syndrome is explained by a single biological feature or set of features (Borsboom & Cramer 2013). Against biological reductionistic approaches, the Network Model approach (Borsboom 2017) classifies psychopathology in terms of interacting networks of biological, psychological, and social factors.

With their hypothesized common causes awaiting discovery, categorical analyses present problems. But dimensional approaches highlight the so-called boundary problem (Rashed 2021) of where to assign the line between normal variation and disorder. Theoretically, the “common cause” in categorical analyses serves as an anchor uniting the disparate and variable observable symptoms making up a given disorder, which justifies the nomological approach of diagnostic classifications. Aside from this theoretical solution, categorical models are similarly beset by boundary (fuzzy edges) problems. The presence of disorder is preceded and followed by a halo of prodromal and postdromal symptoms, over which clinical (and everyday) judgements are often unresolved. In an explicitly normative attempt to resolve an aspect of the boundary problem as it occurs in social and political contexts, Mohammed Rashed (2019, 2021) employs criteria governing recognition of social identities as a guide to pathological status.

The collection of disorders enumerated and described in psychiatric classification systems has prompted alarm over the boundaries of mental disorder, the erosion of normal mentally healthy states and variations, and the inappropriate role played by medical psychiatry (and science) in dictating norms of healthy psychic functioning. Philosophical criticisms of “medicalization” emphasize the increasing influence of neuroscience in transforming cultural expectations and diminishing individual agency and the power of dictating psychological norms by the psychopharmacological industry (Phillips 2009, 2013; Rose & Abi-Rached 2013; Moncrieff 2008; Sadler 2005, 2013, Whitaker & Cosgrove 2015).

In contrast to these commonly-voiced apprehensions about over-medicalization, there remains the persistent charge of under-diagnosis and under-treatment of those with diagnosable mental disorder, often attributed to stigma, and to the socioeconomic status of under-served communities. Epidemiological findings about the incidence of disorder, as distinct from its diagnosis, are notoriously insufficient, however, quite apart from a want of independent biomarkers, due to self-stigma and fear of discrimination, for example, but also to distorting placebo effects, and to research methods misleadingly susceptible to false positives (Jopling 2009; Horwitz & Wakefield 2007; Poland & Von Eckardt 2013). The actual epidemiological data remains opaque and equivocal, leaving these debates unresolved.

DSM and ICD classifications have been remarkably influential worldwide: today, they appear almost immovably permanent. But viewed within their broader moral, political, and social context, which includes psychiatry’s apparently uneven provision of effective treatment, the appropriate stance to adopt towards them, as Christian Perring (2016: 87) has urged, remains critical and skeptical.

7. Natural Kind Status
Philosophers of science have explored whether all or some mental illnesses might be classified as natural kinds, the claim made about particular diagnostic categories or symptom clusters (depression, schizophrenic disorder, and autism, for example), as well as about separate symptoms (Cooper 2007; Samuels 2009; Tsou 2021). With recognition that even the category of biological species would not meet an essentialist criterion for natural kind status, a “homeostatic property cluster” account of natural kinds has been proposed (Ellis 2001, Murphy 2006, Cooper 2007, Samuels 2009, Tsou 2016; also see the entry on Species). A natural kind must be able to ground explanations and inductive inferences, and enable effective human intervention. Linked by mechanisms (e.g., molecular, neurobiological, developmental) that cluster together, the homeostatic aspect of HPC kinds ensures that disorders are sufficiently stable to yield projectable inferences and be explanatory (Kincaid and Sullivan 2014, Tsou 2022).

Psychological categories may resemble biological species in some respects. However, significant differences are suggested by three distinct arguments: (i) Some have taken psychological categories to represent a different order of being (see §5), with its own distinctive forms of causal explanation (Jaspers 1913[1963]; Bolton 2008; Wiggins & Schwartz 2011; Kusters 2016). (ii) Others point out that psychological categories can alter, and eventually even be altered by, the persons they classify, forming “interactive” kinds through such looping effects. Hacking (1995, 1999) argues that mental disorders cannot be natural kinds because the looping effects generated by their classifications render them inherently unstable. And (iii), some have tried to show that the relation between mental illnesses and biological kinds differs according to the role played by values in establishing the taxa of mental illness (Wakefield 1992; see §8). None of these differences has gone uncriticized. A thoroughgoing mind to brain reductionism would reject (i). Regarding (ii), Tsou (2007) argues that classificatory feedback does not necessarily render mental disorders unstable, and Khalidi (2010) argues that that some natural science classifications (e.g., dog) generate looping effects that require classificatory revisions. In response to (iii), it has been argued that values also enter into the classification of biological species, but once we reach the categories of interest, non-evaluative traits form the observable taxa of such species (Cooper 2007).

Although the diverse ends to which disorder taxonomies can be put argue against finding a single answer about the kind status of mental disorders, focus on the purposes served by disorder language and categories has proven fruitful: (i) Mental disorders have been assigned to a category of “practical kinds”, where membership in this class depends on some external criterion that is pragmatically relevant in the clinical context, such as a certain degree of functional impairment, and remains unrelated to the underlying structure of the kind (Zachar 2014). Moreover, they may be further classified according to their status as dimensional, discrete, and fuzzy kinds, and there is little reason to suppose that each and all conform to any one of these (Haslam 2002, 2014). (ii) Whether or not they exhibit the stability required of classifications into true natural kinds, these disorders do possess the properties relevant, and sufficiently stable, to guide clinical treatment, Şerife Tekin illustrates, using the lack of illness awareness (“insight”) common in patients with some diagnoses (Tekin 2016).

8. Values and Mental Disorder
Values have unfailingly played a role in the way mental disorders are classified, conceptualized, experienced as personal diagnosis, and treated. Philosophical accounts differ over the possibility of a value-free science of psychiatry (§8.1). Values also affect societal and personal attitudes towards disorder and diagnosis, in ways that are more immediate, considerably more urgent, and morally consequential (§8.2). Some of these issues are dealt with in bioethical research directed specifically towards psychiatry (§8.3).

8.1 Evaluativism (Normativism) and Objectivism (Naturalism)
Present day conceptions, classifications, and attributions of mental disorder contain many values, some explicit, others implicit, some moral, others non-moral. Unacceptable bias has been repeatedly identified, exemplified in categories such as homosexuality (with its homophobia), pre-menstrual syndrome (unwarrantedly assigning disorder status to normal function), masochistic personality disorder (pathologizing misogynist gender roles), and oppositional defiant conduct disorders (exhibiting racial bias) (Sadler 2005, 2013; Potter 2014; Poland 2014, Gagné-Julien 2021). As in all medicine, the prefixes of “illness”and “disorder,” like “disease,” already declare values such as the preference for health over ill-health. A theory of values based medicine (VBM) emphasizes that values governing mental health are particularly contentious, requiring distinctive forms of negotiation in clinical practice (Fulford 2004, 2014).

A central philosophical question is whether moral values are inescapably attached to the conceptualization and classification of mental disorders at the level of theorizing, forming an inherent part of their definition. Such “evaluativism” (“normativism”, or “constructivism”) is placed in contrast to “objectivism” (“naturalism”), which seeks a value-free account of mental disorder. Debates over these questions have long dominated philosophical research on mental disorder, many played out around attempts to define mental disorder in ways that are value-free (see §4; also see the entry on Philosophy of Medicine, §1).

As discussed in Section 4.4, philosophical definitions aiming to avoid all values appeal to allegedly value-neutral statistical norms, and adaptive function, respectively. The vulnerability in Boorse’s (1997) statistical definition, where normal function is determined according to the person’s reference class identified by such criteria as age, and sex, lies both with assigning the appropriate reference class, a process that re-introduces values, and at the point on a continuous distribution curve where deviance from the mean is granted the status of dysfunctional (Bolton 2008). Recognizing that a trait may be dysfunctional in evolutionary terms without being disvalued, and disvalued without being evidence of dysfunction, Wakefield’s two-part definition explicitly accommodates the evaluative element marking the category. This attempt to provide a naturalistic and value free evolution-based account of “function” and “dysfunction” has been subject to a range of damaging objections, including the claim that with its preference for evolutionary fitness, biological dysfunction is not, as promised, value neutral, even in the first half of the definition. Discerning what would be the maximal response in terms of perpetuating the species represents another of these objections, since no agreed-upon conclusion about this can be drawn in a value-neutral, or perhaps any, way (Murphy & Stich 2000; Faucher & Forest 2021; Tsou 2021; Garson 2022). Critiques of more general disease definitions are also applicable mental disorder (Powell & Scarffe 2019).

Evaluativism and objectivism are customarily depicted as incompatible contraries, although the different domains where claims about disorder occur (including ordinary usage; conceptually clean versions of “health” and “disease”; the operationalization of dysfunction and the justification for that operationalization) indicate the need for a more nuanced analysis of the role of values in health and disease (Kingma 2014). The broad contrast between evaluativism and objectivism has also been resisted for other reasons. Judgments about mental disorder need not be entirely arbitrary and subjective as long as those values are taken to be real features of the world along the lines of McDowell’s secondary property value realism, for example. In this relaxed naturalism, objectivism implies that there is no privileged perspective for identifying the correct values relevant for psychopathology (Thornton 2007).

8.2 Societal and Personal Attitudes Towards Disorder and Diagnosis
The present discussion concerns evaluations that are primarily negative, although as we saw earlier, positive evaluations arise in traditions valorizing madness, and many in the neuro-diversity movement insist that autism spectrum and other mental disorders are unexceptional human variations analogous to differences of gender, which ought to be granted respectful accommodation, not clinical treatment (Hoffman 2019; Chapman & Carel 2022). Negative social attitudes towards observable disorder have led to stigma, self-stigma, and discrimination (Hinshaw 2009). The madman and madwoman have been the subject of fear, misunderstanding, disparagement and condemnation, their failings exaggerated and humanity denied (Gilman 1985). With modernity, care and protection apparently replaced earlier, moralistic and neglectful arrangements (the reforms’ real effects and costs remain an unsettled matter of historical debate).[7] At the same time formal exceptions and protections, such as the insanity defense, recognized mental disorder as an exculpating excuse for wrongdoing and negligence. Despite such attitudinal change, however, these issues around responsibility remain contentious and unresolved (Pouncey & Lukens 2010; Singh, Sinnott-Armstrong & Savulescu 2013; Schramme 2014).

The consequences of being diagnosed has been demonstrated to be extensive, often personally transformative, and usually not benign. The extent of these effects has drawn research attention to first-person report and to the eloquent madness memoirs increasingly available for study. It has led to theorizing within formal philosophical writing, and also within the rhetoric of social movements and identity-focused political interest groups (see §10). The Recovery movement, for example, stresses the way the self and identity are diminished by diagnosis, which erodes and occludes equally important and more positive, attributes making up the whole person (Davidson 2013). Critiques of diagnosis place emphasis on its dehumanizing and “objectifying” effects that, magnified by stigmatizing societal attitudes, engender self-stigma (Hoffman & Hansen 2017; Hinshaw 2009; Thornicroft 2006). More recently, however, social media and our hyperconnected contemporary existence have contributed to a less stigmatizing and discriminatory world, by shifting discussions about ‘pathological diagnoses’ to positive social identities (Sulik 2011).

8.3 Psychiatric Bioethics and Neuroethics
Societal attitudes towards mental disorders (including features associated with disorders themselves) have given rise to a distinctive psychiatric bioethics that differs from traditional medical bioethics. Widespread stigma about disorders raises extra privacy and confidentiality issues, for example. Because of the powerful and disruptive effects of the experience of disorder, conceptions of disorder and its treatment are often linked to the self and identity of the subject in distinctive ways (Tekin 2019). The compromised perceptual, affective, and reasoning capabilities that at least temporarily mark severe disorder are seen to jeopardize the widely-valued traits of rational autonomy, responsibility, and coherent and unified personhood, leading to challenges over agency and decisional capacity (Radoilska 2012; Sadler, Fulford, & van Staden 2015). Finally, the fact that psychiatric treatment sometimes involves coercion raises unique ethical issues.

Coercive practices are judged of serious moral concern. For example, coercive treatment seems to jeopardize rights proclaimed by the United Nations Convention on the Rights of Persons with Disabilities (2006). Important philosophical issues here include whether there are person-centered or paternalist principles that would respectively obviate or justify coercive treatment; how to define coercion; what constitutes valid consent; and identifying links between coercion and stigma (Kallert, Mezzich, & Monahan 2011; Szmukler 2016; Cratsley 2019; Pouncey & Mertz 2019). Recent theorists have discussed “mental disorder exceptionalism” (different treatment for mental and physical conditions) and proposed potential tests for drawing relevant distinctions (Szmukler & Dawson 2011).

Aside from legal and moral liability, disorders affecting volition (e.g., addictive and compulsive disorders) have been considered in light of the moral capacities associated with attributing full adult responsibility. Efforts to ground the intuition that sufferers from these conditions are less than fully responsible agents have appealed to “deep self” and also “reasons responsiveness” theories of responsibility. Neither theory alone has been found to readily accommodate the collection of symptoms associated with this group of disorders (Schramme 2014; Summers & Sinnott-Armstrong 2019).

The related field of neuroethics explores developments and prospects in neuroscience that are particularly urgent and relevant for psychopathology (Bluhm, Jacobson, & Maibom 2012; Roskies 2007; Glannon 2015; Caruso & Flanagan 2018). For example, encroachment on “mental privacy” can be expected to disproportionately affect those with stigmatized genders, disorders and symptoms; and a future can be envisioned in which the semantic authority of first person symptom descriptions is undermined by diagnoses independently verified through imaging or other technologies (Maibom 2012). More generally, this new knowledge seems likely to foster a trend from the treatment of disorder to its prediction based on observed risk factors, which in turn permits initiatives such as the identification and treatment of early onset, “prodromal” conditions in younger subjects (children and youth), likely affecting identity development and self-management (Broome, Fusar-Poli, & Wuyts 2013; Whitaker & Cosgrove 2015; Radden 2018; also see the entries on Philosophy of Neuroscience and Neuroethics).

Concepts of responsibility, together with concepts of personhood, autonomy, diminished capacity, and individual rights, make up an inescapable aspect of the broad field of psychiatric ethics. Areas of recent research concern responsibility and blame. Attitudes of blame are customarily treated as an appropriate sequel to assigning responsibility (Watson 2004), but Hanna Pickard (2011) uncouples responsibility from blame. For the apparently willful behavior of those diagnosed with disorders affecting agency, she argues, the proper stance for the care-giver is grounded in an empathetic attitude (that assigns responsibility without blaming), which is conducive to improvement and recovery.

Closely related responsibility issues involve the personality disorders that—due to their long-recognized relationship to more normal character weaknesses and their evidently dimensional nature—sit uneasily within psychiatric classifications (Sinnott-Armstrong 2008; Pickard 2011, 2016). One DSM grouping (cluster B personality disorders, including borderline, narcissistic and antisocial), are better approached using persuasion and methods reminiscent of the “moral treatment” of earlier times (Charland 2004).

Philosophical challenges to customary moral, ethical, and medical presuppositions introduced in this section have been influenced by, and are difficult to separate from, critiques of medical psychiatry that have taken place not only within academe, but also beyond it (see §10).

9. Particular Disorders
While often more ambitious and encompassing, philosophical attempts to define or characterize mental disorder have also provided finer-grained analyses (See Fulford et al., 2013; Moseley & Gala 2016; Tekin & Bluhm 2019). Beyond research into schizophrenia, which is the most plausible candidate of a natural kind, analyses have been offered for anorexia and other eating disorders (Gadsby 2017a, 2017b, 2020; Bordo 1993; Giordano 2005, 2019; Svenaeus 2013; Morris 2013; Tan, Hope & Stewart 2003; Tan et al. 2010; Radden 2021); addiction (West 2006; Poland & Graham 2011; Flanagan 2017; Vohs & Heatherton 2000; Levy, 2006, 2011, 2013; Foddy & Savalescu 2010; Holton & Berridge 2013; Kennett 2013; Lewis 2015; Summers 2015; Pickard 2016; Sripada 2018; Westin 2020; Glackin, Roberts, & Krueger 2021); anti-social personality disorder (Fuchs 2001, 2005, 2013; Roskies 2003; Levy 2007; Kennett & Fine 2008; Sinnott-Armstrong 2008; Adshead 2013; Maibom 2014; Schramme 2014; Justman 2021); depressive and manic-depressive conditions (Horwitz & Wakefield 2007; Radden 2009, 2013; Biegler 2011; Bluhm 2011; Bluhm, Jacobson, & Maibom 2012; Radoilska 2012; Wakefield 2012; Bolton 2013; Ratcliffe & Stephan 2014; Varga 2016; Hoffman & Hansen 2017; Browne 2018); scrupulosity, obsessive-compulsive, and other volitional disorders (Glas, 2013; Szalai 2016; Summer & Sinnott-Armstrong 2019); anxiety (Horwitz & Wakefield 2012); autism spectrum conditions (Adams 2013; Baron-Cohen, Lombardo, & Tager-Flusberg 2013); dissociative disorders (Maiese 2016; Worrell & Denham 2016); defiance disorders (Potter 2014); borderline personality disorder (Potter 2009); and premenstrual dysphoric disorder (Gagné-Julien 2021).

The category of psychosis—which includes delusions (false beliefs that resist reality testing) and hallucinations (most often auditory)—has received considerable philosophical attention. With almost unfailing consequences for their subject in clinical, legal, social, and personal settings, the severity of hallucinations and delusions distinguishes them from the more controversial disorders noted thus far. The incidence of and pathology associated with hallucinations has been questioned, as has their origins and phenomenology (Leudar & Thomas 2000; Henriksen, Raballo, & Parnas 2015; Ratcliffe 2017). And delusions have attracted the particular attention of philosophers for their incomprehensibility and challenges for theories about meaning, language, belief, and intention (Coltheart & Davies 2000; Bortolotti 2009, 2020; Fletcher & Frith 2009; Miyazono 2019; Evans 2023). They have also been the impetus for important collaborative work between several sciences: in addition to being psychiatric disorders, delusions occur as symptoms of neurological diseases and brain injury, which have made them subject to considerable empirical study. Philosophical research on delusions primarily addresses issues their intelligibility, their status in relation to more normal doxastic states, and their place in explanatory models.

The intelligibility of delusions remains contested. Delusions are expressed using unexceptional syntax, and some involve content that, while inaccurate or implausible, is entirely comprehensible. These, Jaspers insisted, are secondary delusions; primary delusions, in contrast, are distinguished by their meaninglessness: attributing meaning to them is a misapplication of the hermeneutic approach (Jaspers 1913 [1963]; Gorski 2012). Others argue that all delusions are meaningless utterances (Berrios 1991), which is supported by findings from neuroscience (Gerrans 2014). In contrast, some argue that delusions are always comprehensible, but only when contextualized to a person’s entire life, ideas, and values (Bentall 2004; Mullen & Gillett 2014; Glover 2014; Wickham & Bentall 2016; Jeppsson 2021; Gipps 2022).

Delusions are belief-like, but disagreements arise over whether they are beliefs, imaginings, an incomplete form of one of these two, or a distinct hybrid form. The doxastic position (delusions are beliefs) must somehow accommodate the fact that delusions are not responsive to countervailing evidence and are only weakly behavior guiding (see Flores 2021 and the entry on Delusion). Associated more with imagining than with believing, these same features have led to the assertion that delusions are imaginings mistakenly identified as beliefs (Currie & Ravenscroft 2002; Broome & Bortolotti 2009) or the hybrid concept of “bimagining” (Egan 2009).

Increasingly, explanations of delusions are multi-factorial. Influential early models that grew out of research on single-themed delusions resulting from brain damage (e.g., Capgras) hypothesized two deficiencies. The first factor is an initiating aberrant experience or perception due to brain dysfunction, combined with some failure of the system of “belief fixation” by which initial beliefs are critically reviewed in light of other information (Davies et al. 2001; Aimola Davies & Davies 2009; Young 2011). The second factor in such “two factor” theories is faulty inference, which in some accounts is conceptualized as differing in degree (alone) from normal forms of reasoning error, such as attribution bias (Bentall 2004). In “prediction error” models, perceptual aberrations conflict with prior (Bayesian) expectations when accompanied by reasoning bias, giving rise to delusions (Stone & Young 2007; Mishara & Corlett 2009). The “polythematic” and complex delusions more often seen in the psychiatry clinic—which are partially driven by social and environmental factors—present significant challenges for cognitive science since they involve the higher cognitive systems that apparently resist modular analysis and decomposition.

10. Anti-psychiatry, Feminist Theory, Post- and Critical- Psychiatry, Neurodiversity and Identity Politics
10.1 Anti-psychiatry
“Anti-psychiatry” has come to stand for ideas from mid-twentieth century thinkers such as Thomas Szasz, R.D. Laing, and Michel Foucault. Many of these involved social and political critiques and calls to action, with real-world consequences that have been linked to deinstitutionalization, human rights movements, and a shift towards more autonomy-focused mental health care. Szasz and Laing rejected the appropriateness of analogizing particular “problems in living” (Szasz) with medical disorders, insisting that misapplication of the medical model to mental health was emblematic of the overreach of psychiatry. The practices and discourses within society and its institutions making up the era’s episteme are depicted historically by Foucault, the focus on the exercise of psychiatric power that, arising with modern science, is increasingly exerted through mechanisms of protection, surveillance, and control. With modernity, on this account, power is no longer brute force. Instead, it takes a more diffused and subtle form that imperceptibly disciplines and controls not only bodies, but selves (Foucault 1965; Rose 2009; Bracken & Thomas 2010, 2013; Iliopoulos 2012). Foucault’s sweeping ideas remain central to the “post psychiatry” and “critical psychiatry” that emerged during the beginning of the twenty-first century.

10.2 Feminist Theory
Interwoven with these ideas have been critiques from feminism and feminist theory. These include acknowledgment of the women’s actual and unwarranted institutionalization, emphasis on the harms of disempowerment and silencing (Kristeva 1987 [1989]), and discussions of epistemic injustice (Dotson 2011; Kidd, Spencer & Carel 2022; also see the entry on Feminist Social Epistemology). In a legacy affecting mental disorder even today, binary conceptualizations have assigned women and the feminine to illogicality, emotionality, subjectivity, the body, and madness—in contrast to men’s more valued traits (Lloyd 1984; Potter 2009). Feminist thinkers have focused on the medicalization of women’s normal traits; neglected and distorted research into gender-linked disorders; separate and unequal treatments for women; the mental health vulnerabilities associated with traditional women’s roles and identities; and diagnosis and treatment understood as tools of patriarchal social control (Russell 1995; Ussher 2011; Gagné-Julien 2021).

Feminism has consistently rejected traditional causal explanations of women’s disorder derived from allegedly natural biological predispositions, pointing instead to the effects of women’s oppressive socialization and to the consequences of devaluing women’s characteristics and abilities (Bluhm 2011). Some have emphasized the embodiment (and relationality) of the self and avoided the methodological individualism associated with psychiatric medicine (Bluhm, Jacobson, & Maibom 2012). Influenced by social theory and phenomenological approaches, more recent work focuses on the intersection of gender with marginality, invisibility, non-normativity, and oppression in lived experience (Nissim-Sabat 2013; Zeiler & Folkmarson Käll 2014).

10.3 Post and Critical Psychiatry
Proponents of post psychiatry reject both the modernist presuppositions of psychiatry and the assumption that disorder reflects flawed brain mechanisms or processes, arguing that these assumptions only serve to enhance the status of psychiatry and disempower those diagnosed with disorder (Bracken & Thomas 2005, Iliopoulos 2012). The new brain sciences will magnify this disempowerment, it is argued, with the agency and authority previously assigned to persons will be replaced by a bio-scientific “management of the mind” (Phillips 2009, 2013; Rose and Abi-Rached 2013). A more recent descendant of critical mid-twentieth century writing is critical psychiatry: critiques of the influence of the pharmacological industry (Phillips 1996, 2013; Moncrieff 2008; Whitaker & Cosgrove 2015; Karp 2017); a discourse around mental disorder that, influenced by hermeneutics, aims to be more sensitive to the meaning of symptoms (Bracken & Thomas 2010); and the promotion of a more equal and collaborative relationship between carers and those they treat (Double 2006; Cohen & Timimi 2008).

Associated with these ideas is growing recognition of the unique expertise of “service users” or “survivors” for understanding mental disorder and the importance of its inclusion for research (Faulkner & Leyzell 2000; Gergel 2012; Cooper 2017; Bueter 2018). These innovations have appealed to resources from critical theory, narrative research methods, the impediments to representational authority, and the co-production of knowledge (Voronka 2016; Russo & Sweeney 2016).

10.4 Neurodiversity
As the most recent among this range of broadly ‘anti psychiatry’ positions, neurodiversity offers a coherent account and has come of age within a cultural episteme that seems hospitable to it. Mental differences, it asserts, are equally natural and valuable, and no one type of functioning is more correct or valid than another. Analogies are drawn with differences of gender, ethnicity, and culture—including analogies involving social power inequalities. From its ready application to disorders on the autism spectrum, efforts have been made to apply the neurodiversity position more broadly, including to the symptoms of schizophrenia (Washington 2016, Chapman 2019, Chapman & Carel 2022).

10.5 Identity Politics
Claims arising from political movements made up of recipients of psychiatric care call for a seat at the policy-makers’ table; representational authority in the co-production of knowledge based on first person experience of psychiatric symptoms and treatment; attention to complaints of unjust treatment by the “survivors” of diagnosis and care; equality of mental health care with other disabilities or medical conditions; recognition of neuro-atypicality from proponents of a neurodiversity model of disorder (Ortega 2009; Polvora 2011); and from “mad pride”, the claim that madness is an attribution from which to draw strength and cultural identity. Largely neglected until now within psychiatry or philosophical writing, the claims of mad pride have recently been critically evaluated and related to the social theory of philosophers, such as Axel Honneth and Charles Taylor (Rashed 2019, 2021).

11. Future Prospects
Where might we expect philosophical work on mental disorder to go from here? One issue must be what role remains for conceptual analysis and commonsense psychology. Relatedly, whose standards should determine mental health? Modern science, and the merciless dictates of biology, or some richer eudaemonic vision? Even granted the authority to determine ideals of mental health, philosophers would encounter hard questions. How should we relinquish evaluative thinking in view of liberal traditions around responsibility and self identity? How generously should we be in attributing normalcy and diversity, rather than deficiency? How should we navigate the boundary of disorder and risk? New ways to understand, identify, and ameliorate mental disorders—along with technological advances that simultaneously permit new analyses of big data and exacerbate the hyperconnectedness of society—can only augment and extend such questions, perhaps in unimagined directions.

1. Varieties of Anarchism
There are various forms of anarchism. Uniting this variety is the general critique of centralized, hierarchical power and authority. Given that authority, centralization, and hierarchy show up in various ways and in different discourses, institutions, and practices, it is not surprising that the anarchist critique has been applied in diverse ways.

1.1 Political Anarchism
Anarchism is primarily understood as a skeptical theory of political legitimation. The term anarchism is derived from the negation of the Greek term arché, which means first principle, foundation, or ruling power. Anarchy is thus rule by no one or non-rule. Some argue that non-ruling occurs when there is rule by all—with consensus or unanimity providing an optimistic goal (see Depuis-Déri 2010).

Political anarchists focus their critique on state power, viewing centralized, monopolistic coercive power as illegitimate. Anarchists thus criticize “the state”. Bakunin provides a paradigm historical example, saying:

If there is a State, there must be domination of one class by another and, as a result, slavery; the State without slavery is unthinkable—and this is why we are the enemies of the State. (Bakunin 1873 [1990: 178])

A more recent example comes from Gerard Casey who writes, “states are criminal organizations. All states, not just the obviously totalitarian or repressive ones” (Casey 2012: 1).

Such sweeping generalizations are difficult to support. Thus anarchism as political philosophy faces the challenge of specificity. States have been organized in various ways. Political power is not monolithic. Sovereignty is a complicated matter that includes divisions and distributions of power (see Fiala 2015). Moreover, the historical and ideological context of a given anarchist’s critique makes a difference in the content of the political anarchist’s critique. Bakunin was responding primarily to a Marxist and Hegelian view of the state, offering his critique from within the global socialist movement; Casey is writing in the Twenty-First Century in the era of liberalism and globalization, offering his critique from within the movement of contemporary libertarianism. Some anarchists engage in broad generalizations, aiming for a total critique of political power. Others will present a localized critique of a given political entity. An ongoing challenge for those who would seek to understand anarchism is to realize how historically and ideologically diverse approaches fit under the general anarchist umbrella. We look at political anarchism in detail below.

1.2 Religious Anarchism
The anarchist critique has been extended toward the rejection of non-political centralization and authority. Bakunin extended his critique to include religion, arguing against both God and the State. Bakunin rejected God as the absolute master, saying famously, “if God really existed, it would be necessary to abolish him” (Bakunin 1882 [1970: 28]).

There are, however, religious versions of anarchism, which critique political authority from a standpoint that takes religion seriously. Rapp (2012) has shown how anarchism can be found in Taoism. And Ramnath (2011) has identified anarchist threads in Islamic Sufism, in Hindu bhakti movements, in Sikhism’s anti-caste efforts, and in Buddhism. We consider anarchism in connection with Gandhi below. But we focus here on Christian anarchism.

Christian anarchist theology views the kingdom of God as lying beyond any human principle of structure or order. Christian anarchists offer an anti-clerical critique of ecclesiastical and political power. Tolstoy provides an influential example. Tolstoy claims that Christians have a duty not to obey political power and to refuse to swear allegiance to political authority (see Tolstoy 1894). Tolstoy was also a pacifist. Christian anarcho-pacifism views the state as immoral and unsupportable because of its connection with military power (see Christoyannopoulos 2011). But there are also non-pacifist Christian anarchists. Berdyaev, for example, builds upon Tolstoy and in his own interpretation of Christian theology. Berdyaev concludes: “The Kingdom of God is anarchy” (Berdyaev 1940 [1944: 148]).

Christian anarchists have gone so far as to found separatist communities where they live apart from the structures of the state. Notable examples include New England transcendentalists such as William Garrison and Adin Ballou. These transcendentalists had an influence on Tolstoy (see Perry 1973 [1995]).

Other notable Christians with anarchist sympathies include Peter Maurin and Dorothy Day of the Catholic Worker movement. In more recent years, Christian anarchism has been defended by Jacques Ellul who links Christian anarchism to a broad social critique. In addition to being pacifistic, Ellul says, Christian anarchism should also be “antinationalist, anticapitalist, moral, and antidemocratic” (Ellul 1988 [1991: 13]). The Christian anarchist ought to be committed to “a true overturning of authorities of all kinds” (Ellul 1988 [1991: 14]). When asked whether a Christian anarchist should vote, Ellul says no. He states, “anarchy first implies conscientious objection” (Ellul 1988 [1991: 15]).

1.3 Theoretical Anarchism
Anarchist rejection of authority has application in epistemology and in philosophical and literary theory. One significant usage of the term shows up in American pragmatism. William James described his pragmatist philosophical theory as a kind of anarchism: “A radical pragmatist is a happy-go-lucky anarchistic sort of creature” (James 1907 [1981: 116]). James had anarchist sympathies, connected to a general critique of systematic philosophy (see Fiala 2013b). Pragmatism, like other anti-systematic and post-Hegelian philosophies, gives up on the search for an arché or foundation.

Anarchism thus shows up as a general critique of prevailing methods. An influential example is found in the work of Paul Feyerabend, whose Against Method provides an example of “theoretical anarchism” in epistemology and philosophy of science (Feyerabend 1975 [1993]). Feyerabend explains:

Science is an essentially anarchic enterprise: theoretical anarchism is more humanitarian and more likely to encourage progress than its law-and-order alternatives. (Feyerabend 1975 [1993: 9])

His point is that science ought not be constrained by hierarchically imposed principles and strict rule following.

Post-structuralism and trends in post-modernism and Continental philosophy can also be anarchistic (see May 1994). So-called “post-anarchism” is a decentered and free-flowing discourse that deconstructs power, questions essentialism, and undermines systems of authority. Following upon the deconstructive and critical work of authors such as Derrida, Deleuze, Foucault, and others, this critique of the arché goes all the way down. If there is no arché or foundation, then we are left with a proliferation of possibilities. Emerging trends in globalization, cyber-space, and post-humanism make the anarchist critique of “the state” more complicated, since anarchism’s traditional celebration of liberty and autonomy can be critically scrutinized and deconstructed (see Newman 2016).

Traditional anarchists were primarily interested in sustained and focused political activism that led toward the abolition of the state. The difference between free-flowing post-anarchism and traditional anarchism can be seen in the realm of morality. Anarchism has traditionally been critical of centralized moral authority—but this critique was often based upon fundamental principles and traditional values, such as autonomy or liberty. But post-structuralism—along with critiques articulated by some feminists, critical race theorists, and critics of Eurocentrism—calls these values and principles into question.

1.4 Applied Anarchism
The broad critical framework provided by the anarchist critique of authority provides a useful theory or methodology for social critique. In more recent iterations, anarchism has been used to critique gender hierarchies, racial hierarchies, and the like—also including a critique of human domination over nature. Thus anarchism also includes, to name a few varieties: anarcha-feminism or feminist anarchism (see Kornegger 1975), queer anarchism or anarchist queer theory (see Daring et al. 2010), green anarchism or eco-anarchism also associated with anarchist social ecology (see Bookchin 1971 [1986]), Black and indigenous anarchisms and other anarchist critiques of white supremacy and Eurocentrism (to be discussed below); and even anarcho-veganism or “veganarchism” (see Nocella, White, & Cudworth 2015). In the anarcho-vegan literature we find the following description of a broad and inclusive anarchism:

Anarchism is a socio-political theory which opposes all systems of domination and oppression such as racism, ableism, sexism, anti-LGBTTQIA, ageism, sizeism, government, competition, capitalism, colonialism, imperialism and punitive justice, and promotes direct democracy, collaboration, interdependence, mutual aid, diversity, peace, transformative justice and equity. (Nocella et al. 2015: 7)

A thorough-going anarchism would thus offer a critique of anything and everything that smacks of hierarchy, domination, centralization, and unjustified authority.

Anarchists who share these various commitments often act upon their critique of authority by engaging in nonconformist practices (free love, nudism, gender disruption, and so on) or by forming intentional communities that live “off the grid” and outside of the norms of mainstream culture. In extreme forms this becomes anarcho-primitivism or anti-civilizational anarchism (see Zerzan 2008, 2010; Jensen 2006). Alternative anarchist societies have existed in religious communes in post-Reformation Europe and in the early United States, in Nineteenth Century American utopian communities, the hippy communes of the Twentieth Century, anarchist squats, temporary autonomous zones (see Bey 1985), and occasional gatherings of like-minded people.

Given this sort of antinomianism and non-conformism it is easy to see that anarchism also often includes a radical critique of traditional ethical norms and principles. Thus radical ethical anarchism can be contrasted with what we might call bourgeois anarchism (with radical anarchism seeking to disrupt traditional social norms and bourgeois anarchism seeking freedom from the state that does not seek such disruption). And although some argue that anarchists are deeply ethical—committed to liberty and solidarity—others will argue that anarchists are moral nihilists who reject morality entirely or who at least reject the idea that there could be a single source of moral authority (see essays in Franks & Wilson 2010).

In more recent explorations and applications of anarchist thought, the anarchist critique has been related and connected to a variety of emerging theoretical issues and applied concerns. Hilary Lazar (2018) for example, explores how anarchism connects to intersectionality and issues related to multiculturalism. And Sky Croeser (2019) explores how anarchism is connected to the emerging technologies including the Internet. And there are anarchist elements in the development of shared technological and information, as for example in the development of cryptocurrencies, which create economies that outside of traditional state-based economic systems.

1.5 Black, Indigenous, and Decolonizing Anarchism
As mentioned above, among the varieties of applied anarchism we find anarchism associated with various liberation movements and critiques of white supremacy, Eurocentrism, and colonialism. This could be connected with feminist anarchism, women’s liberation movements, and an anarchist critique of patriarchy. We’ll focus here on the anarchist critique found in Black and indigenous liberation movements. Gandhi’s movement in India could be included here (as discussed below).

One focal point here is a claim about anarchist characteristics thought to be found in the social structures of indigenous peoples. Sometimes this is a romantic projection of anti-civilizational anarchists such as John Zerzan, who echoes Rousseau’s naive and ill-informed ideal of the “noble savage.” One must be careful to avoid essentializing claims made about indigenous cultures and political societies. The Inca and the Aztec empires were obviously not utopian anarchist collectives. Nonetheless, scholars of indigeneity affirm the anarchist critique of dominant hegemonies as part of the effort of liberation that would allow indigenous people a degree of self-determination (see Johnson and Ferguson 2019).

Black and indigenous anarchisms provide a radical critique, which holds that the global history of genocide, slavery, colonization, and exploitation rest upon the assumption of white supremacy. White supremacy is thus understood, from this point of view, as a presupposition of statism, centralization, hierarchy, and authority. The anarchist critique of white supremacy is thus linked to a critique of social and political systems that evolved out of the history of slavery and native genocide to include apartheid, inequality, caste/racial hierarchies, and other forms of structural racism. Some defenders of Black anarchism go so far as to suggest that when “Blackness” is defined in opposition to structures of white supremacy, there is a kind of anarchism woven into the concept. Anderson and Samudzi write,

While bound to the laws of the land, Black America can be understood as an extra-state entity because of Black exclusion from the liberal social contract. Due to this extra-state location, Blackness is, in so many ways, anarchistic. (Anderson and Samudzi 2017: no page numbers)

This implies that the experience of Black people unfolds in a social and political world that its defined by its exclusion from power. A similar implication holds for indigenous people, who have been subjugated and dominated by colonial power. Liberation movements thus spring from a social experience that is in a sense anarchic (i.e., developed in exclusion from and opposition to structures of power). It is not surprising, then, that some liberatory activists espouse and affirm anarchism. The American activist Lorenzo Kom’boa Ervin, for example, affirms anarchism in pursuit of Black liberation (Ervin 1997 [2016]). He explains that Black anarchism is different from what he describes as the more authoritarian hierarchy of the Black Panther party. He also argues against the authoritarian structure of religiously oriented Black liberation movements, such as that led by Martin Luther King, Jr.

A significant issue in Black and indigenous anarchisms is the effort to decolonize anarchism itself. Many of the key figures in the anarchist tradition are white, male, and European. The concerns of anarchists such as Kropotkin or Bakunin may be different from the concerns of African Americans or from the concerns of indigenous people in Latin America or elsewhere around the globe. One solution to this problem is to retrieve forgotten voices from within the tradition. In this regard, we might consider Lucy Parsons (also known as Lucy Gonzalez), a former slave who espoused anarchism. Parsons explained that she affirmed anarchism because the political status quo produced nothing but misery and starvation for the masses of humanity. To resolve this an anarchist revolution was needed. Parsons said,

Most anarchists believe the coming change can only come through a revolution, because the possessing class will not allow a peaceful change to take place; still we are willing to work for peace at any price, except at the price of liberty. (Parsons 1905 [2010])

2. Anarchism in Political Philosophy
Anarchism in political philosophy maintains that there is no legitimate political or governmental authority. In political philosophy anarchy is an important topic for consideration—even for those who are not anarchists—as the a-political background condition against which various forms of political organization are arrayed, compared, and justified. Anarchy is often viewed by non-anarchists as the unhappy or unstable condition in which there is no legitimate authority. Anarchism as a philosophical idea is not necessarily connected to practical activism. There are political anarchists who take action in order to destroy what they see as illegitimate states. The popular imagination often views anarchists as bomb-throwing nihilists. But philosophical anarchism is a theoretical standpoint. In order to decide who (and whether) one should act upon anarchist insight, we require a further theory of political action, obligation, and obedience grounded in further ethical reflection. Simmons explains that philosophical anarchists “do not take the illegitimacy of states to entail a strong moral imperative to oppose or eliminate states” (Simmons 2001: 104). Some anarchists remain obedient to ruling authorities; others revolt or resist in various ways. The question of action depends upon a theory of what sort of political obligation follows from our philosophical, moral, political, religious, and aesthetic commitments.

2.1 Anarchism in the History of Political Philosophy
There is a long history of political anarchism. In the ancient world, anarchism of a sort can be found in the ideas of the Epicureans and Cynics. Kropotkin makes this point in his 1910 encyclopedia article. Although they did not employ the term anarchism, the Epicureans and Cynics avoided political activity, advising retreat from political life in pursuit of tranquility (ataraxia) and self-control (autarkeai). The Cynics are also known for advocating cosmopolitanism: living without allegiance to any particular state or legal system, while associating with human beings based upon moral principle outside of traditional state structures. Diogenes the Cynic had little respect for political or religious authority. One of his guiding ideas was to “deface the currency”. This meant not only devaluing or destroying monetary currency but also a general rejection of the norms of civilized society (see Marshall 2010: 69). Diogenes often mocked political authorities and failed to offer signs of respect. While Diogenes actively disrespected established norms, Epicurus counseled retreat. He advised living unnoticed and avoiding political life (under the phrase me politeuesthai—which can be understood as an anti-political admonition).

The assumption that anarchy would be unhappy or unstable leads to justifications of political power. In Hobbes’ famous phrase, in the stateless—anarchic—condition of “the state nature” human life would be solitary, poor, nasty, brutish and short. Hobbes’ social contract—as well as other versions of the social contract theory as found for example in Locke or Rousseau—are attempts to explain how and why the political state emerges from out of the anarchic state of nature.

Anarchists respond by claiming that the state tends to produce its own sort of unhappiness: as oppressive, violent, corrupt, and inimical to liberty. Discussions about the social contract thus revolve around the question of whether the state is better than anarchy—or whether states and state-like entities naturally and inevitably emerge from out of the original condition of anarchy. One version of this argument about the inevitable emergence of states (by way of something like an “invisible hand”) is found in Nozick’s influential Anarchy, State, Utopia (1974). While Nozick and other political philosophers take anarchy seriously as a starting point, anarchists will argue that invisible hand arguments of this sort ignore the historical actuality of states, which develop out of a long history of domination, inequality, and oppression. Murray Rothbard has argued against Nozick and social contract theory, saying, “no existing state has been immaculately conceived” (Rothbard 1977: 46). Different versions of the social contract theory, such as we find in John Rawls’s work, view the contract situation as a heuristic device allowing us to consider justice from under “the veil of ignorance”. But anarchists will argue that the idea of the original position does not necessarily lead to the justification of the state—especially given background knowledge about the tendency of states to be oppressive. Crispin Sartwell concludes:

Even accepting more or less all of the assumptions Rawls packs into the original position, it is not clear that the contractors would not choose anarchy. (Sartwell 2008: 83)

The author of the present essay has described anarchism that results from a critique of the social contract tradition as “liberal social contract anarchism” (Fiala 2013a).

An important historical touchstone is William Godwin. Unlike Locke and Hobbes who turned to the social contract to lead us out of the anarchic state of nature, Godwin argued that the resulting governmental power was not necessarily better than anarchy. Locke, of course, allows for revolution when the state becomes despotic. Godwin builds upon that insight. He explained, “we must not hastily conclude that the mischiefs of anarchy are worse than those which government is qualified to produce” (Godwin 1793: bk VII, chap. V, p. 736). He claimed,

It is earnestly to be desired that each man should be wise enough to govern himself, without the intervention of any compulsory restraint; and, since government, even in its best state, is an evil, the object principally to be aimed at is that we should have as little of it as the general peace of human society will permit. (Godwin 1793: bk III, chap. VII, p. 185–6)

Like Rousseau, who praised the noble savage, who was free from social chains until forced into society, Godwin imagined original anarchy developing into the political state, which tended on his view to become despotic. Once the state comes into being, Godwin suggests that despotism is the primary problem since “despotism is as perennial as anarchy is transitory” (Godwin 1793: bk VII, chap. V, p. 736).

Anarchism is often taken to mean that individuals ought to be left alone without any unifying principle or governing power. In some cases anarchism is related to libertarianism (or what is sometimes called “anarcho-capitalism”). But non-rule may also occur when there is unanimity or consensus—and hence no need for external authority or a governing structure of command and obedience. If there were unanimity among individuals, there would be no need for “ruling”, authority, or government. The ideas of unanimity and consensus are associated with the positive conception of anarchism as a voluntary association of autonomous human beings, which promotes communal values. One version of the anarchist ideal imagines the devolution of centralized political authority, leaving us with communes whose organizational structure is open-ended and consensual.

Given this emphasis on communal organization it is not surprising that political anarchism has a close historical association with communism, despite the connection mentioned above with free market capitalism. Authors such as Bakunin, Kropotkin, and Goldman developed their anarchism as a response to Marx and Marxism. One of the first authors to explicitly affirm anarchism, Pierre Proudhon, defended a kind of “communism”, which he understood as being grounded in decentralized associations, communes, and mutual-aid societies. Proudhon thought that private property created despotism. He argued that liberty required anarchy, concluding,

The government of man by man (under whatever name it be disguised) is oppression. Society finds its highest perfection in the union of order with anarchy. (Proudhon 1840 [1876: 286])

Following Proudhon, Bakunin, Kropotkin, and the other so-called “classical anarchists”, anarchism comes to be seen as a focal point for political philosophy and activism.

Let’s turn to a conceptual analysis of different arguments made in defense of anarchism.

2.2 Absolute, Deontological, and a priori Anarchism
Anarchists often make categorical claims to the effect that no state is legitimate or that there can no such thing as a justifiable political state. As an absolute or a priori claim, anarchism holds that all states always and everywhere are illegitimate and unjust. The term “a priori anarchism” is found in Simmons 2001; but it is employed already by Kropotkin in his influential 1910 article on anarchism, where he claims that anarchists are not utopians who argue against the state in a priori fashion (Kropotkin 1927 [2002: 285]). Despite Kropotkin’s claim, some anarchists do offer a priori arguments against the state. This sort of claim rests upon an account of the justification of authority that is usually grounded in some form of deontological moral claim about the importance of individual liberty and a logical claim about the nature of state authority.

One typical and well-known example of this argument is found in the work of Robert Paul Wolff. Wolff indicates that legitimate authority rests upon a claim about the right to command obedience (Wolff 1970). Correlative to this is a duty to obey: one has a duty to obey legitimate authority. As Wolff explains, by appealing to ideas found in Kant and Rousseau, the duty to obey is linked to notions about autonomy, responsibility, and rationality. But for Wolff and other anarchists, the problem is that the state does not have legitimate authority. As Wolff says of the anarchist, “he will never view the commands of the state as legitimate, as having a binding moral force” (Wolff 1970: 16). The categorical nature of this claim indicates a version of absolute anarchism. If the state’s commands are never legitimate and create no moral duty of obedience, then there can never be a legitimate state. Wolff imagines that there could be a legitimate state grounded in “unanimous direct democracy”—but he indicates that unanimous direct democracy would be “so restricted in its application that it offers no serious hope of ever being embodied in an actual state” (Wolff 1970: 55). Wolff concludes:

If all men have a continuing obligation to achieve the highest degree of autonomy possible, then there would appear to be no state whose subjects have a moral obligation to obey its commands. Hence, the concept of a de jure legitimate state would appear to be vacuous, and philosophical anarchism would seem to be the only reasonable political belief for an enlightened man. (Wolff 1970: 17)

As Wolff puts it here, there appears to be “no state” that is legitimate. This claim is stated in absolute and a priori fashion, a point made by Reiman in his critique of Wolff (Reiman 1972). Wolff does not deny, by the way, that there are de facto legitimate states: governments often do have the approval and support of the people they govern. But this approval and support is merely conventional and not grounded in a moral duty; and approval and support are manufactured and manipulated by the coercive power and propaganda and ideology of the state.

We noted here that Wolff’s anarchism is connected to Kant. But Kant is no anarchist: he defended the idea of enlightened republican government in which autonomy would be preserved. Rousseau may be closer to espousing anarchism in some of his remarks—although these are far from systematic (see McLaughlin 2007). Some authors view Rousseau as espousing something close to “a posteriori philosophical anarchism” (see Bertram 2010 [2017])—which we will define in the next section. Among classical political philosophers, we might also consider Locke in connection with “libertarian anarchism” (see Varden 2015) or Locke as offering a theory “on the edge of anarchism”, as Simmons has put it (Simmons 1993). But despite his strong defense of individual rights, the stringent way he describes voluntary consent, and his advocacy of revolution, Locke believes that states can be defended based upon the social contract theory.

Leaving the canonical authors of Western political philosophy aside, the most likely place to find deontological and a priori anarchism is among the Christian anarchists. Of course, most Christians are not anarchists. But those Christians who espouse anarchism usually do so with the absolute, deontological, and a priori claims of the sort made by Tolstoy, Berdyaev, and Ellul—as noted above.

2.3 Contingent, Consequentialist, and a posteriori Anarchism
A less stringent form of anarchism will argue that states could be justified in theory—even though, in practice, no state or very few states are actually legitimate. Contingent anarchism will hold that states in the present configuration of things fail to live up to the standards of their own justification. This is an a posteriori argument (see Simmons 2001) based both in a theoretical account of the justification of the state (for example, the social contract theory of liberal-democratic theory) and in an empirical account of how and why concrete states fail to be justified based upon this theory. The author of the present article has offered a version of this argument based upon the social contract theory, holding that the liberal-democratic social contract theory provides the best theory of the justification of the state, while arguing that very few states actually live up to the promise of the social contract theory (Fiala 2013a).

One version of the contingent anarchist argument focuses on the question of the burden of proof for accounts that would justify political authority. This approach has been articulated by Noam Chomsky, who explains:

[This] is what I have always understood to be the essence of anarchism: the conviction that the burden of proof has to be placed on authority, and that it should be dismantled if that burden cannot be met. Sometimes the burden can be met. (Chomsky 2005: 178)

Chomsky accepts legitimate authority based in ordinary experience: for example, when a grandfather prevents a child from darting out into the street. But state authority is a much more complicated affair. Political relationships are attenuated; there is the likelihood of corruption and self-interest infecting political reality; there are levels and degrees of mediation, which alienate us from the source of political authority; and the rational autonomy of adults is important and fundamental. By focusing on the burden of proof, Chomsky acknowledges that there may be ways to meet the burden of proof for the justification of the state. But he points out that there is a prima facie argument against the state—which is based in a complex historical and empirical account of the role of power, economics, and historical inertia in creating political institutions. He explains:

Such institutions face a heavy burden of proof: it must be shown that under existing conditions, perhaps because of some overriding consideration of deprivation or threat, some form of authority, hierarchy, and domination is justified, despite the prima facie case against it—a burden that can rarely be met. (Chomsky 2005: 174)

Chomsky does not deny that the burden of proof could be met. Rather, his point is that there is a prima facie case against the state, since the burden of proof for the justification of the state is rarely met.

Contingent anarchism is based in consequentialist reasoning, focused on details of historical actuality. Consequentialist anarchism will appeal to utilitarian considerations, arguing that states generally fail to deliver in terms of promoting the happiness of the greater number of people—and more strongly that state power tends to produce unhappiness. The actuality of inequality, classism, elitism, racism, sexism, and other forms of oppression can be used to support an anarchist argument, holding that even though a few people benefit from state power, a larger majority suffers under it.

There is a significant difference between anarchism that is offered in pursuit of utilitarianism’s greater happiness ideal and anarchism that is offered in defense of the minority against the tyranny of the majority. As we shall see in the next section, individualist anarchists are primarily concerned with the tendency of utilitarian politics to sacrifice the rights of individuals in the name of the greater good.

Before turning to that conception of anarchism, let’s note two classical authors who offer insight into utilitarian anarchism. Godwin articulated a form of anarchism that is connected to a utilitarian concern. Godwin’s general moral thought is utilitarian in basic conception, even though he also argues based upon fundamental principles such as the importance of liberty. But Godwin’s arguments are a posteriori, based upon generalizations from history and with an eye toward the future development of happiness and liberty. He writes:

Above all we should not forget, that government is an evil, an usurpation upon the private judgment and individual conscience of mankind; and that, however we may be obliged to admit it as a necessary evil for the present. (Godwin 1793: bk V, ch. I, p. 380)

This claim is similar to Chomsky’s insofar as it recognizes the complicated nature of the historical dialectic. The goal of political development should be in a direction that goes beyond the state (and toward the development of individual reason and morality). But in our present condition, some form of government may be “a necessary evil”, which we ought to strive to overcome. The point here is that our judgments about the justification of the state are contingent: they depend upon present circumstances and our current form of development. And while states may be necessary features of the current human world, as human beings develop further, it is possible that the state might outlive its usefulness.

We should note that utilitarian arguments are often used to support state structures in the name of the greater good. Utilitarian anarchists will argue that states fail to do this. But utilitarian conclusions are not usually based upon a fundamental appeal to moral principles such as liberty or the rights of the individual. Thus Bentham described claims about human rights as “anarchical fallacies” because they tended to lead toward anarchy, which he rejected. Bentham described the difference between a moderate utilitarian effort at reform and the anarchist’s revolutionary doctrine of human rights, saying that

the anarchist setting up his will and fancy for a law before which all mankind are called upon to bow down at the first word—the anarchist, trampling on truth and decency, denies the validity of the law in question,—denies the existence of it in the character of a law, and calls upon all mankind to rise up in a mass, and resist the execution of it. (Bentham 1843: 498)

More principled deontological anarchism will maintain that states violate fundamental rights and so are not justified. But utilitarian anarchism will not primarily be worried about the violation of a few people’s rights (although that is obviously a relevant consideration). Rather, the complaint for a utilitarian anarchist is that state structures tend to produce disadvantages for the greater number of people. Furthermore what Oren Ben-Dor calls “utilitarian-based anarchism” is based upon the idea that there is no a priori justification of the state (Ben-Dor 2000: 101–2). For the utilitarian, this all depends upon the circumstances and conditions. Ben-Dor calls this anarchism because it rejects any a priori notion of state justification. In other words, the utilitarian anarchist does not presume that states are justifiable; rather a utilitarian anarchist will hold that the burden of proof rests upon the defender of states to show that state authority is justifiable on utilitarian grounds, by bringing in historical and empirical data about human nature, human flourishing, and successful social organization.

2.4 Individualism, Libertarianism, and Socialist Anarchism
Forms of anarchism also differ in terms of the content of the theory, the focal point of the anarchist critique, and the imagined practical impact of anarchism. Socialist forms of anarchism include communist anarchism associated with Kropotkin and communitarian anarchism (see Clark 2013). The socialist approach focuses on the development of social and communal groups, which are supposed to thrive outside of hierarchical and centralized political structures. Individualist forms of anarchism include some forms of libertarianism or anarcho-capitalism as well as egoistically oriented antinomianism and non-conformism. The individualistic focus rejects group identity and ideas about social/communal good, while remaining firmly rooted in moral claims about the autonomy of the individual (see Casey 2012).

Individualistic anarchism is historically associated with ideas found in Stirner who said, “every state is a despotism” (Stirner 1844 [1995: 175]). He argued that there was no duty to obey the state and the law because the law and the state impair self-development and self-will. The state seeks to tame our desires and along with the church it undermines self-enjoyment and the development of unique individuality. Stirner is even critical of social organizations and political parties. While not denying that an individual could affiliate with such organizations, he maintains that the individual retains rights and identity against the party or social organization: he embraces the party; but he ought not allow himself to be “embraced and taken up by the party” (Stirner 1844 [1995: 211]). Individualist anarchism has often been attributed to a variety of thinkers including Josiah Warren, Benjamin Tucker, and Thoreau.

Individualist anarchism also seems to have something in common with egoism of the sort associated with Ayn Rand. But Rand dismissed anarchism as “a naïve floating abstraction” that could not exist in reality; and she argued that governments properly existed to defend people’s rights (Rand 1964). A more robust sort of pro-capitalist anarchism has been defended by Murray Rothbard, who rejects “left-wing anarchism” of the sort he associates with communism, while applauding the individualist anarchism of Tucker (Rothbard 2008). Rothbard continues to explain that since anarchism has usually been considered as being primarily a left-wing communist phenomenon, libertarianism should be distinguished from anarchism by calling it “non-archism” (Rothbard 2008). A related term has been employed in the literature, “min-archism”, which has been used to describe the minimal state that libertarians allow (see Machan 2002). Libertarians are still individualists, who emphasize the importance of individual liberty, even though they disagree with full-blown anarchists about the degree to which state power can be justified.

It is worth considering here, the complexity of the notion of liberty under consideration by appealing to Isaiah Berlin’s well-known distinction between negative and positive liberty (Berlin 1969). Some individualist anarchists appear to focus on negative liberty, i.e., freedom from constraint, authority, and domination. But anarchism has also been concerned with community and the social good. In this sense, anarchists are focused on something like positive liberty and concerned with creating and sustaining the social conditions necessary for actualizing human flourishing. In this regard, anarchists have also offered theories of institutional rules and social structures that are non-authoritarian. This may sound paradoxical (i.e., that anarchists espouse rules and structures at all). But Prichard has argued that anarchists are also interested in “freedom within” institutions and social structures. According to Prichard rather than focusing on state-authority, anarchist institutions will be be open-ended processes that are complex and non-linear (Prichard 2018).

We see then, that individualist anarchism that focuses only on negative liberty is often rejected by anarchists who are interested in reconceiving community and restructuring society along more egalitarian lines. Indeed, individualistic anarchism has been criticized as merely a matter of “lifestyle” (criticized in Bookchin 1995), which focuses on dress, behavior, and other individualistic choices and preferences. Bookchin and other critics of lifestyle individualism will argue that mere non-conformism does very little to change the status quo and overturn structures of domination and authority. Nor does non-conformism and lifestyle anarchism work to create and sustain systems that affirm liberty and equality. But defenders of lifestyle non-conformism will argue that there is value in opting out of cultural norms and demonstrating contempt for conformity through individual lifestyle choices.

A more robust form of individualist anarchism will focus on key values such as autonomy and self-determination, asserting the primacy of the individual over and against social groups as a matter of rights. Individualist anarchists can admit that collective action is important and that voluntary cooperation among individuals can result in beneficial and autonomy preserving community. Remaining disputes will consider whether what results from individual cooperation is a form of capitalism or a form of social sharing or communism. Libertarian anarchists or anarcho-capitalists will defend free market ideas based upon individual choices in trading and producing goods for market.

On the other hand, socialist or communistically oriented anarchism will focus more on a sharing economy. This could be a large form of mutualism or something local and concrete like the sharing of family life or the traditional potlatch. But these ideas remain anarchist to the extent that they want to avoid centralized control and the development of hierarchical structures of domination. Unlike state-centered communism of the sort developed by Marxists, anarchist communism advocates decentralization. The motto of this approach comes from Kropotkin: “all for all”. In The Conquest of Bread (1892) Kropotkin criticizes monopolistic centralization that prevents people from gaining access to socially generated wealth. The solution is “all for all”: “What we proclaim is the Right to Well-Being: Well-Being for All!” (Kropotkin 1892 [1995: 20]). The communist idea that all humans should enjoy the fruits of the collective human product shares something with the Marxist idea of “to each according to his need” (Marx 1875). But Kropotkin argues for the need to evolve beyond centralized communist control—what he criticizes as mere “collectivism”—and toward anarchist communism:

Anarchy leads to communism, and communism to anarchy, both alike being expressions of the predominant tendency in modern societies, the pursuit of equality. (Kropotkin 1892 [1995: 31])

Kropotkin argues that the communal impulse already exists and that the advances in social wealth made possible by the development of individualistic capitalism make it likely that we will develop in the direction of communal sharing. He argues that the tendency of history is away from centralized power and toward equality and liberty—and toward the abolition of the state. Kropotkin’s communist anarchism is based upon some historical and empirical claims: about whether things can actually be arranged more satisfactorily without state intervention; and about whether states really do personify injustice and oppression. Libertarianism and anarcho-capitalism also think that the free market will work to adequately maximize human well-being and help individuals to realize their own autonomy. But for the socialist and communist anarchists, the question of individual self-realization is less important than the idea of social development. Kropotkin’s “all for all” indicates a moral and ontological focus that is different from what we find among the individualists.

Socialist and communally focused forms of anarchism emphasize the importance of social groups. For example, families can be viewed as anarchic structures of social cooperation and solidarity. A social anarchist would be critical of hierarchical and domineering forms of family organization (for example, patriarchal family structure). But social anarchists will emphasize the point that human identity and flourishing occur within extended social structures—so long as it remains a free and self-determining community.

The tension between individualist and socialist anarchism comes to a head when considering the question of the degree to which an individual ought to be subordinated to the community. One problem for so-called “communitarian” theories of social and political life is that they can result in the submergence of individuals into the communal identity. Individualists will want to struggle against this assault upon autonomy and individual identity. Communalists may respond, as Clark does, by claiming that the ideal of a genuine community of autonomous individuals remains a hoped for dream of an “impossible community” (Clark 2013). On the other hand communally focused theorists will point out that individual human beings cannot exist outside of communal structures: we are social animals who flourish and survive in communities. Thus radical individualism also remains a dream—and as more politically oriented anarchists will point out, individualism undermines the possibility of organized political action, which implies that individualist anarchists will be unable to successfully resist political structures of domination.

3. Anarchism and Political Activity
Anarchism forces us to re-evaluate political activity. Ancient Greek philosophers such as Aristotle and Plato held that human beings flourished within just political communities and that there was a virtue in serving the polis. Modern political philosophy tended to hold, as well, that political action—including obedience to the law and the ideal of a rule of law—was noble and enlightened. In Hegelian political philosophy, these ideas combine in a way that celebrates citizenship and service to the state. And in contemporary liberal political philosophy, it is often presumed that obedience to the law is required as a prima facie duty (see Reiman 1972; Gans 1992). Anarchists, of course, call this all into question.

The crucial question for anarchists is thus whether one ought to disengage from political life, whether one ought to submit to political authority and obey the law, or whether one ought to engage in active efforts to actively abolish the state. Those who opt to work actively for the abolition of the state often understand this as a form of “direct action” or “propaganda of the deed”. The idea of direct action is often viewed as typical of anarchists, who believe that something ought to be done to actively abolish the state including: graffiti, street theater, organized occupations, boycotts, and even violence. There are disputes among anarchists about what ought to be done, with an important dividing line occurring with regard to the question of violence and criminal behavior.

Before turning to that discussion, let’s note one further important theoretical distinction with regard to the question of taking action, connected to the typology offered above: whether action should be justified in consequentialist or non-consequentialist terms. Franks has argued that anarchist direct action ought to exemplify a unity of means and ends (Franks 2003). On this view, if liberation and autonomy are what anarchists are pursuing, then the methods used to obtain these goods must be liberationist and celebrate autonomy—and embody this within direct action. Franks argues that the idea that “the end justifies the means” is more typical of state-centered movements, such as Bolshevism—and of right-wing movements. While some may think that anarchists are willing to engage in action “by any means necessary”, that phraseology and the crass consequentialism underlying it is more typical of radical movements which are not anarchist. Coercive imposition of the anarchist ideal re-inscribes the problem of domination, hierarchy, centralization, and monopolistic power that the anarchist was originally opposed to.

3.1 Nonviolence, Violence, and Criminality
One significant philosophical and ethical problem for politically engaged anarchists is the question of how to avoid ongoing cycles of power and violence that are likely to erupt in the absence of centralized political power. One suggestion, mentioned above, is that anarchists will often want to emphasize the unity of means and ends. This idea shows why there is some substantial overlap and conjunction between anarchism and pacifism. Pacifist typically emphasize the unity of means and ends. But not all pacifists are anarchists. However, we mentioned above that there is a connection between anarchism and Christian pacifism, as found in Tolstoy, for example. Gandhi was influenced by Tolstoy and the anarchists. Although Gandhi is better known as an anti-colonial activist, Marshall includes Gandhi among the anarchists (Marshall 2010: chapter 26). It is possible to reconstruct anti-colonial movements and arguments about self-determination and home rule as a kind of anarchism (aimed at destroying colonial power and imperial states). Gandhi noted that there were many anarchists working in India in his time. In saying this, Gandhi uses the term anarchism to characterize bomb-throwing advocates of violence. He says: “I myself am an anarchist, but of another type” (Gandhi 1916 [1956: 134]). Gandhian anarchism, if there is such a thing, embraces nonviolence. In general nonviolent resistance as developed in the Tolstoy-Gandhi-King tradition fits with an approach that turns away from political power and views the state as a purveyor of war and an impediment to equality and human development.

Objecting to this anarcho-pacifist approach are more militant activists who advocate direct action that can include sabotage and other forms of political violence including terrorism. Emma Goldman explains, for example, that anti-capitalist sabotage undermines the idea of private possession. While the legal system considers this to be criminal, Goldman contends it is not. She explains,

it is ethical in the best sense, since it helps society to get rid of its worst foe, the most detrimental factor of social life. Sabotage is mainly concerned with obstructing, by every possible method, the regular process of production, thereby demonstrating the determination of the workers to give according to what they receive, and no more. (Goldman 1913 [1998: 94])

Goldman struggled with the question of violence through the course of her career. Early on she was a more vocal proponent of revolutionary violence. She began to rethink this later. Nonetheless, like other anarchists of her generation, she attributed violence to the state, which she opposed. She writes:

I believe that Anarchism is the only philosophy of peace, the only theory of the social relationship that values human life above everything else. I know that some Anarchists have committed acts of violence, but it is the terrible economic inequality and great political injustice that prompt such acts, not Anarchism. Every institution today rests on violence; our very atmosphere is saturated with it. (Goldman 1913 [1998: 59])

Goldman views anarchist violence as merely reactive. In response to state violence, the anarchists often argued that they were merely using violence in self-defense. Another defender of violence is Malatesta who wrote that the revolution against the violence of the ruling class must be violent. He explained:

I think that a regime which is born of violence and which continues to exist by violence cannot be overthrown except by a corresponding and proportionate violence. (Malatesta 1925 [2015: 48])

Like Goldman, Malatesta warned against violence becoming an end in itself and giving way to brutality and ferocity for its own sake. He also described anarchists as preachers of love and advocates of peace. He said,

what distinguishes the anarchists from all others is in fact their horror of violence, their desire and intention to eliminate physical violence from human relations. (Malatesta 1924 [2015: 46])

But despite this rejection of violence, Malatesta advocates violence as a necessary evil.

Anarchist violence appears as the violence of an individual against the state. It is easy to see why such violence would be characterized as terroristic and criminal. For an individual to declare war against the state and take action to disrupt the state is criminal. And thus anarchists have also been interested in a critique of crime and criminality—arguing that it is the law and the legal system that creates and produces crime and criminality. This critique was advanced by Kropotkin as early as the 1870s, when he called prisons “schools for crime”. Similar ideas are found in Foucault and in more recent criticisms of mass incarceration. Contemporary anarchists will argue that mass incarceration is an example of state power run amok.

3.2 Disobedience, Revolution, and Reform
The question of violence leads us to a further issue: the question of obedience, disobedience, resistance, and political obligation. Much could be said here about the nature of political obligation and obedience: including whether obedience is merely pragmatic and strategic or based upon notions about loyalty and claims about identification with the nation and its laws. But it is clear that anarchists have no principled reason for political obedience. If the anarchist views the state as illegitimate, then obedience and participation are merely a matter of choice, preference, and pragmatism—and not a matter of loyalty or duty.

Christian anarchists will look, for example, to the case of Jesus and his idea of rendering unto Caesar what is due to Caesar (Matthew 22:15–22). The anarchist interpretation of this passage claims that this is an indication both of Jesus’s disaffection with the state and with his grudging acquiescence to political authority. Christoyannopoulos argues, “Jesus’ political subversion is carried out through submission rather than revolt” (Christoyannopoulos 2010: 156). The crucifixion, on this interpretation, is a subversive event, which “unmasks” political power as “demonic” and illegitimate. Jesus does not recognize the ultimate moral and religious authority of Caesar or Pilate. But he goes along with the political regime. Thus some anarchists may simply be compliant and submissive.

But politically motivated anarchists encourage resistance to state power, including strategic and principled disobedience. Such disobedience could involve symbolic actions—graffiti and the like—or acts of civil resistance, protests, tax resistance and so on—up to, and possibly including, sabotage, property crime, and outright violence. Again, there is overlap with the discussion of violence here, but let’s set that question aside and focus on the notion of civil disobedience.

One important example is found in Thoreau, who famously explained his act of disobedience by tax resistance as follows:

In fact, I quietly declare war with the State, after my fashion, though I will still make what use and get what advantage of her I can, as is usual in such cases. (Thoreau 1849 [1937: 687])

Thoreau’s disobedience is principled. He recognizes that a declaration of war against the state is a criminal act. He willingly goes to jail. But he also admits that he will cooperate with the state in other cases—since there is something advantageous about cooperation. This indicates the complexity of the question of cooperation, protest, and disobedience. Thoreau’s essay, “Civil Disobedience” (1849), is often viewed as an anarchist manifesto. Kropotkin discussed him as an anarchist (Kropotkin 1927 [2002]). And Tolstoy admired his act of civil disobedience—as did Gandhi.

Anarchists continue to discuss strategies and tactics of disobedience. One problem throughout this discussion is the degree to which disobedience is effective. If there were to be successful anarchist campaigns of disobedience they would have to be organized and widespread. Whether such campaigns would actually work to disassemble the state apparatus remains an open question.

Until their dreamed-of revolution comes, anarchist must consider the degree to which cooperation with the state involves “selling out” to the political status quo. Perhaps there are reforms and short-term gains that can be obtained through traditional political means: voting, lobbying legislators, etc. But anarchists have often held to an all-or-nothing kind of approach to political participation. We noted above that the Christian anarchist Jacques Ellul has said that he does not vote because anarchy implies conscientious objection. But herein lies a strategic conundrum. If progressively minded anarchists opt out of the political system, this means that less enlightened policies will prevail. By not voting or otherwise engaging in ordinary politics, the anarchist ends up with a system that he or she will be even less happy with than if he or she had actively participated in the system.

This is, really, a problem of revolution versus reform. The revolutionary wants revolution now, believing that it will occur by way of direct action of various sorts. Perhaps the revolutionary is also thinking that the psychological, cultural, and spiritual evolution toward revolutionary consciousness can only occur when direct action is taken: in order for anarchism to emerge, the anarchist may think, one ought to behave and think like an anarchist. But without a concerted and nation-wide revolution, revolutionary action begins to look like mere selfishness, Epicurean opting out, or what Bookchin criticized as “lifestyle anarchism”. Meanwhile those reform-minded folks who work within the system of political power and legality can end up supporting a system that they have doubts about. This philosophical problem of reform vs. revolution exists for all radical political agendas. But the problem is especially acute for anarchists, since anarchism is often an all-or-none proposition: if the state is justified then gradualism and reformism make sense; but if no state can be justified, then what is sometimes called “reformist anarchism” is a non-starter (see L. Davis 2012).

3.3. Utopian Communities and Non-Revolutionary Anarchism
Many anarchists are revolutionaries who want change to be created through direct action. But given our preceding discussion of violence, disobedience, and the potential for success of revolutionary activity, the question arises about opting-out of political life. The Epicureans and Cynics pointed in this direction. The history of anarchism is replete with efforts to construct anarchist communes that are independent and separated from the rest of state centered political life.

We might pick up the history here with the Christian anarchists and pacifists of the Reformation: the Mennonites, for example; or the Quakers who refused to doff their hats for political authorities and who sought a refuge in Pennsylvania. Indeed, there is an anarchist thread to the colonization of North America, as those who were disgruntled with European political and religious hierarchy left for the “new world” or were forced out by the European authorities. In the Seventeenth Century, Anne Hutchinson was cast out of the Massachusetts Bay Colony and forced to found a new community, when she concluded that the idea of government was flawed. Hutchinson is considered as one of the first anarchists of North America (see Stringham 2007). Separatist communities were founded by the New England abolitionists and transcendentalists, by Josiah Warren, and by others.

Anarchist communes were formed in Europe during the Nineteenth Century and in Spain during the 1930s. There have been ongoing movements and organizations of indigenous peoples and others who inhabit the margins of mainstream political life. In the 1960s and 70s, anarchist separatism was reiterated in the Hippy communes and attempts to live off the grid and get back to nature. Alternative communes, squats, and spontaneous gatherings continue to occur.

Separatist communities have to consider: the degree to which they give up on anarchist direct action against dominant political forces, the extent to which they have to accommodate themselves to political reality, and the risk that customary hierarchies will be reinstated within the commune. For the revolutionary anarchist, separatism is a strategy of avoidance that impedes political action. Separatist communes must often obey the rules of the dominant political organization in order to trade and get connected to the rest of the world. Finally, a complaint made about separatist communes is that they can end up being structured by sexist, classist, and other hierarchical organizing principles. One might argue that until the dominant culture is revolutionized, separatism will only be a pale reflection of the anarchist ideal. And yet, on the other hand, advocates of separatism will argue that the best way for anarchist ideals to take hold is to demonstrate that they work and to provide an inspiration and experimental proving ground for anarchism.

If revolutionary activity is taken off the table, then anarchists are left with various forms of gradualism and reformism. One way this might occur is through the creation of “temporary autonomous zones” such as those described by Bey. Along these lines David Graeber provides a description of the cultural and spiritual work that would be required in order to prepare the way for anarchist revolution. Graeber says that this would require “liberation in the imaginary”, by which he means that through activism, utopian communities, and the like there can be a gradual change in the way political power is imagined and understood (Graeber 2004). Revolutionary anarchists will respond to this by arguing that liberation in the imaginary is simply imaginary liberation: without actual change in the status quo, oppression and inequality continue to be a problem.

4. Objections and Replies
Let’s conclude by considering some standard objections to anarchism and typical replies.

4.1 Anarchism is Nihilistic and Destructive
Objection: This objection holds that anarchism is merely another name for chaos and for a rejection of order. This objection holds that anarchists are violent and destructive and that they are intent on destroying everything, including morality itself.

Reply: This objection does not seem to recognize that anarchists come in many varieties. Many anarchists are also pacifists—and so do not advocate violent revolution. Many other anarchists are firmly committed to moral principles such as autonomy, liberty, solidarity, and equality. Some anarchists do take their critique of arché in a nihilistic direction that denies ethical principles. But one can be committed to anarchism, while advocating for caring communities. Indeed, many of the main authors in the anarchist tradition believed that the state and the other hierarchical and authoritarian structures of contemporary society prevented human flourishing.

4.2 Anarchy Will Always Evolve Back into the State
Objection: This objection holds that anarchism is inherently unstable. Hobbes and other early modern social contract theories maintain that the state emerges as a necessary response to natural anarchy which keeps order and protects our interests. A different theory comes from Nozick, who argues that the “night-watchman state” would emerge out of anarchy by an invisible hand process: as people will exercise their liberty and purchase protection from a protection agency, which would eventually evolve into something like a minimal state.

Reply: Anarchists may argue that the state of nature is simply not a state of war and so that Hobbes’s description is false. Some anarcho-primitivists will argue that things were much better for human beings in the original state of nature in small communities living close to the land. Other anarchists might argue that the disadvantages of state organizations—the creation of hierarchies, monopolies, inequalities, and the like—simply outweigh the benefits of state structures; and that rational agents would choose to remain in anarchy rather than allow the state to evolve. Some anarchists may argue that each time a state emerges, it would have to be destroyed. But others will argue that education and human development (including technological development) would prevent the reemergence of the state.

4.3 Anarchism is Utopian
Objection: This objection holds that there simply is no way to destroy or deconstruct the state. So exercises in anarchist political theory are fruitless. It would be better, from this point of view to focus on critiques of hierarchy, inequality, and threats to liberty from within liberal or libertarian political theory—and to engage in reforms that occur within the status quo and mainstream political organization.

Reply: Ideal theory is always in opposition to non-ideal theory. But utopian speculation can be useful for clarifying values. Thus philosophical anarchism may be a useful exercise that helps us understand our values and commitment, even though political anarchism has no hope of succeeding. Furthermore, there are examples of successful anarchist communities on a small local scale (for example, in the separatist communities discussed above). These concrete examples can be viewed as experiments in anarchist theory and practice.

4.4 Anarchism is Incoherent
Objection: This objection holds that a political theory that abolishes political structures makes no sense. A related concern arises when anarchism is taken to be a critique of authority in every case and in all senses. If anarchists deny then that there can be any arché whatsoever, then the claim contradicts itself: we would have a ruling theory that states that there is no ruling theory. This sort of criticism is related to standard criticisms of relativism and nihilism. Related to this is a more concrete and mundane objection that holds that there can be no anarchist movement or collective action, since anarchism is constitutionally opposed to the idea of a movement or collective (since under anarchism there can be no authoritative ruler or set of rules).

Reply: This objection only holds if anarchism is taken to be an all-or-nothing theory of the absolutist variety. Political anarchists do not necessarily agree with the skeptical post-foundationalist critique which holds that there can be no ruling principle or authority whatsoever. Rather, political anarchists hold that there are legitimate authorities but that political power quickly loses its authoritativeness and legitimacy. Furthermore, anarchists tend to advocate for a principle and procedure for organization based upon voluntarism and mutual aid, as well as unanimity and/or consensus. From this point of view anarchist communities can work very well, provided that they avoid coercive authority. To support this point anarchists will point to historical examples of successful anarchist communes. They will also point to ordinary human relations—in families and civil society relationship—which operate quite well apart form coercive and hierarchical political authority

4.5 Philosophical Anarchism is “Toothless”
Objection: One objection to philosophical anarchism of the sort discussed throughout this essay is that it remains merely theoretical. Some political anarchists have little patience for abstract discourses that do not engage in direct action. One worry about philosophical anarchism is that in failing to act—and in failing to take responsibility for the actions that ought to follow from thought—philosophical anarchism remains a bourgeois convenience that actually serves the status quo. Thus when philosophical anarchists remain uncommitted in terms of the concrete questions raised by anarchism—whether they should obey the law, whether they should vote, and so on—they tend to support the interests of defenders of the status quo.

Reply: In response to this objection, one might defend the importance of philosophical reflection. It is important to be clear about principles and ideas before taking action. And with anarchism the stakes are quite high. The puzzles created by philosophical anarchism are profound. They lead us to question traditional notions of sovereignty, political obligation, and so on. They lead us to wonder about cultural and ethical conventions, including also our first principles regarding the theory and organization of social life. Given the difficulty of resolving many of these questions, the philosophical anarchist may hold that caution is in order. Moreover, the philosophical anarchist might also defend the importance of wonder. The anarchist critique gives us reason to wonder about much that we take for granted. Wonder may not change the world in immediate ways or lead to direct action. But wonder is an important step in the direction of thoughtful, ethical action.

1. The normative status of what?
Before we can hope to make any headway with these questions a number of clarifications are in order. First and foremost, in asking after the normative status of logic, we had better get clearer on what we mean by “logic”. For present purposes, I will take a logic to be a specification of a relation of logical consequence on a set of truth-bearers. Moreover, I will assume consequence relations to necessarily preserve truth in virtue of logical form. For simplicity, I will use “⊨
” to denote such a consequence relation. My default assumption will be to take the double turnstile to denote the semantic consequence relation of the classical first-order predicate calculus. But not much hangs on this. Partisans of other types of non-classical consequence relations may read “⊨
” as referring to their preferred consequence relation.

Presumably, if logic is normative for thinking or reasoning, its normative force will stem, at least in part, from the fact that truth bearers which act as the relata of our consequence relation and the bearers of other logical properties are identical to (or at least are very closely related in some other way) to the objects of thinking or reasoning: the contents of one’s mental states or acts such as the content of one’s beliefs or inferences, for example. For present purposes I will assume the identity between truth-bearers and the contents of our attitudes, and I will assume them to be propositions.

1.1 Characterizing logical consequence in terms of its normative role
One may approach the question of the normativity of logic by taking the notions of logical consequence and of validity to be settled and to then investigate how these (and perhaps related) notions constrain our attitudes towards the propositions standing in various logical relations to one another.[1] An alternative approach has it that logic’s normative role in thinking or reasoning may be partly definitive of what logic is. Hartry Field, for one, advances an account of validity along the latter lines. In his 2015, he argues that neither the standard model- or proof-theoretic accounts of validity nor the notion of necessary truth-preservation in virtue of logical form succeed in capturing the notion of validity. More specifically, neither of these approaches is capable of capturing the notion of validity in a way that does justice to logical disputes, i.e., debates over which logical system is the correct one. On the standard approaches to validity, such disputes are reduced to merely verbal disputes inasmuch as “validity” is defined relative to the system of logic in question. No one, of course, ever disputed that a given classical argument form is valid relative to the notion of validity-in-classical logic, where as an intuitionistically valid argument is valid relative to the notion of validity-in-intuitionistic logic. The problem is that there is no neutral notion of validity one could appeal to that would enable one to make sense of logical disputes as genuine debates, which, arguably, they are. What is needed to capture the substantive nature of these disputes, therefore, is a workable non-partisan notion of validity, one that is not internal to any particular system of logic. The key to availing ourselves of such an ecumenical notion of validity, Field claims, resides in its conceptual role. The conceptual role of the notion of validity, in turn, is identified with the way in which a valid argument normatively constrains an agent’s doxastic attitudes. Roughly, in the case of full belief, in accepting an argument as valid, the agent is bound by the norm that she ought not believe the argument’s premises while at the same time not believing its conclusion. In other words, validity’s conceptual role resides (at least in part) in the normative role played by valid arguments in reasoning. Note that Field is not proposing to define validity in terms of its normative role. The notion of validity, Field contends, is best taken to be primitive. But even once we take it to be primitive, it still stands in need of clarification. It is this clarificatory work that is done by a characterization of validity’s conceptual role. And it is in this sense that the normative role of logic is supposed to characterize the very nature of validity (understood as a notion shared by various distinct logics).

In a similar vein, John MacFarlane (2004, Other Internet Resources; henceforth cited as MF2004) contends that a fuller understanding of how logical consequence normatively constrains reasoning may help us settle long-standing issues in the philosophy of logic, debates surrounding the very nature of validity. Attempts at resolving such questions have been thwarted because of their suspect methodology: they relied on the unreliable (because theory-laden) testimony of our intuitions about validity. Appealing to the normative role of logic, MacFarlane hopes, would give us a new angle of attack and hence a potentially better handle on these vexed questions. MacFarlane, too, may therefore be read as suggesting that a proper account of logic’s normative role in reasoning will ultimately enable us to hone in on the correct conception of logical consequence. As examples MacFarlane considers the dispute between advocates of relevantist restrictions of the notion validity and those who reject such restrictions (see entry relevance logic), and the question of the formality of logical validity (see entry logical consequence). The hope, in other words, is that an account of the normative role of logic, will help us pin down the correct concept of validity. In this respect, then, MacFarlane’s project may be thought to be more ambitious than Field’s whose aim is to provide a logic-neutral core concept of validity in terms of its normative role. For MacFarlane a correct account of the normativity of logic would constitute a potential avenue through which logical disputes may be decided; for Field such an account merely renders such disputes intelligible and so serves as a starting point for their resolution.[2]

A potential problem with approaches like Field’s and MacFarlane’s is that logical consequence does not appear to have a unique normative profile that sets it apart from other, non-logical consequence relations. For instance, that one ought not believe each member of a set of premises while at the same time not believing (or disbelieving) its conclusion, is a feature that logical consequence seems to share with strict implication. At least in one sense of “ought”, I ought to believe that this is colored, if I believe it to be red, just as much as I ought to believe A
, if I believe A∧B
. If the general principles characterizing logic’s normative role fail to discriminate logical consequence among other types of consequence, we cannot identify the conceptual role of validity with its normative role as Field proposes. We cannot do so, at least, unless we impose further conditions to demarcate properly logical consequence (see entry logical constants). The problem discussed here was raised (albeit in a different context) by Harman (1986: 17–20) when he argues that logic is not “specially relevant to reasoning”. One response, of course, is simply to concede the point and so to simply broaden the scope of the inquiry: Instead of asking how logic (narrowly construed) normatively constrains us, we might ask how strict implication (Streumer 2007) or perhaps a priori implication does.[3] A further response is that neither Field nor MacFarlane are committed to demarcating logic or carving out any “special” role for it. Their principles are left-to-right conditionals: the existence of a logical entailment gives rise to a normative constraint on doxastic attitudes. One can thus question the operative notion of entailment by questioning the normative constraint. This, it might reasonably be maintained, is all that Field and MacFarlane need for their purposes.

1.2 Logical pluralism
We said that not much of our discussion below hinges on the choice of one’s logic. However, while we countenanced the possibility of disagreement over which logic is correct, we have simply presupposed that there must be a unique correct logic. And this latter assumption does seem to bear on our question in potentially significant ways. The issue has yet to be explored more fully. Here I offer a number of preliminary distinctions and observations.

Logical pluralists maintain that there is more than one correct logic (see entry on logical pluralism). Now, there are perfectly uncontroversial senses in which several distinct logical systems might be thought to be equally legitimate: different logical formalisms might lend themselves more or less well to different applications, e.g., classical propositional logic may be used to model electric circuits, the Lambek calculus naturally models phrase structure grammars, and so forth. If “correct” or “legitimate” is merely understood as “having a useful application”, monists should have no complaints about such anodyne forms of “pluralism”. The monist may happily admit that there is a vast number of systems of logic that make for worthy objects of study, many of which will have useful applications. What monists must have in mind, then, is a more demanding sense of “correctness”. According to Priest, the monist takes there to be, over and above questions of local applicability, a core or “canonical” (Priest 2006: 196) application of logic. The canonical use of logic consists in determining “what follows from what—what premises support what conclusion—and why” (idem). It is only when the question is framed in these terms, that the full force of the opposition between monists and pluralists can be appreciated. The monist maintains that there is but one logic fit to play this core role; the pluralist insists that several logics have an equally good claim to playing it.

One consequence of pluralism, then, is that in a dispute between advocates of different logics both of which lay claim to being the correct logic in this sense—say, a dispute between a classical logician and an advocate of intuitionistic logic—neither party to the dispute needs to be at fault. Each logic may be equally legitimate. For this to be possible, it must be the case that even the canonical application of logic can be realized in multiple ways. Pluralists differ in the accounts they offer of this multiple realizability. One influential such account has been advanced by J.C. Beall and Greg Restall (2005). According to their account, several logics may be equally qualified to fulfill the core function of logic, because “logical consequence” admits of several distinct interpretations (within a specified range). Roughly, A
 is a logical consequence of a set of formulas Γ
 if and only if, in every case in which all of the members of Γ
 are true, so is A
. Depending on how we understand “case” in our definition—e.g., as Tarskian models (classical logic), stages (intuitionistic logic), situations (relevant logic), etc.—we arrive at different concepts of logical consequence.

What does this mean for the question of logic’s normative status? It follows that it is only once we choose to disambiguate “logical consequence” in a particular way—as classical or intuitionistic, say—that the normative import of that particular conception of consequence makes itself felt. After all, on the pluralist picture a given conception of consequence cannot be normatively binding in virtue of being (uniquely) correct, i.e., in virtue of being descriptively adequate with respect to the entailment facts, as it were. Hence, if I opt for an intuitionistic conception of consequence and you go in for a classical one, I have no grounds for criticizing your move from, say, ¬¬A
 to A
, save perhaps pragmatic ones. To be sure, such a move would be impermissible according to my preferred notion of consequence, but it is perfectly acceptable according to yours. According to the pluralist, then, there exists no absolute sense, but only system-relative senses, in which a logic can normatively bind us. Pluralism about logic thus seems to give rise to pluralism about logical normativity: If there are several equally legitimate consequence relations, there are also several equally legitimate sets of logical norms. Consequently, it is hard to see prima facie how substantive normative conflicts can arise. If the consequence relations of classical and intuitionistic logic are equally legitimate, there is little to disagree about when it comes to the norms they induce. The classicist and the intuitionist simply have opted to play by different rules.

This line of thought leads to a potential worry, however. For logical norms do not merely bind us in the way that the rules of a game bind us. I hold myself to be answerable to the rules governing a game (of chess, say) so long as I wish to participate in it. However, the normativity of logic does not seem to be optional in the same way. The norms of logic are themselves responsible to our broader epistemic aims (and would thus need to be coordinated with other epistemic norms). Hence, if my epistemic aim is, say, acquiring true beliefs (and avoiding false ones), this may give me a reason to prefer one set of logical norms over another. For imagine I could choose either of two logics L1
 and L2
. Suppose, moreover, that A
 is true and that A⊨L1B
 but A⊭L2B
, for some relevant proposition B
. Even according to Beall and Restall, not all logics are equal. To pass muster, a logic must satisfy certain core conditions. In particular, it must be truth-preserving. Assuming that both L1
 and L2
 are truth-preserving, it follows that B
 is true. But then it would seem that there is a clear sense in which L1
 outperforms L2
 in terms of the guidance it affords us. According to the norms L2
 gives rise to, there is presumably nothing amiss about an agent who believes A
 but not B
; according to L1
 there presumably is. Hence, L1
 is more conducive to our epistemic aims. It follows that whenever two putatively equally correct logics, L1
 and L2
 are such that L2
 is a proper sub-system of L1
, one would appear to have reason to opt for L1
 since it is more conducive to one’s aim of having true beliefs. In cases where we are dealing with two logics L1
 and L2
 such that ⊨L1
 and ⊨L2
 are not sub-relations of one another, things may be more complicated. All the same, even in such cases, it may well be that our overarching epistemic aims and norms give us reason to prefer one logic over another, and hence that from the standpoint of these epistemic aims, the logics are not equally good after all. The aim of these considerations is not to undermine forms of logical pluralism like the one advanced by Beall and Restall, but merely to point out that once we take the normative dimension of logic into account, we must also reckon with the broader epistemic goals, which the norms of logic may be thought to be subservient to.

Field (2009b) argues for a different form of logical pluralism, one which leaves more room for normative conflict. Logical pluralism is not, for Field, the result of ambiguity in our notion of logical consequence. Rather, it has its source in non-factualism of epistemic norms. His non-factualism, in turn, is fueled partly by general concerns, partly by the nature of how we choose such norms. Among the general concerns Field (2009c) mentions are Hume-style worries about the impossibility of integrating irreducible normative facts into a naturalistic world view, Benacerraf-style worries about our ability to gain epistemic access to such facts, and Mackie-style worries about the “queerness” of such facts (i.e., that they not only appear to have no room within our scientific picture of the world, but that, furthermore, they are supposed to have a somewhat mysterious motivational pull to them). The latter issue of norm selection amounts to this. Given a set of epistemic goals, we evaluate candidate norms as better or worse depending how well they promote those goals. According to Field, we have no reason to assume that there should be a fact of the matter as to which choice of logic is the uniquely correct one; there will typically not be a unique system that best optimizes our (often competing) constraints.

That being said, it seems that we can sensibly engage in rational debates over which logic to adopt in the light of various issues (vagueness, the semantic paradoxes, etc.). Consequently, there is a clear sense in which normative conflicts do arise. Now, since Field takes it to be an essential component of the notion of logical consequence that it should induce norms (Field 2009a,b, 2015), we choose a logic by finding out which logical norms it makes most sense for us to adopt. But because Field does not take there to be a fact of the matter as to which set of norms is correct and since the question as to which of the norms best promotes our epistemic ends is often underdetermined, we may expect there to be several candidate sets of logical norms all of which are equally well-motivated. We are thus left with a (more modest) form of logical pluralism on our hands.

What both of these types of pluralism have in common from the point of view of the question of the normativity of logic, though, is their rejection of the view that logical norms might impose themselves upon us simply as a result of the correctness of the corresponding logical principles. As such, pluralist views stand diametrically opposed to realist forms of monism such as the one championed by Gila Sher (2011). According to Sher, logical principles are grounded, ultimately, in “formal laws” and so in reality. It is these formal laws that ultimately also ground the corresponding logical norms.[4]

2. Normative for what?
Next let us ask what it is that logic is normative for, if indeed it is normative. The paradigmatic objects of normative appraisal are actions, behaviors or practices. What, then, is the activity or practice that logical norms apply to?

2.1 Logic as normative for reasoning
One response—perhaps the most common one—is that logic sets forth norms for (theoretical) reasoning. Unlike thinking, which might consist merely of disconnected sequences of conceptual activity, reasoning is presumably a connected, usually goal-directed, process by which we form, reinstate or revise doxastic attitudes (and perhaps other types of states) through inference. Consider the following two examples of how logic might give rise to norms. First, suppose I am trying to find Ann and that I can be sure that Ann is either in the museum or at the concert. I am now reliably informed that she is not in the museum. Using logic, I conclude that Ann is at the concert. Thus, by inferring in conformity with the valid (by the standards of classical logic) logical principle of disjunctive syllogism, I have arrived at a true belief about Ann’s whereabouts. Second, if I believe that Ann is either at the concert or the museum, while at the same time disbelieving both of the disjuncts, it would seem that there is a tension in my belief set, which I have reason to rectify by revising my beliefs appropriately. Logic may thus be thought to normatively constrain the ways we form and revise doxastic attitudes. And it does so, presumably, in our everyday cognitive lives (as in our example), as well as in the context of more self-conscious forms of theoretical inquiry, as in mathematics, the sciences, law, philosophy and so on, where its normative grip on us would seem to be even tighter.[5]

2.2 Logic as constitutively normative for thought
Other philosophers have taken the normativity of logic to kick in at an even more fundamental level. According to them, the normative force of logic does not merely constrain reasoning, it applies to all thinking. The thesis deserves our attention both because of its historical interest—it has been attributed in various ways to Kant, Frege and Carnap[6]—and because of its connections to contemporary views in epistemology and the philosophy of mind (see Cherniak 1986: §2.5; Goldman 1986: Ch. 13; Milne 2009; as well as the references below).

To get a better handle on the thesis in question, let us agree to understand “thought” broadly as conceptual activity.[7] Judging, believing, inferring, for example, are all instances of thinking in this sense. It may seem puzzling at first how logic is to get a normative grip on thinking: Why merely by engaging in conceptual activity should one automatically be answerable to the strictures of logic?[8] After all, at least on the picture of thought we are currently considering, any disconnected stream-of-consciousness of imaginings qualifies as thinking. One answer is that logic is thought to put forth norms that are constitutive for thinking. That is, in order for a mental episode to count as an episode of thinking at all, it must, in a sense to be made precise, be “assessable in light of the laws of logic” (MacFarlane 2002: 37). Underlying this thesis is a distinction between two types of rules or norms: constitutive ones and regulative ones.

The distinction between regulative and constitutive norms is Kantian at root (KRV A179/B222). Here, however, I refer primarily to a related distinction due to John Searle. According to Searle, regulative norms “regulate antecedently or independently existing forms of behavior”, such as rules of etiquette or traffic laws. Constitutive norms, by contrast

create or define new forms of behavior. The rules of football or chess, for example, do not merely regulate playing football or chess but as it were they create the very possibility of playing such games. (Searle 1969: 33–34; see also Searle 2010: 97)

Take the case of traffic rules.[9] While I ought to abide by traffic rules in normal circumstances, I can choose to ignore them. Of course, rowdy driving in violation of the traffic code might well get me in trouble. Yet no matter how cavalier my attitude towards traffic laws is, my activity still counts as driving. Contrast this with the rules governing the game of chess. I cannot in the same way opt out of conforming to the rules of chess while continuing to count as playing chess; in systematically violating the rules of chess and persisting in doing so even in the face of criticism, I forfeit my right to count as partaking in the activity of playing chess. Unless one’s moves are appropriately assessable in light of the rules of chess, one’s activity does not qualify as playing chess.

According to the constitutive conception of logic’s normativity the principles of logic are to thought what the rules of chess are to the game of chess: I cannot persistently fail to acknowledge that the laws of logic set standards of correctness for my thinking without thereby jeopardizing my status as a thinker (i.e., someone presently engaged in the act of thinking).

Two important clarifications are in order. For one, on its most plausible reading, the thesis of the constitutive normativity of logic for thought must be understood so as to leave room for the possibility of logical error: an agent’s mental activity may continue to count as thinking, despite his committing logical blunders.[10]

That is, although one may at times (perhaps even frequently and systematically) stray from the path prescribed by logic in one’s thinking, one nevertheless counts as a thinker provided one appropriately acknowledges logic’s normative authority over one’s thinking. Consider again the game of chess. In violating the rules of chess, deliberately or out of ignorance, I can plausibly still be said to count as playing chess, so long, at least, as I acknowledge that my activity is answerable to the rules; for example, by being disposed to correct myself when an illegal move is brought to my attention.[11] Similarly, all that is necessary to count as a thinker is to be sensitive to the fact that my practice of judging, inferring, believing, etc., is normatively constrained by the laws of logic. It is not easy to specify, in any detail, what the requisite acknowledgment or sensitivity consists in. A reasonable starting point, however, is provided by William Taschek who, in his interpretation of Frege, proposes that acknowledging

the categorical authority of logic will involve one’s possessing a capacity to recognize—when being sincere and reflective, and possibly with appropriate prompting—logical mistakes both in one’s own judgmental and inferential practice and that of others. (Taschek 2008: 384)

A second point of clarification is that the agent need not be able to explicitly represent to herself the logical norms by which she is bound. For instance, it may be that my reasoning ought to conform to disjunctive syllogism in appropriate ways. I may be able to display the right kind of sensitivity to the principle by which I am bound (with the right prompting if need be), without my having to possess the conceptual resources to entertain the metalogical proposition that ¬A,A∨B⊨B
. Nor must I otherwise explicitly represent that proposition and the normative constraint to which it gives rise.

With these clarifications in place, let us turn to a central presupposition of the approach I have been sketching. What is being presupposed, of course, is a conception of thinking that does not reduce to brute psychological or neurophysiological processes or events. If this naturalistic level of description were the only one available, the constitutive account of the normativity of logic would be a non-starter. What is being presupposed, therefore, is the permissibility of irreducibly normative levels of descriptions of our mental lives. In particular, it is assumed that the boundary between the kinds of mental activity that constitute thinking and other kinds of mental activity (non-conceptual activity like being in pain, for instance) is a boundary best characterizable in normative terms. This is not to deny that much can be learned about mental phenomena through descriptions that operate at different, non-normative levels—the “symbolic” or the neurological level of description, say—the claim is merely that if we are interested in demarcating conceptual activity from other types of mental phenomena, we should look to the constitutive norms governing it. Davidson (1980, 1984), Dennett (1987), and Millar (2004) all hold views according to which having concepts and hence thinking requires that the agent be interpretable as at least minimally sensitive to logical norms. Also, certain contemporary “normativist approaches” according to which accounts of certain intentional states involve ineliminable appeals to normative concepts may advocate the constitutive conception of logic’s normativity (e.g., Wedgwood 2007, 2009; Zangwill 2005).

2.3 Logic as normative for public practices
So far the answers to the question “What is logic normative for?” we considered had in common that the “activities” in question—reasoning and thinking—are internal, mental processes of individual agents. But logic also seems to exert normative force on the external manifestations of these processes—for instance, it codifies the standards to which we hold ourselves in our practices of assertion, rational dialogue and the like. While much of the literature on the normativity of logic focuses on internal processes of individuals, some authors have instead emphasized logic’s role as a purveyor of public standards for normatively regulated practices.

Take the practice of asserting. Assertion is often said to “aim at truth” (or knowledge, Williamson 2000: Ch. 11) as well as being a “matter of putting forward propositions for others to use as evidence in the furtherance of their epistemic projects” (Milne 2009: 282). Since I take the asserted propositions to be true and since truths entail further truths, I am “committed to standing by” the logical consequences of my assertions or else to retract them if I am unable to meet challenges to my assertion or its consequences. Similarly, if the set of propositions I assert is inconsistent at least one of my assertions must fall short of being true and the set as a whole cannot be regarded as part of my evidence. Plausibly, therefore, logic does have a normative role to play in governing the practice of assertion.

Peter Milne takes an interest in assertion mainly in order to “work back” from there to how logic constrains belief. He concludes that logic exerts normative force at least on the stock of beliefs that constitute the agent’s evidence (Milne 2009: 286). Other authors explicitly prioritize the external dimension of reasoning, conceived of as a social, inter-personal phenomenon. According to them, it is reasoning in this external sense (as opposed to intra-personal processes of belief revision, etc.) that is the primary locus of logical normativity (MacKenzie 1989). The norms govern our rational interactions with our peers. For instance, they might be thought to codify the permissions and obligations governing certain kinds of dialogues. Viewed from this perspective, logic’s normative impact on the intra-personal activity of reasoning is merely derivative, arrived at through a process of interiorization. A view along these lines has been advanced by Catarina Dutilh Novaes (2015). In a similar vein Sinan Dogramaci (2012, 2015) has proposed a view he calls “epistemic communism”. According to epistemic communism our use of “rational” applied to certain deductive rules has a specific functional role. Its role is to coordinate our epistemic rules with a view to maximizing the efficiency of our communal epistemic practices. On the basis of this view, he then elaborates an argument for the pessimistic conclusion that no general theory of rationality is to be had.

We will here follow the bulk of the literature in asking after the normative role logic might play in reasoning understood as an intra-personal activity. Yet, much of the discussion to follow applies mutatis mutandis to the other approaches.

3. Harman’s challenge
Despite its venerable pedigree and its intuitive force, the thesis that logic should have a normative role to play in reasoning has not gone unchallenged. Gilbert Harman’s criticisms have been particularly influential. Harman’s skeptical challenge is rooted in a diagnosis: our deep-seated intuition that logic has a special normative connection with reasoning is rooted in a confusion. We have conflated two very different kinds of enterprises, viz. that of formulating a theory of deductive logic, on the one hand, and what Harman calls “a theory of reasoning” (Harman 2002) on the other. Begin with the latter. A theory of reasoning is a normative account about how ordinary agents should go about forming, revising and maintaining their beliefs. Its aim is to formulate general guidelines as to which mental actions (judgments and inferences) to perform in which circumstances and which beliefs to adopt or to abandon (Harman 2009: 333). As such, the subject matter of a theory of reasoning are the dynamic “psychological events or processes” that constitute reasoning. In contrast, “the sort of implication and argument studied in deductive logic have to do with [static, non-psychological] relations among propositions” (idem). Consequently,

logical principles are not directly rules of belief revision. They are not particularly about belief [or the other mental states and acts that constitute reasoning] at all. (Harman 1984: 107)

Once we disabuse ourselves of this confusion, Harman maintains, it is hard to see how the resulting gap between logic and reasoning can be bridged. This is Harman’s challenge.

At least two lines of response come to mind. One reaction to Harman’s skeptical challenge is to take issue with his way of setting up the problem. In particular, we might reject his explanation of the provenance of our intuitions to the effect that logic has a normative role to play in reasoning as stemming from a mistaken identification of deductive logic and theories of reasoning. It might be thought, for instance, that Harman is led to exaggerate the gulf between deductive logic and theories of reasoning as a result of a contestable—because overly narrow—conception of either logic or reasoning, or both. Advocates of broadly logical accounts of belief revision (belief revision theories, non-monotonic logics, dynamic doxastic logic, etc.) may feel that Harman is driven to his skepticism out of a failure to consider more sophisticated logical tools. Unlike standard first-order classical logic, some of these formalisms do make explicit mention of beliefs (and possibly other mental states). Some formalisms do seek to capture the dynamic character of reasoning in which beliefs are not merely accumulated but may also be revised. Harman’s response, it would seem (Harman 1986: 6), is that such formalisms either tacitly rely on mistaken assumptions about the normative role of logic or else fall short of their objectives in other ways. But even if one disagrees with Harman’s assessment, one can still agree that such formal models of belief revision do not obviate the need for a philosophical account of the normativity of logic. That is because such models do typically tacitly rely on assumptions concerning the normative role of logic. An account of the normativity of logic would thus afford us a fuller understanding of the presuppositions that undergird such theories.

On the other hand, some philosophers—externalists of various stripes, for instance—may find fault with the epistemological presuppositions underlying Harman’s conception of a theory of reasoning. Harman views the aim of epistemology as closely linked to his project of providing a theory of reasoning. According to Harman’s “general conservatism”, central epistemological notions, like that of justification are approached from the first-personal standpoint: “general conservatism is a methodological principle, offering methodological advice of a sort a person can take” (Harman 2010: 154). As such Harman's approach contrasts with much of contemporary epistemology which, unconcerned with direct epistemic advice, is mainly in the business of seeking to lay down explanatorily illuminating necessary and sufficient conditions for epistemic justification.[12] Summarizing the first line of response, then, Harman's skepticism is partly premised on particular conceptions of logic and of epistemological methodology both of which may be called into question.

The second line of response is to (largely) accept Harman’s assumptions regarding the natures of deductive logic and of epistemology but to try to meet his challenge by showing that there is a interesting normative link between the two after all. In what follows, I focus primarily on this second line of response.

Of course, saying that deductive logic and theories of reasoning are distinct is one thing, affirming that there could not be an interesting normative connection between them is quite another. As a first stab at articulating such a connection, we might try the following simple line of thought: theoretical reasoning aims to provide an accurate representation of the world. We accurately represent the world by having true (or perhaps knowledgeable) beliefs and by avoiding false ones. But our doxastic states have contents—propositions—and these contents stand in certain logical relations to one another. Having an awareness of these logical relations would appear to be conducive to the end of having true beliefs and so is relevant to theoretical reasoning. In particular, the logical notions of consequence and consistency seem to be relevant. If I believe truly, the truth of my belief will carry over to its logical consequences. Conversely, if my belief entails a falsehood it cannot be true. Similarly, if the set of propositions I believe (in general or in a particular domain) is inconsistent, they cannot possibly afford an accurate representation of the world; at least one of my beliefs must be false. Harman may be able to agree with all of this. His skepticism pertains also (and perhaps primarily) to the question whether logic has a privileged role to play in reasoning; that the principles of logic are relevant to reasoning in a way that principles of other sciences are not (Harman 1986: 20). However, I want to set this further issue to one side for now.

Notice that this simple reflection on the connection between logic and norms of reasoning leads us right back to the basic intuitions at the beginning of this entry: that there is something wrong with us when we hold inconsistent beliefs or when we fail to endorse the logical consequences of our beliefs (at least when we can be expected to be aware of them). Let us spell these intuitions out by way of the following two principles. Let S
 be an agent and P
 a proposition.[13]

Logical implication principle (IMP): If S
’s beliefs logically imply A
, then S
 ought to believe that A
.

Logical consistency principle (CON): S
 ought to avoid having logically inconsistent beliefs.

Notice that on the face of it IMP and CON are distinct. IMP, in and of itself, does not prohibit inconsistent or even contradictory beliefs, all it requires is that my beliefs be closed under logical consequence. CON, on the other hand, does not require that I believe the consequences of the propositions I believe, it merely demands that the set of propositions I believe be consistent. However, given certain assumptions, IMP does entail CON. Against the background of classical logic, the entailment obtains provided we allow the following two assumptions: (i) one cannot (and, via the principle that “ought” implies “can”, ought not) both believe and disbelieve one and the same proposition simultaneously; and (ii) that disbelieving a proposition is tantamount to believing its negation.[14] For let {A1,…,An}
 be S
’s inconsistent belief set. By classical logic, we have A1,…,An−1⊨¬An
. Since S
’s beliefs are closed under logical consequence, S
 believes ¬An
 and hence, by (ii), disbelieves An
. So, S
 both believes and disbelieves An
.

3.1 The objections
IMP and CON are thus a first—if rather flatfooted—attempt at pinning down the elusive normative connection between logic and norms of reasoning. Harman considers these responses and responds in turn. The following four objections against our provisional principles can, in large part, be found in the writings of Harman.

(1) Suppose I believe p
 and p⊃q
 (as well as Modus Ponens). The mere fact that I have these beliefs and that I recognize them to jointly entail q
 does not normatively compel any particular attitude towards q
 on my part. In particular, it is not the case in general that I ought to come to believe q
 as IMP would have it. After all, q
 may be at odds with my evidence in which case it may be unreasonable for me to slavishly follow Modus Ponens and to form a belief in q
. The rational course of “action”, rather, when q
 is untenable, is for me to relinquish my belief in at least one of my antecedent beliefs p
 and p⊃q
 on account of their unpalatable implications. Thus, logical principles do not invariably offer reliable guidance in deciding what to believe (at least, when the relation between logical principles and our practices of belief-formation are understood along the lines of IMP). Let us therefore call this the Objection from Belief Revision.

John Broome (2000: 85) offers a closely related objection, which nevertheless deserves separate mention. Broome observes that any proposition trivially entails itself. From IMP it thus follows that I ought to believe any proposition I in fact believe. But this seems patently false: I might hold any number of irresponsibly acquired beliefs. The fact that, by mere happenstance, I hold these beliefs, in no way implies that I ought to believe them. Call this variation of the Objection from Belief Revision, the Bootstrapping Objection.

(2) A further worry is that a reasoner with limited cognitive resources would be unreasonable to abide by IMP because she would be obligated to form countless utterly useless beliefs. Any of the propositions I believe entails an infinite number of propositions that are of no interest to me whatsoever. Not only do I not care about, say, the disjunction “I am wearing blue socks or pigs can fly” entailed by my true belief that I am wearing blue socks, it would be positively irrational of me to squander my scarce cognitive resources of time, computational power and storage capacity in memory and so on, on idly deriving implications of my beliefs when these are of no value to me. Harman fittingly dubs the principle of reasoning in question Principle of Clutter Avoidance. Let us call the corresponding objection the Objection from Clutter Avoidance.

(3) There is another sense in which both principles—IMP and CON—place excessive demands on agents whose resources are limited. Consider the following example. Suppose I believe the axioms of Peano arithmetic. Suppose further that a counterintuitive arithmetical proposition that is of great interest to me is entailed by the axioms, but that its shortest proof has more steps than there are protons in the visible universe. According to IMP, I ought to believe the proposition in question. However, if the logical “ought” implies “can” (relative to capacities even remotely like our own), IMP cannot be correct. An analogous objection can be leveled at CON. An agent may harbor an inconsistent belief set, yet detecting the inconsistency may be too difficult for any ordinary agent. We may summarize these objections under the label Objection from Excessive Demands.

(4) Finally, I may find myself in epistemic circumstances in which inconsistency is not merely excusable on account of my “finitary predicament” (Cherniak 1986), but where inconsistency appears to be rationally required. Arguably, the Preface Paradox constitutes such a scenario (Makinson 1965).[15] Here is one standard way of presenting it. Suppose I author a meticulously researched non-fiction book. My book is composed of a large set of non-trivial propositions p1,…,pn
. Seeing that all of my claims are the product of scrupulous research, I have every reason firmly to believe each of the pi
 individually. But I also have overwhelming inductive evidence for q
: that at least one of my beliefs is in error. The pi
 and q
 cannot be jointly true since q
 is equivalent to the negation of the conjunction of the pi
. Yet, it would seem irrational to abandon any of my beliefs for the sake of regaining consistency, at least in the absence of any new evidence. The Preface Paradox thus may be thought to tell against CON: arguably, I may be within my rational rights in holding inconsistent beliefs (at least in certain contexts). However, it also seems to constitute a direct counterexample to IMP. For in the Preface scenario I believe each of the pi
 and yet it looks as if I ought to disbelieve an obvious logical consequence thereof: their conjunction (because q
 is transparently equivalent to ¬(p1∧⋯∧pn)
).

So much for the objections to IMP and CON. The question raised by these considerations is whether these principles can be improved upon.

4. Bridge principles
Let us focus on IMP for now. Harman’s objections establish that IMP—in its current form, at least—is untenable. The question is whether IMP can be improved upon in a way that is invulnerable to Harman’s objections. In other words, the question is whether a tenable version of what MacFarlane (MF2004) calls a bridge principle is to be had. A bridge principle, in this context, is a general principle that articulates a substantive relation between “facts” about logical consequence (or perhaps an agent’s attitudes towards such facts) on the one hand, and norms governing the agent’s doxastic attitudes vis-à-vis the propositions standing in these logical relations on the other. IMP is a bridge principle, albeit not a promising one.

Harman’s skepticism about the normativity of logic can thus be understood as skepticism as to whether a serviceable bridge principle is to be had. In order properly to adjudicate whether Harman’s skepticism is justified, we need to know what “the options are”. But how? John MacFarlane (MF2004) offers a helpful taxonomy of bridge principles which constitutes a very good first approximation of the range of options. This section briefly summarizes MacFarlane’s classification, as well as subsequent developments in the literature.

Let us begin with a general blue print for constructing bridge principles:[16]

(⋆
)	If A1,…,An⊨C, then N(α(A1),…,α(An),β(C))
.
A bridge principle thus takes the form of a material conditional. The conditional’s antecedent states “facts” about logical consequence (or attitudes toward such “facts”). Its consequent contains a (broadly) normative claim concerning the agent’s doxastic attitudes towards the relevant propositions. Doxastic attitudes, as I use the term, include belief, disbelief, and degree of belief.[17] Here α
 may (but need not) represent the same attitude as β
. In fact, for principles with negative polarity, it may represent the negation of an attitude: “do not disbelieve the conclusion, if you believe the premises”.

In what ways, now, can we vary this schema so as to generate the space of possible bridge principles? MacFarlane introduces three parameters along which the schema may be varied. Each parameter allows for multiple “discrete settings”. We can think of the logical space of bridge principles as the range of possible combinations among these parameter settings.

In order to express the normative claims, we will need deontic vocabulary. Bridge principles may differ in the deontic operator they deploy: does the normative constraint take the form of an ought (o), a permission (p) or merely of having (defeasible) reason (r)?

What is the polarity of the normative claim? Is it a positive obligation/permission/reason to believe a certain proposition given one’s belief in a number of premises (+)? Or rather is it a negative obligation/prohibition/reason not to disbelieve (−)?

What is the scope of the deontic operator? Different bridge principles result from varying the scope of the deontic operator. Let O
 stand generically for one of the above deontic operators. Given that the consequent of a bridge principle will typically itself take the form of a conditional, the operator can take

narrow scope with respect to the consequent (C): A⊃O(B)
wide scope (W): O(A⊃B)
or it can govern both the antecedent and the consequent of the conditional (B):[18] O(A)⊃O(B)
These three parameters admit of a total of eighteen combinations of their settings and hence eighteen bridge principles. The symbols in parentheses associated with each parameter setting combine to determine a unique label for each of the principles: The first letter indicates the scope of the deontic operator (C, W or B), the second letter indicates the type of deontic operator (o[bligation], p[ermissions], r[easons]) and the “+” or “−” indicate positive and negative polarity respectively.[19] For example, the label “Co+” corresponds to our original principle IMP:

If A1,A2,…,An⊨C
, then if S
 believes A1,A2,…,An
, S
 ought to believe C
.

And “Wr−” designates:

If A1,A2,…,An⊨C
, then S
 has reason to (believe A1,A2,…,An
, only if S
 does not disbelieve C
).

Many will regard the bridge principles we have presented thus far to be problematic. They all relate “facts” about logical entailment—assuming there are such things—to certain normative constraints on the agent’s attitudes. The trouble, they will say, is that these principles are not sensitive to the cognitive limitations of ordinary agents. Agents, if they are even remotely like us, are not apprised of all entailment “facts”. Consequently, especially the “ought”-based principles (at least on some understanding of “ought”) are therefore vulnerable to Harman’s Objection from Excessive Demands.

A natural response is to consider attitudinal bridge principles. I call attitudinal bridge principles whose antecedents are restricted to logical implications to which the agent bears an attitude. For instance, to take the type of attitudinal principle considered by MacFarlane, Co+ may be transformed into:

(Co+k)	If S
 knows that A1,…,An⊨C
, then if S
 believes the Ai
, S
 ought to believe C
.
According to (Co+k), the agent’s belief set ought to be closed only under known logical consequence. Let us call this an attitudinally constrained or, more specifically, the epistemically constrained variant of Co+ (whence the “k” in the label). Different authors may go in for different types of attitudes. Knowledge, of course, is a factive attitude. Some will wish to leave room for the possibility of (systematic) logical error. For instance, an agent might mistakenly comply with the principle A⊃B,B⊨A
. Perhaps even someone with erroneous logical convictions such as this should, for the sake of internal coherence, comply with the principles he deems correct. An agent who sincerely took an erroneous principle to be correct but failed to reason in accordance with it may be seen to manifest a greater degree of irrationality than someone who at least conformed to principles he endorses. But we can also imagine more interesting cases of systematic error. Suppose I am impressed with an argument for a particular non-classical logic as a means of parrying the semantic paradoxes. I thus come to espouse the logic in question and begin to manage my doxastic attitudes accordingly. But now suppose in addition that unbeknownst to me the arguments that persuaded me are not in fact sound. Again, it might be thought that though I am mistaken in my adherence to the logic, so long as I had good reasons to espouse it, it may nevertheless be proper for me to comply with its principles. If logical error in either of these two senses is to be accommodated, the appropriate attitude would have to be non-factive.

A further issue is that ordinary agents are presumably normatively bound by logical principles without being able to articulate or represent those principles to themselves explicitly. Assuming otherwise runs the risk of overly intellectualizing our ability to conform to logical norms. The attitudes borne by such logically untrained agents to the logical principles therefore presumably are not belief-like. Perhaps such agents are better thought of as exercising an ability or having a disposition to take certain forms of entailment to be correct. See Corine Besson 2012 for a criticism of dispositionalist accounts of logical competence, and Murzi & Steinberger 2013 for a partial defense.

Having thus outlined the classificatory scheme, a number of additional comments are in order. Notice that disbelieving A
 is to be distinguished from not believing A
. One cannot rationally believe and disbelieve the same proposition (although see note 12). Hence, I ought to ensure that when I disbelieve A
, I do not believe A
. The converse, however, obviously does not hold since I can fail to believe A
 without actively disbelieving it. I may, for instance, choose to suspend my judgment as to whether A
 pending further evidence, or I may simply never have considered whether A
. Furthermore, I will remain neutral on the question as to whether the attitude of disbelieving A
 should be identified with that of believing ¬A
.

Moreover, a note on deontic modals is in order. “You ought not Φ
” (O¬Φ
) is not the same as saying “It is not the case that you ought to Φ
” (¬OΦ
). But rather “You are forbidden from Φ
ing”. Consequently, “You ought not disbelieve A
” should be read as “disbelieving A
 would be a mistake”, as opposed to “it is not the case that you ought to disbelieve A
”, which is compatible with the permissibility of disbelieving A
.

Ought and may are understood to be strict notions. By contrast, reason is a pro tanto or contributory notion. Having reason to Φ
 is compatible with simultaneously having reason not to Φ
 and indeed with it being the case that I ought not to Φ
. Reasons, unlike oughts, may be weighed against each other; the side that wins out determines what ought to be done. Finally, I am here treating all deontic modals as propositional operators. This too is not uncontroversial. Peter Geach (1982) and more recently Mark Schroeder (2011) have argued that so-called deliberative or practical oughts are best analyzed not as operators acting on propositions but rather as expressing relations between agents and actions. (Interestingly, MacFarlane (2014: Ch. 11) has recently followed suit.) Nevertheless, I will assume without argument that the operator-reading can be made to work even in the case of deliberative oughts. For defenses of this position see e.g., Broome 2000, 2013; Chrisman 2012; and Wedgwood 2006. We can capture the particular connection between an agent and the obligation she has towards a proposition at a particular time, by indexing the operator: OS,t
. I will drop the indices in what follows.

A last comment: MacFarlane is not explicit as to whether bridge principles are to be understood as synchronic norms—norms that instruct us which patterns of doxastic attitudes are, in a specified sense, obligatory, permissible or reasonable at a given point in time; or whether they are to provide diachronic norms—norms that instruct us how an agent’s doxastic state should or may evolve over time. To illustrate the distinction, let us consider Co+ (aka IMP) once again. Understood synchronically, the principle should be spelled out as follows.

If A1,A2,…,An⊨C
, then if, at time t
, S
 believes A1,A2,…,An
, then S
 ought to believe C
 at time t
.

In other words, the principle demands that one’s beliefs be, at all times, closed under logical consequence. Alternatively, on might interpret Co+ as a diachronic norm as follows:

If A1,A2,…,An⊨C
, then if, at time t
, S
 believes A1,A2,…,An
, then S
 ought to believe C
 at time t′
 (where t
 precedes t′
 suitably closely).

Different principles lend themselves more or less well to these two readings. C
- and B
-type principles can be interpreted as either synchronic or diachronic principles on account of the fact that they make explicit claims as to what an agent ought, may or has reason to believe or disbelieve given her other beliefs. The W
s, by contrast, are most plausibly read as synchronic principles. Such principles do not, in and of themselves, instruct the subject which inferences to make. Rather, they tend to proscribe certain patterns of belief (and, perhaps, disbelief) or distributions of degrees of belief.

4.1 Evaluating bridge principles
With the logical terrain of bridge principles charted, the question now arises as to which principles (if any) are philosophically viable. This is discussed in the following supplementary document:

Bridge Principles – Surveying the Options
In that supplement we discuss a variety of desiderata that have been put forward and consider candidate principles with respect to those desiderata.

4.2 The Preface Paradox
Given that the Preface Paradox constitutes a major stumbling block for many otherwise plausible principles, we do well to explore the ways in which the Preface Paradox might be dealt with. One way, of course, of dealing with the Preface Paradox is to deny it its force. That is, one might try to outright solve, or in some way dissolve, the paradox. Since it seems fair to say that no such approach has won the day (see entry epistemic paradoxes), I will assume that the Preface Paradox intuitions are to be take seriously.[20]

Alternatively, one might acknowledge the force of the Preface intuitions while at the same time trying to hold on to a strict, ought-based principle. But how? According to all such principles, I, the author of a non-trivial non-fiction book (let us assume), ought to believe (or at least not disbelieve) the conjunction of the propositions in my book, given that I firmly endorse each conjunct individually. MacFarlane’s response is that we must simply reconcile ourselves to the irreconcilable: the existence of an ineliminable normative conflict. Our strict logical obligations clash with other epistemic obligations, namely, the obligation to believe that some of my beliefs must be mistaken. Our agent becomes a tragic heroine. Through no fault of her own, she finds herself in a situation in which, no matter what she does, she will fall short of what, epistemically speaking, she ought to do.

It might be retorted that, as a matter of sound methodology, admitting an irresolvable normative clash should only be our last resort. A better approach (all other things being equal) would consist in finding a way of reconciling the conflicting epistemic norms.

Among the qualitative principles we have been considering, the only way out is via non-strict principles like (Wr+b*), which we considered at the end of the previous section. On this principle, I, the author, merely have reason (as opposed to having sufficient reason) for believing the conjunction of the claims that make up the body of my book, given that I believe each of the claims individually. The crucial difference resides in the fact that this leaves open the possibility that my reason for being logically coherent can be overridden. In particular, it can be outweighed by reasons stemming from other epistemic norms. In the case at hand, it might be thought that our logical obligations are superseded by a norm of epistemic modesty. This, of course, is not uncontroversial. Some maintain that what the Preface Paradox shows is not merely that the normative grip of logic does not take the form of a strict ought, but rather that we in fact have no reason at all to believe in multi-premise closure of belief under logical consequence: my reasons for believing in the conjunction of my claims are not being trumped by weightier reasons for disbelieving it; I have no logic-based reason whatsoever to believe the conjunction in the first place.

So far, then, we have considered the following reactions to the Preface Paradox: reject the Preface Paradox altogether; follow MacFarlane and cling to the strict ought-based principle at the cost of accepting an irresolvable normative clash; or opt for the weaker reason operator and give up the intuition motivating the Strictness Test. But none of these proposals incorporates what is perhaps the most natural response to the Preface Paradox outside of the debate surrounding the normativity of logic. A standard response to the Preface Paradox consists in appealing to graded credal states in lieu of “full” (“qualitative”, “binary” or “all-or-nothing”) beliefs. Such “credences” or “degrees of belief” (I will use the two labels interchangeably) are typically modeled by means of a (possibly partial) credence function (which we will denote by “cr
”) that maps the set of propositions into the unit interval. Probabilists maintain that an ideally rational agent’s credence function ought to be (or at least ought to be extendable to) a probability function (i.e., it ought to satisfy the standard axioms of probability theory). In other words, an ideally rational agent should have probabilistically coherent credences.

Probabilists have no trouble accounting for the Preface phenomena: the subjective probability of a (large) conjunction may well be low—even zero, as in the case of the Lottery Paradox (see entry epistemic paradoxes)—even if the probability assigned to each of the individual conjuncts is very high (reflecting the high degree of confidence the author rightly has in each of her claims).

A tempting strategy for formulating a bridge principle capable of coping with the Preface Paradox is to incorporate these insights. This might be done by going beyond MacFarlane’s classification and devising instead a quantitative bridge principle: one in which logical principles directly constrain the agent’s degrees of belief (as opposed to constraining her full beliefs).

Hartry Field (2009a,b, 2015} proposes a bridge principles of just this form. Here is a formulation of such a principle:

(DB)	If A1,…,An⊨C
, then S
’s degrees of belief ought to be such that: cr(C)≥∑1≤i≤ncr(Ai)−(n−1)
Note first that DB is a wide scope principle: it requires that our degrees of belief respect the specified inequality, which can be achieved in one of two ways: by suitably raising one’s degree of belief in the conclusion or else by readjusting one’s degrees of belief in the premises.

DB is based on a well-known result in probability logic, which is usually stated in terms of “uncertainties” (see Adams 1998 for more details; for a helpful overview, see Hájek 2001). Define the uncertainty of a proposition A
, u(A)
 as u(A)=1−cr(A)
. Put in this way, DB says that the uncertainty of the conclusion must not exceed the sum of the uncertainties of the premises. DB can be seen to share a number of important features with standard probability theory. Plug in 0
 for n
 and you get that one should assign 1
 to any logical truth. Plug in 1
 and you get that one’s degree of belief in the premise of a valid single-premise argument should not exceed your degree of belief in the conclusion. The idea underlying DB is that uncertainties can add up and therefore need to be accounted for when we are trying to determine how the logical relations between our belief contents should affect our degrees of belief in those contents. Even if my uncertainty about each of a large number of premises is next to negligible when taken individually, the uncertainty may accumulate so as to make the conclusion highly (perhaps even maximally) uncertain. It is for this reason that DB gets us around the Preface Paradox; in the Preface case the number of premises is sufficiently high for the conclusion to admit of a very low credence.

5. Further challenges
5.1 Kolodny’s challenge
Logical norms are naturally regarded as a species of rational requirements. If I believe a set of propositions and at the same time disbelieve an obvious logical consequence thereof my set of beliefs presumably exhibits a rational defect. Rational requirements are characterized by their demand for coherence: they demand either a particular kind of coherence among our attitudes or else coherence between our attitudes and the evidence. Niko Kolodny has dubbed the former “requirements of formal coherence as such” (Kolodny 2007: 229). They are formal in the sense that they concern logical relationships between attitude contents or the arithmetical relationships between the degrees of confidence we invest in those contents. The qualification “as such” indicates that an internal coherence among the attitudes is demanded to the exclusion of other epistemologically relevant factors (evidential considerations, for example). Requirements of this type, it has been argued (Broome 2000; Dancy 1977), take the form of wide scope principles. Hence, they do not generally prescribe a particular attitude, but are satisfiable in a number of ways. Or, to put it another way, they prohibit particular constellations of attitudes. For instance, Wo− proscribes states like the one just imagined, in which the agent believes all of the premises of a valid argument while disbelieving its conclusion. It may be satisfied, as we have seen, by either coming to believe the conclusion or by abandoning some of the premises.

The status of logical norms as a species of rational requirement raises weighty questions. For one, Kolodny (2005) has challenged the seemingly natural assumption that rationality is normative at all. That is, he has questioned whether we in fact have reason to do what rational requirements require of us. It might be that rationality makes certain demands on us, but that it is an open question as to whether we should want to be rational. Here is not the place to develop these ideas, let alone to try to resolve the “normative question” for rationality (see Way 2010 for an overview). In the absence of a convincing response to Kolodny’s challenge, some might take umbrage at our talk of logical norms. Strictly speaking, we should speak of them as necessary conditions for rationality, leaving open whether we have reason to be rational.

While it would take us too far afield to address the question of the normativity of rationality, there is a related strand of Kolodny’s argument that is more directly relevant to our discussion. The claim in question, put forth in Kolodny 2007 & 2008, is that there simply is no reason for postulating the existence of formal coherence requirements as such at all. This may seem surprising. After all, to take Kolodny’s simplest example, we certainly do have the intuition that an agent who, at a given time, believes both p
 and ¬p
 is violating a requirement—a requirement, presumably, of something like the following form:

(NC)	S
 is required not to both believe A
 and ¬A
 at t
 (for any time t
).
If Kolodny is right that there are no pure formal coherence requirements like (NC), how are we to explain our intuitions? Kolodny’s strategy is to devise an error theory, thereby seeking to show how coherence (or near enough coherence) in the relevant sense emerges as a by-product of our compliance with other norms, norms that are not themselves pure formal coherence requirements, thus obviating the need for postulating pure formal coherence requirements.

Consider how this plays out in the case of (NC). Kolodny proposes an evidentialist response. Any violation of (NC) is indeed a violation of a norm, but the relevant norm being violated is a (narrow scope) evidential norm: the norm, roughly, that one has reason to believe a proposition only in so far as “the evidence indicates, or makes likely, that” the proposition is true. A norm, in other words, much like (EN) (in the supplement on Bridge Principles). The thought is that any instance of my violating (NC) is eo ipso an instance in which my beliefs are out of whack with the evidence. For when I hold contradictory beliefs, at least one of the beliefs must be unsupported by the evidence. As Kolodny puts it,

The attitudes that reason requires, in any given situation, are formally coherent. Thus, if one has formally incoherent attitudes, it follows that one must be violating some requirement of reason. The problem is not, as the idea of requirements of formal coherence as such suggests, that incoherent attitudes are at odds with each other. It is instead that when attitudes are incoherent, it follows that one of these attitudes is at odds with the reason for it—as it would be even if it were not part of an incoherent set. (Kolodny 2007: 231)

Another way of making Kolodny’s point is to note the following. Suppose I find myself believing both p
 and ¬p
, but that the evidence supports p
 (over its negation). If (NC) were the operative norm, I could satisfy it “against reason”, i.e., by coming to believe ¬p
. But adherence to (NC) contra the evidence seems like an unjustified “fetish” for “psychic tidiness”. (Kolodny proposes similar maneuvers for other types of putative formal coherence norms, and for norms of logical coherence in particular.)

What Kolodny assumes here is that there are, in Broome’s words, “no optional pairs of beliefs” (Broome 2013: 85). That is, it is never the case that belief in A
 and belief in ¬A
 is equally permissible in light of the evidence. As Broome points out, Kolodny’s assumption is founded on a commitment to evidentialism, which may cause some to get off the bus. Notice, though, that even if we accept Kolodny’s argument along with its evidentialist presuppositions, there may still be room for logical norms. Such norms would not constrain beliefs directly, since only evidence constrains our beliefs on Kolodny’s view. Yet, the evidence itself would be structured by logic. For instance, if A
 entails B
, then since A
 cannot be true without B
 being true, any evidence that counts in favor of A
 should also count in favor of B
. Logic would then still exert normative force. However, its normative force would get only an indirect grip on the agent’s doxastic attitudes by constraining the evidence. It is not clear how robust the distinction is, especially against the background of conceptions that take evidence to be constituted largely (or entirely) by one's beliefs. Moreover, Alex Worsnip 2015 has argued that in cases of misleading higher-order evidence, failures of coherence cannot ultimately be explained in terms of failures to respond adequately to the evidence.

5.2 Consistency and coherence
At the outset we identified two logical properties as the two central protagonists in any story about the normative status of logic: consistency and logical consequence. So far our focus has been almost exclusively on consequence. Let us now briefly turn to norms of consistency.

The most natural and straightforward argument for consistency is that the corresponding norm—something along the lines of CON—is entailed by the truth norm for belief:

(TN)	For any proposition A
, if an agent S
 considers or has reason to consider A
, S
 ought to believe A
 if and only if A
 is true.[21]
The truth norm entails the consistency norm (given certain assumptions):

(CN)	For any agent S
, the set of propositions believed by S
 at any given time ought to be logically consistent.
For if the set of propositions I believe at a particular point in time is inconsistent, they cannot all be true, which is to say that I am violating the truth norm with respect to at least one of my beliefs.

Some objections to the consistency norm are closely related to the considerations of Excessive Demands. And even in cases where it would be within our powers to discover an inconsistency given our resources of computational power, time and so on, it may still be reasonable to prioritize other cognitive aims rather than expending significant resources to resolve a minor inconsistency (Harman 1986). However, many authors who invoke (CN) do so in a highly idealized context. They think of the norm not as reason-giving or as a basis for attributing blame, but merely as an evaluative norm: an agent with an inconsistent belief set is less than perfectly rational.[22]

Another reason for rejecting CON is dialetheism (see entry on dialetheism). Clearly, if there are true contradictions, there are special cases in which one ought to have inconsistent beliefs.

But there is a further worry about consistency borne out of less controversial assumptions. It stems from the aforementioned fact that we do not only evaluate our beliefs according to their truth status but also in terms of their reasonableness in light of the evidence. Accordingly, there would seem to be an epistemic norm, like (EN) in the supplement on Bridge Principles, that one ought to (or may) believe a proposition only if that proposition is likely to be true given the evidence. But if that is so, the following well-known scenario may arise: it may be that, for a set of propositions, I ought to (may) believe each of them in light of the evidence, yet—because evidential support is not factive—the resulting belief set turns out to be inconsistent. Therefore, if rationality demands that I align my beliefs with the evidence, rationality is no guarantee for logical consistency. Of course, it is precisely this clash between our (local) evidential norm and the (global) coherence norm of logical consistency that is dramatized in the Preface and in the Lottery paradoxes.

In light of such considerations, no small number of authors have come to reject the consistency norm (see inter alia Kyburg 1970 and Christensen 2004). A particularly interesting positive alternative proposal was recently made by Branden Fitelson and Kenny Easwaran (Fitelson and Easwaran 2015, Easwaran 2015). They advance a range of sub-consistency coherence norms for full belief inspired by Joyce-style accuracy-dominance arguments for probabilism as a norm for credences (see Joyce 1998, 2009 and also the entry on epistemic utility arguments for probabilism). One important such norm is based on the following conception of coherence. Roughly, a belief set is coherent just in case there is no alternative belief set that outperforms it in terms of its lower measure of inaccuracy across all possible worlds, i.e., just in case it is not weakly dominated with respect to accuracy.

5.3 Logic vs. probability theory
Even if there is a plausible sense in which logic can be said to be normative for thought or reasoning, there remains a worry about competition. Logic-based norms usually target full beliefs. If that is correct, a significant range of rationally assessable doxastic phenomena fall outside of the purview of logic—most significantly for present purposes, degrees of belief.[23] Degrees of belief, according to the popular probabilist picture, are subject not to logical, but to probabilistic norms, in particular the synchronic norm of probabilistic coherence.[24] Consequently, the normative reach of logic would seem (at best) to be limited; it does not exhaust the range of doxastic phenomena.

Worse still, some philosophers maintain that degrees of belief are the only doxastic attitudes that are, in some sense, “real”, or at least the only ones that genuinely matter. According to them, only degrees of belief are deserving of a place in our most promising accounts of both theoretical (broadly Bayesian) and practical (broadly decision-theoretic) accounts of rationality. Full belief talk is either to be eliminated altogether (Jeffrey 1970), or reduced to talk of degrees of belief (ontologically, explanatorily or otherwise). Others still acknowledge that the concept of full belief plays an indispensable role in our folk-psychological practices, but nevertheless deem it to be too blunt an instrument to earn its keep in respectable philosophical and scientific theorizing (Christensen 2004). Virtually all such “credence-first” approaches have in common that they threaten to eliminate the normative role of logic, which is superseded or “embedded” (Williams 2015) in probabilism.

A number of replies might be envisaged. Here we mention but a few. First, one may question the assumption that logical norms really have no say when it comes to credences. Field’s quantitative bridge principle is a case in point. As we have seen, it does directly connect logical principles (or our attitudes towards them) with constraints on the allowable ways of investing confidence in the propositions in question. To this it might be retorted, however, that Field’s proposal in effect presupposes some (possibly non-classical) form of subjective probability theory. After all, in order to align one’s credences with the demands of logic, one must be capable of determining the numerical values of one’s credences in logically complex propositions on the basis of one’s degrees of belief in simple propositions. This is most naturally done by appealing to probability theory.[25] But if so, it looks as if probability theory is really doing all of the normative work and hence that logic would seem to be little more than a redundant tag-along. Second, one might try to downplay the importance of degrees of belief in our cognitive economy. In its strongest form such a position amounts to a form of eliminativism or reduction in the opposite direction: against credences and in favor of full belief. Harman (1986), for instance, rejects the idea that ordinary agents operate with anything like credences. Harman does not deny that beliefs may come in varying degrees of strength. However, he maintains that this feature can be explained wholly in terms of full beliefs: either as belief in a proposition whose content is probabilistic or else

as a kind of epiphenomenon resulting from the operation of rules of revision [e.g., you believe P
 to a higher degree than Q
 iff it is harder to stop believing P
 than to stop believing Q
]. (Harman 1986: 22)

More moderate positions accord both graded and categorical beliefs along with their respective attendant norms a firm place in our cognitive economies, either by seeking to give a unified account of both concepts (Foley 1993; Sturgeon 2008; Leitgeb 2013) or else by reconciling themselves to what Christensen (2004) calls a “bifurcation account”, i.e., the view that there is no unifying account to be had and hence that both types of belief and their attendant norms operate autonomously (Buchak 2014; Kaplan 1996; Maher 1993; Stalnaker 1984). Summarizing, then, so long, at least, as full belief continues to occupy an ineliminable theoretical role to in our best theories, there still is a case to be made that it is to logic that we should continue to look in seeking to articulate the norms governing these qualitative doxastic states.

1. Defining Perceptual Learning
In 1963, the psychologist Eleanor Gibson wrote a landmark survey article on perceptual learning in which she purported to define the term. According to Gibson, perceptual learning is “[a]ny relatively permanent and consistent change in the perception of a stimulus array, following practice or experience with this array…” (1963: 29).[1] Gibson’s definition has three basic parts. First, perceptual learning is long-lasting. Second, it is perceptual. Third, it is the result of practice or experience. This entry expands on each of these features of the definition.

1.1 Perceptual Learning as Long-Term Perceptual Changes
Perceptual learning involves long-term changes in perception. This criterion rules out short term perceptual changes due to sensory adaptation (for more on sensory adaptation see Webster 2012). In the waterfall illusion, for instance, a person who looks at a waterfall for a minute, and then looks away at some rocks, sees the rocks as moving even though they are not. This is a short-term change in perception, lasting perhaps for fifteen to thirty seconds. Since it is not a long-term change in perception, however, it does not count as perceptual learning. In another short term adaptive change, a person who goes indoors after walking through a blizzard may have trouble as her eyes adjust to the new lighting. There is a change in her perception as a result of her experience in the blizzard. But it is not a long-term change, and so it does not count as perceptual learning.

While there are clear cases of long-term experience-induced perceptual changes and clear cases of short-term experience-induced perceptual changes, there may be intermediary cases where it is difficult to tell whether they count as long-term or not. In such cases, in order to determine whether the case is a genuine case of perceptual learning, it may be necessary to look at the mechanisms involved (see section 2 below on the mechanisms of perceptual learning). If the mechanisms involved are characteristic of other cases of perceptual learning, then that is a reason to count the case as an instance of perceptual learning. If the mechanisms involved are uncharacteristic of perceptual learning, then that is a reason not to count the case as an instance of perceptual learning.

1.2 Perceptual Learning as Perceptual Changes
Perceptual learning involves changes in perception.[2] This rules out mere changes in aesthetic taste, among other things. For instance, imagine a contrarian who likes things only insofar as other people do not like those things. Suppose he finds out that everyone else has come to like his favorite microbrew. This might cause him to change how he judges that beer aesthetically. However, the beer may well taste the same to him. So, it is not a case of perceptual learning, but a mere change in the person’s aesthetic judgment. The fact that perceptual learning involves changes in perception also rules out mere changes in belief. Suppose someone acquires the belief that the symphony movement they are hearing is a scherzo. If nothing changes in that person’s perception, this is not a case of perceptual learning. It is a change in the person’s belief, not a change in the person’s perception.

Exactly how to distinguish perceptual from non-perceptual changes is a matter of ongoing inquiry. In the empirical literature, Goldstone (2015) and Watanabe and Sasaski (2015) characterize perceptual learning in terms of a change in task performance, such as increased perceptual sensitivity. Connolly (2019) and Prettyman (2019) have argued that perceptual change must also involve a change in the phenomenology of perception, or what it’s like to undergo that perceptual experience. By contrast, Chudnoff (2020) defends the view that perceptual learning sometimes involves the acquisition of new perceptual facts, such as which features of a stimulus are most relevant for categorization. Jenkin (2023b) adopts a permissive definition of perceptual change, including not only changes in phenomenology but also perceptual content, format, or the link between perception and action.

Whichever way this debate is settled, it is important here to distinguish perceptual learning from learning that is simply based on perception (see Dretske 2015: fn. 6).[3] Perceptual learning involves changes in perception, while learning that is based on perception need not. Looking at my table, I might learn that the cup is on the table. However, this does not involve any long-term changes in perception. It is learning that is based on perception, but it is not perceptual learning. Furthermore, I might learn to put the cup on the table into the dishwasher every time it is empty. Again, this is learning that is based on perception (I need to perceive the cup in order to move it). However, it is not perceptual learning.

One of the main reasons for holding that improvements in perceptual discrimination can be genuinely perceptual is due to somewhat recent evidence from neuroscience. As Manfred Fahle puts it, during the 1970s and 1980s, it tended to be the case that improvements in perceptual discrimination were thought to be cognitive rather than perceptual (2002: xii). However, during the 1990s, pressure was put on the cognitive interpretation due to new neuroscientific evidence in perceptual learning studies. In particular, studies found that learning-induced plasticity occurs in the adult primary sensory cortices much more than researchers had previously thought (Fahle 2002: xii). Neurological evidence of plasticity in adult primary sensory cortices due to learning provides some evidence that changes in perceptual discrimination can be due to perceptual learning. (See also Garraghty & Kass 1992: 522; Gilbert 1996: 269; Goldstone 2003: 238; Gilbert & Li 2012: 250; and Sagi 2011: 1552–53).

1.3 Perceptual Learning as Resulting from Practice or Experience
Perceptual learning involves perceptual changes of a particular kind, namely, those that result from practice or experience. For this reason, laser eye surgery or cataracts removal do not count as instances of perceptual learning. They are not really cases of learning because they do not result from practice or experience. So, while such cases involve long-term changes in perception, they do not count as cases of perceptual learning.

To be authentic cases of learning, perceptual changes have to be the result of a learning process. As a contrast case, suppose someone undergoes a long-term change in their perception due to a brain lesion. Such a change in perception does not result from a learning process, since the change in perception comes from the lesion, rather from practice or experience. Because of this, the case does not count as an instance of perceptual learning, even though it involves a long-term change in perception.

While some perceptual learning involves deliberate practice, as when a radiologist undergoes training to see a medical scan (Krasne et al. 2013), other learning can happen through mere exposure. For instance, Connolly (2019) and Jenkin (2023b) point out that perceptual learning can occur through exposure to bias or stereotypes in the environment. The portrayal of racist tropes in media may result in visual bias toward black faces when presented with a prime involving crime (Eberhard et al. 2004), and visual bias toward weapons when presented with a black face (Payne 2001). Cases of bias raise the possibility that we might be morally responsible for perception or harmed when our perception is warped in racist or sexist ways. Ransom and Goldstone (2024) argue that bias can be an unintended effect even when perceptual learning is successful. They point out that perceptual learning’s benefits are tied to a person’s interests and the training environment. Outside of that narrow context, perceptual improvements may become liabilities. Research on bias shows that the same mechanisms for improving perception can sometimes lead to changes that make perception less successful in some contexts.

1.4 Potential Further Criteria for Defining Perceptual Learning
The conversation above roughly follows Eleanor Gibson’s definition of perceptual learning. However, there are also other accounts in the psychology literature. Robert Goldstone’s account of perceptual learning, for instance, agrees with Gibson’s account in many respects, but it additionally offers a story about why perceptual changes occur in the first place. On Goldstone’s account,"Perceptual learning involves relatively long-lasting changes to an organism’s perceptual system that improve its ability to respond to its environment and are caused by this environment." (1998: 587) This definition offers an account of why perceptual learning occurs at all. On Goldstone’s account, perceptual learning occurs to improve an organism’s ability to respond to the environment.

Goldstone’s account admits of two different interpretations. On one interpretation, the account places a condition on perceptual learning: that to count as an instance of perceptual learning, a long-term perceptual change has to improve an organism’s ability to respond to the environment. Such an account gains plausibility if one thinks of “learning” as a success term. The idea is that each genuine instance of perceptual learning leads to success for the organism. Namely, it improves the organism’s ability to respond to the environment. On a second interpretation of Goldstone’s account, however, it is not that each instance of perceptual learning has to improve an organism’s ability to respond to the environment. Rather, it is that perceptual learning is a general capacity for improving an organism’s ability to respond to the environment, even if perceptual learning fails to do so in some instances. Why might organisms have such a capacity? One possibility is that the capacity is a trait that improves fitness and is the product of natural selection. However, the biological origin of perceptual learning is an area of research that still needs to be carefully explored.

1.5 Contrast Classes
1.5.1 Perceptual Development
How much of the perceptual development we undergo as infants and young children is the result of learning? There are many difficulties distinguishing development from learning, conceptually (for some discussion, see Carey 2009, especially pp. 11–14). The issue of how to distinguish development from learning bears on the traditional philosophical debate between nativists and empiricists (see Markie 2015, for a summary of that debate). In the perceptual learning literature, for instance, Kellman and Garrigan reject the view that all perceptual development is the result of learning, a view that they consider to be empiricist (2009: 57). Specifically, they think that data on infant perception collected in and around the 1980s provide evidence that at least some perceptual development is innate:

What this research has shown is that the traditional empiricist picture of perceptual development is incorrect. Although perception becomes more precise with age and experience, basic capacities of all sorts – such as the abilities to perceive objects, faces, motion, three-dimensional space, the directions of sounds, coordinate the senses in perceiving events, and other abilities – arise primarily from innate or early-maturing mechanisms (Bushnell, Sai, & Mullin 1989; Gibson et al., 1979; Held 1985; Kellman & Spelke 1983; Meltzoff & Moore 1977; and Slater, Mattock, & Brown 1990). (Kellman & Garrigan 2009: 57)

In short, according to Kellman and Garrigan, evidence on infant perception—including evidence about object perception, the perception of faces, and the perception of three-dimensional space—tells against the view that all perceptual development is learned.

If not all perceptual development is learned, while all perceptual learning is learned, then there is a distinction between perceptual development and perceptual learning. One way to draw the distinction more fully is the following. Perceptual development involves perceptual learning. However, it does not just involve perceptual learning. It also involves what is called maturation. For instance, the abilities that Kellman and Garrigan describe above (object perception, the perception of faces, the perception of three-dimensional space, etc.) fall under the category of maturation.

There are many ways to try to draw the further distinction between perceptual maturation and perceptual learning. Some such ways are found in the debate between nativism and empiricism (see Samet 2008 and Markie 2015) and specifically in the difference between innate and acquired characteristics (see Griffiths 2009 and Cowie 2016). One potential criterion here is that cases of perceptual maturation involve perceptual abilities that are typical of the species, while cases of perceptual learning involve perceptual abilities that are not typical of the species. This criterion seems to get it right for some instances of perceptual learning, say, for those involved in birdwatching. After all, the perceptual abilities acquired in birdwatching are unique to birdwatchers, not typical of the entire human species. However, the criterion seems to get it wrong for other, more universal, instances of perceptual learning. For instance, since human faces are both ubiquitous and important to humans, the perceptual learning involved in face perception is in fact typical of the species.

In the literature on perceptual learning, by contrast, the distinction between perceptual learning and perceptual maturation is often drawn in terms of the role of the environment. On Goldstone’s account of perceptual learning, to count as perceptual learning, perceptual changes must be caused by the environment. It is important to understand why exactly Goldstone thinks that caused by the environment is a crucial feature of the definition. He thinks it is crucial since this criterion distinguishes between perceptual changes that are simply the result of maturation, and perceptual changes that are the result of learning. As Goldstone puts it, “If the changes are not due to environmental inputs, then maturation rather than learning is implicated” (1998: 586). Manfred Fahle puts it similarly by saying that the term maturation “ascribe[s] the main thrust of the changes in a behavior to genetics, not the environment” (2002: xi). For Fahle, this is what distinguishes it from perceptual learning.

1.5.2 Perception-Based Skills
A further point of contrast with perceptual learning is perception-based skills, such as dart-throwing or racecar driving. To understand the relationship between perceptual learning and perception-based skills, start by considering the following case. Williams and Davids (1998) reported that when expert soccer players defend opponents, they focus longer on their opponent’s hips than non-experts do. This tuned attention is a long-term change in perception that results from practice or experience. That is, it is an instance of perceptual learning (see section 2.3 below). Such changes certainly serve to enable perception-based skills. For instance, attending to the hips is part of what enables the soccer players to defend well. Since the hips provide a cue for what the offensive player will do next, when the defender attends there, it helps them to do all sorts of things: to keep the offensive player from dribbling by them; to keep the offensive player from completing a pass; and to keep them from shooting and scoring. Without the attentional tuning, the expert soccer players would not be able to perform as high above baseline as they do.

Perceptual learning can enable perception-based skills, yet it is important to distinguish these skills from perceptual learning. In fact, arguably, as Stanley and Krakauer (2013) claim, perceptual learning does not in itself give you a skill, properly speaking. One reason why, drawing on Stanley and Krakauer, is that skills quite plausibly require instruction (at least initially), or observation of someone else (2013: 3). Perceptual learning, by contrast, can at times be unsupervised learning (see Goldstone 2003: 241 and Goldstone & Byrge 2015: section 3). Long-term, learning-induced changes in perception sometimes happen through mere exposure to stimuli, and without any instruction whatsoever. Furthermore, arguably, as Stanley and Krakauer put it, “our skilled actions are always under our rational control…” (2013: 3; see also Stanley & Williamson 2017: 6). Yet, there is an important sense in which one cannot control a tuned attentional pattern like that of the expert soccer players mentioned above. Goldstone, for instance, cites a study on attentional tuning by Shiffrin and Schneider (1977). In that study, letters were used first as targets in the experiment, but later letters were used as distractors to be ignored (Goldstone 1998: 589). Due to their prior training with the letters, the subjects’ attention became automatic with respect to the letters in the scene, even though they were trying to deliberately ignore them. More generally, after training, it is difficult to rationally control a tuned attentional pattern because the attention is automatic toward particular properties.

1.5.3 Cognitive Permeation
Perceptual learning involves changes in perception that are long-term. This long-term criterion rules out some cases of cognitive permeation,[4] that is, cases where one’s beliefs, thoughts, or desires influence one’s perception (see Macpherson 2012: 24). For instance, to borrow a case from Susanna Siegel (2012), if Jill sees Jack as angry because she just now believes Jack is angry, this need not be a case of perceptual learning, since it need not be a long-term change. After all, if Jill changes her belief that Jack is angry shortly after, she will no longer see his neutral face as angry. It would be a short-term change in her perception, not a long-term one. And so it would not be a case of perceptual learning.

Simply because some cases of cognitive permeation are not cases of perceptual learning, however, it does not follow that no cases of cognitive permeation are cases of perceptual learning. Jerry Fodor distinguishes between synchronic permeation and diachronic permeation, where only the latter involves “experience and training” (1984: 39). The case of Jack and Jill is a case of synchronic permeation, one where the permeation does not involve experience and training. However, at least some cases of perceptual learning might more plausibly fit into the category of diachronic permeation. (For more on the relationship between perceptual learning and cognitive permeation, see section 3.2)

1.5.4 Machine Learning
Machine perception seeks “to enable man-made machines to perceive their environments by sensory means as human and animals do” (Nevatia 1982: 1). Standard cases of machine perception involve computers that are able to recognize speech, faces, or types of objects. Some types of machine perception are simply programmed into the device. For instance, some speech recognition devices (especially older ones) are simply programmed to recognize speech, and do not learn beyond what they have been programmed to do. Other types of machine perception involve “machine learning” where the device learns based on the inputs that it receives, often involving some kind of feedback.

Like cases of perceptual learning, machine learning can be either supervised or unsupervised, although these distinctions mean something very specific in the machine case. In supervised learning, builders test the machine’s initial performance on, say, the recognition of whether a given image contains a face. They then measure the performance error and adjust the parameters of the machine to improve performance (LeCun, Bengio, & Hinton 2015: 436). Importantly, in cases of supervised learning, engineers program into the machine which features it should look for when, say, identifying a face. In cases of unsupervised learning, by contrast, the machine does not have information about its target features. The machine merely aims to find similarities in the given images, and if it is successful, the machine comes to group all the faces together according to their similarities (Dy & Brodley 2004: 845).

In machine learning, one major difficulty is that machines can develop racist and sexist patterns (for several examples, see Crawford 2016). The problem is often that engineers input a biased set of images (such as a set of images that include too many white people) into the machine, from which the machine builds its model (Crawford 2016). This suggests a potential corresponding source of bias in human perceptual learning, based on the inputs that humans receive through media.

1.6 The Function of Perceptual Learning
Why do perceptual systems remain plastic throughout the life course, rather than fixed? Or, to put the question slightly differently, what is the function of perceptual learning? According to Connolly’s (2019) “Offloading View,” the purpose of perceptual learning is the offloading of cognitive tasks onto perception in order to free up cognitive resources for other tasks. Just as for a president of a country, more menial jobs are offloaded to others in order to prioritize more important ones, so too are some previously cognitive tasks offloaded to perception so that cognition can prioritize others (Connolly 2019, ch. 1, s. 1.4). Consider the example of learning a second language. At first, the learner must pay careful attention to each sentence and word, laboriously recalling definitions or rules of grammar to decipher the meaning inferentially. As they develop fluency, these tasks are offloaded to perception, and the listener can direct attention to more sophisticated tasks, like formulating a response.

While the Offloading View appears to be shared by some psychologists working on perceptual learning (see Goldstone, de Leeuw, & Landy 2015 and Kellman & Massey 2013), it is also open to a number of criticisms (see O’Callaghan 2022 and Jenkin 2023d). Two alternatives to the Offloading View have emerged in the philosophical literature.

The first alternative is that perceptual learning (like learning more generally) aims at knowledge. O’Callaghan (2022), for instance, suggests that the purpose of perceptual learning is the acquisition of perceptual know-how. Learning improves perception via the acquisition of new perceptual capacities. Returning to Connolly’s example of learning a language, the idea is that the novice language learner does not know how to perceive meaningful sentences, whereas the expert does know how, in virtue of acquiring new perceptual capacities to detect and differentiate phonological features of that language.

Another alternative is what Jenkin (2023d) calls the “Perceptual View”: the function of perceptual learning is to improve the functioning of perception. Perception is improved when it enables better contact with the world around us, for instance, by being more accurate or efficient. For example, learning a language enables a person to more accurately or efficiently perceive words and sentences in that language. But, as Jenkin points out, not all examples of perceptual learning involve higher-cognitive functions like learning a language does. There is evidence that even infants and non-human animals undergo perceptual learning for a range of stimuli. On Jenkin’s view, improving perception is the function of perceptual learning, regardless of its effects on cognition.

2. Varieties of Perceptual Learning
The psychology literature provides ample evidence of perceptual learning. Goldstone (1998) helpfully distinguishes between four different types of perceptual learning in the literature: differentiation, unitization, attentional weighting, and stimulus imprinting. This section surveys these four types of perceptual learning (for further review, see Goldstone 2003; Goldstone, Braithwaite, & Byrge 2012; and Goldstone & Byrge 2015).

2.1 Differentiation
When most people reflect on perceptual learning, the cases that tend to come to mind are cases of differentiation. In differentiation, a person comes to perceive the difference between two properties, where they could not perceive this difference before. It is helpful to think of William James’ case of a person learning to distinguish between the upper and lower half of a particular kind of wine. Prior to learning, one cannot perceive the difference between the upper and lower half. However, through practice one becomes able to distinguish between the upper and lower half. This is a paradigm case of differentiation.

Psychologists have studied differentiation in lab environments. In one such study, experimenters took six native Japanese speakers who had lived in the United States from between six months and three years (Logan, Lively, & Pisoni 1991). The subjects were not native English speakers. The experimenters found that they were able to train these subjects to better distinguish between the phonemes /r/ and /l/. This is a case of improved differentiation, where the subjects became better at perceiving the difference between two properties, which they had more trouble telling apart before.

2.2 Unitization
Unitization is the counterpart to differentiation. In unitization, a person comes to perceive as a single property, what they previously perceived as two or more distinct properties. One example of unitization is the perception of written words. When we perceive a written word in English, we do not simply perceive two or more distinct letters. Rather, we perceive those letters as a single word. Put another way, we perceive written words as a single unit (see Smith & Haviland 1972). This is not the case with non-words. When we perceive short strings of letters that are not words, we do not perceive them as a single unit. Goldstone and Byrge provide a list of items for which there is empirical evidence of such unitization:

birds, words, grids of lines, random wire structures, fingerprints, artificial blobs, and three-dimensional creatures made from simple geometric components. (2015: 823)

While unitization and differentiation are converses, the one unifying and the other distinguishing, Goldstone and Byrge also conceive of them as “flip sides of the same coin” (2015: 823). This is because, as they put it, both unitization and differentiation “involve creating perceptual units…” (2015: 823). Regardless of whether the unit arises from the fusion or the differentiation of two other units, both instances of perceptual learning involve the creation of new perceptual units.

2.3 Attentional Weighting
In attentional weighting, through practice or experience people come to systematically attend toward certain objects and properties and away from other objects and properties. Paradigm cases of attentional weighting have been shown in sports studies, where it has been found, for instance, that expert fencers attend more to their opponents’ upper trunk area, while non-experts attend more to their opponents’ upper leg area (Hagemann et al., 2010). Practice or experience modulates attention as fencers learn, shifting it towards certain areas and away from other areas.

In the case of the expert fencer, a shift in the weight of attention to the opponents’ upper trunk area facilitates the expert’s fencing skills. However, shifts in attentional weighting can also fail to facilitate skills or even stifle them. For example, a new golfer with inadequate coaching might develop the bad habit of attending to their putter while putting, rather than learning to keep their “eye on the ball.” This unhelpful shift in attentional weighting may well stifle the new golfer’s ability to become a skillful putter.

One way to understand weighted attention is as attention that has become automatic with respect to particular properties. In other words, when the expert fencer attends to the upper trunk area, this attention is no longer governed by her intention (see Wu 2014: 33, for more on this account of automaticity). Rather, as the result of practice, the expert fencer’s attention is now automatic with respect to the trunk area. This italicized part is important. On Wayne Wu’s account of attention, for instance, one might ask whether attention is automatic with respect to different features of the process of attention: “where attention is directed and in what sequence, how long it is sustained, to what specific features in the scene, and so on” (p. 34). In the case of the expert fencer, plausibly her attention is automatic with respect to the trunk area, even if it is not automatic in other respects. This automaticity is the product of her learning process.

2.4 Stimulus Imprinting
Recall that in unitization, what previously looked like two or more objects, properties, or events later looks like a single object, property, or event. Cases of “stimulus imprinting” are like cases of unitization in the end state (you detect a whole pattern), but there is no need for the prior state—no need for that pattern to have previously looked like two or more objects, properties, or events. This is because in stimulus imprinting, the perceptual system builds specialized detectors for whole stimuli or parts of stimuli to which a subject has been repeatedly exposed (Goldstone 1998: 591). Cells in the inferior temporal cortex, for instance, can have a heightened response to particular familiar faces (Perrett et al., 1984, cited in Goldstone 1998: 594). One area where these specialized detectors are helpful is with unclear or quickly presented stimuli (Goldstone 1998: 592). Stimulus imprinting happens entirely without guidance or supervision (Goldstone 2003: 241).

3. The Philosophical Significance of Perceptual Learning
Perceptual learning is philosophically significant both in itself, and for the role that it has played in prior philosophical discussions. Sections 3.1–3.4 will focus on the latter. However, there are good reasons to see perceptual learning as philosophically significant in itself, independently from the role that it has played in prior philosophical discussions.

Why is perceptual learning philosophically significant? One reason is that it says something about the very nature of perception—that perception is more complex than it might seem from the first-person point of view. Specifically, the fact that perceptual learning occurs means that the causes of perceptual states are not just the objects in our immediate environment, as it seems at first glance. Rather, given the reality of perceptual learning, there is a long causal history to our perceptions that involves prior perception. When the expert wine-taster tastes the Cabernet Sauvignon, for example, that glass of wine alone is not the sole cause of her perceptual state. Rather, the cause of her perceptual state includes prior wines and prior perceptions of those wines. One way to put this is to say that perception is more than the immediate inputs into our senses. It is tied to our prior experiences.

Another way in which perceptual learning is philosophically significant is because it shows how perception is a product of both the brain and the world. In this respect, there are some similarities between the role of constancy mechanisms and the role of perceptual learning, in that both involve the brain playing a role in structuring perception in a way that goes beyond the perceptual input. Constancy mechanisms, such as those involved in shape, size, and color constancy, are brain mechanisms that allow us to perceive shapes, sizes, and colors more stably across variations in distance or illumination. In cases of constancy, the brain manipulates the input from the world, and this allows the perceiver to track the shape, size, or color more easily. Similarly, in cases of perceptual learning, the brain manipulates the input from the world. In many cases, this may actually make the perception more helpful, as when through learning the perceptual system weights attention in a particular way, say, towards the features relevant for identifying a Cabernet Sauvignon. Perceptual learning might upgrade the epistemic status of perception, putting the perceiver in a better position with respect to knowledge (see Siegel 2017). At the same time, people can learn incorrectly, leading to perceptions that are unhelpful, as when a new golfer with inadequate coaching develops the bad habit of attending to their putter while putting, rather than attending to the golf ball.

Perceptual learning is philosophically significant in itself. In addition, the rest of section 3 goes on to explore the role that perceptual learning has played in prior philosophical discussions.

3.1 The Contents of Perception
In the philosophy literature, cases of perceptual learning have often been used to show that through learning we come to represent new properties in perception, which we did not represent prior to learning. Siegel (2006, 2010), for instance, asks us to suppose that we have been tasked to cut down all and only the pine trees in a particular grove of trees. After several months pass, she says, pine trees might begin to look different to us. This is a case of perceptual learning, a long-term change in our perception following practice or experience with pine trees. Siegel uses the case to argue that perception comes to represent kind properties, like the property of being a pine tree. The idea is that the best way to explain the change in perception is that perception represents the property of being a pine tree after, but not before, learning takes place. That property becomes part of the content of perception: it comes to be presented in perceptual experience (for more background on the contents of perception, see Siegel 2016).

Thomas Reid’s notion of acquired perception has recently been interpreted in a way similar to Siegel’s pine tree case. According to Reid, some of our perceptions, namely acquired perceptions, are the result of prior experience. For instance, Reid writes about how through experience we might come to “perceive that this is the taste of cyder,” or “that this is the smell of an apple,” or that “this [is] the sound of a coach passing” ([1764] 1997: 171). Rebecca Copenhaver (2010, 2016) has interpreted Reid as claiming that through experience properties like being a cider, being an apple, and being a coach can come to be part of the content of our perception.

Cases of perceptual learning might also be used to show that through learning we come to represent new properties in perception, even if those properties are simply low-level properties like colors, shapes, textures, and bare sounds, rather than high-level kind properties like being a pine tree or being a cider. For instance, in discussing the perceptual expertise of jewelers, the 14th-century Hindu philosopher Vedānta Deśika writes, “[T]he difference among colours [of a precious stone], which was first concealed by their similarity, is eventually made apparent as something sensual”…. (Freschi [trans.] manuscript, Other Internet Resources, pp. 12–13) In this case, the jeweler comes to perceive new colors in the gemstone, which others cannot perceive. This is a case where through learning someone comes to perceive a new low-level property.

The cases from both Reid and Vedānta Deśika both speak to the internal complexity of perception mentioned in the previous section. If Vedānta Deśika’s description of the jeweler case is accurate, then perception is more than the inputs into our senses, since both an expert jeweler and a non-expert can have the same visual inputs, but have different perceptions. Similarly, to take a new example from Reid, suppose that a farmer acquires the ability to literally see the rough amount corn in a heap ([1764] 1997: 172). Since both a farmer and a non-farmer can have the same visual inputs, but have different perceptions, the causes of their perceptions are not just restricted to the immediate objects out in their environment. Perception is more complex than that.

One of the most detailed contemporary discussions of cases of perceptual learning is found in Siewert (1998: section 7.9). Siewert discusses in detail the role that learning plays in altering perceptual phenomenology, although he stops short of saying that this affects the high-level contents of perception. He writes, for instance, that there is a difference in perceptual phenomenology between just seeing “something shaped, situated, and colored in a certain way,” and recognizing that thing as a sunflower (or another type) (1998: 255). Siewert also writes that a person might look different to you after you know them for a long time than they did the first time you met them, and that your neighborhood might look different to you after you have lived there for a long time than the first time you moved in (pp. 256, 258). Furthermore, he writes about how a chessboard in midgame might look differently to a chess player than to a novice, and how a car engine might look differently to a mechanic than to someone unfamiliar with cars (1998: 258). These are all examples where learning affects one’s sensory phenomenology.

Several cases of perceptual learning in the philosophical literature involve language learning, both in the case of written and spoken language. As an example of the former, Christopher Peacocke writes that there is a difference “between the experience of a perceiver completely unfamiliar with Cyrillic script seeing a sentence in that script and the experience of one who understands a language written in that script.” (1992: 89)

With regard to spoken language, as Casey O’Callaghan (2011) points out, several philosophers have made the claim that after a person learns a spoken language, sounds in that language comes to sound different to them (O’Callaghan cites Block 1995: 234; Strawson 2010: 5–6; Tye 2000: 61; Siegel 2006: 490; Prinz 2006: 452; and Bayne 2009: 390). Ned Block, for instance, writes, “[T]here is a difference in what it is like to hear sounds in French before and after you have learned the language” (1995: 234). It is tempting to think that this difference is explicable in terms of the fact that, after learning a language, a person hears the meanings of the words, where they do not before learning the language. On such a view, meanings would be part of the contents of auditory perception. However, O’Callaghan (2011) denies this (see also O’Callaghan 2015 and Reiland 2015). He argues that the difference is in fact due to a kind of perceptual learning. Specifically, through learning we come to hear phonological features specific to the new language. As O’Callaghan argues, these phonological features, not the meanings, explain what it’s like to hear a new language.

By contrast, Brogaard (2018) argues that meanings are in fact part of the content of perception (see also Pettit 2010). After offering arguments against the opposing view, she relies on evidence about perceptual learning to help make the positive case for her view. In particular, she uses evidence about perceptual learning to rebut the view that we use background information about context and combine it with what we hear, in order to get meanings. Instead, she argues, language learning is perceptual in nature. She points to changes in how we perceive utterances, more in chunks rather than in parts, as a result of learning. Background information directly influences what we hear, she argues, altering how language sounds to us.

Both Siegel’s pine tree case and the case of hearing a new language fundamentally involve phenomenal contrasts. That is, the motivating intuition in both cases is that there is a contrast in sensory phenomenology between two perceptual experiences. Interestingly, in both cases the phenomenal contrast is due to learning. The question in both the pine tree case and the new language case is what explains the difference in sensory phenomenology. Siegel argues that the best explanation in the pine tree case is that the property of being a pine (and, more generally, natural kind properties) can come to be represented in perception. O’Callaghan (2011) argues that the best explanation for the difference in sensory phenomenology in the new language case is that we come to hear phonological features specific to the new language. Brogaard (2018) argues that the best explanation in that case is that we come to hear meanings in the new language. Ongoing debate in the literature concerns the extent to which perceptual experts represent high-level properties (like kinds or meanings) as such (Ransom 2020; Burnston 2021, 2023; Landers 2021).

3.2 Cognitive Permeation
Recall that cases of cognitive permeation are cases where one’s beliefs, thoughts, or desires influence one’s perception (see Macpherson 2012: 24). One role of perceptual learning in the philosophical literature has been to explain away putative cases of cognitive permeation. For instance, it might seem at first glance that Siegel’s pine tree case is a case of cognitive permeation, a case where one’s newly acquired concept of a pine tree influences one’s perception. Connolly (2014b) and Arstila (2016), however, have both argued that the best way to understand Siegel’s pine tree case is not as a case of cognitive permeation, but rather through the particular mechanisms of perceptual learning. Connolly counts it as a case of attentional weighting, while Arstila understands it as involving both unitization and differentiation.

One reason why perceptual learning is a good instrument for explaining away putative cases of cognitive permeation is the following. In cases of perceptual learning, it is the external environment that drives the perceptual changes. As Raftopoulos puts it, “perceptual learning does not necessarily involve cognitive top-down penetrability but only data-driven processes” (2001: 493). For putative cases of cognitive permeation, the strategy for the perceptual learning theorist is to show how the perceptual changes involved may have been data-driven instead of top-down. Several philosophers have used this strategy at times, including Pylyshyn (1999: section 6.3), Brogaard and Gatzia (2015: 2), as well as Stokes (2015: 94), and Deroy (2013) might be interpreted in that way as well.

Canonical examples of cognitive permeation involve a putative synchronic effect of cognitive states on perception (such as Siegel’s example of Jack and Jill discussed in s. 1.5.3). Even if synchronic cases of cognitive permeation can be explained away, perceptual learning cases complicate this picture by showing that perception is responsive to cognition diachronically (Siegel 2013; Cecchi 2014; Stokes & Bergson 2015; Stokes 2021; Burnston 2021). For instance, Jenkin gives an example involving chess players who undergo unitization, learning to chunk patterns of pieces on the chessboard in visual perception (Jenkin 2023c; Chase & Simon 1973; Gobet & Simon 1996; Leone et al. 2014). As she points out, this process is not only driven by visual exposure to the chessboard, but also by the players’ knowledge of rules and strategy. Perception is sensitive to the players’ beliefs and desires over time. This type of case raises the possibility that perception itself can be responsive to reasons, and therefore rationally evaluable. As Jenkin points out in her discussion of the chess players, it is an open question whether unitization is a rational response for the chess player to have, given what they know about the game and their goals. That is, one’s rational appraisal may depend not only on how they respond to perception, but also on which perceptual experiences they have (see also Siegel 2017).

An exception to the trend of explaining away putative cases of cognitive permeation in terms of perceptual learning is Cecchi (2014). Cecchi argues that a particular case of perceptual learning—that found in Schwartz, Maquet, and Frith (2002)—should count as a case of cognitive permeation. The study in question found changes in the primary visual cortex due to learning, and also that these changes were brought about by higher areas in the brain influencing the primary visual cortex. Because the perceptual changes were the result of top-down influence, Cecchi argues that this case of perceptual learning should count as a case of cognitive permeation.

3.3 The Theory-Ladenness of Observation
One traditional debate in the philosophy of science is whether scientific observation is permeated with the theory of the scientist, or theory-laden (see the entry on theory and observation in science). As Raftopoulos and Zeimbekis point out, when asking whether observation is theory-laden, the answer will depend in part on what it means for a subject to possess a theory (2015: 18). On their view, theories can be tacit, rather than just “having a set of beliefs and concepts” (p. 18).

Assuming that theories can be held tacitly, perceptual learning might plausibly play a role in making observation theory laden. Raftopoulos and Zeimbekis, for instance, ask us to imagine a scientist who has undergone perceptual learning in her expert domain (2015: 19). Specifically, through repeated exposure to items in her expert domain, she has developed perceptual sensitivity to certain features, in accordance with her professional needs. This includes learned attention to particular dimensions, and involves physical changes early in her visual system (p. 19). As a result, the scientist might quite literally see the world differently within her expert domain than someone from outside her expertise would see it.

Such a case suggests that perceptual learning can make observation theory-laden. The scientist’s perceptual system comes to shape the kind of visual information that makes it into the scientist’s conscious perception, and does so based on her professional needs. As Raftopoulos and Zeimbekis put it, the case suggests “that non-cognitive, clearly perceptual influences on incoming visual information can be indirect bearers of the kinds of theoretical commitments that we usually think of as the content of conceptually couched theories.” (2015: 19) Although the case does not involve explicit beliefs directly influencing perception, arguably it involves a theory being held tacitly and appropriated into one’s perceptual system.

One reason to care about the theory-ladenness of observation is that it challenges scientific objectivity, threatening skepticism or relativism. Stokes (2021, Chapter 8) resists this line of thinking. According to Stokes, although any particular observation may be theory-laden, this is compatible with objectivity because observation in science is not an individual endeavor, but instead relies on intersubjective practice. The scientific community works to resolve disputes by appealing to shared standards. This process might achieve intersubjective objectivity even in cases where an individual’s perception is theory-laden.

3.4 Modularity
According to the modular view of the mind (Fodor 1983), the basic systems involved in perception are encapsulated from information outside of it, excluding its inputs (see Robbins 2015, for a summary of modularity). It might then seem at first glance that cases of perceptual learning challenge the view that the mind is modular, at least insofar as they involve the modulation of perception through any background theory that the subject has. However, it is important to note that Fodor himself seems to allow for such cases of perceptual learning. While he thinks that perception is synchronically impermeable, he allows for the possibility of diachronic permeation, that is, cases where “experience and training can affect the accessibility of background theory to perceptual mechanisms” (1984: 39).

Why think that a modular view of the mind should allow for diachronic permeation? When Fodor allows for diachronic permeation, he does so because the alternative is to say that all modular systems are specified endogenously (1984: 39). Fodor admits that this alternative would be too extreme, and he points out, for instance, that children learn something from hearing a language. In other words, the modules for language are not just specified endogenously. However, Fodor is conservative about the scope of diachronic permeation, suggesting that it may only happen within strict limits, perhaps limits that are themselves endogenously defined (1984: 39–40).

Other philosophers have argued that diachronic permeation of perception undermines modularity. Churchland (1988), for instance, sees Fodor’s allowance of diachronic permeation as “grudgingly conceded,” and he argues that diachronic permeation is in fact widespread, rather than something that happens within strict limits (p. 176). One such case, raised by Churchland, is the case of perceiving music. Churchland argues that a person who knows the relevant music theory and vocabulary “perceives, in any composition whether great or mundane, a structure, development, and rationale that is lost on the untrained ear” (1988: 179). Fodor replies that it is unclear whether such cases are genuinely perceptual (1988: 195). He suggests another possibility, which is that the person who knows the relevant music theory does not perceive it differently, but rather forms different beliefs about the music. Furthermore, even if the case is genuinely perceptual, Fodor replies that it could be that a trained ear results simply from repeated exposure to the relevant music, rather than through knowledge of theory (1988: 195).

Stokes (2021) challenges this view using evidence for perceptual expertise. He argues against modularity and in favor of malleability, the view that perception has a “malleable architecture” that is sensitive to cognition and learning. Stokes’ argument against modularity has two prongs. The first challenges modularity with empirical examples; the second attempts to show that modularity does not have the kind of strong evidential support or explanatory power required for being the default position in theorizing about the mind. Stokes argues that malleability better explains empirical evidence for perceptual expertise (which he understands in terms of top-down cognitive permeation, not perceptual learning). Perceptual expertise shows that thinking both affects and improves perception, and this has wide reaching consequences not only for modularity but also for theories of epistemic virtue, agency, and perceptual success.

3.5 Epistemology
Experts in certain domains (wine-tasting, bird-watching, etc.) undergo perceptual changes that go beyond the perceptual learning that amateurs undergo in those same fields. The level of perceptual learning they achieve is more accurately called “perceptual expertise” (see Stokes 2021b; Chudnoff 2020). Epistemologists distinguish between two types of expert knowledge within an expert domain. First, there is the acquisition of specialized facts (or knowledge-that). And secondly, there is the development of specialized skills (or knowledge-how). Analogously, there are two options for understanding perceptual expertise. The first option conceives of perceptual expertise as a special acquisition of perceptual facts (Chudnoff 2017; Chomanski & Chudnoff 2018). On this view, a radiologist knows facts about disease that she accesses through the representational content of her experience of an X-ray. The second option conceptualizes perceptual expertise as a type of know-how that is constituted by a set of specialized perceptual capacities (Brogaard & Gatzia 2018; O’Callaghan 2022). On this view, a radiologist’s perceptual expertise consists in her differential sensitivity to the visual features of disease in an X-ray, such that she responds to those features’ presence and differentiates them from distinct features.

Perceptual expertise has epistemological consequences. For one, as Ransom (2020) argues, it expands the scope of perceptual knowledge. Perceptual learning enlarges the scope of immediately justified beliefs, and full-blown perceptual expertise does so even more. According to Ransom, this is independent of an expert’s background theory. Rather, it’s a consequence of their improved perceptual capacities within their domain of expertise. A second consequence concerns expert impressions of the world more broadly, such as intuitions. Chudnoff (2021) draws on the psychology of perceptual expertise to argue for an account of expert intuition as a type of intellectual perception. Due to learning, experts form epistemically better impressions than novices. This is part of what justifies our trust in them in the relevant perceptual and intellectual cases.

3.6 Aesthetics
The study of perceptual learning stands to deepen our understanding of the perceptual capacities involved in experiencing art (Stokes 2014). Perceptual learning can be taken to challenge the view of “aesthetic realism” by showing that an artwork’s appearance is not fixed by the work itself, but instead depends upon the perceiver and her prior experience. Nanay (2017), for instance, has argued for a modest antirealist position based on evidence for the mere exposure effect, which is an effect resulting from the perceptual learning process. The mere exposure effect is the finding that subjects tend to prefer art that they have seen before (Cutting 2003). As Nanay points out, this does not directly support an antirealist position, but it does undermine the main support for realism: the argument from agreement. Roughly and briefly, the argument from agreement states that realism is the best explanation for widespread agreement about aesthetic value. Nanay points out that the mere exposure effect undermines this argument by offering a more compelling account of agreement. Since most people within a culture have been exposed to similar “sensory properties,” they will come to prefer those properties (see also Cutting 2017 for a critical response).

On the other hand, perceptual learning provides the realist with a new avenue for understanding the role of expertise in accessing aesthetic properties like beauty or ugliness. Ransom (2022) appeals to perceptual learning to explain how training improves the perception of such properties in a work of art. On her view, the mechanisms of attentional-weighting and stimulus imprinting can result in changes to both low-level and high-level properties of art works (such as the property of “being an Impressionist painting”). These changes enable an expert to veridically perceive aesthetic properties in a work of art that are not accessible to the novice. But perceptual learning may not always improve the expert’s access to aesthetic properties, and could even impede it. Jenkin (2023a) gives an example of an architect who has trained their visual perception of 2-D depth and therefore cannot appreciate art works that rely on visual depth illusions, such as Edgar Mueller’s 3-D street art. The trained viewer would miss out on the awe and shock that the work is meant to inspire precisely because they not as susceptible to the same depth illusions as the novice.

1. Introduction
Compared with more widely discussed attitudes like belief and desire, the phenomenon of hope presents some unique challenges for both theories of the mind and theories of value. Hope is not only an attitude that has cognitive components—it is responsive to facts about the possibility and likelihood of future events. It also has a conative component—hopes are different from mere expectations insofar as they reflect and draw upon our desires. A classic analysis of hope—the so-called “standard account” (see section 3)—takes hope to be a compound attitude, consisting of a desire for an outcome and a belief in that outcome’s possibility. But not all outcomes that we believe to be possible and that we desire are thereby objects of our hope. In order to hope one not only has to consider an outcome possible, one also has to affectively engage with this outcome in a distinctive way. This raises the question as to whether hope can be reduced to beliefs and desires.

Popular discourse often takes hope to be synonymous with optimism. But while optimism can be usefully analyzed as a desire for an outcome together with a belief that the outcome is more likely than not (or more likely than the evidence leads other people to believe), many philosophers hold that hope, properly understood, is independent of probability assessments (see section 3). One can hope for outcomes that one considers to be very unlikely and that one does not expect to happen, such as a miraculous cure of an illness. In such cases, optimism is not an appropriate response.

It is an open question whether the contribution of hope to human agency is to be identified with that of the underlying desires or whether hope makes an independent contribution to motivation or reasoning. If one assumes that hope cannot make any independent contribution to practical reasoning but still motivates, this raises the suspicion that it distorts rational agency. While such an assessment can be found across the history of philosophy, many past and contemporary philosophers provide analyses of hope that add further elements to the belief-desire analysis and use these elements to explain why acting on one’s hopes is (sometimes) rational.

2. The Philosophical History of Hope
Historically, evaluations of hope change together with the prevailing view of the relationship between human action and the future. As long as the human condition is seen as essentially unchangeable, hope is more often treated as arising from mere epistemic uncertainty and as having ambivalent effects on human happiness. In philosophical contexts where either the possibility of a future life beyond this world or the idea of human progress is emphasized, hope is more often seen as an appropriate and even virtuous attitude that enables humans to direct their agency towards these possibilities (see Miceli and Castelfranchi 2010).

2.1 Ancient Accounts of Hope
Although there are few explicit and systematic treatments of hope (elpis) in ancient Greek philosophies, they nevertheless contain important approaches to the nature of hope and its role in the good life and practical deliberation (Gravlee 2020). Ambivalent evaluations of hope can be found in many texts. On the one hand, hope is often seen as an attitude of those who have insufficient knowledge or are easily swayed by wishful thinking. It thus has a negative reputation (Vogt 2017) as an attitude that (at least potentially) misleads actions and agents. Even Solon focuses on empty hopes (see Lewis 2006: 85; Caston and Kaster 2016). On the other hand, hope is praised as a response to despair, e.g., in the dialogues of Thucydides, who advances a nuanced view of the potential dangers and advantages of hope (Schlosser 2013). An ambivalent evaluation of hope is also reflected in Hesiod’s version of the tale of Pandora. When all the evils had escaped from Pandora’s jar, famously, only hope (elpis) remained (“Works and Days”, §90). This seems to suggest that hope can also sustain human agency in the face of widespread evil. It must be noted, however, that there are many competing interpretations of why elpis remained in the jar (Verdenius 1985): Was it to keep hope available for humans or, rather, to keep hope from humankind? Is hope consequently to be regarded as good (“a comfort to man in his misery and a stimulus rousing his activity”, Verdenius 1985: 66) or as evil (“idle hope in which the lazy man indulges when he should be working honestly for his living”, Verdenius 1985: 66)? These different interpretations of Pandora’s myth are taken up throughout the history of Philosophy (especially among existentialist authors, see section 2.5).

In Plato’s dialogues, we find negative as well as positive assessments of hope. In particular, Plato even argues that hope can be rational. In the Timaeus, Plato adopts a rather negative attitude towards hope by recounting a myth according to which the divine beings give us “those mindless advisers confidence and fear, (…) and gullible hope” (Timaeus, 69b). In the Philebus, by contrast, he seems to also allow for a more favorable view of the role of hope in human life. The relevant discussion of hope takes place in the context of an argument about “false pleasures”. Against Protarch’s objection that only opinions can be true or false, but not pleasures, Socrates develops an analogy between opinion and pleasure (Philebus, 36d). In this context, he describes “pleasures of anticipation”, that is, expectations of future pleasures, that are called hopes (Philebus, 39e3). As Frede (1985) argues, in the case of such pleasures of anticipation what we enjoy at present is only a thought. As there can be a discrepancy between the thought that we enjoy and what is in fact going to happen, the pleasure can be true—in which case it seems appropriate to say that the corresponding hope can be rationally endorsed—or false (Frede 1985: 174f.). The Philebus also presents hope as essential to human agency: Plato seems to suggest that all our agential representations are concerned with the future, which connects them to hope (Vogt 2017). Plato’s positive view of hope can also be found in the Apology and the Phaedo, where he argues that hope for the afterlife is rational (Gravlee 2020).

Aristotle’s treatment of hope in the context of his discussion of the virtue of courage has received some attention (Gravlee 2000; Lear 2006), as well as the role of hope in his practical philosophy in general (Kontos 2021a). On the one hand, Aristotle describes the relationship between hope and courage as a contrast. He identifies two sources of hopefulness that are non-courageous: First, it is possible to be hopeful “at sea […] and in disease”, but this hope does not involve courage, insofar as, in such situations, there is neither “opportunity of showing prowess”, nor is death “noble” in these cases, according to Aristotle (Nicomachean Ethics 3.6, 1115a35ff.). Second, one can be hopeful based on one’s experience of good fortune (Nicomachean Ethics 3.8, 1117a10ff.). In this case, the belief in the probability of a good outcome is not well grounded, but founded on mere induction. Both kinds of hopefulness are non-courageous. On the other hand, there is also a connection between hope and courage via the concept of confidence (Gravlee 2000). For example, Aristotle says:

The coward, then, is a despairing sort of person; for he fears everything. The brave man, on the other hand, has the opposite disposition; for confidence is the mark of a hopeful disposition. (Nicomachean Ethics 3.7, 1116a2)

Thus, even though not every hopeful person is courageous, every courageous person is hopeful. Hopefulness creates confidence, which, if derived from the right sources, can lead to the virtue of courage. Gravlee (2000: 471ff.) identifies two further considerations that are relevant for hope’s value in Aristotle’s thought. First, hope underlies deliberation, which is needed for any exercise of a virtuous disposition. Second, hopefulness is also presented as valuable in its connection with youth and the virtue of megalopsychia (high-mindedness): Hopefulness spurs us to the pursuit of the noble. Kontos (2021a, 2021b) focuses both on the phenomenology of hope in Aristotle’s thought, and the normative question of what the conditions are for “hoping-well”: He argues that hoping-well constitutes a correct engagement with moral luck, and it requires drawing on past experiences in a proper way as well as reliably perceiving the present reality.

Perhaps unsurprisingly, hope received a less favorable treatment by the Stoic philosophers. In particular, Seneca emphasizes hope’s relation to fear (an idea that is later taken up by Spinoza, see section 2.3):

[t]hey are bound up with one another, unconnected as they may seem. Widely different though they are, the two of them march in unison like a prisoner and the escort he is handcuffed to. Fear keeps pace with hope. Nor does their so moving together surprise me; both belong to a mind in suspense, to a mind in a state of anxiety through looking into the future. Both are mainly due to projecting our thoughts far ahead of us instead of adapting ourselves to the present. (Seneca, Letter 5.7–8; in: 1969: 38)

According to Seneca, we should avoid both fear and hope and instead focus on the present and cultivate tranquility of the soul.

2.2 Christian Authors on Hope
Pre-Christian accounts see hope mostly as an attitude to reality that is based on insufficient insight into what is true or good. By contrast, Christian philosophers such as Augustine and Thomas Aquinas analyze hope as one of the most central virtues of a believer: Hope, precisely in virtue of its capacity to justify action in a way which is not bound to knowledge, is a part of rational faith.

Even in Saint Paul’s argument for the extension of the Christian community beyond the Jewish law, hope plays a central role. Paul states that we can only hope for what is uncertain (Romans 8:24; see also Augustine, City of God, book XIX, §IV, 1960: 139). Nevertheless, such hope can be the product of the experience of suffering, if this experience is seen through the lens of faith (Romans 5:3–5) and if the desire to be saved from this suffering is supported by confidence in not being disappointed. Instead of backward-looking law-conformity (associated by Paul with the Jewish faith), it is such forward-looking hope that characterizes the appropriate relation to God. As an illustration, Paul describes Abraham as “hoping against hope” (Romans 4:18), emphasizing the way in which hope goes beyond the evidence.

Augustine of Hippo discusses hope systematically in his Enchiridion on Faith, Hope and Love (c. 420). Hope is distinguished from faith—which is also based on incomplete evidence—by two features: First, hope is necessarily directed to future events, whereas faith can also relate to past events (such as Christ’s resurrection). Second, hope only relates to what is good for the hopeful person, whereas faith can also relate to what is bad (such as punishment for one’s sins). Finally, hope, faith and love are seen as interconnected. Only if one loves the future fulfillment of God’s will and thus hopes for it can one arrive at the correct form of faith (Enchiridion, II.7). As love provides the normative outlook that underlies hope and faith (and thus, in some sense, the desire-component of hope), love is seen as a more central virtue than hope (Enchiridion, XXX.114).

The hope for a life after death also plays an important role in Augustine’s political philosophy. In the City of God, Augustine distinguishes the actual earthly city from the heavenly city that only exists in the hope placed in God (City of God, book XV, §XXI, 1966: 541). The latter provides a reference point for a Christian view of politics. Hope, however, not only provides for a perspective on politics which surpasses the narrow perspective of classical politics (Dodaro 2007), but an appropriate theorizing of hope also modifies the understanding of traditional political virtues, as it redirects their purpose from the earthly to the heavenly city. One example of such a modification concerns punishment: Through hope, a Christian ‘statesman’ will redirect punishment away from an exclusive concern with proportionality towards the potential reform of the criminal (City of God, book V, §XXIV, 1963: 263).

In one of his letters to Macedonius, a public official, Augustine finally emphasizes that the hope for a future life underlies all true human happiness, both on the level of the individual and of the state (Letter 155, Political Writings, §4–8, pp. 91–94). Thus, hope is not just of concern for individual believers but also for political leaders that are concerned with collective happiness, as paying attention to hope allows them to pursue a political constitution that allows true virtue of citizens to emerge (see also Dodaro 2007).

While Augustine is more or less exclusively concerned with the significance of hope for our pursuit of a good Christian life, Thomas Aquinas’ Summa Theologiae contains a systematic discussion of (ordinary) hope as a passion (ST I-II, q. 40) and as a theological virtue (ST II-II, qq. 17–22). The former is directed to finite, earthly goods, whereas hope as a theological virtue is directed to ultimate happiness in the union with God. Even though the two kinds of hope are clearly distinct, Aquinas provides a unified account of the formal features of their objects (I-II, q. 40, art.1) (see Bobier 2020a). The object of hope, he argues, is always thought to be good and future. Further, in contrast to mere desire, the objects of hope must be difficult to obtain but nevertheless in the realm of possibility (ST I-II 40.1). This rules out hope for that which is trivial to procure.

Regarding the rationality of hope, Aquinas has a nuanced view. On the one hand, he admits that a lack of experience can make one unaware of obstacles. This tendency (and drunkenness, ST I-II 40.6) can promote (irrational) hope. On the other hand, he assumes that hope can promote rational agency: As hope incorporates both knowledge of the possible and knowledge of the difficulties to reach the desired outcome, it can motivate agents to devote energy to their activities.

Because of this ambivalence, hope in the ordinary sense is not a virtue for Aquinas. As a passion, humans can display an excess and a deficiency of hope (ST II-II 17.5); furthermore, passions are not virtues by definition (Bobier 2018). This changes, however, as soon as we examine theological hope, i.e., the hope we can put in God. First, as primarily directed towards God, such hope does not know any excess. Second, we cannot understand theological hope as a passion. We must analyze it as a habit of the will. While hope as a passion can only be incited by sensible goods (and subsequently motivates action insofar as the subject takes herself to be capable of realizing that good), we can also hope for God’s assistance (ST II-II 17.1) in reaching eternal happiness (ST II-II 17.2). As eternal life and happiness are not sensible goods, this kind of hope cannot be a passion but must reside in the will (ST II-II 18.1). Note, however, that Aquinas describes the theological virtues as habits of the will of a special sort: They cannot be acquired by habituation, but can only be given by God’s grace (ST II-II 17.1, see Pinsent 2020 for an interpretation of hope as an “infused” virtue).

Because of these two features, hope is a theological virtue (ST II-II 17.5; see also 1 Corinthians 13). While love (or charity) is directed to God for the sake of unity, faith and hope are directed towards God with a view to some good to be obtained from that unity: Faith relates to God as a source of knowledge, hope relates to God as a source of goodness (ST II-II 17.6).

The rationality of theological hope can only be properly understood, according to Aquinas, when we acknowledge that hope has to be preceded by faith (which underlies the belief in the possibility of salvation), but, given faith, hope for the good of salvation is rational. In contrast to most modern discussions of hope, Aquinas and other Christian authors therefore see hope as compatible with confidence or even certainty about the hoped-for outcome while still excluding knowledge (Jeffrey 2020: 44). Despair, as caused either by the absence of faith or the desire to be saved, is sinful (ST II-II 20.1). As hope is, by definition, future-directed, it is only possible for human beings who are uncertain of whether they are blessed or damned, whereas love can persist even after their ultimate fate has been revealed (ST II-II 18.2–3).

2.3 Hope in 17th and 18th Century Philosophy
In 17th and 18th century philosophy, many philosophers reject Aquinas’ division between different kinds of passions in favor of a moral psychology which classifies emotions and desires together as passions that generate action, of which hope is usually conceived as a species. Almost all authors mentioned in the following also embrace some version of the idea defining for the “standard account” that hope is based on uncertainty in belief together with a representation of an object as desirable (Blöser 2020a).

According to Descartes, hope is a weaker form of confidence (Passions of the Soul, [1649] 1985: 389) and consists in a desire (a representation of an outcome to be both good for us and possible) together with a disposition to think of it as likely but not certain (Passions of the Soul, [1649] 1985: 350f, 389). This means that hope and anxiety always accompany each other (in contrast to both despair and confidence which are absolute opposites). Hobbes adopts a similar analysis. For him, hope is a complex passion or a “pleasure of the mind”, i.e., a pleasure that arises not from direct sensation but from thinking. For Hobbes, the simplest building block underlying hope is appetite, and “appetite with an opinion of obtaining” is hope (Leviathan, 36, I.VI.14). As in Descartes, hope serves as a building block for more complex mental phenomena, such as courage or confidence (Leviathan, 36f, I.VI.17/19). But hope also plays a role in the mental activity of deliberation which is defined as the alternation of hope and fear with appetites and aversion (Leviathan, 39, I.VI.49; see also Bobier 2020b). Hope—a term which Hobbes often uses more or less synonymously with (justified) expectation—plays an important role in the political application of his moral psychology: Not only is the equality in the state of nature defined as an equality of hope (Leviathan, 83, I.XIII.3)—which makes it rational for everyone to pursue their individual advantage—the laws of nature also command one to seek peace where one has hope for obtaining it (Leviathan, 87, I.XIV.4). Both the collective agency problem in the state of nature and the solution to it thus depend on what hopes individuals can rationally entertain.

Spinoza also defines the passion of hope as a form of pleasure (Ethics III, P18, Spinoza [1677] 1985: 505) or joy that is mingled with sadness (due to the uncertainty of the outcome, see Short Treatise, book II, ch. IX, Spinoza [c. 1660] 1985: 113). In contrast to more modern definitions, Spinoza distinguishes the pleasure that is involved in hope from desire. Hope (in the Ethics) is thus not necessarily connected to desire, but rather a way in which the mind is affected by the idea of a future event. In contrast to Hobbes and Descartes, Spinoza understands hope as fundamentally irrational. He argues that it must be the result of false belief inasmuch as it does not correctly represent that everything is governed by necessity (Short Treatise, book II, ch. IX, [c. 1660] 1985: 113). Additionally, in the Ethics, Spinoza describes hope as one of the causes of superstition, especially as it is always accompanied by fear (Ethics III, P50, [1677] 1985: 521). Such fear necessarily precludes it from being intrinsically good (Ethics IV, P47, [1677] 1985: 573). This is also the reason why we should attempt to make ourselves independent from hope (although Gatens et al. (2021: 202) argue that Spinoza also has room for the idea of reasonable hopes).

Spinoza agrees with Hobbes, however, by ascribing political significance to hope. As he explains in the Theological-Political Treatise, the fact that people are governed by hope and fear makes them easy victims of superstition and false belief (Theological-Political Treatise, [1670] 2002: 389); however, good laws can also take advantage of this and motivate people by arranging outcomes such that they can be motivated by hope (Theological-Political Treatise, [1670] 2002: 439; see Gatens et al. 2021 for a discussion of the political significance of hope in Spinoza). The same importance he places on hope also underlies his social contract argument. Like Hobbes, he argues that the only reason why people remain faithful to the social contract or carry out the orders of a sovereign has to be found in their hope of obtaining a certain good this way (Theological-Political Treatise, [1670] 2002: 529). Even a people as a whole is always united by common hopes and fears (Political Treatise, [1675] 2002: 700), but hope rather than fear is dominant in the case of free peoples (ibid.). This leads Spinoza to proclaim hope and fear as the basis of political power in the Political Treatise ([1675] 2002: 686).

Hume’s account is another example of an analysis of hope as a passion—modified, however, by the specific approach he takes to human psychology. For Hume, hope is a “direct passion” that is produced when the mind considers events that have a probability between absolute certainty and absolute impossibility. Hume describes probability-beliefs as an effect of the mind entertaining contrary views—of an event or object as either existent or non-existent—in quick succession after another. Each of these views gives rise to either joy or sorrow (when the object is something good or bad) which linger longer in the mind than the original imagination of the object’s existence or non-existence. When considering objects that are probable, but not certain, the mind is thus affected by a mixture of joy and sorrow that, depending on the predominant element, can be called hope or fear.

It is after this manner that hope and fear arise from the different mixture of these opposite passions of grief and joy, and from their imperfect union and conjunction. (Treatise, [1738] 2007: 283)

As Hume sees hope as a necessary effect of the consideration of an uncertain event, it follows that we cannot but hope for any positive outcome about which we are uncertain. The uncertainty in question can be based on the actual uncertainty of the event but also on uncertain belief.

2.4 Immanuel Kant
While hope is primarily discussed as a feature of the psychology of individual humans in the 17th and 18th century and, as a non-cognitive attitude, taken to be neither essentially rational nor irrational, it is given much greater significance by Immanuel Kant who adopts a much more substantial (and complex) view of the connection between hope and reason.

Kant’s definition of hope as an “unexpected offering of the prospect of immeasurable good fortune” (AE 7:255) in the Anthropology seems to remain within the traditional discourse about hope. However, Kant eventually accords hope a central place in his philosophical system by focusing on hope as an attitude that allows human reason to relate to those questions which cannot be answered by experience. In the Critique of Pure Reason, Kant states the question “For what may I hope?” as one of the fundamental questions of philosophy, after “What can I know?” and “What should I do?” (A805/B833). This question, as far as its answer depends on claims regarding the consequences of moral righteousness and the existence of God, is “simultaneously practical and theoretical” (A805/B833) and it is answered by religion (AE 9:25). Kant’s account of hope consequently connects his moral philosophy with his views on religion. He emphasizes the rational potential of such hope, but he also makes clear that rational hope is intimately connected to religious faith, i.e., the belief in God.

Kant considers three primary objects of hope in his writings: (1) One’s own happiness (as part of the highest good), (2) one’s own moral progress (in the Religion) and (3) the moral improvement of the human race as a whole (in his historical-political writings).

(1) In the Canon of the Critique of Pure Reason, Kant states clearly: “all hope concerns happiness” (A805/B833). However, it is not the hope for one’s own happiness simpliciter that is at stake, but the hope for happiness that one deserves because of one’s moral conduct (A809/B837). Kant argues that there is a necessary connection between the moral law and the hope for happiness. However, this connection exists only “in the idea of pure reason”, not in nature (A809/B837). A proportionality between happiness and morality can only be thought of as necessary in an intelligible, moral world, where we abstract from all hindrances to moral conduct. In the empirical world of experience, there is no guarantee for a necessary connection between moral conduct and happiness. Thus, Kant concludes, we may reasonably hope for happiness in proportion to morality only if we introduce the additional non-empirical assumption of “a highest reason, which commands in accordance with moral laws, as […] the cause of nature” (A810/B838). This way, Kant connects morality and happiness in the object of hope and secures its possibility in a highest reason, i.e., in God. Kant calls the connection between “happiness in exact proportion with the morality of rational beings, through which they are worthy of it” the highest good (A814/B842). A peculiarity of Kant’s treatment of hope in the Canon is that hope for the highest good is apparently considered necessary for moral motivation (A813/B841)—a thesis he rejects in his later writings.

Kant’s account of hope for happiness presents hope as very closely connected to Kant’s concept of faith. This becomes obvious in the Critique of Practical Reason. Kant argues that in order to believe in the possibility of the highest good—and we have to believe in this possibility, as it is prescribed by the categorical imperative—we have to believe in or postulate the existence of God and the immortality of the soul. Kant himself uses both the concept of belief or faith and the concept of hope in explaining the content of the postulate of immortality: we must presuppose immortality in order to conceive of the highest good as “practically possible” and we may therefore “hope for a further uninterrupted continuance of this [moral] progress, however long his existence may last, even beyond this life” (AE 5:123). Thus, Kant can be understood as arguing in favor of a traditional religious form of hope—hope for a life after death or immortality of the soul. However, he points out that immortality is not a ‘mere’ hope (i.e., a hope for an outcome where we lack evidence for the claim that it is really possible), but that reason makes it necessary (as a consequence of the categorical imperative) to assume that immortality is possible.

Whereas some Kant interpreters do not clearly distinguish between hope and faith (Rossi 1982, Flikschuh 2010), Andrew Chignell emphasizes that hope is an attitude that is distinct from faith or belief and that Kant follows an “assert-the-stronger” policy: He asserts the strongest justified attitude towards p (justified belief), even if one holds also weaker attitudes towards p (hope) (Chignell 2013: 198). O’Neill interprets Kant as holding that hope provides a reason for religious belief: Belief in God and immortality is not “merely possible”, but a matter of “taking a hopeful view of human destiny” (O’Neill 1996: 281). According to O’Neill, the reason for faith is the hope that moral action is successful, i.e., that our moral intention can make a difference to the natural order.

(2) In the Religion, Kant envisages one’s own moral improvement as an object of hope, which requires that one change one’s fundamental maxim from a bad one to a good one. The problem is that on the one hand, we have a duty to improve morally and hence must be capable of doing so (AE 6:45), but on the other hand, it is unclear how this can be possible if one’s fundamental maxim is corrupt. Since we cannot know how this is possible, moral improvement remains an object of hope. Kant suggests two alternative hopes: the hope to, through one’s “own efforts”, become a better person (AE 6:46) and the hope that what exceeds one’s power will be taken care of by God (AE 6:52).

(3) In his political and historical writings, Kant considers another object of reasonable hope: the hope for historical progress towards a morally better, peaceful future. We find a similar relationship between rational belief and hope as with regard to God and immortality: Kant sees the moral improvement of the human race as a hope that is based on a transcendental assumption (in the mode of faith) in a teleological order of nature. Kant assigns “hope for better times” an important function for moral motivation by claiming that without it, the desire to benefit the common good would “never have warmed the human heart” (AE 8:309). Kant recommends a view of human history with a “confirmation bias” (Kleingeld 2012: 175), i.e., with a view to the realization of moral demands.

Aside from these systematic issues regarding hope in Kant’s philosophy, it is worth summarizing some general features that Kant touches upon concerning hope. Regarding a descriptive account of what it means that a person hopes that p, one can extract two necessary conditions from Kant’s remarks that are in line with the standard account of hope: The object of hope must be uncertain, and the person must wish for it. Both conditions can be found in the following passage from Perpetual Peace:

[R]eason is not enlightened enough to survey the entire series of predetermining causes that foretell with certainty the happy or unhappy consequences of humankind’s activities in accordance with the mechanism of nature (although it does let us hope that these will be in accord with our wishes). (AE 8:370)

In regard to the normative conditions under which hope is rational, Kant is sensitive to a theoretical and practical dimension: He focuses on hopes that are (necessarily) connected with a moral duty and thus involve a practical necessity. From a theoretical point of view, Kant’s main concern is to show that these hopes are not impossible. While he holds that empirical evidence permits hoping as long as there is no proof to the contrary (AE 8:309f.), this minimal criterion is connected to the idea that hope is based on transcendental assumptions (i.e., the existence of God, immortality, and a teleology of nature) (Blöser 2020b).

Kant’s account of hope has recently attracted considerable interest, both regarding matters of Kant scholarship and the application and development of a Kantian notion of hope in various contexts. As to Kant scholarship, Düring and Düwell (2017) follow Beyleveld and Ziche (2015) in emphasizing the relevance of the Critique of Judgment for an understanding of Kantian hope –– they view hope as aesthetically structured. Zuckert (2018) argues that Kantian hope is a feeling. Danziger (2020) makes the case that hope plays a role even in Kant’s theoretical philosophy.

As to the application and development of Kant’s account of hope, Chignell (2018) reconstructs Kant’s moral argument for faith in the existence of God (where hope plays a crucial role) and explores its relevance for political contexts (the food system), where the chances that an individual will make a difference are very low. Similarly, Huber (2019) argues that Kantian hope can be seen as playing an important role in preventing demoralization and sustaining the commitment to political action when the prospects of success are dim. Dineen (2020) delineates a Kantian conception of hope that might inform practical education, because it warrants us in thinking that we are able to set and achieve ends, even in light of imperfection and vulnerability. Speight (2021) shows how Walter Benjamin took up and transformed Kant’s account of hope by shifting from a personal to a collective perspective on hope and to a concern with the past.

2.5 Post-Kantian Philosophy and Existentialism
In Post-Kantian philosophy, the role of hope is disputed. One can identify two distinct approaches. On the one hand, there are authors like Arthur Schopenhauer, Friedrich Nietzsche and Albert Camus who reject hope, not so much as epistemically irrational but as an expression of a misguided relationship to the world that is unable to face the demands of human existence. On the other hand, authors like Søren Kierkegaard and Gabriel Marcel take hope to be a means to overcome the limitations of ordinary experience.

Kierkegaard examines hope primarily as it is connected to religious faith. However, whereas Kant aims to show that our belief in God and hope for the highest good is possible within the limits of reason, Kierkegaard is keen to emphasize that (eternal) hope must transcend all understanding. As an antidote to despair, hope plays a positive role in Kierkegaard’s work, culminating in his advice: “a person’s whole life should be the time of hope!” (Kierkegaard [1847] 1995: 251). In Works of Love, Kierkegaard defines hope in its most general form as a relation to the possibility of the good: “To relate oneself expectantly to the possibility of the good is to hope” (Kierkegaard [1847] 1995: 249).

Most interpreters of Kierkegaard emphasize a distinction between “heavenly” (or eternal) hope and “earthly” (or temporal) hope (Bernier 2015; Fremstedal 2012; McDonald 2014). In some passages, Kierkegaard indeed seems to assume that there is also “natural hope” (Kierkegaard [1851] 1990: 82) or hope “for some earthly advantage” (Kierkegaard [1847] 1995: 261). However, strictly speaking, Kierkegaard considers this the “wrong language usage” (Kierkegaard [1847] 1995: 261). He completes his definition as follows: “To relate oneself expectantly to the possibility of the good is to hope, which cannot be any temporal expectancy but is an eternal hope” (Kierkegaard [1847] 1995: 249). On Kierkegaard’s view, hope—strictly speaking—is thus always directed towards the eternal, “since hope pertains to the possibility of the good, and thereby to the eternal” (Kierkegaard [1847] 1995: 249). This is connected to Kierkegaard’s account of time. Hope, as a form of expectation, is an attitude towards the possible. While expectation, generally speaking, relates to the possibility of both good and evil (Kierkegaard [1847] 1995: 249), hope relates only to the possibility of good. The possibility of the good, on Kierkegaard’s account, is a feature of the eternal (“in time, the eternal is the possible, the future”).

While the expectation of earthly goods is often disappointed—either because it is fulfilled too late or not at all (Kierkegaard [1843–1844] 1990: 215)—eternal hope cannot in principle be disappointed (Kierkegaard [1847] 1995: 261–3, Kierkegaard [1843–1844] 1990: 216). Eternal hope means “at every moment always to hope all things” (Kierkegaard [1847] 1995: 249). Kierkegaard mostly equates eternal hope with Christian hope (McDonald 2014: 164).

In order to understand the relation between earthly and heavenly hope, it is helpful to consider the dialectical progression of hope that Kierkegaard presents in the Nachlaß (Malantschuk (ed.) 1978: 247). There is a kind of hope that occurs spontaneously in youth, which appears to be a pre-reflexive hope, a kind of immediate trust or confidence (Fremstedal 2012: 52). It is followed by the “supportive calculation of the understanding”, i.e., by hope involving the reflection about the probability of the hoped-for outcome. This (earthly) hope is often disappointed by the lateness or non-arrival of the expected goods. This disappointment is necessary in order to acquire eternal hope, which “is against hope, because according to that purely natural hope there was no more hope; consequently this hope is against hope” (Kierkegaard [1851] 1990: 82). Kierkegaard’s interpretation of Abraham’s story in Fear and Trembling can be understood as an illustration of this kind of hope (Lippitt 2015).

Whereas earthly hope is judged by the understanding according to its probability, eternal hope exceeds the limits of understanding. It is therefore commonly judged as irrational or as “lunacy” (Kierkegaard [1851] 1990: 83). Kierkegaard does not explicitly take up the question of when hope is rational—presumably because eternal hope exceeds reason—but he frames the question of good or bad hope in terms of “honor” and “shame” (Kierkegaard [1847] 1995: 260f.). He observes that a person who entertained an earthly hope that has not been fulfilled is very often criticized as imprudent (or “put to shame” (Kierkegaard [1847] 1995: 260)) because this is supposed to show that she “miscalculated” (ibid.). Kierkegaard objects to this perspective of “sagacity” that judges hope only with regard to its fulfillment. Rather, we should pay attention to the value of the hoped-for ends (Kierkegaard [1847] 1995: 261). Eternal hope, on this account, “is never put to shame” (Kierkegaard [1847] 1995: 260, see also 263). Further, and in line with the Christian tradition, he argues that the value of hope depends on its relation to love: We hope for ourselves if and only if we hope for others, and only to the same degree. Love

is the middle term: without love, no hope for oneself; with love, hope for all others—and to the same degree one hopes for oneself, to the same degree one hopes for others, since to the same degree one is loving. (Kierkegaard [1847] 1995: 260)

Thus, similarly to Kant’s account, one’s hope stands in a proportional relationship to an ethical demand. However, Kierkegaard does not see hope limited by our meeting an ethical demand.

Rather, Kierkegaard sees the proportional relation as determining whether we are in fact hoping, and the actual degree of our expectancy. Our hope for ourselves is only realizable in and through our hope for another. (Bernier 2015: 315)

As already mentioned, Schopenhauer represents the opposite approach in post-Kantian philosophy. Even though he holds that it is natural for humans to hope (Parerga and Paralipomena II, 1851: §313), he also claims that we generally ought to hope less than we are inclined to, calling hope a “folly of the heart” (ibid.). Ambivalent remarks concerning the value of hope (he interprets Pandora’s box as containing all the goods, Parerga and Paralipomena II, 1851: §200) can be found throughout his writings, but on the whole, criticism prevails. There are two aspects to his critical evaluation of hope: hope’s influence on the intellect and its role for happiness. In Schopenhauer’s dichotomy of the will and the intellect, hope is an expression of the will or, more precisely, an inclination. One reason why hope is problematic with respect to its influence on the intellect is that it presents what we wish for as probable (The World as Will and Representation, vol. 2, [1818] 1958: 216, 218). Schopenhauer concedes that hope sharpens our perception insofar as it makes certain features of the world salient. But he links this thesis to the stronger claim that hope may make it (often) impossible to grasp things that are relevant. Hope thus distorts cognition in a problematic way because it hinders the intellect in grasping the truth. However, Schopenhauer also concedes the possibility of a positive effect of hope, namely as motivation and support of the intellect (The World as Will and Representation, vol. 2, [1818] 1958: 221).

With regard to its contribution to personal happiness, Schopenhauer mentions a positive role of hope in his comparison of the life of animals with that of humans. He states that animals experience less pleasure than humans, because they lack hope and therefore the pleasures of anticipation. But hope can not only lead to disappointment when the hoped-for object is not realized, it can even be disappointing when it is fulfilled if the outcome does not provide as much satisfaction as was expected (The World as Will and Representation, vol. 2 [1818] 1958: 573). Schopenhauer also criticizes Kant’s idea that we may hope for our own happiness in proportion to our moral conduct (the highest good). This conception of hope, according to Schopenhauer, leads Kant to remain implicitly committed to a form of eudaimonism (Basis of Morality II, §3, 34).

Thus, even though Schopenhauer occasionally hints at positive aspects of hope, his overall evaluation of hope is negative. This is consistent with his view that life is filled with unavoidable frustration and suffering, and that suffering can be reduced only by getting rid of one’s desires. Ideally, this amounts to the “negation of the will to life” (The World as Will and Representation, vol. 1, [1818] 2010: 405). The “temptations of hope” (The World as Will and Representation, vol. 1, [1818] 2010: 419) function as obstacles to the negation of the will, whereas hopelessness can help to transform one’s mind and acquire “genuine goodness and purity of mind” (The World as Will and Representation, vol. 1, [1818] 2010: 420). Interestingly, Schopenhauer does have sympathies with the idea of salvation, which lies in the denial of the will (Schopenhauer [1818] 1958: 610), that is, he seems to subscribe to a kind of transcendent hope for an end of all suffering (Schulz 2002: 125). Even though he does not say so, one could characterize his view as a “hope for the end of hope”.

Nietzsche is perhaps the most famous critic of hope in the post-Kantian tradition. In the third preface to Zarathustra, he warns: “do not believe those who speak to you of extraterrestrial hopes!” (Zarathustra, [1883–85] 2006: 6) Similarly, in Beyond Good and Evil (1886) he opposes all notions of hope “in hidden harmonies, in future blessedness and justice” (Beyond Good and Evil, [1886] 2008: 562). In his interpretation of Pandora’s myth (Human, All Too Human, 1878: §71), he calls hope “the worst of all evils because it prolongs the torments of man”. However, a closer look reveals that, outside his criticism of religious and metaphysical hopes, he also hints at a positive perspective on hope: “that mankind be redeemed from revenge: that to me is the bridge to the highest hope and a rainbow after long thunderstorms” (Zarathustra, [1883–85] 2006: 77). Nietzsche counts hope among the “strong emotions” (Nietzsche [1887] 2006: 103), next to anger, fear, voluptuousness, and revenge. Furthermore, he repeatedly characterizes hope using the metaphor of a rainbow: “hope is the rainbow over the cascading stream of life” [“Die Hoffnung ist der Regenbogen über den herabstürzenden jähen Bach des Lebens”] (as cited in Bidmon 2016: 188). However, the metaphor of the “rainbow” is ambivalent. On the one hand, it is connected to Nietzsches vision of the “overman”: “Do you not see it, the rainbow and the bridges of the overman?” (Zarathustra, [1883–85] 2006: 36). On the other hand, however, the rainbow is elusive and withdraws itself—Nietzsche calls it an “illusory bridge” (Zarathustra, [1883–85] 2006: 175; see also Bidmon 2016: 188f.). In Beyond Good and Evil, he finally claims that we should “fix our hopes” in “new philosophers”, “in minds strong and original enough to initiate opposite estimates of value” (Beyond Good and Evil, [1886] 2008: 600). In Human, All Too Human, he similarly envisages change of the social order as an object of hope:

[W]e are only reasonably entitled to hope when we believe that we and our equals have more strength in heart and head than the representatives of the existing state of things. (Human, All Too Human, 1878: §443)

Reasonable hope is thus grounded in a trust in one’s capacity to bring about the desired outcome. However, Nietzsche adds that usually this hope amounts to “presumption, an over-estimation” (ibid.).

Camus follows Nietzsche in declaring (religious) hope the worst of all evils (Judaken and Bernasconi 2012: 264). His critique of hope is linked to the idea that the human existence is absurd. The “elusive feeling of absurdity” (Camus 1955: 12) is characterized by a discrepancy: The human mind asks fundamental questions about the meaning of life, but the world does not provide answers. Camus’ understanding of the absurd is best captured in the image of Sisyphus, who exemplifies life’s absurdity in his “futile and hopeless labor” (Camus 1955: 119). The assumption that life is absurd goes hand in hand with the denial of religious hope for salvation. In his early writing Nuptials ([1938] 1970), Camus opposes religious ideas about the immortal soul and hope for an afterlife. In fact, “[h]ope is the error Camus wishes to avoid” (Aronson 2012). Even though Camus is often regarded as an existentialist, he distances himself from this movement. One reason is precisely his disagreement with the account of hope of the existentialists, Kierkegaard in particular, of which he says that “they deify what crushes them and find reason to hope in what impoverishes them. That forced hope is religious in all of them” (Camus 1955: 32).

As already mentioned, one kind of hope that Camus flatly rejects is religious hope for a life beyond death. A second kind of hope, primarily discussed in The Rebel, is the hope founded on a great cause beyond oneself, i.e., “hope of another life one must ‘deserve’” (Camus 1955: 8). The problem with hoping for social utopias, according to Camus, is that they tend to be dictatorial. A further reason to reject such hopes seems to be that they distract from the life of the senses, from the here-and-now and from appreciating the beauty of this life. We also do not need hope to cope with the hardships of life and death: Instead of hoping for a life after death (or committing suicide), one should be conscious of death as “the most obvious absurdity” (Camus 1955: 59) and “die unreconciled and not of one’s own free will” (Camus 1955: 55). Sisyphus exemplifies the attitude of lucidity and consciousness that Camus recommends. Even though he does not hope for a better future,—or rather because he does not hope for a better future—“[o]ne must imagine Sisyphus happy” (Camus 1955: 123).

Despite his criticism of hope, Camus states that it is (nearly) impossible to live without hope, even if one wishes to be free of hope (Camus 1955: 113). Presumably this claim is only descriptive, stating a fact about human psychology. However, in a letter to his friend and poet René Char, Camus called The Rebel a “livre d’espoir” [book of hope] (Schlette 1995: 130). On that note, it has recently been suggested that Camus allows for a positive view of hope—a kind of “étrange espoir” [strange hope] that is directed towards the possibilities inherent in the present (Schlette 1995: 134) and that is characterized by humanism and solidarity with all human beings (Bidmon 2016: 233).

Whereas the positive role of hope in Camus is at best hidden, it surfaces prominently in the writings of Marcel. At the heart of Marcel’s account of hope is the distinction between “‘I hope…’, the absolute statement, and ‘I hope that…’” (Marcel [1952] 2010: 26). Marcel is mostly interested in a general, absolute hope, which he conceives as “the act by which […] temptation to despair is actively or victoriously overcome” (Marcel [1952] 2010: 30f.). One way in which Marcel characterizes the “mystery” (Marcel [1952] 2010: 29) of hope is by alluding to the connection between hope and patience (Marcel [1952] 2010: 33). Hope implies the respect for “personal rhythm” (ibid.) and “confidence in a certain process of growth and development” (Marcel [1952] 2010: 34). Marcel takes up the question of the rationality of hope in asking whether hope is an illusion that consists in taking one’s wishes for reality (Marcel [1952] 2010: 39). He answers that this objection against the value of hope applies primarily to hopes that are directed towards a particular outcome (“to hope that X”), but it does not apply when hope transcends the imagination. Because the person who hopes simpliciter does not anticipate a particular event, her hope cannot be judged with regard to whether it is likely to be fulfilled. Marcel illustrates this with the example of an invalid (Marcel [1952] 2010: 40). If this person hopes that he will be healthy at a certain point in time, there is the danger of disappointment and despair if it does not happen. However, absolute hope, Marcel explains, implies a “method of surmounting”: The patient has absolute hope if he realizes that “everything is not necessarily lost if there is no cure” (Marcel [1952] 2010: 40). Being a “theistic Existentialist” (Treanor and Sweetman 2016) like Kierkegaard, Marcel ultimately connects this possibility of absolute hope to the existence of God. Absolute hope is necessarily connected to faith in God and is a “response of the creature to the infinite Being to whom it is conscious of owing everything that it has” (Marcel [1952] 2010: 41).

2.6 Pragmatism
Even though hope rarely features explicitly in pragmatist writings, it has been suggested that pragmatist accounts of hope can be found in the works of William James and John Dewey (Fishman and McCarthy 2007; Green 2008; Koopman 2006, 2009; Rorty 1999; Shade 2001). As Patrick Shade notes, the issue of hope is “implicit in most pragmatic philosophies”, as it is related to central pragmatist topics, such as meliorism and faith, and particular hopes for social progress (Shade 2001: 9f.). Sarah Stitzlein (2020) argues that a conception of hope as a set of habits unites the understanding of hope in the writings of the classical pragmatists (Charles Peirce, William James, John Dewey) and is further developed in the social and political writings of recent pragmatists (Richard Rorty, Judith Green, Cornel West, Patrick Shade, Colin Koopman).

Indeed, James’ concept of faith in The Will to Believe is closely linked to hope. In his essay, James aims to offer a “justification of faith, a defense of our right to adopt a believing attitude in religious matters” (James [1897] 2015: 1). Even though his primary subject is religious faith, he points out that a structurally similar justification of faith or trust can be applied to social questions. It can be rational to believe that the other is trustworthy or likes us, even though we may not be able to prove it. Three criteria have to be fulfilled for faith to be rational: the question cannot be decided scientifically, the belief may be true, and we are better off (even now) if we believe. In his argument, James draws a link to the concept of hope when claiming that the skeptic or agnostic attitude is not more rational than the attitude of faith. The skeptic holds “that to yield to our fear of its being error is wiser and better than to yield to our hope that it may be true” (James [1897] 2015: 27). James criticizes this attitude: “what proof is there that dupery through hope is so much worse than dupery through fear?” (James [1897] 2015: 27).

A pragmatist conception of hope has often been seen as closely linked to the idea of meliorism and progress (e.g., in Dewey’s work, see Shade 2001: 139). In his lectures on Pragmatism, James situates the doctrine of meliorism between pessimism and optimism: “Meliorism treats salvation as neither necessary nor impossible. It treats it as a possibility” (James 2000: 125). For Dewey, the object of hope or meliorism is first and foremost democracy, which is “the simple idea that political and ethical progress hinges on nothing more than persons, their values, and their actions” (Dewey [1916] 1980: 107).

Drawing on James’ account of conversion in the Varieties of Religious Experience, Sheehey argues that James can be seen as advocating a concept of hope that does not rely on the idea of progress, but relies on a “temporality of crisis” that allows for an understanding of historical change beyond progress or decline (Sheehey 2019).

3. The Standard Account and the Rationality of Hope
The contemporary debate about hope in analytic philosophy is primarily concerned with providing a definition of hope, explicating standards of rationality and explaining the value of hope. The debate takes as its starting point what has been called the “orthodox definition” (Martin 2013: 11) or the “standard account” (Meirav 2009: 217), which analyzes “hope that p” in terms of a wish or desire for p and a belief concerning p’s possibility. R.S. Downie is representative of this position:

There are two criteria which are independently necessary and jointly sufficient for ‘hope that’. The first is that the object of hope must be desired by the hoper. […] The second […] is that the object of hope falls within a range of physical possibility which includes the improbable but excludes the certain and the merely logically possible. (Downie 1963: 248f.)

Similarly, J. P. Day writes:

“A hopes that p” is true iff “A wishes that p, and A thinks that p has some degree of probability, however small” is true. (Day 1969: 89)

The desire-condition captures the intuition that we only hope for what we take to be good (at least in some respect) or desirable. The belief component is meant to capture the intuition that we do not normally hope for what we think is impossible (or certain), whereas this is not a problem for desires or wishes (in e.g., “I wish I could fly”).

Most authors implicitly assume that the hoped-for event is in the future. In ordinary usage however, people often express hopes regarding past events of which they do not have complete knowledge. An example is the hope that someone did not suffer excessively when they died. While some authors consider this use of language to be parasitic on the future-directed case (McGeer 2004: 104), others argue that these are genuine cases of hope (Martin 2013: 68).

Another question in this context concerns the concept of possibility that is at issue: It seems clear that we cannot hope for the logically impossible, but can we hope for the physically impossible, e.g., that the dead will rise tomorrow? Downie, for example, holds that logical possibility is not enough (Downie 1963: 249), whereas Chignell does not exclude the possibility of hope for something which is physically impossible (Chignell 2013: 201ff.). Whatever the answer to this question, all views (except Wheatley 1958) allow for cases of hope in which the outcome is extremely improbable; in other words, no lower bound to the probability is required for hoping (Meirav 2009: 219).

Objections have been raised against the idea that the standard definition provides sufficient conditions for hope. There are two main lines of objections: the “despair objection” and the “substantial hope objection” (Milona 2020a: 103). According to the “despair objection”, two people can have identical desires and beliefs about the possibility of an outcome, and yet one of them may hope for the outcome while the other despairs of it (Meirav 2009). The “substantial hope objection” holds that even though the standard definition might capture a minimal sense of hope, it fails to explain the special value of more “substantial” kinds of hope. In particular, it fails to explain how hope can have special motivating force in difficult circumstances, especially when the probability of the desired outcome is low (Pettit 2004; Calhoun 2018). These objections either lead to the claim that the standard definition must be revised or motivate the proposal that hope is entirely different from desire and belief, and hence irreducible to them.

Luc Bovens suggests that besides desire and belief, hope also involves mental imaging (Bovens 1999). However, it has been objected that mental imaging is already entailed by desire (and hence, that the standard definition can account for this) and that it is still not able to distinguish hope from despair, since a despairing person can still form mental images about the desired outcome. Andrew Chignell suggests a variant of Bovens’ account, although he does not require imaging but a specific kind of attention: A subject who hopes is disposed to focus on the desired outcome under the aspect of its possibility, while a despairing subject focuses on the outcome under the aspect of its improbability (Chignell forthcoming).

According to Meirav’s “External Factor Account” (Meirav 2009: 230), hope also involves an attitude towards an external factor (e.g., nature, fate, God) on which the realization of the hoped-for end causally depends. “If one views the external factor as good, then one hopes for the prospect. If one views it as not good, then one despairs of it” (Meirav 2009: 230). However, it is doubtful whether Meirav’s account is applicable to cases of hope where the realization of the outcome depends on luck (e.g., hoping to win the lottery). Further, it seems that one might hope even in circumstances where one believes the external factor to be bad, e.g., in unjust political circumstances.

While Meirav aims to answer the despair objection, Philip Pettit and Cheshire Calhoun suggest solutions to the substantial hope objection. In order to capture the motivating power of hope, Pettit distinguishes the “superficial” kind of hope described by the orthodox definition from a more “substantial” hope (Pettit 2004: 154). He construes substantial hope as acting on a belief that the agent does not really hold:

Hope will consist in acting as if a desired prospect is going to obtain or has a good chance of obtaining, just as precaution consists in acting as if this were the case with some feared prospect. (Pettit 2004: 158)

However, in typical cases, a hopeful person does not describe herself as acting as if the chances were higher, but as taking the chances as they are as good enough to try (Martin 2013: 23). Cheshire Calhoun (2018) shares Adrienne Martin’s criticism and argues that we need to distinguish a ‘planning idea’ from a ‘phenomenological idea’ of the future: The third component of hope besides desire and belief, according to her, is “a phenomenological idea of the determinate future whose content includes success” (Calhoun 2018: 86). This phenomenological idea, she argues, has motivational effects independently of the agent’s desires.

According to Martin’s suggestion (Martin 2013), hope involves two more elements in addition to belief and desire: First, the agent must see or treat her belief about the possibility of the outcome’s occurring as licensing hopeful activities, i.e., as not advising against some specific activities. Second, the agent must treat her attraction to the outcome as a practical reason to engage in the activities characteristic of hope. Martin calls her account the Incorporation Thesis, which refers to the fact that the hoping person incorporates the desire-element into her rational scheme of ends.

Martin’s proposal has been criticized as being overly reflective and unable to account for “recalcitrant” hopes where the hoping person does not see herself as justified in her hopeful activities (Milona and Stockdale 2018). Milona and Stockdale offer an account of hope that is inspired by the philosophy of emotions: They describe hope as a kind of perceptual state that involves a “hopeful” feeling.

There is an ever-increasing number of accounts that aim to remedy the shortcomings of the standard definition (see also Kwong 2019, Palmqvist 2021). The discussion seems to come full circle with Michael Milona’s return to the standard definition: Rather than augmenting the standard account, he suggests that one should employ a rich notion of desire and a suitable account of the relation between the desire and the belief—the belief in the possibility of the outcome must be in the “cognitive base” of the desire (Milona 2019).

The view that hope can be reduced to desires and beliefs (and a third factor) is not without alternative, however. Segal and Textor (2015) argue that hope is a primitive mental state that can be characterized by its functional role; Blöser (2019) argues that hope is an irreducible concept. This latter view is compatible with ontological variety and the view that different manifestations of hope are related in terms of family resemblance.

As for the norms of hope, there is consensus regarding the point that there is a theoretical (or epistemic) and a practical aspect to the rationality of hope. On the theoretical side, the question is whether the outcome is indeed possible (this amounts to evaluating hope in terms of its correctness) and whether the person is justified in her taking the outcome to be possible (this amounts to evaluating hope in terms of justification or responsiveness to reasons). One question of debate is whether the outcome must also be probable to a certain degree in order for hope to be rational (for an affirmative answer, see Moellendorf 2020 and Stockdale 2021). Andy Mueller captures the epistemic rationality of hope by specifying the idea that “hoping that p” is rationally incompatible with “knowing that not-p” (Mueller 2021: 45). (On the relation between hope and knowledge, see also Benton 2021).

On the practical side, most authors focus on the instrumental rationality of hope. Martin holds that hope is rational “so long as it promotes her [the agent’s] rational ends to do these things [i.e. engage in hopeful activities such as acting to promote the end, fantasizing about the outcome, entertaining certain feelings of anticipation]” (Martin 2013). Similarly, Pettit emphasizes the instrumental value hope has for the pursuit of our ends (Pettit 2004: 161).

However, the practical rationality of hope does not seem to be exhausted by instrumental considerations. Bovens argues that in cases where hoping has no instrumental value (because we cannot help bring about the desired state), hope can still have intrinsic value in virtue of its concomitant mental imaging: This characteristic of hope is responsible for its intrinsic value in three respects: First, hope has intrinsic value because the mental imaging connected to it (that is, the imaginative anticipation of the fulfillment of one’s hope) is pleasurable in itself (Bovens 1999: 675f.). Second, hope has epistemic value because it increases one’s self-understanding. Third, hope has intrinsic worth because it is constitutive of love towards others and towards oneself, which are intrinsically valuable activities. It is in virtue of mental imaging that hope is intimately connected to love, because spending mental energy in thinking about the well-being of another person is constitutive of loving her. Bloeser and Stahl (2017) argue that certain hopes—fundamental hopes—can be rational in virtue of their contribution to the practical identity of the hoping person.

Finally, it is a matter of debate how the theoretical and the practical dimension of rationality are related. On Martin’s account, the practical dimension has priority. Miriam Schleiffer McCormick, by contrast, holds that the theoretical and practical dimensions equally contribute to hope’s overall rationality and are intertwined (McCormick 2017).

Another approach to the value of hope explores the prospects of understanding hope as a virtue. Michael Milona interprets hope as a moral virtue along the lines of “getting one’s priorities straight” (Milona 2020b). (For another attempt to understand hope as a moral virtue, see Han-Pile/Stern, forthcoming; for a critical view of such an enterprise, see Bobier 2018.) Michael Lamb aims to apply the structure of Thomas Aquinas’ theological virtue of hope to argue that hope can be a democratic virtue that perfects acts of hoping in fellow citizens to achieve democratic goods (Lamb 2016). Nancy Snow (2013) proposes that hope can be understood as an intellectual virtue. (For a critical assessment of Snow’s approach, see Cobb 2015.)

Accounts of hope as a virtue suggest that not all instances of hope can be described as “hope that p”, i.e., as propositional hopes that the standard definition and its successors aim to analyze. There are two kinds of non-propositional hope that are subject to debate (see Rioux 2021): First, as Lamb’s account suggests, we might have hope in a person, which Adrienne Martin calls “interpersonal hope” (Martin 2020). Second, it has been suggested that there is an attitude of indeterminate hope that is able to survive the loss of particular, determinate hopes. The distinction between “hope that” and hope without a determinate object has been introduced into the philosophical discourse by Gabriel Marcel and has recently been taken up (with or without explicit reference to Marcel) by otherwise different accounts. Joseph Godfrey calls hope without object “fundamental hope” and bases his account on an analysis of Bloch, Kant and Marcel (Godfrey 1987). Patrick Shade’s pragmatist theory distinguishes particular hopes and hopefulness as “an openness to possibilities that are meaningful and promising for us” (Shade 2001: 139). Jonathan Lear similarly describes “radical hope” as a sense of a future in which “something good will emerge” (Lear 2006: 94), even though all particular hopes were destroyed; and Matthew Ratcliffe takes such radical hope as an instance of “pre-intentional hope”, which is

a kind of general orientation or sense of how things are with the world, in the context of which intentional states of the kind “I hope that p” are possible. (Ratcliffe 2013: 602)

4. Analyses of Hope in the Psychological Literature
Psychologists and psychoanalysts have systematically investigated hope since the 1950s (Frank 1968, for an overview, see Gallagher et al. 2020). In many of these first studies, hope was seen as a cognitive process of directing agency that rests on the perception of an outcome as important for an agent to achieve and as having a certain probability (Stotland 1969). While this understanding of hope deviates from the standard philosophical account (see section 3) by requiring a minimal probability, it continues to play a major role in the current psychological literature.

Currently, the most influential psychological approach to hope is Charles Snyder’s hope theory (for an overview, see Rand and Cheavens 2009). Snyder defines hope as follows:

Within a goal-setting framework, we propose that there are two major, interrelated elements of hope. First, we hypothesize that hope is fueled by the perception of successful agency related to goals. The agency component refers to a sense of successful determination in meeting goals in the past, present, and future. Second, we hypothesize that hope is influenced by the perceived availability of successful pathways related to goals. (Snyder et al. 1991: 570)

On this basis, Snyder and others have developed various measures of hope, such as the Adult Hope Scale (ibid.), and the State Hope Scale (Snyder et al. 1996) that have received strong experimental support and are widely used globally (see Gallagher et al. 2020: 193–196 and Rose and Sieben 2018 for discussion of other measures).

Several objections have been raised against Snyder’s analysis of hope. One is that the “perception of agency” relates both to the past and the future and therefore measures a general trait of hopefulness rather than the hope for specific outcomes. As a response, psychologists have developed further “domain-specific” hope scales (Lopez et al. 2000: 61). A second question concerns the issue of whether Snyder’s definition of hope is sufficiently distinct from optimism (see Miceli and Castelfranchi 2010; Aspinwall and Leaf 2002). Snyder wants to distinguish hope from optimism by linking hope to beliefs about self-efficacy (Snyder 2002; Snyder, Rand and Sigmon 2018; Magaletta and Oliver 1999) and reserving the term “optimism” for generalized expectations about positive outcomes. However, the ordinary use of the term is better captured by the idea that hope can be upheld even if one does not assign a high probability to the outcome.

5. Hope in Political Philosophy
Hope can play three distinct roles in politics (see Stahl 2020): It can be instrumentally valuable insofar as its motivating influence makes it more likely that people achieve politically desirable goals. It can also be constitutive of politics, in that it is necessary for certain hopes to be present for the space of the political to emerge at all. For example, Spinoza argues that citizens can only act together politically if they have civic hope, through which they see each other as sources of potential benefits (Steinberg 2018: 90). Lastly, hope can also play a justificatory role, insofar it is possible that certain policies can only be publicly justified by reference to hopes that those promoting them reasonably entertain.

The potential for hope to both motivate and mislead is widely discussed in ancient and modern philosophy, but systematic accounts of the political relevance of hope stem only from the 20th century (for an overview, see Blöser, Huber and Moellendorf 2020). Many of these contributions can be understood as raising questions about the possible justifications of being guided in one’s political agency by hope, on the one hand, and about the benefits and risks of hope for politics on the other.

Regarding the first question about the justification of hope, one of the earliest and most ambitious accounts can be found in Ernst Bloch’s The Principle of Hope. Bloch advances his argument in the context of a debate in early 20th-century Marxism, distinguishing between what he calls the “cold” and the “warm stream”: The first designates the materialist insight that all historical developments are conditioned and constrained by concrete, existing material conditions, “strict determinations that cannot be skipped over” (Bloch [1954–59] 1986: I:208), whereas the second acknowledges a processual constitution of reality which is captured by hope. Hope, in other words, is justified by its correctly grasping facts about the world. In particular, Bloch describes hope as always related to the “not-yet-conscious” that in turn reflects “objective possibilities”. This idea is related to Bloch’s processual metaphysics, according to which objective tendencies and possibilities interact with “closed” matters of fact, such that the moment of potentiality surpassing into actuality always opens up opportunities for the interventions of active decision-making. The right way to relate to these opportunities is, according to Bloch, “militant optimism”, i.e., not a mere assumption that things will develop in a desirable direction, but an active attitude towards real tendencies with the goal to realize them (Bloch [1954–59] 1986: I:201). Arguing from these premises, Bloch develops an integrated theory in which hope is not merely a subjective combination of desires and beliefs about probabilities or facts, but rather a reflection of metaphysical possibilities in the world and part of a range of human capacities that make it possible to relate to that which is not yet, but which is already prefigured in the objective potentials of reality.

While most contemporary political philosophers acknowledge that many of our political hopes are grounded in reality, few go as far as Bloch to also see a general attitude of hopefulness as justified by metaphysical considerations. In Law of Peoples, Rawls, for example, holds that political theories need to develop a “realistic utopia” of justice to reliably guide our political agency and to “support and strengthen” our political hopes (Rawls 2003: 23). Howard (2019: 300) argues that such a utopia refers to an outcome that is possible and reachable under favorable conditions, but which may be extremely improbable nevertheless. Following Kant, Rawls seems to assume that the main justification for our political hopes for justice seems to come from the fact that we need such hopes to be able to continue to be moved by considerations of justice, and that it would be unreasonable to give up political hope for that reason. Bourke (forthcoming) takes a closer look at the similarities and differences between Kant and Rawls regarding their justifications of belief and hope.

In similar terms, some contemporary authors think of a disposition to have certain hopes as a democratic virtue that can be fostered or undermined by states. Moellendorf (2006) makes an argument to this effect that is restricted to societies transitioning from severe injustice towards justice: Because citizens need hopes to be motivationally capable to engage in the risky activities necessary to pursue societal change, and because hopes for a more just future can support their self-respect under unjust circumstances, institutions of transitional societies must supply the “institutional bases of hope”, such as possibilities for free political campaigning and open debate. Snow (2018: 414) argues that societies that do not offer citizens “secure attachment” create “worrier” citizens that are more likely to succumb to paranoid nationalism, whereas “carers” who are hopeful citizens are more likely to embrace a more inclusive national identity. More narrowly, Snow defines “civic hope” as an “entrenched disposition of openness to the political possibilities a democratic government can provide. Hope must include the belief that the ends of democracy are possible” (2018: 419) and argues—drawing on the pragmatist tradition (see section 2.6 above)—that this disposition is a virtue that contributes to the flourishing of their lives as citizens as well as of the state they live in.

While most contemporary liberal views follow these arguments in replacing Bloch’s metaphysical foundations of hope with moral justifications, defenders of “unjustifiable” political hope, such as Richard Rorty, argue for the more radical claim that we cannot, as a matter of principle, provide any fundamental justification for the desirability of the outcomes that we hope for. As Rorty famously rejects the idea of a political philosophy that is based on privileged knowledge or insight, he argues that “liberal hope” (i.e., hope for the emergence and sustenance of liberal societies) similarly cannot be based on any foundations—such as knowledge about probabilities. Rather, it is an attitude by which those who have it express their commitment to certain forms of future interaction and their belief in their possibility. In Contingency, Irony, and Solidarity, Rorty correspondingly contrasts two forms of liberalism: The “liberal metaphysician” expects social cooperation to be based on scientific or philosophical insight that penetrates individual idiosyncrasy and aims at the adoption of a universal, final vocabulary that then leads to solidarity. By contrast, the “liberal ironist” renounces the idea of a final vocabulary and instead assumes that only the contingent overlap between “selfish hopes” can be a source of the solidarity that grounds the commitment to liberal principles (Rorty 1989: 93). As Smith (2005) notes, Rorty does not intend to argue for unjustified hope (hope for which there is no adequate justification, although such justification is possible). Rather, he must refer to a form of hope for which the question of an ultimate justification does not arise, since it does not incorporate the idea that it is based on any such justification.

While the authors surveyed so far all agree on a positive role of hope in politics, there is also a more skeptical tradition in political thought that either questions whether hope in the standard sense is always available to political agents or argues that, at least sometimes, hope ought to be abandoned for political reasons.

One set of arguments revolves around whether the positive aspects of political hope are accessible to everyone as classic liberal accounts of hope seem to assume. Stockdale (2021) argues that many hopes of members of oppressed groups are not forms of pleasurable anticipation, but “fearful hope”, that is, hope for avoiding the worst effects of their oppression. In this sense, hope is not always something that ought to be preserved. Of course, this does not exclude more positive hopes, such as hoping for a less oppressive future. A more radical challenge to the idea that specific, objectual hopes are always available as a response to injustice is to be found in Lear’s (2006) reflections on “radical hope”. Lear considers a situation—such as that which members of the Crow nation may have faced after they were forced to live on reservations and, as a consequence, their traditional form of life became impossible—where, as a result of historical catastrophe, the vocabulary with which a group makes sense of the good collapses, and the only thing they can hope for is that a new version of a good life will become possible—a version they currently lack the words to conceptualize.

A second, skeptical argument is concerned with the objection that hope in politics might serve to encourage wishful thinking or undermine a realistic, critical evaluation of social reality (see Blöser, Huber and Moellendorf 2020 for an overview): It is often equated with optimism (see Eagleton 2015 for an argument that does not do so) and thus a naive approach to politics. It is said to disempower since hope involves seeing the outcome as dependent on factors beyond one’s control, and to misdirect our agency towards Utopian goals. As Moellendorf (2019: 154) argues, all hope imposes opportunity costs, since it precludes alternative attitudes which may be more instrumentally valuable. Political realists (such as Sleat 2013) argue that hope may be a necessary element of politics, but will by necessity go beyond that which is actually possible and thus mislead our political agency. Although these arguments draw attention to the dangers of hope in politics that have to be taken seriously, a balanced judgment must also take into account the dimensions of value discussed above. Indeed, philosophers working in the field of climate change often emphasize the instrumental value of hope in sustaining action where the attainment of the ultimate goal—managing climate change—is uncertain (McKinnon 2014, Roser 2019). Moellendorf highlights the need to develop hopeful politics when discussing climate issues (Moellendorf 2022).

A third argument finally confronts the fundamental issue of whether hope and hopefulness are always as desirable in politics as much of the preceding arguments have assumed. Warren (2015), for example, argues that the discourse and the valuation of political hope in Black American politics, serves to appropriate a theological notion of hope and uses it to enforce a “compulsory investment” of Black people’s hope in the political—although the resulting politics only prolongs and reinforces the racist structures towards the ending of which their political hope is ostensibly directed. Instead, Warren advocates for “Black nihilism”, that is, the rejection of the metaphysical and political framework in which political hope operates (see Lloyd 2018, Winters 2019 for discussion). But even Warren leaves space for “spiritual hope” as a hope for the end of political hope.

1. Introduction
The phenomenal intentionality theory is a theory of intentionality, the “aboutness” of mental states, on which phenomenal consciousness plays a central role in accounting for intentional states. Unlike many other contemporary theories of intentionality, which aim to account for intentionality in terms of causal relations, information, functional roles, or other “naturalistic” ingredients, the phenomenal intentionality theory’s main ingredient is phenomenal consciousness, the felt, subjective, or “what it’s like” (Nagel 1974) aspect of mental life. Accordingly, Pautz (2013) describes the general approach as taking a “consciousness first” approach to intentionality, since it claims that consciousness either grounds or is explanatorily prior to intentionality, and Kriegel (2011a, 2013a) describes the approach as one on which consciousness is the “source” of intentionality. (These ways of characterizing the phenomenal intentionality theory suggest a reductive picture, on which intentionality is reduced to or explained in terms of consciousness, but in section 2.3 we will see that some versions of the phenomenal intentionality theory are not reductive.)

By explaining intentionality in terms of phenomenal consciousness, the phenomenal intentionality theory challenges the received view of the past few decades that the mind divides into two mutually exclusive and independent types of states: intentional states and phenomenal states (see Kim 1998 for a clear articulation of the received view). According to the phenomenal intentionality theory, intentional states and phenomenal states are intimately related. Some intentional states are constituted by phenomenal states, and the rest are in some way importantly related to phenomenal states.

Phenomenal intentionality has been discussed under that label only recently (see, e.g., Horgan and Tienson 2002 and Loar 2003, and related influential work by Searle, Siewert, and others), but many modern philosophers have suggested a close relation between thought, which is characteristically intentional, and perception, which is characteristically phenomenal, or consciousness itself. For example, rationalists such as Descartes held that all cognition is conscious, while empiricists such as Hume and Locke held that all cognition is grounded in perceptual experience. Later, Brentano, Husserl and the phenomenologists that they influenced conceived of intentionality primarily as a conscious phenomenon. Like the phenomenal intentionality theory, the views of these figures can be understood as taking a “consciousness first” approach. For more on the history of the phenomenal intentionality theory, see Kriegel (2013a) and the entry Consciousness and Intentionality.

In this article we describe various versions of the phenomenal intentionality theory, their motivations, the challenges they face, and their relations to other views.

2. The phenomenal intentionality theory
2.1 The general view
Intentionality is the “aboutness” or “directedness”of mental states. For example, a thought that snow is white “says” or represents that snow is white. Similarly, your current visual experience might represent a blue cup or that there is a blue cup in front of you. When a state exhibits intentionality, it involves the instantiation of an intentional property, a property of representing something. What the state represents is its (intentional) content. In this article, we use the term “state” for instantantiations of properties, which are sometimes called token states. (See the entries Intentionality and Mental Representation.)

Phenomenal consciousness is the felt, subjective, or “what it’s like” aspect of mental states (see Nagel 1974). Paradigmatic examples of phenomenal states include perceptual experiences, pains, emotional feelings, episodes of mental imagery, and cognitive experiences such as the experience of déjà vu. Each of these states has a characteristic phenomenal character—there is something that it’s like to be in it. When there is something that it is like for a subject, we can say that she instantiates a phenomenal property, or that she has a phenomenal state. (See the entry Consciousness.)

Phenomenal intentionality is intentionality that is constituted by phenomenal consciousness. A phenomenal intentional state is an intentional state that is constituted by a subject’s phenomenal states. For example, someone who accepts phenomenal intentionality might say that a perceptual intentional state representing a red cube is constituted by a reddish-cube-ish phenomenal state—the reddish-cube-ish phenomenal experience automatically and necessarily results in the representation of a red cube. We will call intentional states that are not phenomenal intentional states non-phenomenal intentional state.

PIT takes phenomenal intentionality to play a central role in accounting for intentional phenomena. The next subsections discuss ways that this initial gloss on PIT can be precisified.

A central idea common to phenomenal intentionality theories is that phenomenal intentionality plays an important role in the mind. The next subsections discuss ways that this idea can be precisified.

2.2 Weak, Moderate, and Strong PIT
The following three theses about the relationship between phenomenal intentional states and intentional states are ways of precisifying the idea that phenomenal intentionality plays an important role in the mind:

Strong PIT:	All intentional states are phenomenal intentional states.
Moderate PIT:	All intentional states either are phenomenal intentional states or are at least partly grounded in phenomenal intentional states.
Weak PIT:	Some intentional states are phenomenal intentional states.
The “all” in the above theses should be understood as quantifying over all actual intentional states, not all metaphysically possible intentional states. In the same way that some physicalist theories of intentionality allow that there are merely possible forms of intentionality that are independent of physical properties, PIT can allow that there are non-actual intentional states that have nothing to do with phenomenal consciousness. Of course, more specific versions of PIT might make stronger claims.

Of the three views mentioned above, Strong PIT asserts the strongest possible relationship between phenomenal intentionality and intentionality: it claims that phenomenal intentionality is the only kind of intentionality there is. Relatively few hold this view, but versions of it have been defended by Pitt (2004), Farkas (2008a), and Mendelovici (2010, 2018). The difficulty with this view, as we will see below, is that it is not clear that there are enough phenomenal states or phenomenal states of the right kind to constitute all intentional states. For example, it is not easy to see how standing beliefs like your belief that grass is green could be constituted by phenomenal states.

Moderate PIT is significantly weaker than Strong PIT. It is compatible with the existence of non-phenomenal intentional states but claims that any such non-phenomenal intentional states are at least partly grounded in phenomenal intentional states.

There are different ways of explicating the intuitive notion of grounding used in the definition of Moderate PIT. For our purposes here, we can say that A grounds B when B obtains in virtue of A. This gloss is itself in need of further analysis, but for now it is enough to know that grounding is an asymmetric relation of metaphysical determination (see Trogdon 2013 for an introduction to grounding). An example of grounding that is similar to the grounding relation posited by some proponents of Moderate PIT is the (alleged) grounding of linguistic meaning in speaker intentions: on many views of language, words have their meanings in virtue of speakers’ intentions toward them. To say that A is partly grounded in B is to that say that A is grounded in the combination of B and other factors.

There are different views of how phenomenal intentionality might partly ground non-phenomenal intentionality:

One view is that non-phenomenal intentional states are simply dispositions to have phenomenal intentional states and that these dispositions get their contents from the phenomenal intentional states that they are dispositions to bring about (Searle 1983, 1990, 1991, 1992). On this view, standing beliefs about grass that are not phenomenal intentional states are dispositions to have phenomenal intentional states with the same or related contents.

Another view is that non-phenomenal intentional states get their intentionality from functional relations they bear to phenomenal intentional states (Loar 2003a, Horgan & Tienson 2002, Graham, Horgan, & Tienson 2007). On this view, a standing belief that grass is green might have its content in virtue of being suitably connected to a host of phenomenal intentional states.

A third view is that non-phenomenal intentionality is a matter of ideal rational interpretation (Kriegel 2011a,b, Pautz 2013). On Kriegel’s view, for example, the relevant phenomenal intentional states are in the mind of a possible ideal rational interpreter.

More versions of Moderate PIT will be discussed below. Proponents of Moderate PIT (or something close to it) include Loar (1987, 1988, 1995, 2003a, 2003b), Searle (1983, 1990, 1991, 1992), Goldman (1993a,b), Siewert (1998), McGinn (1988), Kriegel (2003, 2011a,b), Horgan, Tienson & Graham (2003, 2004, 2006, 2007), Georgalis (2006), Pitt (2004, 2009, 2011), Farkas (2008a,b, 2013), Mendola (2008), Chalmers (2010: xxiv), Bourget (2010), Pautz (2010, 2013), Smithies (2012, 2013a, 2013b, 2014), and Montague (2016).

Weak PIT merely claims that there is phenomenal intentionality. It allows that there are non-phenomenal intentional states that have nothing to do with phenomenal consciousness. The proponents of Weak PIT are too many to list. As we will see below, Weak PIT is entailed by some widely accepted views in philosophy of mind, including many forms of representationalism about phenomenal consciousness, the view that phenomenal states are identical to intentional states (perhaps that meet certain further conditions).

Since Moderate PIT is the strongest view that is endorsed by most proponents of the general approach, it is the view that has the best claim to being the phenomenal intentionality theory. For this reason, this article will focus mainly on Moderate PIT. Unless otherwise indicated, we will use “PIT” to refer to Moderate PIT. (Note that Strong PIT is a version of Moderate PIT, while Weak PIT is not a version of PIT at all, but rather a weakening of the view.)

2.3 Grounding, Identity, and Reductive PIT
Our definition of phenomenal intentional states is neutral between two types of views regarding how phenomenal states constitute intentional states. On grounding views, phenomenal intentional states are grounded in phenomenal states (either in individual states or in sets of such states). Since grounding is asymmetric, this view implies that phenomenal intentional states are distinct from the phenomenal states that ground them. In contrast, identity views take the relation that obtains between phenomenal intentional states and phenomenal states (in virtue of which the former are constituted by the latter) to be that of identity: certain instantiations of intentional properties are identical to instantiations of phenomenal properties. On this view, phenomenal intentional states are identical to individual phenomenal states or sets of phenomenal states.

Farkas (2008a,b), Pitt (2004) (though not in Pitt 2009), and Woodward (2016, forthcoming-a) defend a grounding version of PIT. It is also possible to read Horgan and Tienson (2002) as holding a grounding version of PIT, since they take the relevant relation between phenomenal intentionality and phenomenal consciousness to be that of “constitutive determination”, which might be understood as a kind of grounding relation. Other proponents of PIT, such as Mendelovici (2018), favor an identity view.

We can also distinguish between versions of PIT that are reductive and versions that are not. To a first approximation, a theory of intentionality is reductive if it specifies the nature of intentionality in terms that are supposed to be more basic or fundamental. A theory that is not reductive might either be neutral on the question of reduction or incompatible with reduction.

All grounding versions of (Moderate or Strong) PIT are reductive. Such views entail that all intentionality is ultimately grounded in phenomenal states. Since grounding is asymmetric, the grounding phenomenal states cannot themselves be intentional and are more fundamental than intentional states.

An identity version of (Moderate or Strong) PIT will be reductive if it holds or entails that phenomenal intentional states are identical to phenomenal states and that phenomenal descriptions are more fundamental than intentional descriptions (just as “H2O” descriptions are more fundamental than “water” descriptions). If such views are correct, it should be possible to understand phenomenal states independently of intentionality.

Versions of (Moderate or Strong) PIT that identify phenomenal intentional states with phenomenal states can also be nonreductive. On such nonreductive views, phenomenal descriptions of intentional states are not more fundamental then intentional descriptions. Exactly which versions of PIT that identify phenomenal intentional states with phenomenal states are reductive or nonreductive is an open question.

Regardless of whether PIT provides a reductive account of intentionality in general, versions of Moderate PIT that allow for non-phenomenal intentional states aim to reduce such states to phenomenal intentionality and other ingredients, so they provide a reductive account of at least some intentional states. We will discuss some of these views below.

2.4 Other dimensions of variation
An important dimension of variation between versions of PIT concerns the extent of phenomenal intentionality. The disagreement here cuts across the disagreement between Moderate and Strong PIT. For example, Loar (2003a), who falls in the Moderate PIT camp, mostly limits phenomenal intentionality to perceptual and other sensory states. In contrast, other advocates of Moderate PIT (for example, Strawson (1994) and Pitt (2004)) claim that many thoughts have phenomenal intentionality. Most theorists maintain that unconscious subpersonal states, such as states in early visual processing or unconscious linguistic processing, lack phenomenal intentionality, though Bourget (2010, forthcoming-b), Pitt (2009, Other Internet Resources), and Mendelovici (2018) claim that some such states might have phenomenal intentionality that we are unaware of.

Phenomenal intentionality theorists also disagree on which mental states, if any, have non-phenomenal intentionality. Horgan & Tienson (2002) and Kriegel (2011a) claim that at least some unconscious subpersonal states have non-phenomenal intentionality, while Searle (1990, 1991, 1992) and Mendelovici (2018) deny this. Searle (1990, 1991, 1992) takes at least some standing states, such as non-occurrent beliefs and desires, to have non-phenomenal intentionality, which Strawson (2008) and Mendelovici (2018) deny.

Another important question concerns the structure of phenomenal intentionality. Some proponents of phenomenal intentionality hold that it has a relational structure (Pautz 2010, 2013; Speaks 2015; Bourget forthcoming-a, forthcoming-c), while others (Farkas 2008a,b; Kriegel 2011a,b, 2013; Mendelovici 2018; Pitt 2009) deny this. We briefly discuss this question in Section 4.6.

3. The place of PIT in logical space
This section outlines some important relations between PIT and other views.

3.1 Alternative theories of intentionality
Reductive PIT stands in contrast with two well-known classes of reductive theories of intentionality: tracking theories (Stampe 1977, Dretske 1988, 1995, Millikan 1984, Fodor 1987), which take the content of mental states to be a matter of causal-informational-historical links between them and things in the environment (see the entries on causal theories of mental content and teleological theories of mental content), and conceptual role theories, which take the content of mental states to be a matter of their relations to other mental states and sometimes to the external world (Block 1986, Harman 1987, Greenberg & Harman 2007). (See the section Conceptual role in the entry on narrow mental content.) Reductive PIT also contrasts with primitivism, the view that intentionality cannot be reduced.

Reductive PIT is a competitor to tracking, conceptual role, and primitivist theories in that it is an alternative account of the grounds of intentionality. Versions of PIT that are not reductive are also competitors to these theories, but to a more limited extent: they only offer an alternative explanation of the grounds of non-phenomenal intentional states. Such views are compatible with reducing phenomenal intentional states to tracking states and similar states.

While PIT offers a different account of the grounds of intentionality than conceptual role and tracking theories, it is noteworthy that all versions of PIT are, strictly speaking, compatible with these theories. It could turn out that PIT is true but phenomenal consciousness reduces to conceptual role or tracking, making both PIT and the tracking or conceptual role theory true.

3.2 Other views of the relationship between consciousness and intentionality
Representationalism (or intentionalism) is the view that phenomenal states are intentional states that meet certain further conditions (Harman 1990, Dretske 1995, Lycan 1996, Tye 2000, Byrne 2001, Chalmers 2004; see also the entry Representational Theories of Consciousness). As in the case of PIT, some versions of representationalism are reductive while others are not. When one says that phenomenal states are intentional states that meet certain conditions, one might intend this as a reduction of phenomenal consciousness or one might merely intend to point out a true identity. As in the case of PIT, many proponents of representationalism take the view to be reductive.

The reductive versions of representationalism and PIT are incompatible: if consciousness reduces to intentionality, then intentionality does not reduce to consciousness, and vice-versa. However, versions of PIT and representationalism that are not reductive are compatible. It is common for the two views to be combined: many advocates of PIT also endorse a version of representationalism, claiming that all phenomenal states are also representational states (Horgan and Tienson 2002, Graham, Horgan, and Tienson 2007, Pautz 2010, Mendelovici 2013, 2018, Bourget 2010). In the other direction, representationalism, as we are understanding the view, is committed to Weak PIT, because it entails that some intentional states are phenomenal states.

Another view of the relationship between intentionality and consciousness is what Horgan & Tienson dub “separatism”, the view that consciousness and intentionality are wholly distinct mental phenomena (see e.g., Kim 1998). On this view, consciousness and intentionality do not bear interesting metaphysical relations to each other. For example, there is no identity or grounding relation between them (separatists reject both PIT and representationalism). Separatism is typically associated with the view that consciousness is limited to perceptual and sensory states, and intentionality is limited to beliefs, desires, and other propositional attitudes.

4. Arguments for PIT
This section overviews the main arguments and motivations for PIT.

4.1 The phenomenological case
Horgan and Tienson (2002) argue for the claim that “[t]here is a kind of intentionality, pervasive in human mental life, that is constitutively determined by phenomenology alone” (2002: 520). This is a (fairly strong) version of Weak PIT. They do so by arguing for the following two principles:

IOP:	(The intentionality of phenomenology) Mental states of the sort commonly cited as paradigmatically phenomenal (e.g., sensory-experiential states such as color-experiences, itches, and smells) have intentional content that is inseparable from their phenomenal character. (Horgan and Tienson, 2002: 520)
POI:	(The phenomenology of intentionality) Mental states of the sort commonly cited as paradigmatically intentional (e.g., cognitive states such as beliefs, and conative states such as desires), when conscious, have phenomenal character that is inseparable from their intentional content. (Horgan and Tienson, 2002: 520)
We take IOP to say that each paradigmatic phenomenal property has an associated intentional content such that, necessarily, all instances of the property have this associated content. We take POI to say that each paradigmatic intentional property has some associated phenomenal character such that, necessarily, all instances of the property have this associated phenomenal character.

Horgan and Tienson defend IOP by appealing to broadly phenomenological considerations:

You might see, say, a red pen on a nearby table, and a chair with red arms and back a bit behind the table. There is certainly something that the red you see is like to you. But the red that you see is seen, first, as a property of objects. These objects are seen as located in space relative to your center of visual awareness. And they are experienced as part of a complete three-dimensional scene—not just a pen with table and chair, but a pen, table, and chair in a room with floor, walls, ceiling, and windows. This spatial character is built into the phenomenology of the experience. (Horgan & Tienson 2002: 521, footnote suppressed)

The basic idea is that introspective consideration of paradigmatic phenomenal states suggests that they are intentional. This argument echoes the transparency considerations for representationalism (see the entry Representational Theories of Consciousness).

Horgan and Tienson’s case for POI (the phenomenology of intentionality) rests primarily on detailed phenomenological observations purporting to show that there are phenomenological features corresponding to most contents of propositional attitudes as well as the attitudes of belief and desires. We discuss these arguments in section 5.

With IOP and POI in hand, Horgan and Tienson proceed to argue for the widespread existence of phenomenal intentionality. The following is a reconstruction of the key steps of their argument:

The perceptual phenomenal states of a pair of phenomenal duplicates (creatures that have the same phenomenal experiences throughout their existence) necessarily share some contents, including many perceptual contents (from IOP).
Therefore, the phenomenal duplicates necessarily have the same perceptual beliefs.
Therefore, the phenomenal duplicates necessarily share many of their non-perceptual beliefs.
Therefore, the phenomenal duplicates necessarily share many of their intentional contents at the level of perception, perceptual beliefs, and non-perceptual beliefs.
The general idea is that phenomenal states, with their phenomenally determined intentionality, bring in their train much of the rest of the “web of belief”.

Horgan and Tienson argue for the transition from (1) to (2) by articulating in some detail how the contents of perceptual experiences, either individually or in groups, bring in their train perceptual beliefs. A key idea, supported by POI, is that perceptual beliefs and other attitudes towards perceptible contents have phenomenal characters closely associated with them. For example, there is a phenomenology of accepting various contents as true. The suggestion is that once one has a vast number of perceptual experiences with their associated perceptual contents and feelings of accepting and rejecting some of these, one qualifies as having a number of perceptual beliefs.

Regarding the transition from (2) to (3), a key idea, again derived from POI, is that non-perceptual beliefs have extensive phenomenology. For example, according to Horgan and Tienson, there is something that it’s like to wonder whether to cook meatloaf for dinner. The phenomenology of such non-perceptual thoughts, together with one’s vast collection of perceptual beliefs and perceptual experiences, fixes a large number of non-perceptual beliefs and other non-perceptual propositional attitudes. (4) combines conclusions (1)–(3).

The following considerations, while not exactly Horgan and Tienson’s, seem to go in the same direction as their line of argument: If all beliefs and desires have phenomenal characters unique to them, as Horgan and Tienson take themselves to have established, then phenomenal duplicates will share these phenomenal characters. By IOP, these phenomenal characters must determine contents. Plausibly, they determine the contents of the beliefs and desires that they characterize. So if an individual has a given belief with content C, then his or her phenomenal duplicate has this content as the content of a phenomenal experience. Moreover, the duplicate has a feeling of accepting C. It is then quite plausible that the duplicate believes C.

Horgan and Tienson’s argument establishes Weak PIT, but it does not yet establish any version of Moderate PIT. It could be that many intentional states are phenomenal intentional states but some intentional states are neither phenomenal intentional states nor grounded in phenomenal intentionality (Bailey and Richards (2014) point out related limitations of the argument). However, when combined with Horgan and Tienson’s arguments for the claim that many non-phenomenal intentional states are grounded in phenomenal intentionality (more on this view below), we have some support for Moderate PIT.

Mendelovici (2018) also argues for Moderate PIT on the grounds of metaphysical sufficiency: The ingredients invoked by alternative theories of intentionality, such as tracking and functional role theories, are not metaphysically sufficient for intentionality. For instance, it is unclear why having internal states playing certain functional roles should result in those internal states representing a particular content, or any content at all. Likewise, while tracking relations relate us to items that may seem to be well-suited to playing the role of content, such as objects, properties, and states of affairs, it is mysterious how tracking such items could make them psychologically relevant to us. For instance, it is unclear how merely tracking such items can make them introspectively accessible, available to reason with, or in any sense “entertained”. (See also BonJour 1998 for similar worries with tracking and functional role theories.) In contrast, PIT’s central ingredient, phenomenal consciousness, is arguably metaphysically sufficient for intentionality. For instance, it is arguably inconceivable for there to be someone with a reddish phenomenal experience who does not thereby represent redness. If all this is right, then there is reason to think that phenomenal consciousness alone is metaphysically sufficient for intentionality, which supports Moderate PIT.

4.2 Assessability for accuracy
Siewert (1998) argues for Weak PIT by arguing that phenomenal states are automatically assessable for accuracy. A key element of Siewert’s argument is his assumption that phenomenal characters can be identified with “how it seems for it to look some way to someone”. We take this to mean that phenomenal states are states of things seeming a certain way, where the relevant kind of seeming is the kind we are familiar with from cases where things look a certain way in perception (perhaps there are other kinds of seemings that are not phenomenal states). Siewert’s argument is contained in the following passage, in which we have added numbers corresponding to the premises:

First, consider some instance of its seeming to you as it does for it to look as if something is shaped and situated in a certain way, such as its seeming to you just as it does on a given occasion for it to look as if there is something X-shaped in a certain position. (1) If it seems this way to you, then it appears to follow that it does look to you as if there is something X-shaped in a certain position. (3) If this is right, then its seeming this way to you is a feature in virtue of which you are assessable for accuracy—(5) that is to say, it is an intentional feature. For, from what we have said, (2) if it seems to you as it does for it to look this way, then, if it is also the case that there is something X-shaped in a certain position, it follows that the way it looks to you is accurate. (Siewert 1998: 221)

Siewert suggests that this argument straightforwardly generalizes to a large number of perceptual experiences.

Let S be the phenomenal state in which it seems to you just as it does on a given occasion for it to look as if there is something X-shaped in a certain position. The argument in the above quotation can be broken down as follows:

Necessarily, if you are in S, it looks to you as if things are a certain way W, in virtue of being in S.
Necessarily, if it looks to you as if things are in way W, things being (or not being) W would make you accurate (or inaccurate).
Therefore, if you are in S, you are assessable for accuracy with respect to things being W, in virtue of being in S.
If you are assessable for accuracy in virtue of being in a certain state, this state has intentional content.
Necessarily, S has intentional content.
Siewert does not explicitly defend premises (1) and (2). (4) is defended in section 6.2 of the book.

One might object that (3) does not follow from (1) and (2). Perhaps S is such that, necessarily, things being a certain way (or not) would make the bearer of S accurate (or not), but it is not in virtue of being in S that its bearer is assessable for accuracy. The assessability might come from the inevitable addition of an interpretation to S in all circumstances. Siewert argues against this possibility extensively between pages 222 and 245, ruling out various sources of interpretation.

Gertler (2001) objects that there is an alternative explanation of Siewert’s observations about the co-occurrence of phenomenal and intentional properties: intentional properties automatically give rise to phenomenal properties. Gertler argues that Siewert has not ruled out this alternative, and so fails to establish PIT. See Siewert 2004 for a response.

4.3 Internalism and brains in a vat
It is possible to argue for PIT on the basis of internalism about mental content, the view that what a subject’s mental states represent is fully determined by her intrinsic properties. (The alternative to internalism is externalism. Intentional content that is determined by a subject’s intrinsic properties is said to be narrow as opposed to wide. See the entries on narrow mental content and externalism about mental content.)

Loar (2003a) argues from internalism to PIT. First, Loar proposes the following two desiderata for a theory of intentionality: (1) The theory should be a non-referential theory, where a non-referential theory is a theory that does not take intentionality to be a matter of reference to external entities, for example, concrete or abstract objects. This desideratum is motivated by internalism. (Note that, for Loar, intentionality is not the same thing as reference, and so a non-referential theory of intentionality does not commit one to denying that there is such a thing as reference.) (2) The theory should accommodate externalism about reference and truth-conditions (see, e.g., Putnam 1975, Burge 1979, Kripke 1980).

Loar then argues that internalist views that do not appeal to phenomenal consciousness fail to meet desiderata (1) and (2). The first view he considers is short-arm functionalism, the view that causal interactions between brain states give rise to intentionality. The second view is a version of the descriptivist theory of reference combined with short-arm functionalism about its primitive representations. Having excluded these views, he argues that a version of PIT can meet his two desiderata. Phenomenal properties are inherently intentional in that they exhibit directedness, or purport to refer. Since purporting to refer is not the same thing as referring, the result is non-referential mental content. This satisfies the first desideratum.

Loar argues that his view satisfies the second desideratum by arguing that phenomenal properties do not by themselves secure reference or truth-conditions. Instead, reference and truth-conditions are a matter of externally-determined relations, as externalists such as Putnam (1975), Burge (1979), and Kripke (1980) claim. However, which externally-determined relations matter for reference depends on a subject’s non-referential internalist content. Horgan, Tienson, & Graham (2004) also suggest that PIT is the best available theory of narrow content and suggest that phenomenal intentionality can provide a basis for externalist content.

Another argument for PIT involves appeal to brain in a vat scenarios (see Loar 2003a and Horgan, Tienson & Graham 2004). A brain in a vat duplicate is an exact physical duplicate of a normally embodied human brain that is kept in a vat of life-sustaining liquids and is hooked up to a computer that delivers to it the same kinds of stimulation its embodied twin receives. It intuitively seems that a brain in a vat would have a mental life “matching” that of its embodied twin. The brain in a vat and its twin would have matching perceptual experiences, perceptual judgments, and beliefs. For example, when the embodied twin believes that she is lying on the beach sipping a frappé, the brain in a vat twin believes that they are lying on the beach sipping a frappé. However, while the normal subject’s belief might be true, the envatted subject’s beliefs, and many other of their mental states, would be false or non-veridical.

Farkas (2008a) agrees with Loar and Horgan et al. (2004) that PIT is the best available theory of narrow content but criticizes Loar (2003a) and Horgan et al. (2004) for making a concession to externalism by allowing for externally-determined reference, truth-conditions, or broad content. Instead, Farkas argues that internalist, phenomenally-constituted intentionality is all that a theory of intentionality needs.

Wilson (2003) objects to Loar’s appeal to brains in vats, claiming that intuitions concerning them are theoretical intuitions and are likely to be rejected by many of PIT’s opponents.

4.4 Aspectual shape
In an early defense of PIT, Searle (1990, 1991, 1992) puts forth an argument based on the “aspectual shapes” of intentional states. The argument is rather complex and open to several interpretations, but here is one simplified way of understanding it: Searle begins by noting that all intentional states have an aspectual shape, where an aspectual shape is a matter of how something is represented. For example, there is a difference between representing Hesperus and representing Phosphorus, or representing Superman and representing Clark Kent. The differences lie not in which objects are represented, but in how they are represented—these are differences in their aspectual shapes.

Searle then argues that no internal or external unconscious physical or functional facts can determine aspectual shapes. The only thing that can determine aspectual shape is consciousness. If that is so, then it looks like unconscious states can only have their aspectual shapes in virtue of their connections to conscious states. Searle concludes, more specifically, that unconscious intentional states involve dispositions to have conscious states, a thesis that he calls the connection principle. (Sometimes he says that unconscious states are potentially accessible to consciousness, apparently meaning that they can be introspected consciously (1992, p. 156), but other times he says what we say here: that unconscious states involve dispositions to have conscious states (1992, p. 159, 161–162). The latter is what Searle says as part of his argument for the connection principle, and this interpretation is more in line with the argument he deploys.)

In sum, the argument seems to go as follows:

All intentional states have aspectual shape.
Only states that are conscious or involve dispositions to have conscious states have aspectual shape.
Therefore, all intentional states are either conscious or involve dispositions to have conscious states.
According to the argument’s conclusion, all intentional states are either phenomenal intentional states or involve dispositions to have such states. This is a version of Moderate PIT.

Searle’s arguments have elicited a large number of responses. Fodor and Lepore (1994) argue that there is no suitable way of cashing out what it would take for a state to be potentially conscious such that Searle’s claims are both plausible and tendentious (i.e., that they entail, as Searle claims, that much of cognitive science’s appeal to non-conscious intentional states is misguided). For a response, see Searle 1994. Davies (1995) argues that Searle might be right about a kind of intentionality but that there are other kinds of intentionality invoked in cognitive science that are not dependent on consciousness. Van Gulick (1995) argues that Searle’s notion of aspectual shape smuggles in the notion of consciousness, and that on a less contentious understanding of aspectual shape, his argument that consciousness is the only way of accounting for aspectual shape does not succeed. Baaren (1999) also takes issue with the notion of aspectual shape. See also the commentaries accompanying Searle 1990.

4.5 Arguments from content determinacy
Another line of argument for PIT similar to Searle’s aspectual shape argument is an argument from content determinacy. Graham, Horgan & Tienson (2007) and Horgan & Graham (2012) argue that it is difficult to see how unconscious neural activity, functional role, dispositions to behavior, and other possible physical bases of intentionality can yield the sorts of determinate contents we manifestly represent (see also Dennett 1987, Quine 1960: ch. 2, and Kripke 1982). For example, no causal, functional, or purely physical features of one’s brain or environment seem to make it the case that one is thinking about rabbits rather than undetached-rabbit-parts. A Martian looking down on Earth with complete knowledge of all Earthly physical facts could not tell whether we are representing rabbits or undetached rabbit parts. Thus, it appears that a physical-functional theory of intentionality will predict that one’s concept RABBIT is indeterminate between the two contents.

Similarly, nothing about our brains, their finite dispositions, or their environments indicates that our word “plus” means the plus operator rather than a Kripkean quus operator, an operator that works just like plus when the operands are less than 57 and returns 5 when either operand is 57 or greater (see Kripke 1982). If we do determinately represent plus and rabbits, something other than tracking relations, dispositions towards behaviors, internal functional roles, or brain states has to determine this. Along similar lines, Strawson (2008) argues that phenomenal intentional facts about what we take an intentional state to refer to play a key role in determining what an intentional state refers to.

Some argue that phenomenal consciousness is capable of explaining content determinacy. According to Graham, Horgan and Tienson, there is a phenomenal difference between representing rabbits and representing undetached-rabbit-parts. Since PIT claims that phenomenal intentional content is determined by phenomenal character, it allows that the two states have distinct contents. The supposition that there is high-level cognitive phenomenology corresponding to such abstract contents as rabbits and undetached-rabbit-parts is key to this argument. This is a controversial claim, but one that is quite central to many versions of PIT. We discuss this claim in section 5.

Arguments for PIT from content determinacy rely on the strong claim that the totality of physical facts do not fix content determinately and that content is fixed determinately. While PIT does not entail dualism about consciousness, PIT combined with this claim does (see Pautz 2013, who objects to arguments for PIT from content determinacy for related reasons). This claim will be resisted by anyone who thinks that physicalism about the mind is well-motivated. One might say that the intuition that physical facts cannot fix determinate contents arises from the fact that we do not have a suitably good understanding of how intentionality arises from physical facts; had we such an understanding, the intuition would disappear.

4.6 Intentional states about non-existents
Relationalism about intentionality is the view that intentionality is a relation to distinctly existing entities that serve as contents. Non-relationalism about intentionality is the view that intentionality is not a relation to distinctly existing entities that serve as contents.

Kriegel (2007, 2011a) argues that a non-relational view of intentionality provides the best explanation of how we can represent things that don’t exist, such as Bigfoot, and that PIT is the best candidate non-relational view of intentionality. Kriegel first argues that the following three intuitively appealing claims are inconsistent:

(a)	One can represent non-existents.
(b)	One cannot bear a relation to non-existents.
(c)	Representing something involves (constitutively) bearing a relation to it. (Kriegel 2007: 308)
One of these claims needs to be rejected. Kriegel argues that it is (c), the claim that asserts relationalism. His’s argument proceeds by a process of elimination.

Kriegel considers rejecting (a). On this proposal, when we seem to represent dragons, Bigfoot, or Santa Claus, we either fail to have an intentional state or we represent something else. One reason Kriegel rejects the first option is that it implies that there is a gap between trying to represent and representing, which he takes to be implausible. On the second option, when we seem to represent non-existent concrete entities, we are really just representing something else, such as existent abstract entities (e.g., universals or propositions), existent mental entities (e.g., sense data or ideas), or existent possible but non-actual entities. But Kriegel takes this option to be highly counterintuitive. When we seem to be thinking about concrete flesh-and-blood Bigfoot, we are in fact thinking about an abstract or mental entity. (See, however, Mendelovici 2018, section 9.3.1 for a response to this line of argument.) Another worry is that accounting for the representation of non-existents seems like the wrong kind of reason to accept the existence of these abstract, mental, or merely possible entities.

Another option is to reject (b). Kriegel argues that just as a monadic property cannot be instantiated without an existing particular that instantiates it, so too a relation cannot be instantiated without existing particulars that instantiate it. In short, it is a general rule that relations require relata. Rejecting (b) is tantamount to claiming that the intentionality relation is an exception to this general rule, which is implausible.

Kriegel concludes that we should reject (c). He calls his non-relational view “adverbialism”, since it draws its inspiration from the adverbialist views of perception of Ducasse (1942) and Chisholm (1957). According to Kriegel’s adverbialism, representing Bigfoot is not standing in a relation to an entity, but rather instantiating a non-relational intentional property, which we might describe as the property of representing Bigfoot-wise.

So far, this only motivates adverbialism. The final step of the argument motivates PIT: One objection to adverbialism is that it is mysterious what non-relational intentional properties are. What is it to represent Bigfoot-wise? Kriegel suggests that a plausible account of these properties is that they are phenomenal properties. Phenomenal properties are usually taken to be non-relational and there is independent reason to think they give rise to intentionality (see the other arguments in this section). The resulting picture is one on which phenomenal intentionality is non-relational. Kriegel suggests that this view can be combined with the view that non-phenomenal intentionality is derived from phenomenal intentionality and is relational.

In short, Kriegel’s argument attempts to show that PIT is the best way to account for the representation of non-existents.

This argument motivates non-relational versions of PIT. However, it does not motivate relational versions of PIT, on which intentionality is relational. Loar (2003a), Pitt (2009), Kriegel (2007, 2011a), and Mendelovici (2010, 2018) hold non-relational versions of PIT, while Pautz (2013) and Bourget (forthcoming-a, forthcoming-c) defend a relational version of PIT, on which both phenomenal properties and intentional properties are relational. Speaks (2015) also defends a relational view of phenomenal representation (without endorsing PIT).

Arguing in the direction opposite the preceding considerations, some have challenged PIT on the grounds that intentionality is relational. Ott (2016) raises worries for PIT along such lines, arguing that most versions of PIT fail to adequately explain how phenomenal consciousness can give rise to intentionality, which he takes to necessarily involve a relation to extra-mental reality.

There are two lines of response open to phenomenal intentionalists: One is to maintain that phenomenal consciousness is itself relational in the relevant way. Pautz (2010) and Bourget (forthcoming-a, forthcoming-c) argue that consciousness is a relation to items in extra-mental reality, such as clusters of abstract properties or abstract propositions. Of course, this response gives up on the benefits of non-relational PIT alleged by Kriegel. (Bourget (forthcoming-c) responds to some of Kriegel’s arguments against relationalism.)

Another response is to deny that intentionality secures the required relation to extra-mental reality. Along such lines, Mendelovici (2018, sections 1.3.4 and 9.3.4) argues that it is a substantive question whether intentionality on its own or with the help of additional ingredients secures such a relation. Of course, whether this is so depends on what exactly we mean by “intentionality”. If intentionality involves such a relation by definition, then there is no further substantive question to be asked. But if, as Mendelovici (2010, 2018) and Kriegel (2010) suggest, the core notion of intentionality leaves open this aspect of its nature, it might very well turn out that intentionality does not involve such relations.

Even if intentionality does not involve a relation to extra-mental reality, one might worry that it should at least play a role in facilitating such a relation and that PIT cannot allow for this. But Ott (2016) suggests that PIT can in fact connect us to extra-mental reality through relations of resemblance. Similarly, Mendelovici (2018, chapter 9) argues that intentionality does not involve a connection to extra-mental reality but that truth and reference do and that truth and reference are a matter of a special kind of superficial resemblance called “matching”. Woodward (forthcoming-b) and Bourget (forthcoming-b) challenge Mendelovici’s account of truth and reference for non-relational versions of PIT.

4.7 The argument from predictive accuracy
Another line of argument for PIT begins by noting that theories of intentionality, combined with certain facts about the world, often make predictions as to what particular intentional states represent. For example, a causal theory of intentionality combined with the fact that cows often cause tokens of the concept COW might predict that COW represents the content cow, which might be the property of being a cow.

One line of argument for PIT is based on the claim that PIT makes correct predictions in certain paradigm cases of intentionality that other theories fail to accommodate. One such case is that of color experience: It is plausible (though not undisputed) that color experiences represent what Chalmers (2006) calls “Edenic colors”—primitive, non-physical, qualitative properties (see also Pautz 2006a, 2009). This might be supported by introspection, epistemic considerations, and considerations of psychological role. But since Edenic colors are arguably not instantiated, it is difficult for causal, informational, teleological, and other “tracking” theories of intentionality to allow us to represent them. Instead, such theories predict that perceptual color representations represent the likes of particular dispositions to reflect, emit, or transfer light of particular wavelengths. In contrast, since Edenic colors “match” the phenomenal characters of color experience, PIT has the resources to make the correct predictions in the case of color experiences. Mendelovici (2018) refers to this as the argument from matching for PIT. Pautz (2006b) makes a related argument against tracking representationalism and for primitivist representationalism based on a structural mismatch between the contents represented by color experience and the properties color experiences track. See also Causal Theories of Mental Content.

The argument from predictive accuracy purports to show that PIT is the only theory of intentionality that stands a chance of being empirically adequate (whether it can indeed handle all the cases depends on whether it can deal with challenging cases, such as those discussed in section 6). It does not make a complete case for PIT, but it is an important consideration as part of the overall case for PIT.

4.8 Other arguments for PIT
We will briefly mention a few other lines of argument for PIT.

One revolves around the idea that norms of rationality are constitutive of (non-phenomenal) intentional states. Pautz writes:

Consciousness grounds rationality because it is implicated in basic epistemic norms. … In turn, the facts about rationality help to constitutively determine belief and desire (Davidson, Lewis). So consciousness also ultimately grounds belief and desire. (Pautz 2014: 176)

This line of argument combines two claims that have been defended independently. The first is a view of non-phenomenal states (chiefly, propositional attitudes) on which they derive their contents from norms of rationality (Davidson 2001, Lewis 1983, Chalmers 2012). The second is the view that consciousness plays a role in determining rational norms (Siewert 1998, Campbell 2002, Smithies 2012, 2014). In addition to the above passage from Pautz, this argument for PIT is also made in Chalmers 2012: 467 and Pautz 2013: 226.

Another line of argument for PIT is that there is nothing to determine who a given non-conscious state of mind belongs to unless that state consists in a disposition to produce a conscious mental state of the right sort (Ludwig 1996). Kriegel (2003) similarly argues that only PIT can account for the fact that intentional states have a subjective or “for-me” character.

5. Cognitive phenomenology
Many defenses and elaborations of PIT maintain that occurrent thoughts have a rich and varied phenomenology. Such a view of thought is required by versions of PIT that claim that the contents we normally attribute to thoughts are phenomenal contents (see section 6.2). Cognitive phenomenology is also a widely debated topic independently of any connection to PIT (see, e.g., Cognitive Phenomenology, edited by Bayne and Montague 2011).

Advocates of PIT that take thought content to be phenomenal content mainly focus on arguing for the following two claims:

(Proprietary)	Thoughts have proprietary phenomenal characters.
(Individuative)	Thoughts have individuative phenomenal characters.
The term “proprietary” is due to David Pitt (2004). Thought has a proprietary phenomenal character just in case the phenomenal characters of thoughts are special or unique to thought, i.e., they are not perceptual, verbal, bodily, or affective phenomenal characters, or other phenomenal characters that are present in mental states other than thoughts. Following current usage, we call all of the aforementioned kinds of phenomenology sensory phenomenology and the putative proprietary phenomenology of thought cognitive phenomenology. The claim that thought has a proprietary phenomenology is then just the claim that it has a non-sensory phenomenology.

Thoughts have individuative phenomenal characters just in case thoughts with different intentional contents have different phenomenal characters and thoughts with different phenomenal characters have different intentional contents. (We use “individuative” in the way Bayne and Montague (2011: ch. 1) use it. Pitt (2004) uses the term “distinctive” for a similar notion and the term “individuative” to mean something else.)

While most advocates of PIT take thoughts to have individuative phenomenal characters, this isn’t required by PIT. Grounding PIT can allow that there is a one-many grounding relation between contents and phenomenal characters. For example, phenomenal properties r1 and r2 might both ground the intentional property of representing red421. If all intentional properties were grounded in this way, PIT would be true, but (Individuative) might not be.

It is possible for thoughts to have proprietary but not individuative phenomenal characters. For example, suppose every thought came with either a generic feeling of understanding or a generic feeling of confusion. These phenomenal characters might be proprietary in that they do not occur outside of thoughts, but they are not individuative, since thoughts with different intentional contents might have the same phenomenal characters.

It is also possible for thoughts to have individuative but not proprietary phenomenal characters. For example, suppose every thought came with a different kind of perceptual imagery. Then thoughts with different contents would have different phenomenal characters, but these phenomenal characters would not be special to thoughts, since perceptual states could have them too.

In addition to the claims that there is a proprietary and an individuative phenomenology of thought, advocates of PIT usually aim to establish that thought’s content is phenomenal intentional content and thus that thought’s intentional properties are obtained in the requisite way from phenomenal properties.

While much of the discussion of the phenomenology of thought involves careful argumentation and consideration of cases, it is worth mentioning that many advocates of a proprietary phenomenology of thought find the view obvious and the negation of the view clearly false or even absurd. Strawson writes:

To deny this [cognitive phenomenology], one must hold that the total lifelong character of our lived experience—everything that life is to us experientially—consists entirely of bare or pure sensation or feeling of one kind or another. It must, for example, be false to say that anguish at someone’s death includes conscious comprehending believing entertaining of the proposition that he is dead. (Strawson 2011a: 295, italics in original)

In a similar vein, Kriegel writes:

For my part, I am persuaded of the existence of cognitive experience […] most vividly by something like everyday experiential overwhelm: it simply seems that my inner life is much more interesting to me than it would be if my conscious experience consisted merely in perceptual experiences. (Kriegel 2011a: 50)

In what follows we discuss the main arguments that have been offered to supplement such appeals to the alleged obviousness of cognitive phenomenology.

5.1 Phenomenal contrast cases
Phenomenal contrast cases are cases of two thoughts that are alike in sensory phenomenal character but differ in thought content.

Siewert (1998) asks his readers to compare an experience of hearing or reading a sentence without understanding, as when one reads a difficult passage without paying attention to it, and an experience of hearing or reading a sentence with understanding. There is clearly a phenomenal difference between these cases. Siewert argues that the difference is not a difference in verbal or perceptual imagery, since the verbal and perceptual imagery might be the same in both cases. The best explanation of the phenomenal contrast is that thought involves proprietary cognitive phenomenology.

Strawson (1994) argues for a kind of “understanding experience” by contrasting the cases of a monolingual English speaker and a monolingual French speaker listening to the news in French. The experiences of the two subjects differ in a way that is not fully explained by a difference in sensory phenomenology. The best explanation involves a difference in cognitive phenomenology. Siewert (1998) also employs examples involving the comparison of hearing sentences in familiar versus unfamiliar languages.

As it stands, Strawson’s argument can only establish that thought has a proprietary phenomenology, but Kriegel (2011a: 49) extends it to argue that thought has an individuative phenomenology. He asks us to imagine a case of two languages involving graphically and phonetically identical words such that the same report can be interpreted in one language as describing a faraway war and in the other language a children’s bedtime story. Monolingual speakers of each language will experience different phenomenal characters upon reading or hearing this report. The best explanation of this involves a difference in cognitive phenomenology. This supports the claim that cognitive phenomenology is individuative.

Other arguments from phenomenal contrast cases aim to create the contrasting experiences in the reader herself. Horgan and Tienson (2002) present the reader with sentences that are likely to give rise to two different interpretations, such as the following:

(Relatives)	Visiting relatives can be boring.
On one reading, the sentence is about the act of visiting relatives. On another reading, the sentence is about relatives that visit. Both readings are likely to generate the same verbal imagery, but they differ in content. Horgan and Tienson encourage the reader to notice that they also differ in phenomenal character. If this is right, then this suggests that thought has a proprietary and individuative phenomenology.

The following sentences are also used to generate phenomenal contrast cases:

(Dogs)	Dogs dogs dog dog dogs. (Horgan and Tienson 2002)
(Time)	Time flies! (Horgan and Tienson 2002)
(Bar)	Before she had a chance to pass the bar, she decided to change directions, but she was not so pleasantly surprised with where she wound up. (Siewert 1998: 279)
(Dogs) might at first be read without understanding, but might subsequently be read with understanding, giving rise to a phenomenal contrast case. (Time) can be read as a cliché or as a command at the insect races. (Bar) can be read as being about an aborted legal career or a trip around town. Again, the claim is that these different readings of the sentences give rise to different phenomenal experiences and that the best explanation of this is that thought has a proprietary and individuative phenomenology.

Though instances of pairs of thoughts differing in intentional content and differing in phenomenal character provide some evidence for the existence of individuative cognitive phenomenology, in order for the thesis that thought has a individuative phenomenology to be true, there have to be no cases of thoughts that are alike in content but that differ in phenomenal character. This latter kind of case would be a counterexample to (Individuative). Wilson (2003) responds to Horgan and Tienson by accepting their observations in their phenomenal contrast cases but attempting to provide such a counterexample:

In the spirit of Horgan and Tienson’s appeal for a reader to “pay attention to your own experience” ([2002] p. 521), I have just done the decisive experiment: I thought first that George Bush is President of the United States, and had CNN-mediated auditory and visual phenomenology that focussed on one of his speeches. I then took a short break, doodled a little, wandered around the room, and then had a thought with that very same content and … nothing. Or at least nothing distinctly Bush-like, as in the first case. (Wilson 2003: 417)

If Wilson is right, this not only shows that arguments based on phenomenal contrast ultimately fail, but also provides positive considerations against (Individuative), since it shows that there can be thoughts with the same contents that fail to have the same phenomenal character.

Versions of PIT that require only a one-many relation between phenomenal intentional content and phenomenal character, and hence that do not need to endorse (Individuative), can accommodate observations such as Wilson’s putative observation, since they allow that multiple phenomenal characters can ground or constitute the same phenomenal intentional content.

Another kind of objection to arguments from phenomenal contrast involves agreeing that there is a phenomenal difference between the relevant cases but claiming that this difference is exhausted by sensory phenomenology, where this might include the phenomenology of perceptual imagery, affective experience, or verbal imagery (see, e.g., Lormand 1996, Tye and Wright 2011, Levine 2011, Robinson 2011, Carruthers and Veillet 2011). What makes the phenomenal contrast cases described above vulnerable to this kind of objection is that they do not control for all potential accompanying perceptual imagery. This leaves open the possibility that the observed phenomenal differences are fully accounted for by such imagery.

Chudnoff (2013) provides a phenomenal contrast case that he claims avoids this reply. He asks his readers to compare the experience of an array of dots to an experience of the same array of dots experienced as part of a proof for a mathematical theorem. In the second experience, but not in the first, the perceptual experience involves cognitive phenomenology. The array of dots is in some sense experienced as part of a larger whole, representative of something, or in some sense meaningful. (Chudnoff 2015a,b also contain extensive critical discussions of phenomenal contrast cases.)

One might worry that, like the original phenomenal contrast cases, Chudnoff’s case does not control for certain forms of accompanying imagery, in this case, verbal imagery. The adamant opponent of cognitive phenomenology might insist that just as the phenomenal differences in the phenomenal contrast cases involving sentences might be explained by perceptual imagery, the differences in Chudnoff’s cases can be accounted for by differences in verbal phenomenology.

It might seem that what is needed is a phenomenal contrast case that plausibly controls for both verbal and perceptual phenomenology, as well other kinds of sensory phenomenology. Mendelovici (2010: 107) argues that thoughts about chiliagons (one-thousand sided figures) and megagons (one-million sided figures) might involve the same mental imagery (both shapes effectively look like circles) and so might provide the basis for such cases. Imagine a person who mistakenly uses the word “megagon” to mean chilliagon. Compare her experience of viewing a chilliagon and thinking that it is a chilliagon with your experience of viewing a megagon and thinking that it is a megagon. Since you both use the word “megagon” to describe the shape you are thinking about, and since the two shapes are perceptually similar, you will likely have the same perceptual and verbal imagery. If there is a phenomenal difference between the two cases, it is plausibly attributed to a difference in thought content.

5.2 Spontaneous thoughts
Siewert (1998, 2011) claims that sudden realizations are cases in which cognitive phenomenology is particularly noticeable.

[Y]ou are standing at the door to your house, reaching in your pants pocket for the door key, and find it empty. You feel a sudden panic; you think perhaps you have locked yourself out; you try to remember where you put the keys, then recall switching them to your coat pocket earlier; you reach and find them there—relief. (Siewert 1998: 277)

I meet a friend, and she asks me, “Did you bring the book?” For a moment I am at a loss as to what book she’s talking about—and then I realize in an instant what book it is. (Siewert 2011: 258)

Siewert claims that such realizations needn’t involve any verbal or perceptual imagery. In the case of the first example, you don’t think the words “I have locked myself out” or visualize your keys. Siewert takes these and other similar examples to show that thought has a proprietary phenomenology.

Similarly, in order to argue that the phenomenal properties of thought are not merely associated with verbal imagery, Horgan and Tienson (2002) point to examples of spontaneous thoughts we have when engaging in activities such as cooking or working in a garage or woodshop:

There is something that it is like to think that a certain tool is just there—in that cabinet, say—but such beliefs are typically not verbalized either vocally or subvocally or by way of verbal imagery. (Horgan and Tienson 2002: 523)

Like Siewert’s examples, this example helps motivate the claim that thought has a proprietary phenomenology.

This line of argument relies heavily on introspection. Unfortunately, detractors of cognitive phenomenology (for example, Robinson 2011 and Tye & Wright 2011) claim that their own observations of sudden realization reveal less phenomenology, resulting in an apparent stalemate.

5.3 The tip-of-the-tongue phenomenon
Some experiences with a cognitive character seem to make a fairly good case for a minimal amount of proprietary phenomenology of thought. For example, Goldman (1993a) invokes the tip-of-the-tongue phenomenon to argue that thought has a proprietary phenomenology, an argument he attributes to Jackendoff (1987).

When one tries to say something but can’t think of the word, one is phenomenologically aware of having requisite conceptual structure, that is, of having a determinate thought-content one seeks to articulate. What is missing is the phonological form: the sound of the sought-for word. The absence of this sensory quality, however, does not imply that nothing (relevant) is in awareness. Entertaining the conceptual unit has a phenomenology, just not a sensory phenomenology. (Goldman 1993a: 24)

The tip-of-the-tongue phenomenon occurs when one cannot think of a word, so it involves the absence of verbal phenomenology corresponding to that word. But instances of this phenomenon do involve some phenomenology. Goldman proposes that this phenomenology is non-sensory.

Lormand (1996) responds to this suggestion by providing an alternative account of the relevant phenomenology on which it is sensory, which he also takes to be supported by Jackendoff 1987. According to Lormand, the relevant phenomenology involves a sensory phenomenal experience of a void, which is akin to hearing silence, along with an experience of effort, whose phenomenology is also sensory.

5.4 Epistemic markers of consciousness
Phenomenal consciousness has various epistemic markers: It gives rise to (at least the appearance of) an explanatory gap (see Levine 1983 and the entry on consciousness), it is susceptible to zombie thought experiments (see Chalmers 1996 and the entry on zombies), and it is susceptible to the knowledge argument (see Jackson 1982 and the entry Qualia: The Knowledge Argument). These arguments usually focus on sensory phenomenal consciousness. For example, Levine’s central example is that of pain and Jackson’s is that of experiencing red.

The initial plausibility of these kinds of arguments might be taken to serve as an indicator of phenomenal consciousness: plausibly, if these arguments have some traction with some mental state, then that mental state is likely to have phenomenal properties. Some have used the presence or absence of such markers to argue for or against cognitive phenomenology.

Goldman (1993b) argues that a version of Jackson’s (1982) thought experiment can be run with propositional attitudes, such as doubt and disappointment:

Jackson’s example is intended to dramatize the claim that there are subjective aspects of sensations that resist capture in functionalist terms. I suggest a parallel style of argument for attitude types. Just as someone deprived of any experience of colors would learn new things upon being exposed to them, viz., what it feels like to see red, green, and so forth, so (I submit) someone who had never experienced certain propositional attitudes, e.g., doubt or disappointment, would learn new things on first undergoing these experiences. There is “something it is like” to have these attitudes, just as much as there is “something it is like” to see red. (Goldman 1993b: 365)

In other words, Goldman argues that Jackson’s thought experiment is compelling in the case of propositional attitudes and that this supports the claim that propositional attitudes have proprietary phenomenal properties above and beyond functional properties. (Presumably, Goldman intends his argument to apply only to occurrent propositional attitudes, since he takes standing states to be purely dispositional (1993b: 366).) Goff (2012) makes similar observations.

Horgan (2011a) also uses epistemic indicators of phenomenal consciousness to argue for cognitive phenomenology. He argues that since partial zombies lacking cognitive phenomenology are conceivable and phenomenally different from us, we have cognitive phenomenology.

Interestingly, Carruthers and Veillet (2011) use epistemic indicators to argue against cognitive phenomenology. They claim that thought is not susceptible to the explanatory gap, and thus that there is no cognitive phenomenology.

5.5 Self-knowledge
Pitt (2004) argues that there is a kind of self-knowledge that can only be explained by cognitive phenomenology. Pitt’s argument not only aims to establish that there is a proprietary and individuative cognitive phenomenology but also that this phenomenology is constitutive of thought’s content, i.e., that thought’s content is phenomenal intentional content.

Pitt’s argument runs as follows: Normally, we can consciously, introspectively, and non-inferentially (1) distinguish an occurrent thought from other mental states, (2) distinguish an occurrent thought from other occurrent thoughts, and (3) identify which occurrent thoughts we are thinking. Pitt considers various explanations of these abilities, and argues that the only plausible explanation is that thought has a proprietary, individuative, and constitutive phenomenology. Thought’s proprietary phenomenology explains how we can tell the difference between thoughts and other kinds of mental states, thought’s individuative phenomenology explains how we can tell the difference between one thought and another, and thought’s phenomenology being constitutive of its content explains how we can identify which thoughts we are thinking.

Levine (2011) argues that Pitt (2004) fails to rule out an alternative explanation of the relevant kind of self-knowledge: immediate self-knowledge is a matter of non-inferentially coming to have an intentional state that represents that one is thinking what one is in fact thinking. In having such a state, one is automatically aware of its content. Pitt (2011) responds that, when properly understood, Levine’s proposal can’t work unless there is the contested kind of cognitive phenomenology.

Goldman (1993a,b) also uses considerations from self-knowledge to argue for a phenomenology of thought. He argues that the way we can tell what mental states we are in is not through their functional roles or neural properties, but through their phenomenal properties. In the case of cognitive states, the best explanation for how we can discriminate between different strengths of desires or degrees of belief is that thoughts have an accompanying phenomenology.

6. Challenges for PIT
PIT faces both in-principle challenges and empirical challenges. We have already discussed the in-principle worry that phenomenal consciousness is not metaphysically sufficient for intentionality (see section 4.1). Here, we focus on the empirical challenges PIT faces in accommodating specific kinds of mental states.

The problematic mental states are those that might reasonably be taken to have intentionality without having phenomenal intentionality. Here we will discuss four types of mental state that give rise to challenges of this kind: thoughts, standing propositional attitudes, wide intentional states, and occurrent unconscious states. These states don’t seem to be phenomenal intentional states, so it is not immediately clear how PIT can accommodate them.

There are three general strategies for handling a problematic state: eliminativism, inflationism, and derivativism. Eliminativism consists in denying the existence of the putative intentional state (or denying that it is an intentional state). Inflationism consists in claiming that the state in question is a phenomenal intentional state. In the case of thought, this strategy often involves arguing for rich cognitive phenomenology (see section 5). Derivativism agrees that the problematic state is not a phenomenal intentional state, but maintains that it nonetheless derives its content in part from phenomenal intentional states and so is at least partly grounded in such states. We will now discuss these strategies in more detail in relation to the four problematic kinds of states.

6.1 Thoughts
Thoughts are occurrent conceptual states, the kinds of states we have when we think, reflect, or muse over something. Examples of thoughts include judgments, occurrent beliefs, and occurrent desires. Thoughts, especially thoughts about abstract ideas such as democracy and the square root function, might seem to lack phenomenal properties. Even if thoughts have phenomenal properties, it does not seem that these phenomenal properties are rich or determinate enough to fully account for their intentional properties. For example, these phenomenal properties might seem to be limited to verbal and visual imagery.

Inflationism is the most widely endorsed strategy for dealing with occurrent thoughts, at least in cases of thoughts that do not seem to have wide contents (see 6.3 below for the latter). Strawson (1994, 2008), Siewert (1998), Horgan & Tienson (2002), Horgan, Tienson & Graham (2004), and Pitt (2009) all hold that occurrent thought has a phenomenology that is rich and determinate enough to fix its intentional contents. Horgan & Tienson (2002), Horgan, Tienson & Graham (2004), and Pitt (2009) also argue that the difference between beliefs, desires, and other kinds of attitudes is phenomenally constituted. The case for this approach rests on the arguments for cognitive phenomenology we discuss above.

In contrast, Loar (2003a,b), Bourget (2010, 2015), and Mendelovici (2010, 2018) maintain that thoughts have a fairly impoverished phenomenology that cannot fully constitute all the contents we might want to attribute to them. Loar (2003a,b) endorses a derived content strategy on which much of thought’s content is determined by the “lateral connections” between thoughts and other mental states. The network of interconnected states eventually derives its content from phenomenal intentional states. Bourget (2010) adopts a derived content strategy on which thoughts derive their contents from phenomenal intentional states through a variety of derivation mechanisms.

Mendelovici (2010, 2018) has a largely eliminativist take on the intentionality of thought. Like Pitt (2004, 2009), she holds that all intentional states are phenomenal intentional states, but unlike Pitt, she maintains that the phenomenology of thought is too impoverished to capture all the contents we might pre-theoretically want to attribute to thoughts. However, she recognizes the existence of derived representational contents, which capture the rich contents we tend to attribute to thoughts. Derived representational states are not strictly speaking intentional states, but they fill the role that intentional states with rich contents have been thought to play.

6.2 Standing propositional attitudes
Standing propositional attitudes are states one is in independently of what one is thinking about or experiencing at the time (i.e., independently of one’s occurrent states). For example, five minutes ago you had the standing belief that monkeys like bananas even though you weren’t occurrently thinking that content. Standing propositional attitudes do not seem to have phenomenal properties, and so, it seems their intentionality is not phenomenal intentionality.

As far as we can tell, no one has applied the inflationist strategy to standing propositional attitudes—no one claims that they are phenomenal intentional states.

Strawson (2008) and Mendelovici (2010, 2018) adopt the eliminativist strategy as part of their defenses of PIT: they deny that standing beliefs and other standing propositional attitudes are intentional states. As Strawson puts it, “To have a belief is not to be in any contentful mental state.” (p. 271) Rather, it is to be disposed to be in such a state. Horgan & Tienson (2002) are not eliminativists about the intentionality of standing states, but they do not consider them part of the scope of their version of PIT.

Searle (1990, 1991, 1992), Bourget (2010), and Kriegel (2011a,b) favor derivativism about standing states. Searle holds that non-phenomenal intentional states have their intentionality in virtue of subjects’ dispositions to have conscious states. This account applies most naturally to standing propositional attitudes. Bourget (2010) holds a similar but more nuanced view according to which standing propositional attitudes derive from connections to occurrent thoughts, which themselves either are phenomenal intentional states or derive their contents from distinct phenomenal intentional states (see the next section on the derivativist strategy for thoughts).

The simple derived content approach defended by Searle and Bourget is open to well-known objections. One of these objections, discussed by Peacocke (1998), is that a state that causes occurrent thoughts to the effect that P is not a belief that P unless it is accompanied by the right behavior. Imagine someone who claims not to be sexist and tends to form occurrent non-sexist thoughts but who behaves in demonstrably sexist ways. Such an individual is naturally said to have unconscious sexist beliefs.

Kriegel’s (2011a,b) account aims to explain standing states and unconscious occurrent states in a unified way. On his account, which he calls interpretivism, a non-phenomenal state s has a certain derived intentional content C just in case an ideal interpreter is disposed to ascribe C to s. An ideal interpreter is a being that is perfectly rational and knows all the phenomenal and non-phenomenal (but not derivatively intentional) facts about the world. On the resulting derivativist view, non-phenomenal intentional states derive from an ideal interpreter’s phenomenal intentional states.

The disagreement between eliminativism and derivativism about standing states might be partly terminological. Most of the above-mentioned theorists agree that standing states are a matter of a certain kind of disposition to have phenomenal states. What they disagree on is whether the potentially conscious or dispositional states count as intentional states.

6.3 Wide intentional states
Wide intentional states are intentional states that depend on relations to items in our environments. They are states for which externalism is true (see section 4.3). Prime candidates of wide intentional states are thoughts about natural kinds (e.g., H2O) and thoughts about individual objects (e.g., Bill Gates). Arguably, subjects that are phenomenally alike and have all the same phenomenal intentional states can nonetheless differ in their wide intentional states. So, it seems that wide intentional states are not phenomenal intentional states.

A Twin Earth case helps illustrate the options available in the case of wide intentional states (see Putnam 1975). Consider two individuals, Alice and Twin Alice. Alice lives on Earth, while Twin Alice lives on a copy of Earth located far away from us in this world. Let us suppose that Alice and Twin Alice are phenomenal duplicates: they instantiate all the same phenomenal properties throughout their existences.

Alice and Twin Alice each have a brother called “Bob”. When Alice thinks a thought that she would express by making the sounds “Bob is happy”, it seems that her thought is true at just the worlds where Bob is happy. By contrast, it seems that the thought that Twin Alice expresses with “Bob is happy” in her idiolect is one that is true at just the worlds where Twin Bob is happy. So it looks like the Alices’ thoughts have different truth conditions. This suggests that the Alices’ thoughts have different contents. Alice’s thought represents that Bob is happy, while Twin Alice’s thought represents that Twin Bob is happy. The Alices’ “Bob”-thoughts are paradigmatic examples of putatively broad intentional states.

Few advocates of PIT seem to endorse an inflationist strategy for broad intentional states. Even advocates of PIT who take consciousness to be relational seem to agree that what a subject gets related to in consciousness depends solely on her intrinsic properties (Pautz 2010). However, Campbell (2002) holds that perceptual experience is broad and intentional, and his view might be counted as a type of phenomenal intentionality theory.

Siewert (1998), Kriegel (2007), and Farkas (2008a) adopt an eliminativist strategy with respect to broad intentional states. Their views are the same in broad outline. On their views, the two Alices’ thoughts have the same content, and that content is narrow. We can account for the fact that the two Alices’ thoughts are made true by different Bobs by adding contextual parameters to their shared content: their shared content is not a function from possible worlds to truth values but a function from possible worlds and relevant elements of context to truth values. The introduction of contexts enables us to account for the fact that the Alices’ thoughts are true at different worlds. For example, one (over-simplistic) view along these lines could state that the shared content of the two Alices’ thoughts can be modeled as a function from worlds W and contexts of use C that returns true just in case the person that bears the name “Bob” in C is happy in W. Given that different contexts are relevant to Alice and Twin Alice, different worlds can satisfy the common thought they express as “Bob is happy”. If this is the right way to think about content, the Bobs’ case and other cases motivating broad content do not force us to recognize broad contents.

Pitt (1999, 2011) also endorses an eliminativist strategy, arguing against externalist intuitions. Mendelovici (2010, 2018) also endorses eliminativism but claims that she can capture many externalist intuitions through the notion of derived mental representation (see the previous section).

Derivativist strategies have also been applied to broad contents (Loar 2003a,b, Horgan and Tienson 2002, Horgan, Tienson & Graham 2004, Bourget 2010, Chalmers 2010). The idea here is that broad intentional states have two contents: a phenomenally constituted narrow content, and a broad content that is determined by the narrow content together with relevant factors in the environment. So Alice’s thought has two contents: one narrow and one broad. The broad content of her thought is true at just the worlds where Bob is happy. The narrow content is true at the worlds where a person bearing certain Bob-like characteristics is happy. The relevant Bob-like characteristics might, for example, centrally involve being called “Bob” by people of a certain community.

Of course, such a derivativist approach is compatible with other accounts of the narrow content of Alice’s thought. The options available to proponents of PIT are the same as for theories of narrow content in general. For instance, this derivativist approach can draw on all the resources of two-dimensional theories of narrow content (see Chalmers 2002a and the entries on two-dimensional semantics and narrow mental content).

Pautz (2008, 2013, 2017) offers a related derivativist approach that he dubs consciousness-based best systems theory. On this view, facts about (sensory) phenomenal states and their internal causal roles fix the facts about what is rational for an agent to believe. These facts about rationality in turn fix the narrow contents of an individual’s beliefs. Wide contents are fixed by causal relations between beliefs and the environment.

6.4 Unconscious occurrent states
Cognitive science posits various kinds of occurrent unconscious representation, e.g., dorsal stream states and internal representations of syntactic structures. It seems that such states have intentional properties but lack phenomenal properties, so their intentionality cannot be phenomenal intentionality.

Some supporters of PIT adopt an eliminativist strategy towards such unconscious states. Searle (1990, 1991, 1992) argues, roughly, for the claim that only conscious or potentially conscious states exhibit intentionality. Since most unconscious states posited by cognitive science are not potentially conscious, they are not intentional. Searle presents this view of unconscious states as being in conflict with cognitive science. In contrast, Graham, Horgan, and Tienson (2007) and Mendelovici (2018) highlight the agreement between the assumptions of cognitive science and eliminativism about unconscious states: everyone agrees that unconscious states play functional roles, bear tracking relations to things in the environment, and have no phenomenal properties. Everyone also agrees that it can be fruitful to treat unconscious states as if they represented certain contents. The main disagreement is over whether unconscious states really do qualify as intentional.

Bourget (2010, 2015) and Pitt (2009, Other Internet Resources) suggest that an inflationist strategy may be acceptable in case of at least some unconscious occurrent states. On their views, we can have phenomenal states that we are not aware of. Unconscious occurrent states could be such states.

A derived content strategy is also an option in the case of some unconscious occurrent states. Bourget (2010) argues for this strategy by arguing for the claim that the low-level systems that allegedly support unconscious occurrent intentional states don’t seem intentional when they are taken out of the organisms in which they belong. Kriegel’s interpretivism (2011a,b) is also meant to apply to unconscious occurrent states (see section 6.2).

1. The Primacy of the Aesthetic
One common concern strikingly unifies otherwise different romantic contributions. Early and late, German, British and French, the romantics advocated what may legitimately be called “the primacy of the aesthetic”. In romanticism, the “aesthetic”—most broadly that which concerns beauty and art—is not just one aspect of human life or one branch of the humanistic studies. Rather, if the romantic ideal is to materialize, aesthetics should permeate and shape human life. Friedrich Schlegel, one of the leading figures in Early German Romanticism, put this idea in a few memorable phrases: “The Romantic imperative demands [that] all nature and science should become art [and] art should become nature and science” (FLP: #586); “poetry and philosophy should be united” (CF: #115), and “life and society [should be made] poetic” (AF: #16).

Schlegel is not alone on this matter. Similar sentiments and slogans had been expressed just a little earlier in what is commonly regarded as the manifesto of German romanticism, The Oldest Programme:

The idea that unites everyone [is] the idea of beauty…I am now convinced that the highest act of reason, by encompassing all ideas, is an aesthetic act, and that truth and goodness are siblings only in beauty. (Hölderlin, in Bernstein 2003: 186).[3]

The British romantics have taken up and developed this view that the aesthetic is the foundation of knowledge and the pursuit of truth. “‘Beauty is truth, truth beauty,’—that is all//Ye know on earth, and all ye need to know”, Keats famously declared in the Ode on a Grecian Urn ([1820] lines 49–50, PJK). And in the Preface to Coleridge and Wordsworth's Lyrical Ballads (1800), we read, “Poetry is the first and last of all knowledge—it is as immortal as the heart of man” (paragraph 20, in PWWW, I, p. 141).

How is this core feature of romantic aesthetics, the primacy of the aesthetic, to be explained?

A textually grounded and philosophically viable way to approach the imperative is as a structural or formal demand. On that reading, the imperative requires that we model our epistemological, metaphysical, ethical, political, social and scientific pursuits according to the form of the aesthetic comportment to the world, exemplified in poetry. On such an approach, rather than aiming to replace “real” life, science and philosophy with poetry, the romantics urge human beings to fashion their ordinary lives and to do science and philosophy according to the model provided by poetry. Philosophy, science and everyday life need not be poetry, but poetic or poetry-like. Structurally, they should become similar. Why so? The main task of this entry is to offer an answer to this question and to show that the reasons for “poeticizing” life, science and philosophy are philosophical.

2. Aesthetics and Reason
2.1 Enlightenment and Sturm und Drang
For over a century, romanticism has standardly been regarded as a reaction against the Enlightenment (e.g., Haym 1870). The primacy of aesthetics may seem to speak in favor of this story because, on this interpretation, the romantics replaced the Enlightenment’s faith in the sovereignty of reason with a belief in the sovereignty of art and the affective and imaginative capacities that are involved in aesthetic experience. On this traditional interpretation, romanticism is antirationalist or irrationalist. But, while the romantic pursuit of the primacy of aesthetics marks a break with the Enlightenment, regarding romantic aesthetics as antirational or irrational and as antagonistic to the core Enlightenment values is unjustified for a host of reasons (cf. Beiser 2003, Engell 1981, Gregory 2005).

First, the romantics’ focus on and praise for rational and autonomous criticism is continuous with the Enlightenment’s commitment to the value of rational criticism. Admiring Goetthold Ephraim Lessing’s ideal of criticism and his devotion to independent thinking, Friedrich Schlegel writes, “critique is the common pillar on which the entire edifice of knowledge and language rests” (Critique: 271). Rather than discontinuing the Enlightenment’s call to submit every belief and every action to the authority of rational criticism, the romantics are responsible for continuing “the age of criticism”—which is usually taken to characterize the eighteenth century—well into the nineteenth century. In that sense, they are the “children” of the Enlightenment.

Second, many of the core features of romantic aesthetics in addition to criticism—like the relation between beauty, truth and goodness, the pursuit of unity among variety and the significance of the imagination and the sublime—would have been impossible independently of key Enlightenment thinkers.

Third, the romantic elevation of aesthetic feeling and the creative imagination did not come at the price of their faith in and respect for reason. Even Friedrich Schlegel, who is often considered to be the most enthusiastically inclined romantic, opened his Lectures on Transcendental Philosophy by arguing that philosophy is “a striving towards a knowledge…of the whole person” (ITP: 241). In one of his fragments, he commanded: “Never tire of cultivating the intellect until you will have finally found what is original and essential” (Ideas: #124). And yet in another fragment, he claimed that one of the two centers of genuine philosophy is “the rule of reason” (Ideas: #117).

Such proclamations challenge the alleged break between the Enlightenment and romanticism as much as they challenge another standard interpretation of romanticism, one that takes it to be a direct outgrowth of Sturm und Drang, a counter-Enlightenment movement that flourished in the 1760s and 1770s. Briefly, this response to the Enlightenment, expressed in works of literature, theatre, music and the plastic arts, heralded individual subjectivity and the free expression of unconstrained feelings as the proper replacements for the values of the Enlightenment.

No doubt, the romantics shared with this movement the belief in a call “back to feeling”. But regarding romanticism as simply a continuation of Sturm und Drang finds no grounding in romantic texts. In his review of Friedrich Jacobi, one of the main sources of influence on Sturm und Drang, Schlegel declared, “Only when striving toward truth and knowledge can a spirit be called a philosophical spirit” (Review of Jacobi’s Woldamer, KA II: 71–2). In the same review, Schlegel harshly criticized what is known as Jacobi’s salto mortale or “leap of faith”: this is Jacobi’s view that the only way to salvage our ethical and religious beliefs, in the face of the limitations of the Enlightenment, is to renounce reason in favor of mere sensation and faith. In contrast to Jacobi, the German romantics never attempted to replace reason with faith, sensation, unconstrained feeling or intuition. Instead, they wished to bring out the rationality of the passions and the passionate nature of reason as part of a unified and balanced picture of human life. Rather than a straight development of Sturm und Drang, then, romanticism is better understood as an attempt to synthesize the grain of truth in the movement with the grain of truth in the philosophy of Enlightenment, or simply put, to synthesize reason and sensibility.

Similarly, the British and French romantics did not mean to dismiss reason and replace it with passion and imagination, but strived after “a conjunction of reason and passion” (Wordsworth, “Essays on Epitaphs 1810” in PWWW). Accordingly, what Coleridge, for example, admired in Wordsworth was not imagination and feeling alone, but

the union of deep feeling with profound thought; the fine balance of truth in observing with the imaginative faculty in modifying the objects observed. (Coleridge, BL: Ch. 4)

The romantics, then, sought to supplement but not to supplant reason with the receptive capacities of the mind, primarily with the capacities involved in aesthetic apprehension and artistic production. They extended Kant’s renowned view of concepts and intuitions, suggesting that reason without feeling is empty and feeling without reason is blind. Without the former, human beings would be reduced to mere animality; without the latter they would lose their humanity:

We cannot deny the drive to free ourselves, to ennoble ourselves, to progress into the infinite. That would be animalistic. But we can also not deny the drive to be determined, to be receptive; that would not be human. (Hölderlin, Hyperion, HSA 3:194)

For the romantics, our receptive and spontaneous capacities could only be abstracted in thought, but not separated in reality: “Action and passion are inseparable as north and south” (Novalis, FS: #317). Human dignity is grounded in rational and normatively constrained receptivity just as much as it is grounded in spontaneity.

The restless striving after activity, the highest criterion of judgment, does not exclude all the virtues of receptivity but can only exist with them. (F. Schlegel, KA 12: 130)

Rather than dismissing the role and the significance of reason as such, the romantics challenged merely certain uses of reason—for example, dogmatic uses of reason, the laying down of absolute foundations, and system-building. And in a Kantian manner, they were concerned to expose the limits of reason and constrain its uses to legitimate boundaries. But even the romantic exposure of limits is, as it were, “aesthetic”. “Aesthetic?” one may ask. Yes, aesthetic in the sense that some of the romantic central devices for exposing the limits of reason are (originally) “aesthetic”, “artistic” or “literary”. “Romantic Poetry” is one such device and “Irony” is another.

2.2 Romantic Poetry and Romantic Irony
“Romantic Poetry” is a notion that Friedrich Schlegel coined and described in most detail in Athenaeum Fragments (AF) number 116. Rather than a particular genre or kind of poetry, Romantic Poetry is poetry as such insofar as “all poetry is or should be romantic” (Schlegel, AF: #116). Romantic Poetry brings out the limits of reason in virtue of being reflective, “[hovering] on the wings of poetic reflection, and [capable of raising] that reflection again and again to a higher power” (AF: #116). Rather than being merely the “portrayed” object itself—a poetic representation—it “hover[s] at the midpoint between the portrayed and the portrayer” (AF: #116), and so, like Kant’s transcendental philosophy, reflects on the conditions of its own possibility and of human mindedness itself. It is not surprising, then, that Romantic Poetry is called “transcendental” poetry: “a poetry and a poetry of poetry” (AF: #238). Goethe’s Wilhelm Meister, a romantic favorite, manifests this dual reflective and substantive nature:

It was so much the poet’s intentions to set up a comprehensive theory of art or rather to represent one in living examples and aspects.…This might suggest that the novel is as much an historical philosophy of art as a true work of art, and that everything which the poet so lovingly presents as his true aim and end is ultimately only means. But that is not so: it is all poetry, high, pure poetry. (F. Schlegel, WM: 274)

The transcendental nature of romantic poetry suggests that it does not transcend merely the boundaries of a particular genre, but even the boundaries of the literary as such. Romantic Poetry is poetry as much as it is a philosophical method and a vital approach to human life. It is a creative and reflective human power, manifested in the theoretical, practical and aesthetic aspects of life:

transcendental poetry…really embraces all transcendental functions…. The transcendental poet is the transcendental person altogether. (Novalis, Logological Fragments: #41)

Romantic poetry is not alone in exposing the conditions of finite existence, but accompanied by an ironic way of living. Irony is a mode of self-restriction, whose “value and dignity” as a crucial dimension of human life, must be recognized (F. Schlegel, CF: #28). Irony is the balance between “self-creation and self-destruction” (CF: #28), which means that irony is creative—it is constructive of its own perspective on the world. But at the same time, it is also “destructive” of the pretensions implicit in any perspective—the pretention to be holistic. Irony thus presents its perspective as restricted—as only one among many different perspectives on the unconditioned whole. Accordingly, what romantic irony insists on through its restricting function is (a) the conceptual inaccessibility of the “Absolute” (explained in §3), and (b) what is known as “perspectivism”—the view that human beings are capable only of finite and limited perspective on the universe as a whole. Being ironic is a way of consciously and intentionally bringing out the fragmentary nature of the human situation as lacking a “view from nowhere”.

Like Romantic Poetry, irony is not merely a literary or even a rhetorical device. Nor is it a purely theoretical method. Rather, in a Socratic spirit, romantic irony is a way of life. For it is,

after all, for the artist as well as the man, the first and the last, the most necessary and the highest duty…most necessary because wherever one does not restrict oneself, one is restricted by the world; and that makes one a slave. (CF: #37)

Everyone, then, not only the writer, should be ironic. For, as exposing our finitude, irony is not only another romantic analogue of Kant’s transcendental method—the antidote to reason’s natural but spurious tendency to transcend its limits—but also an existential condition of humility (On irony see also CF: #26, #42, #48, 108; AF: 51, 121; and On Incomprehensibility).

The romantic use of irony was sharply criticized, most famously by Hegel, as free floating form of subjectivity. But not only does this criticism fail to do justice to the romantic insistence that irony itself is a form of self-constraint, but also to the imperative: “Don’t exaggerate self-restriction” (F. Schlegel, CF: #37). This demand to constrain and regulate self-restriction itself is of equal importance to the demand to practice irony. Rather than a free floating form of subjectivity, then, romantic irony is a constrained, and normatively governed form of life, meant to expose the limits of reason and facilitate a life of humility (cf. Rush 2006: 187). Romantic irony is a commitment to the form of life that is governed by the acknowledgement of finitude; a “transcendentally-Socratic” life of humility.

Accordingly, rather than an irrational or an anti-Enlightenment stance, romantic aesthetics is marked by a respect for and devotion to reason and rationality “within their bounds”.

3. Aesthetics, Epistemology and Metaphysics
Even a cursory glance through the writings of the romantics assures the reader that their interest in art and aesthetics is closely tied to their epistemological and metaphysical concerns. The primacy that the romantics attributed to aesthetics is explained by (but is not reduced to) the roles that art and beauty may play in the pursuits of epistemic and metaphysical goals. One such goal concerns what the German romantics, and following them, Coleridge, called the “Absolute” [das Absolute].

Briefly, this is how this explanation goes: in the aftermath of Kant’s philosophy, the romantics were concerned with the Absolute, understood as the unconditioned totality of all conditions. Like Kant, they believed that such an unconditioned totality is inaccessible to discursive reason and is, to that extent, unknowable to human beings. But reason’s natural drive towards this “Absolute” is nonetheless significant and valuable (§3.1). In aesthetics they found a mode of life that best approximates (even if never reaches or grasps) the Absolute, insofar as the aesthetic approach to artworks (a) includes indeterminate affective aspect (§3.2), (b) involves a sui generis normativity, constituting its own norms in attunement with the artwork it faces (§3.3), (c) is particularly suited to approach individual unities (§3.4), and (d) is open-ended (§3.5).

3.1 The Absolute
Most broadly, by the “Absolute”, the romantics refer to the unconditioned totality of all conditions. While the absolute itself is conditioned by nothing, it conditions all the finite physical and mental manifestations of the world. Inspired by Kant’s discussion of omnitudo realitatis—“All of Reality”—and by Spinoza’s all encompassing “substance”, the romantic Absolute is a whole, rather than an aggregate, that encompasses everything else, physical and mental: “Only the whole is absolute” (Novalis, AB: #454); “The universe is the absolute subject, or the totality of all predicates” (AB: #633). Metaphysically, every finite thing is merely one manifestation of an unconditional totality: only a single perspective on the whole. It is thus ultimately finite but also infinite, as part and parcel of the infinite whole.

This notion of the Absolute is not distinctively romantic. The German Idealists, Fichte, Schelling, and Hegel, were also concerned with related conceptions of the Absolute. But the romantic treatment of the Absolute is distinctively different from the idealistic one. And it is the distinctive romantic treatment of the Absolute that explains much in romantic aesthetics: While the idealists took the Absolute to be transparent to the human mind, conceptually representable, and inferentially related to other items of knowledge, the romantics regarded it as (1) ungraspable by concepts (i.e., as “non-discursive”) and (2) as non-foundational.

Following Kant, the romantics believed that all knowledge is discursive: knowing requires conceptualization. But since concepts condition everything that might be known by determining it to be one way or another according to the forms of discursive thought, the Absolute, by its very definition as unconditioned, cannot be known.

Knowledge [Erkennen] already denotes conditioned knowledge. The unknowability of the absolute is, therefore, an identical triviality. (F. Schlegel, KA 18: 511, #64)

The romantics further argued that the attempt to ground the whole edifice of knowledge in the Absolute—familiar to them from Fichte’s project, which they both admired and harshly criticized—is futile. Like Kant, they believed that reason’s natural and necessary drive to proceed towards the unconditioned can never be fully realized. The unconditioned totality of experience is “a regulative idea” (Novalis, FS: #472): it cannot serve as a systematic grounding of experience. As Novalis memorably puts it:

We seek the unconditioned [Das Ubedingte] and always find only [conditioned] things [Dinge]. (Blüthenstaub, NS 2: 413, #1)

Skeptical as they were about the discursive accessibility of the Absolute and about its capacity to ground all knowledge, the romantics never questioned either its existence or the worth of (open-endedly) striving after it:

Neither our knowledge nor our action can ever attain the point at which…. All is one; the determinate line can be united with the indeterminate only through an infinite approximation [in unendlicher Annäherung] (Hölderlin, “Hyperion”, HSA 3: 326).

Therefore, philosophy, whose first theorem is “All is One and One is All” (F. Schlegel, ITP: 244), must be “a striving” (ITP: 244). Even though philosophy cannot systematically deduce all knowledge from the Absolute, it must nonetheless pursue its approximation. But if not through concepts, how can one approximate the Absolute?

This is where aesthetics comes into the picture. Although scholars of romanticism disagree about the exact nature of the romantic approximation of the Absolute,[4] they widely agree that it includes a variety of feelings associated with the aesthetic, like aesthetic pleasure, poetic feeling, “longing for the infinite [Sehnsucht nach dem Unendlichen]” and “love”, and that it depends on the deployment of critical notions like “romantic poetry”, wit, irony, allegory, myth and the creative imagination:

If we abstract from all knowledge and will…we still find something more, that is feeling and striving. We want to see if we will perhaps find something here that is analogous to the consciousness of the infinite…. (F. Schlegel, ITP: 244–45).

Poetry elevates each single thing through a particular combination with the rest of the whole, [by allowing] the individual [to] live in the whole and the whole in the individual. (Novalis, Poësie, NS 2: 533, #31).

The romantics believed that these aesthetic and affective attitudes make it impossible for us to deny that there is something “which is not I, nor comes from the I, and which is also not merely a Non-I” (F. Schlegel, Thoughts, KA 18: #83). Baudelaire summarizes these romantic sentiments, declaring,

The one who says romanticism says modern art—which is to say intimacy, spirituality, color, aspiration towards the infinite—expressed by all the resources of art. (Salon of 1846 [1981])

What is it about the aesthetic engagement with art and beauty that is particularly suitable for approximating the Absolute? The rest of this section will develop a few possible answers to this question.

3.2 Aesthetic Feeling
In the introduction to the Critique of the Power of Judgment, Kant writes that the feeling of pleasure in general, and aesthetic pleasure in particular, is the only representation that can never “become an element of cognition at all” (AK 5: 189).

One might think that feelings are thus placed outside of rationality. But this would be a mistake. On Kant’s picture, aesthetic feeling is rational insofar as it is grounded in a universal mental state that underlies our capacity to judge in general (the free play of the imagination and the understanding), and insofar as it is, through this mental state, responsive to the claims that beautiful objects make on everyone’s satisfaction (AK 5: 282). Rationality, then, is irreducible to cognition both in the Kantian framework and in its romantic inheritance. Aesthetic feeling is rational because of its ground and responsiveness to a claim, but non-cognitive insofar as it cannot be subsumed under concepts. Feeling does not determine any concrete property that its object has independently of subjectivity (as cognition would), but is rather responsive to a relation between a subject and an object. Aesthetic pleasure, particularly, is a non-determining mode of reflecting on the relation, not between a particular subject and a particular object, but between subjectivity and objectivity as such.

This rational but non-cognitive nature of feeling, in general, and of aesthetic feeling, in particular, is perhaps the central feature that renders aesthetic feeling an attractive ingredient in addressing the epistemic and metaphysical concerns that occupied the romantics. For while all cognition is determination through concepts, Kant’s aesthetics suggests a mode of reflective awareness that is not determining, but yet a way of being aware of and responsive to aspects of the world. This is exactly what the romantics have been looking for—a non-discursive, but rational and normatively governed mode of awareness. And they found it in poetry, regarding it as grounded in feeling:

Not art and artworks make the artist, but feeling and inspiration and impulse. (F. Schlegel, CF: #63)

Poetry is passion. (Wordsworth, “Note to the Thorn” in LB: 136)

All good poetry [originates in] the spontaneous overflow of powerful feelings. (Wordsworth, Preface to Lyrical Ballads (1800), paragraph 26, in LB)

If, then, feelings and passions are constitutive of art, and if aesthetic or poetic feeling is a key ingredient in the pursuit of the Absolute, then philosophy should become poetic and “poetry and philosophy should be made unified” (F. Schlegel, CF: #115). We are now in a position to appreciate that this romantic imperative is explained partly by the view that philosophy cannot be reduced to concepts and propositions, but must also include certain kinds of affective mental states. To paraphrase Wittgenstein, discursive reasoning comes to an end.

3.3 Sui-Generis Normativity
The non-determining character of aesthetic feeling is related to the distinctive kind of normativity that characterizes artistic production and aesthetic appreciation. An expression borrowed from Kant is fitting here: on the romantic picture, both artistic production and aesthetic appreciation are “lawful without a law”. Both are the source of their own normativity, without being subject to any external law. Given that, they are appropriate for approximating the Absolute insofar as this approximation must be non-determining (applying no conditions), but normatively governed rather than arbitrary.

Following Kant’s account of the genius, the romantics developed an understanding of the artist as, on the one hand, original and imaginative (rather than submitting to any law of nature or principle borrowed from the tradition of art), and, on the other hand, receptive to nature: “Every good poem must be wholly intentional and wholly instinctive” (F. Schlegel, CF: #23). This combination of being independent of given rules and attuned to something other than yourself is required not only for the genius, but also for approximating the Absolute. And it is this requirement that explains “the categorical imperative of genius[:] You should demand genius from everyone” (F. Schlegel, CF: #16). If everyone is to approximate the Absolute, then everyone should model herself after the genius.

Criticism consists of a related combination of features. While it is based on no prior rules, it is also open and receptive to the work it concerns. And it is through the engagement with the work that each critical judgment constitutes its own norms. Although we can and should legitimize our judgments of beauty and art, we cannot do so by appeal to any given concepts or norms that are external to the work at stake. The artwork, on this picture, is sui generis—it provides its own standards of appreciation: “Poetry is a republican speech: a speech which is its own law and end unto itself” (F. Schlegel, CF: #65). The critic should seek to express the work in a way that is faithful to its individual nature and be responsive to the specific norms that it constitutes:

To judge [Goethe’s Wilhelm Meister] according to an idea of genre drawn from custom and belief, accidental experiences and arbitrary demands is as if a child tried to clutch the stars and the moon in his hand and pack them in his satchel…. Fortunately, [the novel] turns out to be one of those books, which carries its own judgment within it. (F. Schlegel, WM: 275)

That means that beauty makes demands on us, demands that, according to the romantics, are analogous to the demands that other persons make on us. Beautiful objects make a claim on us to respond to them as the specific individuals that they are, on their own terms: “See your statues, your paintings, your friends as they are” (Diderot, Salon of 1767). Hence, the romantic declaration, “one cannot really speak of poetry except in the language of poetry” (F. Schlegel, DP).

This lawfulness without a law fits the requirements of the Absolute. For, if we adopt this structure of normativity and expression in our pursuit of the Absolute, we may approach it in a normatively governed and committed way, without determining and thus conditioning it according to any given law, principle, or concept. Here, then, is another reason why philosophy should become poetic, and the true philosopher, not merely a “half critic” (as the romantics alleged against Kant), but a complete critic: philosophy should be open and attuned to the Absolute without trying to subsume it under any principle of reason, just as criticism is open and attuned to each work without subsuming it under any external law.[5]

3.4 Concrete Individuality
Like Spinoza’s God and Kant’s omnitudo realitatis (All of Reality), the Absolute is an all-encompassing individual: while it comprehends everything else, the Absolute is also concrete. It is an individual whole—a totality, the parts of which could be understood only negatively, as its limitations. To approximate the Absolute, then, we need a mode of consciousness that is particularly suited to discern a holistic unity in an individual. While §5.3 discusses what is required in order to apprehend holistic unities, and the holistic unities of artworks and natural beauties, this section focuses on the individual character of artworks and natural beauties.

On the romantic picture, an artwork that does not present itself as a “living individual” (Novalis, Poësie, NS 2: 534, #35) is not worthy of the title of a work of art, and the one who does not approach artworks as unique individuals is not a genuine aesthetic critic: “Whoever conceives of poetry or philosophy as individuals has a feeling for them” (F. Schlegel, AF: #415). The aesthetic approach to beauty, then, is an approach to those things that are irreducibly individuals, those that should not be approached merely as ones of many—as instances of general kinds—but as concrete individuals: “Everything that is to be criticized must be an individual” (F. Schlegel, FLP: #634).And this is the very approach that is required in the pursuit of the Absolute given its individual nature.

3.5 Open-Endedness
Kant attributes to aesthetic pleasure:

a causality in itself, namely that of maintaining the state of the representation of the mind and the occupation of the cognitive powers without a further aim. We linger over the consideration of the beautiful because this consideration strengthens and reproduces itself. (AK 5: 222)

Aesthetic feeling is open-ended and future-oriented. In contrast to practical pleasures (the “pleasure in the good”) and to private, sensory pleasures (the “pleasure in the agreeable”) that need to bring forth an action or an object in order to maintain themselves, aesthetic pleasure is self-maintaining. This is partly because aesthetically enjoying an object involves a commitment to remain faithful to the beauty of that object, beauty that calls for and deserves an open-ended affective pursuit. The romantics welcomed this structure of aesthetic feeling as particularly suitable for the pursuit of the Absolute. Since the Absolute can never be determined, the stance that approximates it must itself be open-ended. It should involve a commitment to keep striving after the Absolute open-endedly.

Since the romantics take philosophy to be a tendency “towards the Absolute” (Schlegel, ITP: 242), philosophy itself should be reconceived. The systematic search after first principles is not only hopeless, but also unfortunate. It can only slight the significance of the Absolute by the effort to determine it through principles. Instead, philosophy should be aesthetically shaped, as an open-ended pursuit:

If knowledge of the infinite is itself infinite, therefore always only incomplete, imperfect, then philosophy as a science can never be completed closed and perfect, it can always only strive for these high goals, and try all possible ways to come closer and closer to them. (Schlegel, Lectures on Transcendental Philosophy, KA 12: 166)

4. Aesthetics, Ethics and Politics
The intersection between romantic aesthetics, ethics and politics offers a particularly clear challenge to the standard view of the romantics as anti-Enlightenment (discussed in §2). This is because the romantics turned to aesthetics to a large extent in order to pursue, rather than to reject, some of the core ethical and political values of the Enlightenment, such as autonomy or self-determination and the ideal of Bildung. Art and aesthetics also provided a model for the romantic political ideal: a democratic, egalitarian community grounded in the republican values of liberty, equality and fraternity.

In addition to proving the anti-Enlightenment interpretation of the romantics false, tracing these romantic notions of autonomy, Bildung and political community also offers a challenge to another well-known interpretation of the movement as apolitical (see Schmitt 1986). In contrast to this interpretation, we find the romantics exploring and emphasizing the importance of aesthetics for ethical and political concerns. Shelley, for example, wrote in a letter to a friend: “I consider Poetry subordinate to moral & political science” (Shelley, LS 2: 71). In his famous Defence of Poetry (1821), he proclaimed, “Poets are the unacknowledged legislators of the world” (SPP). Rather than “aestheticizing” politics, then, the romantics found in art and aesthetics resources for solving ethical and political problems.

Yet, a central difficulty facing any interpretation of romantic ethics and politics lies in the change that this view has undergone during the later years of many a romantic: the strong democratic and egalitarian views of the likes of Friedrich Schlegel and Friedrich Schleiermacher gave way to a growing conservatism and religiosity after 1800. The first generation of British romantics likewise turned from their conviction that to be young during the revolution was, as Wordsworth said, “bliss” and “heaven”, to an acknowledgement of the challenges awaiting a genuine political reform. With this shift in mind, they turned from political optimism to religion. A unified account of romantic politics is thus untenable. Instead, the section will focus on the political views of the German romantics during their “formative years” (from 1797–1800) and of the British romantics mainly during their early and middle phases This is because the ideals developed during these phases, though different from some of the later ideals, can shed light on the romantic path towards conservatism later on (Beiser 1992). §4.5 will briefly present the romantics’ later political thought.

4.1 Autonomy
“Freedom is the only reality in wishing, willing, sensing and striving”, writes F. Schlegel (TPL II: 155). While the absolute reality of freedom might not admit of a proof, according to many of the romantics, human beings should nonetheless approximate freedom by developing autonomy—self-determination and self-legislation. Autonomy is the right of the individual to think for herself and act rationally and freely (TPL II: 155). The work of art and aesthetic judgment were seen as paradigmatic expressions of autonomy and, as such, as splendid models for the cultivation of individual human autonomy. For (as discussed in §3.3) neither the creation of art nor its appreciation is grounded in prior given laws. And yet, both the production and judgment of art are not lawless, but normatively governed by the laws generated autonomously by each individual work and by each individual aesthetic judgment. Poetry is a “law unto itself”.

This characteristic of the production and judgment of art should not only be incorporated into the way every person is to govern herself—as the source of her own rational laws rather than as subject to external laws, and as self-determining rather than passively determined—but also serve as a model for the way in which every person should be respected and treated. Aesthetics provides us with a paradigm for following two central ethical demands—the demand to govern oneself autonomously and the demand to respect everyone else as autonomous.

These two duties, then, constitute another explanation of the “categorical imperative of the genius” previously mentioned—the demand that every person be a genius. For if every individual is to be autonomous, she should fashion herself after the model of the artist.

4.2 Bildung
Bildung is another characteristic romantic value that each individual should develop in herself. While literally meaning “formation”, Bildung is best understood as a mode of ethical and cultural cultivation, or self-realization that allows the individual to mature into independence and responsibility. “Concerning Bildung, we speak not of external culture, but the development of independence” (F. Schlegel, TPL II: 148). Bildung is a particularly modern value, formed at least in part as a challenge to what the romantics regarded as the rift between sensibility and reason in modern life. To achieve Bildung, each individual has to constitute herself as a unified whole that coordinates a balance between sensibility and reason: “The end of humanity is…to achieve harmony in knowing, doing and enjoying” (F. Schlegel, On the Study of Greek Poetry, in KA I, 627).

The artwork is a good model for such an ideal insofar as it is, according to the romantics, an organic and harmonious whole of diverse and even conflicting parts:

Poetry…must be a harmonious mood of our mind…where everything finds its proper aspect…. Everything in a truly poetic book seems so natural—and yet so marvelous. We think it could not be otherwise…and we feel the infinite…sensations of a plurality in agreement. (Novalis, Last Fragments: #3)

This is why “Every human being who is cultivated and who cultivates himself”, namely, the person who achieves Bildung, “contains a novel within himself” (F. Schlegel, AF: #78).

Aesthetic judgment is also a harmony of reason and sensibility. On this issue too, the romantics were inspired by Kant’s aesthetics, according to which aesthetic judgment consists in the free play between the understanding, imagination and pleasure. Approaching the world, ourselves and one another aesthetically, then, is approaching it with a harmony of “knowing, doing, and enjoying”. And achieving this harmony constitutes a genuine moral being: a balanced rational, sensible and affective person. For that reason, it is not surprising to find Coleridge, the critic, aiming to establish “the close and reciprocal connections of Just Taste with pure Morality” (Lecture I, CLL).

Romantic Bildung was a political ideal as much as it was an ethical one. It was needed, not only for the sake of independent individual responsibility, but also for the possibility of a genuine non-revolutionary republic:

There is no greater need of the age than the need for a spiritual counterweight to the Revolution and to the despotism which the Revolution exercises over people…. Where can we seek and find such a counterweight? The answer isn’t hard: unquestionably in ourselves…the center of humanity lies there. (F. Schlegel, Ideas: #41)

The French revolution had shown the romantics both the value of a republic based on liberty, equality and fraternity, but also the dangers of anarchism and strife that revolutions carry with them. The proper path to a republic, they thought, is not through a revolutionary act, but through proper education. Art does not only offer a model for a harmonious, cultivated soul, but is also the best medium through which to achieve the moral education that leads to this harmony and, on its basis, to the best republic. Attending to art (as well as producing it) is a form of self-cultivation because the spirit of art allows human beings to transcend baseness (a particular danger given modern instrumentalism and materialism), and to develop their humanity.

As we now turn to see, the romantics regarded art also as a particularly effective medium for uniting people, no matter their differences, and so took it to be a great spur for united, social and political action.

4.3 Individuality and Sociality
The allegiance to autonomy and to the value of Bildung may seem to indicate individualism. And it does, to an extent. While individuality is indeed a romantic value, anti-communal individualism is not. The romantics never celebrated uncurbed individuality, but called for a balance between individuality and sociality: “A certain regulated interaction between individuality and universality…constitutes the first condition for moral well-being” (F. Schlegel, OP: 427).

Without doubt, the romantics criticized Kant’s categorical imperative as proposing a problematically universalistic ethics that discourages the free expression of unique personalities. They viewed such a universalist ethics as problematic because they regarded individual expression and the development of a unique, characteristic and unified self as intrinsically and morally valuable. Yet, the romantics were also critical of extreme individualism, such as the one they found promoted by some Enlightenment thinkers. In other words, they challenged those individualists who criticized any form of social and communal participation as potentially a form of passive submission to external authority.

In response to these two extremes of universalism and radical individualism, the romantics sought after a golden mean—romantic ethics strived to preserve and strengthen social bonds and encouraged a pluralistic communal life while supporting rational criticism, autonomy, individual rights, liberties and freedom of expression: “Does not the universal gain from the individual, the individual from universal relations?” (Novalis, Faith and Love: #5). The romantics believed that individualism is not merely compatible with sociality and communitarianism, but that it actually depends on genuine forms of the latter: “The vocation of man is attainable only through human society” (F. Schlegel, TPL II: 144). Autonomy and Bildung, in particular, though nothing other than individual freedom and self-realization, can never be divorced from the social:

Autonomy should be universal and not relate to the individual but the whole, for otherwise it would destroy itself…. We cannot consider human beings individually. (TPL II: 156)

On the romantic picture, the achievement of free, fully-formed individuality is impossible independently of strong sociality and vice versa. An ideal of sociality is deficient if it leaves no freedom for the distinct expression and liberties of each individual, and the individual is most herself, as an individual only insofar as she freely interacts with others: “A person can be a person only among people” (TPL II: 145).

Rather than contradictory impulses, as they are often regarded today, sociality and individuality, on the romantic picture, are not only compatible but also naturally harmonious—grounded in human nature:[6]

No man is merely man, but…at the same time he can and should be genuinely and truly all mankind. Therefore, man, in reaching out time and again beyond himself to seek and find the complement of his innermost being in the depths of another, is certain to return to himself. (F. Schlegel, DP: 54)

It is this romantic view of natural human sociability—rather than some exaggerated zeal or effusiveness—that explains and is explained by the centrality of love in romanticism. In contrast to many a modern thinker, the romantics regarded love rather than self-interest as a basic condition of human nature (“Love is…the core of ourselves” (F. Schlegel, TPL II: 151)), and as the proper basis for a genuine sociable but pluralistic community:

Yes, love, you power of attraction of the spiritual world! No individual life or development is possible without you. Without you everything must degenerate into a crude, homogeneous mass…. There is no individual development without love, and without the development of one’s individuality there is no perfection in love. When one complements the other, both grow together inseparably. I feel united within me the two fundamental conditions of ethical life! (Schleiermacher, ”Monologue II”, 180).

But as natural as it may be, the romantics believed that love has suffered paralysis in modernity. On their view, the rise of capitalism and instrumentalism had suppressed natural social bonds and encouraged self-interest. The consequent view of human beings as solely quantitatively distinct further leveled them and inhibited their distinctive and unique expressions.

How could people balance individuality and sociality in the face of modernity? Here too romantic poetry and the creative imagination come to the rescue. Poetry is not only based in love, but is itself a form of love insofar as it bonds different individuals:

Poetry befriends and binds with unseverable ties the hearts of all those who love it. Even though in their own lives they may pursue the most diverse ends, may feel contempt for what the other holds most sacred, may fail to appreciate or communicate with one another, and remain in all other realms strangers forever; in poetry through a higher magic power, they are united and at peace. (F. Schlegel, DP: 53)

The poet is, quintessentially, “a social being” (F. Schlegel, DP: 55) insofar as he both expresses, “in lasting works the expression of his unique poetry” (DP: 55) and reaches to others and reciprocally communicates with them. The poet integrates:

his part with the entire body of poetry…. He can do this when he has found the center point through communication with those who have found theirs from a different side, in a different way. Love needs a responding love. Indeed, for the true poet’s communication…can be beneficial and instructive. (DP: 55)

Following the “categorical imperative of the genius” is required, then, also for achieving Bildung and autonomous individuality in and through society: it is an ethical and social demand as well.

4.4 Political Community
While sociality and communal spirit are ethically required for the achievement of autonomy and Bildung, community was also a romantic political ideal. Such an ideal required that what the romantics viewed as modern alienation—estrangement of the self from others—be challenged in three ways: by promoting love (as discussed above), developing a sphere of free social interaction and pursuing a holistic, social unity.

The ideal political community must facilitate a sphere of social life, which is free and independent of political control because free sociality and conversation, the ends of this sphere, are both valuable in themselves and the best alternative for external laws. The romantics believed that social bonds should not be upheld by laws that are imposed on individual citizens from outside, but by the love encouraged by a common culture and free interaction. Romantic poetry is an exemplary model for achieving such a free domain since it is “a republican speech…in which all the parts are free citizens and have the right to vote” (Schlegel, CF: #65).

Aesthetics is at the center of this political vision also because the political ends of free sociability and conversation are the very same ones that the romantics practiced in their intellectual-artistic salons and in their communal, cooperative aesthetic projects. The political community should allow for creative and artistic endeavors such as the Athenaeum journal, which was the mouthpiece of the German romantics at the end of the eighteenth century and a journal that was independent of the control of the publishing establishment. It was written in collaboration (mainly by the Schlegel brothers, Novalis, and Schleiermacher), and aimed at rational criticism and Bildung. Such aesthetic projects are a model for the politician. This is because “sympoetry” and “symphilosophy”, as Schlegel and Novalis called such cooperative intellectual and aesthetic projects, should be an integral part of political life:

Perhaps a whole new epoch of science and art would be inaugurated were symphilosophy and sympoetry to become so common and deeply felt that there would be nothing odd were several people of mutually complementary natures to create works in communion with each other. (F. Schlegel, AF: #125)

The ideal political community must also be characterized by a specific kind of relation between the political body as a whole and its members: the state should be an organic or holistic whole, which means most broadly that the state as a whole must be prior to the parts (see Beiser 1992).

First, the best state is prior to its parts since, as we saw, it is necessary for individual identity and self-realization.

Additionally, the romantic community as a whole is prior to the individual citizens (i.e., its parts), insofar as genuine social bonds and a well-functioning political entity cannot be “constructed” out of separate self-sufficient and self-interested individuals (as the modern social contract theory has it). To properly function and achieve the ethical aim of sociality, the links between the political members should be organic: the members should not be connected to one another by an externally imposed social contract, but by natural love, affection and attraction. Unsurprisingly, it is through poetry that the familial-like bonds, required for the ideal state, should be developed over and above the unit of the biological family. “Within the family, minds become organically one, and for this reason, the family is total poetry” (F. Schlegel, Ideas: #152).

While the state as a whole should be prior to its parts in this sense, the law of such a state should not be imposed on its citizens from outside, but be self-determined. Individual autonomy should be supported by promoting the direct and active participation of all individuals in the political process. The organic unity of the state, then, implies reciprocity: the parts are dependent on and are posterior to the whole, while the whole, in respect of its essential self-determination, also depends on and is posterior to its parts.

The work of art provides, once again, the structural model for this political ideal by virtue of its organic unity, where “every whole can be a part and every part really a whole” (Schlegel, CF: #14). When genuine, art is characterized exactly by the kind of holistic, organic, but egalitarian and pluralistic unity that must characterize the ideal community:

Many works that are praised for the beauty of their coherence have less unity than a motley heap of ideas simply animated by the ghost of a spirit and aiming at a single purpose. What really holds the latter together is that free and equal fellowship in which, so the wise man assures us, the citizens of the perfect state will live at some future date; it’s that unqualifiedly social spirit…. (F. Schlegel, CF: #103)

An organic state is called for also because the mechanistic structure of the modern state is responsible for the decline of religion. This structure caused, according to the romantics, a form of “enslavement” and a faith in materialism and instrumentalism, both of which prevent people from cultivating their spirituality and relation to the divine. Both in their early and late phases, the romantics believed that poetry was the best way for inspiring spirituality and religiosity. “Every artist is a mediator for all other men”, writes F. Schlegel (Ideas: #44), regarding this “mediator” as mediating between man and God. Schleiermacher confirms and develops this connection when suggesting that poets are:

the true priests of the Highest…. They place the heavenly and eternal before them as an object of pleasure and unity, as the sole inexhaustible source of that toward which their poetry is directed. They strive…to ignite a love for the Highest…This is the higher priesthood that proclaims the inner meaning of all spiritual secrets and speaks from the kingdom of God. (Schleiermacher, On Religion [translation modified]).

It is for these reasons that “at the time of the republic, the artists will not be a special class” (F. Schlegel, PF: #749). In such an ideal republic everyone must be an artist who, by means of the poetic spirit of love, is related to the other citizens as artists relate to one another.

4.5 Late Romanticism
Statements such as Blake’s claim, “Princes…and Houses of Commons & Houses of Lords [are] something Else besides Human Life” (“Public Address” (1809) in PPWB) clearly display the revolutionary nature of the romantics. But the romantic transition from a more liberal framework to a more conservative one is explained primarily by their reaction to the terror of the French revolution. Though many of the romantics kept allegiance to the revolution until fairly late (1798), the acknowledgement of its failures and the dangers involved in any revolutionary act led them to modify, though not to renounce, their republican ideal. Even during this stage of their development, the romantics believed that the republic offered the best political structure. But, while still involving democratic elements, a proper republic, they argued should also involve aristocratic and monarchical elements because the educated should rule over the uneducated:

A perfect republic would have to be not just democratic but aristocratic and monarchic at the same time: to legislate justly and freely, the educated would have to outweigh and guide the uneducated, and everything would have to be organized into an absolute whole. (F. Schlegel, AF: #214)

Rather than opposed to the original romantic ideal, this late view is a natural outgrowth of the earlier ideal since it does not only maintain the early republicanism, but also continues, through modification, the early romantic emphasis on Bildung as a necessary condition for a proper republic.

Since even during this later period, the romantic political ideal consisted of a republican, holistic community grounded in love, art and aesthetics still played significant ethical and political roles in the late romantic phase. Even later on in their careers, the romantics insisted that art and aesthetics were crucial models and resources for the pursuit of ethical and political ends.

5. Aesthetics and Nature
One of the romantics’ central aims was to (re)enchant nature in the face of what they regarded as a threat from modern science. The threat was embodied primarily in the worry that modern science alienated (rational and free) human beings from nature, which, through the lens of this new science, had been viewed as a domain of brute, determined, mechanical causality (§5.1). Aesthetics is capable of (re)enchanting nature insofar as it brings out a different conception of nature as organic rather than mechanic. On this organic conception, nature is (a) an organic whole, which is reciprocally interdependent on its parts; (b) a domain of teleological rather than merely mechanical causality; and (c) a dynamic and living force, which is self-organizing and self-generating (§5.2). “Science should become poetic” insofar as it should approach nature in the same way that criticism approaches romantic poetry. Like romantic poetry, nature should be viewed as an organic and spontaneous whole. Under this conception of nature, rational, autonomous human beings are not alienated from, but are rather part and parcel of, nature (§5.3).

5.1 The Worry
We have fallen out with nature, and what was once (as we believe) One is now in conflict with itself, and mastery and servitude alternate on both sides. It often seems to us as if the world were everything and we nothing, but often too as if we were everything and the world nothing. (Hölderlin, Preface to Hyperion, HSA 3: 326).

Hölderlin expresses here a ubiquitous romantic sentiment. Not only has modernity divided man from himself by enforcing the duality between reason and sensibility and severed the individual from his natural social relations (section 4), but it also alienated man from nature. Modern science, “[a] vulture, whose wings are dull realities”, was regarded as the main culprit (Edgar Allen Poe, “Sonnet—To Science”).

Through the lens of modern science, nature was regarded as an inanimate, mechanistic domain of dead and meaningless matter that is composed of separate atoms and thoroughly determined by efficient causality. Modern science “dissected [nature] atomistically like a dead corpse” (Eichendorff, EW 5: 423). The romantics regarded this approach to nature as reductive as much as they regarded it as “dissecting”: it reduces nature to mere matter, devoid of the features that the romantics took to be essential to it, like holistic unity, self-organization and life. The growing sense of man’s alienation from his natural surrounding was seen as a product of this reduction of nature: human beings seemed alienated from nature exactly because the rational, soulful and sense-making character that is usually associated with them is opposed to a mechanistic and deterministic domain.

The troublesome consequences of this approach to nature are multiple. First, there is the psychological and existential crisis that is well encapsulated by Novalis’s claim, “Philosophy is actually homesickness—the urge to be everywhere at home” (General Draft: #45), and commemorated by landmark romantic works, such as Caspar David Friedrich’s “The Wanderer above the Mist” (1818).

In the epistemological and metaphysical domains, varieties of skeptical doubts loom large behind the modern approach to nature. If modern science is right then the relation between nature and normativity is unclear. But if nature cannot provide rational norms, then how can we account for and justify our empirical claims to knowledge (human experience)? On the flipside of this epistemological worry is a metaphysical concern about the nature of the subject. For the subject, as the source of meaning, is seen as only that—a dematerialized source of meaning, devoid not only of a body, as Descartes emphasized, but, if Kant is right, of any substantiality at all (see Bernstein 2003).

Third among the consequences is the threat to any awe-inspiring stance towards the world. Not only can the divinity once attributed to nature no longer be found therein, but modern science was also seen as posing a challenge to any attempt at a secular alternative to religion. Seen as fully accessible to the calculative part of the human mind, nature becomes transparent and devoid of any mystery or human-transcending power. Are we left without a source of wonder, awe or reverence in our modern world?

According to the romantics, the way out of these worrisome consequences requires that we recognize that modern science is reductive not only in terms of its object—nature—but also in terms of its methodology: modern science employs merely what Wordsworth called the “independent intellect”. The romantics understood this as calculative reason when it is isolated from non-calculative reason, sensibility and imagination. Employed thusly, the independent intellect works as a “knife in hand” (Wordsworth, The Prelude (1805), book X, line 877).

This is crucial because, if the romantics are to retrieve the lost unity of nature itself and our lost unity with nature, they must propose a new scientific methodology, or, what comes to the same thing, a new approach to nature. The romantics aspired to reform and counterbalance the merely calculative, quantitative and mathematical use of reason that is characteristic of modern science, and open an era “When no more numbers and figures feature//As the keys to unlock every creature” (Novalis, Henry von Ofterdingen, NS 1:344). Human beings should strive to return to “the laws of things which lie/beyond the reach of human will or power;/The life of nature” (Wordsworth, “The Tables Turned”, 1798, LB) by adopting a more holistic approach that includes practical reason, sensibility, feeling, imagination, and above all the aesthetic capacity of the mind.

It should be no surprise that this holistic approach to nature—the new romantic science—is, in essence, poetic. It is romantic poetry, which, as Athenaeum Fragments (AF) #116 announces, “fuses and mixes” opposing forces: reason, feeling, imagination, physics, poetry, philosophy, medicine and alchemy—when it comes to methodology—and matter, form, freedom and nature—when it comes to the object of study, nature:

Anyone who finds in infinite nature nothing but one whole, one complete poem, in every word, every syllable of which the harmony of the whole rings out and nothing destroys it, has won the highest prize of all. (Ritter, Fragmente 2: 205)

5.2 Romantic Science
While Kant’s discussions of nature, organisms and teleological judgment in the third Critique, and Schelling’s On the World Soul (1798) and First Outline of a System of Philosophy of Nature (1799) are the primary sources of inspiration for romantic science, the metaphysical starting point for the romantic view of nature is what Fredrick Beiser aptly dubbed “a strange wedding plan” between Fichte’s idealism and Spinoza’s realistic monism (2003: 131).[7]

Why synthetize these seemingly opposed philosophical projects—a form of idealism with realism, indeterminism with determinism, and dualism with monism? Briefly, in Fichte, the romantics found a philosopher that took the Kantian insight about the absolute value of freedom a step further, and in Spinoza, one who recognized the genuine monistic structure of the universe, where the mental (in the form of reason and subjectivity, the seats of freedom) is the flipped side of the physical (in the form of matter and objectivity). If nature itself is both physical and mental, if it has a soul or reason and a body, then, it differs from human beings only in degree, not in kind. Natural phenomena and human beings are simply different manifestations of an encompassing nature, which is therefore nothing other than Spirit: “Nature should be visible spirit, and spirit should be invisible nature” (Schelling, Ideas for a Philosophy of Nature, SW 2: 56).

Thus, the marriage between the philosophical outlooks of Fichte and Spinoza promises to consummate the valuable nucleus of modernity (the Enlightenment’s emphasis on freedom and individual rational criticism), while rebutting the modern ills of division and alienation. It promises to allow human beings to “feel at home” in a meaningful, free and natural world.

But this is only the metaphysical presupposition behind the romantic conception of nature. Their understanding of nature, not only as monistic but also as an organic whole that is self-forming and self-generating—in their terms, as a creative, living force—is inspired by what, according to them, Kant only started to point to, but failed fully to develop in the third Critique since he restricted it to a regulative and heuristic conception: namely, the conception of organic nature.

Thinking about nature as Spirit, different from the human merely in degree, already presupposes a holistic conception of nature, where the whole is prior to the parts. For, if all individuals are, in Spinoza’s words “modes” of nature, namely, merely different manifestations of the one and same whole, then these parts are necessarily dependent on the whole. But insofar as nature is also an (all encompassing) organism, then just as its parts are dependent on it (for their existence and intelligibility), so it depends on its parts for its existence as the organism that it is: independently of its parts, an organism could not sustain its particular organization, i.e., its life form. In an organism, the parts are the reciprocal cause and effect of one another and of the organism as a whole.

But an organism is also self-organizing and self-forming. While the organization of artifacts is imposed on them from outside by their producers, the particular organization and so the life form of any organism is self-produced. Consequently, to view nature as an organism is to view it dynamically—not as a dead matter, but as self-forming and self-generating. Indeed, for the romantics, nature is one living force, whose different parts—not only self-conscious philosophers, creative artists, animals, plants, and minerals, but also kinds of matter—are different stages of its organization.

From moss, in which the trace of organization is hardly visible, to the noble Form [Gestalt] which seems to have shed the chains of matter, the one and same drive within rules, a drive that strives to work according to one and the same ideal of purposiveness, strives to express ad infinitum one and the same archetype [Urbild], the pure form of our Spirit. (Schelling, “Review of the Newest in Philosophical Literature, 1796”)

5.3 Art’s Nature, Nature’s Art
Beauty in nature and art is a key for this organic and dynamic conception of nature for multiple reasons. First, the holistic and unifying character of poetry is suitable not only for the reformed scientific methodology that fuses together reason, imagination and feeling, but also for unraveling analogies and unities that are usually hidden from the bare eye, for example, the unity between kinds of matter and self-conscious human beings as different stages in the organization of the same life force.

Second, natural beauties and artworks inspire an interest in natural organization and life by their analogy with organisms, or as the romantics often put it, by being themselves organic in nature.

The transcendental poetry of the future could be called organic. When it is invented it will be seen that all true poets up to now made poetry organically without knowing it. (Novalis, Logological Fragments: I, #38).

Artworks and natural beauties are analogous to organisms in various respects.

To begin with, the analogy concerns their structure or unity. Both have holistic unities, where the parts and the whole are reciprocally interdependent. Artworks and natural beauties are so structured since (1) their beauty as a whole depends on the existence and the exact organization of their parts (for, if, say, any of the specific shapes, hues, or composition of a painting were to change, the painting as a whole may not be beautiful any longer), and (2) their parts are recognized as what they are (as beauty-making parts, or parts of a beautiful object) only in light of the whole (so that, for example, a mere shade of white may be beautiful only in light of the beauty of the painting to which it contributes as a whole, but not necessarily beautiful on its own, or when it figures in any other object). “In poetry”, then, just as in organisms, “every whole can be a part and every part really a whole” (F. Schlegel, CF: #14).

Kant claimed that the main difference between the holistic unity of organisms and the holistic unities of artworks and natural beauties is the difference between a causal or existential unity and what he called a formal unity. In organic life, the reciprocal interdependence between parts and wholes is causal and existential in the sense that it is life-sustaining. Kant thought that in aesthetics, the reciprocal interdependence is formal, rather than causal or existential, in the sense that it does not explain the existence of the objects at stake, but their beauty. While, for example, a painting might continue to exist as a painting even if some of its parts changed (say, if its composition, shapes, or hues changed), the beauty of this painting is unlikely to survive such a change. In this case, it is the beauty of the whole painting that depends on its parts, and it is the beauty of the parts, rather than their existence, that depends on the beauty of the whole: for were the painting as a whole not beautiful, its parts would not be recognized as what they are, namely, beauty-making parts.

The romantics seemed to diverge from Kant on that matter. For them, great poetry is materially and not merely formally organic:

The innate impulse of this work [Wilhelm Meister], so organized and organizing down to its finest detail to form a whole. No break is accidental or insignificant;…everything is at the same time both means and end. (F. Schlegel, WM: 273–74)

This means that the romantics took the work of art to be analogous to organisms in yet a stronger sense—not only in terms of its holistic unity, but also in terms of its life—its self-organization and self-judgment. Recall the sui generis character of artworks (discussed in §3.2): each work constitutes the norms according to which alone it could be properly judged. In romantic terms, every work has its own self-judgment. Seen as such, the artwork is not a mere artifact, but a quasi-organism in the sense that it organizes and regulates itself. And like other organic products of nature, the work too has, as it were, a life of its own, even though it is not self-organizing in the strict sense:

Just as a child is only a thing which wants to become a human being, so a poem is only a product of nature which wants to become a work of art. (F. Schlegel, CF: #21)

It is the holistic unity and life in the aesthetic domain that draws our attention to organisms and inspires us to seek the organic structure of nature as a whole.

Third, following Kant, the romantics believed that the beauty of nature reveals the purposiveness without a purpose of nature as a whole. It inspires and guides us in seeing nature as purposively organized—organized as if according to a specific purpose—even though we cannot attribute this purposive structure to any will, creator, or any end-governed activity:

That which reminds us of nature and thus stimulates a feeling for the infinite abundance of life is beautiful. Nature is organic, and therefore, the highest beauty is forever vegetative; and the same is true for morality and love. (F. Schlegel, Ideas: #86)

While this view is to be found in the third Critique, the romantics went a few steps further than Kant: first, they considered purposiveness, teleological structure and life real features of nature, rather than regulative principles for approaching nature. Second, they took these features to indicate that nature is different from self-conscious, creative human beings only in degree, but not in kind: like human beings, nature is end-governed. It is beauty, above all, that inspires this realization. As Novalis puts it, “Through beauty, nature transforms itself into a human being” (Heinrich von Ofterdingen, NS 1), the same being that governs itself by creatively and self-consciously setting ends. The more we properly attend to beauty and art the more capable we would be of seeing nature and humanity as different aspects of a single, unified phenomenon:

Actually criticism…that doctrine which in the study of nature directs our attention to ourselves…and in the study of ourselves directs it to the outside world, to outer observations and experiments—is…the most fruitful of all indications. It allows us to sense nature, or the outside world, like a human being. (Novalis, General Draft: #42).

Aesthetics is central for the romantic “scientific revolution” for yet another reason that concerns its capacity to “enchant” nature. “Enchanting” stands here for the process of rendering nature magical, or mysterious, and thus inspiring reverence and awe (see Stone 2005). While bringing out nature’s organic structure is decisive for rebutting modern alienation, enchantment is required primarily for challenging two other consequences of modern science: the threat of a detached and unresponsive treatment of nature and what the romantics regarded as a threat of secularization. Not only did modern science portray nature as a brute domain of mechanism, and thus devoid of any awe-inspiring power, but it also rendered it completely transparent to the human mind, and thus lacking in the kind of mystery and magic that may inspire awe in a secular world. Changing our attitude towards nature and inspiring awe for it requires that we recover a sense of mystery and magic in nature, and, indeed, in everything ordinary, in everything that we have come to take for granted. This process—of recovering a sense of mystery and magic in nature and the ordinary—is so central in romanticism that it takes on the movement’s name:

Romanticizing is nothing other than a qualitative raising into higher power…. By giving a higher meaning to the ordinary, a mysterious appearance to the ordinary, the dignity of the unacquainted to that of which we are acquainted, the mere appearance of infinity to finite, I romanticize them. (Novalis, Logological Fragments: #66)

Poetry is most suitable for the business of romanticizing by virtue of two of its main features: (a) its “defamiliarizing” power, and, (b) its “ironic” ability to point to the limits of our knowledge, and thus to what must remain mysterious—beyond our cognitive capacities.

First, by virtue of its power to subtly describe even the most concrete of details and to bring to life even what, independently of it, attracts no attention, poetry has a special capacity for defamiliarization—a power that was first noticed by the romantics in their account of “romanticizing”, but dubbed “defamiliarization” only later, by 20th century literary theorists. By its non-ordinary use of language, attention to details and evoking power, poetry brings out in vivid colors what we are usually blind to, even if it is, literally, the closest and most familiar to us. Poetry has the power to make the most familiar new, refreshing, and thus, other than familiar—different and even mysterious.

Like Novalis, Wordsworth is one of the first proponents of romanticizing in this sense. He instructs: while romantic poetry should start with the most familiar and contingent—“the incidents and situations from common life”—it should also strive to elevate them by

throw[ing] over them a certain coloring of the imagination, whereby ordinary things should be presented to the mind in an unusual way; and further and above all [poetry should aim] to make these incidents and situations interesting by tracing in them…the primary laws of our nature. (Preface to the Lyrical Ballads.)

Wordsworth calls on poets to write in the language of “low and rustic life”. But it is exactly the poetic use of this language that allows the “passions” of those whose language it is—ordinary people—to be “incorporated with the beautiful and permanent forms of Nature” (ibid.). And it is through this process of romanticizing that nature appears again as great and awe-inspiring, “The great Nature that exists in words/Of might Poets” (Wordsworth, The Prelude (1805), Book V, lines 618–19).

Second, romantic poetry is essentially ironic insofar as it brings our finitude, particularly the limits of our knowledge, to consciousness (see §2.2). While romantic irony is the basis for a way of life that is centered on humility, it also paves the way for awe and reverence for it suggests that there is much beyond our comprehension, much that remains mysterious, incomprehensible, greater than our capacities and possibly infinite rather than finite like us. There is much around us that merits awe.

Wordsworth’s description of nature is possibly the most powerful portrayal of the awe-inspiring character of nature as it is revealed by the poetic imagination:

A sense sublime
Of something far more deeply interfused,
Whose dwelling is the light of setting suns,
And the round ocean, and the living air,
And the blue sky, in the mind of man,
A motion and a spirit, that impels,
All thinking things, all objects of all thought,
And rolls through all things.
…
I, so long
A worshipper of Nature, hither came,
Unwearied in that service: rather say
With warmer love, oh! With far deeper zeal
Of holier love.
(Wordsworth, “Lines Written a Few Miles above Tintern Abbey” (1798), lines 96–103 and 154–57, in LB)

Through the romantic lens, then, nature becomes alive and a locus of Spirit. Rather than an alien force, nature speaks to us as we speak to it and to each other.

Nature is a temple where living columns
Sometimes let confused words come out;
Man walks through these forests of symbols
Which observe him with a familiar gaze.
(La Nature est un temple où de vivants piliers
Laissent parfois sortir de confuses paroles
L'homme y passe à travers des forêts de symbols
Qui l'observent avec des regards familiers) (Baudelaire, Correspondences, 1861 [2000])

This is liberating and re-enchanting, but it also puts certain demands on us, for example, the demands to love nature as we love other human beings:

Oh, most magnificent and noble Nature!
Have I not worshipped thee with such a love
As never mortal man before displayed?
Adored thee in thy majesty of visible creation,
And searched into thy hidden and mysterious ways
As Poet, as Philosopher, as Sage?
(unknown date, Humphry Davy [1778–1829], Fragmentary Remains, 14)

As eccentric as the romantic call to poeticize nature and science may initially seem, it is arguably of relevance today. The organic and re-enchanted conception of nature did not only anticipate some currents in the modern ecological movement, but it also contains resources for further developments in contemporary environmental philosophy and philosophy of science.

6. Romantic Legacy
Interestingly, scholars tend to explain romantic aesthetics not only in terms of its sources (discussed in §2.1), but also in terms of its legacy. While there are very interesting and well-established connections between romantic aesthetics and modernism (see Abrams 1971, Frye 1968, Cavell 1979), this section focuses on the attempt to draw a link between the former and postmodernism, a link whose ground is significantly weaker.

In recent decades, a large number of romantic scholars have argued that romanticism, in general, and the romantic primacy of aesthetics, in particular, is a precursor of the fundamental outlook of postmodernist and poststructuralist views (see, for example, Lacoue-Labarthe and Nancy 1988, Bowie 2003, Bowman 2014, and Gasche 1991). This reading is based on the skepticism the romantics raised about first principles and about systematicity, the romantic emphasis on human creation and language, historicism and hermeneutics, their view of the fragmented nature of modern life and on certain formulations of the primacy of aesthetics that may seem, initially, to erase any distinction between what is “real” and what is “poetic”, a product of the creative imagination. Friedrich Schlegel, for example, proclaims: “No poetry, no reality…. There is, despite all the senses, no external world without imagination” (AF: #350), and “Everything that rests on the opposition between appearance and reality…is not purely poetic” (FLP: #146).

These proclamations may seem to suggest that “there is no way out” of creative constructions, or “texts”, or that “art…does not need to point beyond itself” (Bowie 2003: 53), as if romantic aesthetics anticipates central trends in post-modernism and post-structuralism.[8] But there are reasons to worry about such a “postmodernist” reading. Some lines in romanticism—skepticism about foundationalist philosophy and system-building, the emphasis on human creation, language, and the role of historicism and hermeneutics—are indeed related to certain strands in postmodernism. But reading romantic aesthetics as proto-postmodernist is limited for a host of reasons.

First, the romantic faith in the imaginative and emotive capacities associated with the production and reception of art, and their skepticism of absolute principles and philosophical systems did not make them skeptical of reason, as many postmodernist thinkers are (see §2.1 and Beiser 2003: 3). Even romantic skepticism of absolute principles (see §3.1). cannot be equated with the rejection of all principles and rules. For example, though art and art appreciation cannot be reduced to any given, prior rules, they are not lawless, but the source of their own normativity (see §3.3).

Second, in spite of the romantic stress on the fragmentary nature of human experience (embodied in their choice of the aphoristic style, which is emphasized by their post-modernist readers), the romantics never gave up the striving after unity and wholeness. Art was not meant as a replacement for unity, but exactly as the best way to strive after and approximate unity in our modern and fragmentary condition.

For the philosopher…art is supreme, for it opens to him the holiest of holies, where that which is separated in nature and history, and which can never be united either in life and action or in thought, burns as though in a single flame in eternal and primordial unity. (Schelling, System of Transcendental Philosophy, 1800, in Heath 1978: 231)

Third, the romantics’ desire for and search after the Absolute (discussed in 3) is another reason to reject the post-modernist interpretation. For such a desire is anathema to most post-modernist thinkers, who resist and shun the possibility (and desirability) of any absolute reality.

Moreover, if one opposes the idea that there is “no way out of texts”, or that reality is “nothing other than construction”, then the post-modernist reading of the romantics appears uncharitable. Fortunately, this interpretation does not force itself on us since there are many other charitable and (historically, textually and philosophically) well-grounded readings of the proclamations just mentioned and of the romantic primacy of the aesthetics. Many of these readings were proposed in this entry under the umbrella of the formal approach to romantic aesthetics. On this formal account, rather than claiming that there is no distinction between “reality” and “fiction”, or that there is “no way out of imaginative constructions”, the romantics urged human beings to fashion their ordinary life and philosophy aesthetically for epistemological, metaphysical, ethical, political and scientific reasons.

Arguably, romantic aesthetics is not of merely historical interest. This entry has pointed to a few facets of the relevance of romantic aesthetics, thus supporting views like Berlin’s, for example, according to which the revolution brought about by romanticism is “the deepest and most lasting of all changes in the life of the West…” (1999: xiii). Its tremendous impact on generations to come all the way up to the present day is one explanation of the difficulty of precisely delimiting when the age of romanticism begins and when it ends. Indeed, rather than a post-romantic age, our age may be yet another phase in the age of romanticism:

Romanticism…is the first major phase in an imaginative revolution which has carried on until our own day, and has by no means completed itself yet. (Frye 1968: 15; see also, Larmore 1996)

1. What Is Music?
1.1 Music Alone and Together
It is plausible that song is the most common kind of music listened to across history and the globe. Moving images (film, television, videogames, etc.) are ubiquitous in the contemporary world, and most have musical soundtracks. Nonetheless, most philosophy of music considers what Peter Kivy calls music alone (1990)—instrumental music with no non-musical aspects, elements, or accompaniments. At least three reasons can be given to defend this narrow focus. First, pure music often presents the most difficult philosophical problems. The maudlin text of a song plausibly contributes to the song’s expressiveness; it is more puzzling how a piece of music alone could be emotionally expressive. Second, though the problems are more difficult, the solutions are likely to be more easily evaluated with respect to music alone. Just as apportioning blame is easier when one person is responsible for a crime than when the blame must be divided between a number of conspirators, the success of a solution to the problem of musical expressiveness may be clearer if it can explain the expressiveness of music alone. Third, the expressiveness of music alone will play a role in the expressiveness of musical hybrids such as song or film. Though its text may contribute to the expressiveness of a song, for instance, the musical aspects of the song must play some role. A maudlin text set to a jauntily upbeat melody will clearly not have the same overall expressiveness as the same text set to a plodding dirge. Though expressiveness is used as an example here, these same points apply to discussions of musical understanding and value.

Even if these three reasons are compelling (see Ridley 2004 for a sustained critique), music’s combination with other media raises further philosophical questions. There is no space to consider those questions here, but on the aesthetics of song, see Levinson 1987; Gracyk 2001; Bicknell & Fisher 2013; and Bicknell 2015. On music drama, see Kivy 1988b, 1994; Goehr 1998; and Penner 2020. On film music, see Carroll 1988: 213–225; Smith 1996; Levinson 1996b; and Kivy 1997a. See also the chapters in part V of Gracyk & Kania 2011. On hybrid art forms more generally, see Levinson 1984 and Ridley 2004.

1.2 The Definition of “Music”
Explications of the concept of music usually begin with the idea that music is organized sound. They go on to note that this characterization is too broad, since there are many examples of organized sound that are not music, such as human speech, or the sounds non-human animals and machines make. There are two further kinds of necessary conditions philosophers have added in attempts to fine tune the initial idea. One is an appeal to “tonality” or essentially musical features such as pitch and rhythm (Scruton 1997: 1–79; Hamilton 2007: 40–65; Kania 2011a). Another is an appeal to aesthetic properties or experience (Levinson 1990a; Scruton 1997: 1–96; Hamilton 2007: 40–65). As these references suggest, one can endorse either of these conditions in isolation, or both together.

The main problem with the first kind of condition is that every sound seems capable of being included in a musical performance, and thus characterizing the essentially musical features of sounds seems hopeless. (We need only consider the variety of “untuned” percussion available to a conservative symphonist, though we could also consider examples of wind machines, typewriters, and toilets, in Ralph Vaughan Williams’s Sinfonia Antartica, Leroy Anderson’s The Typewriter, and Yoko Ono’s “Toilet Piece/Unknown.”) Defenders of such a condition have turned to sophisticated intentional or response-dependent theories of tonality in order to overcome this problem. If the essentially musical features of a sound are not intrinsic to it, but somehow related to how it is produced or perceived, we can classify just one of two “indiscernible” sounds as music.

If one endorses only an aesthetic condition, and not a tonality condition, one still faces the problem of poetry—non-musical aesthetically organized sounds. Levinson, who takes this approach, excludes organized linguistic sounds explicitly (1990a: 272). This raises the question of whether there are further distinctions to be made between arts of sound. Andy Hamilton defends a tripartite division, arguing that sound art, as opposed to both music and literature, was established as a significant art form in the twentieth century (2007: 40–65). This is one reason that Hamilton endorses both tonal and aesthetic conditions on music; without the former, Levinson is unable to make such a distinction. On the other hand, by endorsing an aesthetic condition, Hamilton is forced to exclude scales and Muzak, for instance, from the realm of music. Kania (2020: 296–301) suggests that it is a mistake to think that music is necessarily an art. He argues that we should distinguish the medium of music from its artistic uses, just as we do in the cases of language and literature, depiction and painting, and so on.

Jonathan McKeown-Green (2014) makes trenchant criticisms of definitions of music that assume that the nature of music is settled by our conception of music (395, italics removed). He argues that no such definition could be future-proof, since it would be hostage to our changing conception of music. At best, we would end up with a kind of sociological history of music that would fail to fulfill any of the functions of a definition. McKeown-Green singles out the definitions of Kania (2011a) and Levinson (1990a), stated in terms of necessary and sufficient conditions, as of this hopeless kind. But Kania (2020: 302–5) argues that McKeown-Green’s criticisms apply equally to the looser definitions of Hamilton and S. Davies (2012).

Having discussed complications, it’s worth returning to the basic idea of “organized sound.” Most theorists note that music does not consist entirely of sounds. Most obviously, much music includes rests. You might think that silence can function only to organize the sounds of music. One counterargument is that an understanding listener listens to the rests, just as she listens to the sounds (Kania 2010). Another is to provide putative cases of music in which the silences do not structure sounds as ordinary rests do. John Cage’s 4′33″ is frequently discussed, though there is broad agreement that this piece is not silent—its content is the ambient sounds that occur during its performance. (See Dodd 2018 for dissent.) Anyway, S. Davies (1997a), Dodd (2018), and Kania (2010) all argue that Cage’s piece is not music—Davies and Dodd because its sounds (if any) fail to qualify as organized, Kania because they fail to meet a tonality condition. Wadle (forthcoming) argues that the piece is music, because of its contextual connections to previous musical works. Kania considers several other contenders for the label of “silent music,” arguing that there are indeed extant examples, most notably Erwin Schulhoff’s “In Futurum” from his Fünf Pittoresken, which predates Cage’s 4′33″ by some 33 years.

2. Musical Ontology
Musical ontology is the study of the kinds of musical things there are and the relations that hold between them. The most discussed issues within this field have been the metaphysical nature of works of Western classical music (the “fundamentalist debate”), and what it is to give an “authentic performance” of such works. Recently there has been growing interest in the ontologies of other Western musical traditions, such as rock and jazz, and discussion of the methodology and value of musical ontology. (For more detailed overviews of these debates, see Matheson & Caplan 2011, and Nussbaum 2021.)

2.1 The Fundamentalist Debate
Musical works in the Western classical tradition admit of multiple instances (performances). Much of the debate over the nature of such works thus reads like a recapitulation of the debate over the “problem of universals”; the range of proposed candidates covers the spectrum of fundamental ontological theories. We might divide musical ontologists into the realists, who posit the existence of musical works, and the anti-realists, who deny their existence. Realism has been more popular than anti-realism, but there have been many conflicting realist views. We begin with two unorthodox realist views before moving on to more orthodox Platonist and nominalist theories, concluding with a consideration of anti-realism.

Idealists hold that musical works are mental entities. Collingwood (1938) and Sartre (1940) respectively take musical (and other) works to be imaginary objects and experiences. The most serious objections to this kind of view are that (i) it fails to make works intersubjectively accessible, since the number of works going under the name The Rite of Spring will be as multifarious as the imaginative experiences people have at performances with that name, and (ii) it makes the medium of the work irrelevant to an understanding of it. One might have the same imaginative experience in response to both a live performance and a recording of The Rite of Spring, yet it seems an open question whether the two media are aesthetically equivalent. But see Cox 1986 and Cray & Matheson 2017 for attempts to revive idealism.

David Davies argues that musical works, like all works of art, are actions, in particular the compositional actions of their composers (2004). Thus he revives what we might call an “action theory” of the ontology of art. (An earlier defender of such a view is Gregory Currie (1989), who argues that artworks are types of action, rather than the particular actions with which Davies identifies them.) Although deciding between theories of musical ontology is always to some extent a matter of finding a balance between the benefits of a theory and its cost in terms of our pre-theoretic intuitions, action theories have a particularly hard row to hoe since they imply that an instance of a work is some action performed by a composer, rather than a performance. In order to make up for such damage to our intuitions the theoretical benefits of an action theory would have to be quite extensive.

Most theorists think that some kind of Platonist or nominalist theory of musical works is more plausible than those so far considered. Platonism, the view that musical works are abstract objects, is arguably still the dominant view, though it seems to be losing ground to sophisticated nominalisms. Its great advantage is its ability to respect more of our pre-theoretic intuitions about musical works than other theories can. On the other hand, it is the most ontologically puzzling, since abstract objects are not well understood. Nonetheless, Platonism has been tenacious, with much of the debate centering around what variety of abstract object musical works are. What we might call “simple Platonism” (known simply as “Platonism” in the literature), is the view that works are eternal existents, existing in neither space nor time (Kivy 1983a, 1983b, Dodd 2007). Puy (2019) presents a variation according to which musical works are higher-order types, of which the types other Platonist thinks are works are specific versions of works. (See D. Davies 2021 for discussion.)

According to “complex Platonism,” musical works come to exist in time as the result of human action. The complexity is motivated by a number of features of musical practice, including the intuition that musical works are creatable, the attribution of various aesthetic and artistic properties to works, and the fine-grained individuation of works and performances (e.g., in terms of who composed them, or what instruments they are properly performed upon) (Ingarden 1961; Thomasson 2004; Wolterstorff 1980; Wollheim 1968: 1–10, 74–84; Levinson 1980, 1990b, 2012; S. Davies 2001: 37–43; Howell 2002; Stecker 2003a: 84–92).

Nominalists identify a musical work with something concrete. The most obvious candidate is a collection of performances, whether the collection be understood as a set (Goodman 1968; Predelli 1995, 1999a, 1999b, 2001), a fusion (Caplan & Matheson 2004, 2006), or something more esoteric (Tillman 2011; see also Moruzzi 2018). Charles Nussbaum (2007: 143–87) and P. D. Magnus (2012) argue for a close analogy between musical works and species. Nussbaum (2021: 334) points out that a sophisticated nominalist theory of species has been developed in great detail over the years by Ruth Millikan (1984, 2000). While such views are attractive because they appeal only to the least problematic kinds of entities, they face serious challenges. Though many of our claims about musical works may be paraphraseable into claims about sets of (possible) performances, some seem to make intractable reference to works. For instance, most performances of The Rite of Spring—even including the possible ones—include several wrong notes. Thus it is difficult to imagine how the paraphrase schema will avoid the nonsensical conclusion that The Rite of Spring contains several wrong notes, if the work consists entirely of performances. In response to this problem, most nominalists add to the collection of performances some provenential item, such as an original score or act of composition. Whether this addition can solve the problem without necessitating the reintroduction of an abstract entity is one question any nominalist must address.

Intermediate between Platonism and nominalism are the views of Philip Letts (2018) and Guy Rohrbaugh (2003). Letts argues that any view of musical works as types would be improved by identifying those types with their associated properties, a proposal that may be developed in a Platonist or nominalist direction. Rohrbaugh’s view of musical works as historical individuals “embodied in,” but not constituted by, physical things such as scores and performances closely resembles to the views of Nussbaum and Magnus, discussed above, but Rohrbaugh takes the work to be an abstract object over and above its embodiments. (For discussion, see Dodd 2007: 143–66.)

In contrast to all these realist views stand those of the anti-realists, who deny that there are any such things as musical works. An early proponent of such a view is Richard Rudner (1950), though it is difficult to say whether he is best interpreted as an eliminativist or a fictionalist, the two anti-realist views currently on the table. According to eliminativists, there are no such things as musical works, and thus we ought to stop trying to refer to them. Ross Cameron (2008) defends such a view, but only with respect to “Ontologese”—the language we speak when we do ontology. He argues that ordinary English locutions such as “there are many musical works” can be true without there being any musical works. (For critical discussion, see Predelli 2009 and Stecker 2009.) According to fictionalists, the value of discourse about musical works is not truth, and thus we ought not to abandon the discourse despite the non-existence of its subject matter, but rather to adopt a different, make-believe attitude towards it (or perhaps we already do so). (See Kania 2008; for criticism, see D. Davies 2011: 45–50, Letts 2015, and Nussbaum 2021: 337.)

Much of this debate over the fundamental ontological category to which musical works belong has turned on “technical” issues, that is, controversial general metaphysical claims about the nature of properties, causation, embodiment, and so on (e.g., Howell 2002; Trivedi 2002; Caplan & Matheson 2004, 2006; Dodd 2007; Hazlett 2012; Kleinschmidt & Ross 2012; Dodd & Letts 2017; Cameron 2008). In the face of this, some theorists have pointed out that musical works are cultural entities, and thus the methodology appropriate to uncovering their ontological status might be quite different from that of general metaphysics (Goehr 1992; S. Davies 2003a; D. Davies 2004; Thomasson 2006). For further discussion of the methodology of musical ontology, see D. Davies 2009, 2017; Predelli 2009; Stecker 2009; Dodd 2010, 2013; Mag Uidhir 2012b; and Nussbaum 2021.

2.2 Higher-level Ontological Issues
It might seem that, since musical works are ontologically multiple, once we have figured out their true nature, we will know what relation holds between the work and its performances, namely, whatever relationship holds between entities of that kind and their instances. However, since the fundamentalist debate is about the basic ontological category to which works belong, resolving that debate may leave open many questions about the relation between a work and its performances. For instance, is the use of a harpsichord required to instance Bach’s Brandenburg Concerto No. 5 in performance? Would producing harpsichord-like sounds on a synthesizer do just as well? What about using another keyboard instrument from Bach’s time, or a modern piano? Learning that musical works are, say, eternal types will not necessarily help settle this issue of “authentic performance,” which is perhaps the most discussed music-ontological issue, of interest to philosophers, musicologists, musicians, and audiences alike. (For an excellent overview of the authentic performance debate, see S. Davies 2001: 201–53. For an investigation of authenticity with respect to things other than instantiation of the work, see Kivy 1995; Gracyk 2001, 2009, 2017; Bicknell 2015; and Cray 2019.)

There have been two sources of widespread confusion in the debate over authenticity in performance. One is a failure to recognize that authenticity is not simply a property, but a relation that comes in degrees and holds with respect to different aspects of its target. Something may be more authentic in one regard and less authentic in another (S. Davies 2001: 203–5). Another is the assumption that authenticity is an evaluative concept, in the sense that “authentic” implies “good.” That this is not the case is clear from the fact that an authentic murderer is not a good thing (S. Davies 2001: 204). Thus, our value judgments will be complex functions of the extent to which we judge performances authentic in various regards, and the values we assign to those various kinds of authenticity.

The central kind of authenticity that has been discussed is authenticity with respect to the instantiation of the work. Most agree that the fullest such authenticity requires the production of the right pitches and rhythms in the right order. (For skepticism based on the history of the practice, see Dyck 2014; Ravasio 2019a; and the discussion in Dodd 2020b and Ravasio 2020.) Pure sonicists argue that this is sufficient (e.g., Kivy 1988a). Timbral sonicists argue that these pitches must also have timbres reflecting the composer’s instrumentation (e.g., Dodd 2007: 201–39). Instrumentalists argue that such sounds must be produced on the kinds of instruments specified in the score (e.g., Levinson 1990c). Much of the debate is over what kinds of aesthetic or artistic properties are essential to musical works. If the limpid textures of Bach’s Brandenburg Concerto No. 5 are essential to it, then one cannot authentically instance the work using a grand piano instead of a harpsichord. As such, the debate reflects a wider one in aesthetics, musical and otherwise, between formalists (or empiricists, or structuralists), who believe that the most important properties of a work are intrinsic ones, accessible to listeners unaware of the historical and artistic context in which it was created, and contextualists, who believe that a work is essentially tied to its context of creation. Stephen Davies has argued for a strong contextualism, claiming that one cannot give a single answer to the question of whether particular instrumentation is required for the fully authentic instantiation of a work. Works can be ontologically “thicker” or “thinner” as a result of the specifications of a composer working within certain conventions (1991, 2001). The more properties of a fully authentic performance a particular work specifies, the thicker it is. Thus for some works (typically earlier in the history of Western music) instrumentation is flexible, while for others (e.g., Romantic symphonies) quite specific instrumentation is required for fully authentic performances.

In addition to the question of what constitutes authenticity, there has been debate over its attainability and value. Those who question its attainability point to our historical distance from the creation of some works (Young 1988). We may no longer be able to read the notation in which the work is recorded, or construct or play the instruments for which it was written. If so, full authenticity is not attainable. But we rarely have no idea about these matters, and thus we might achieve partial authenticity (S. Davies 2001: 228–34). Those who question the value of authenticity often target kinds other than work-instantiation. For instance, one might question the value of producing a performance that authentically captures the sound of performances as they took place in the context of a work’s composition, on the basis that musicians were not as highly skilled then as now, for instance (Young 1988: 229–31). Such arguments, though, have no consequences for the value of work-instantiation. Some argue that although we might attain an authentic instance of a work, the idea that we might thereby hear the work as its contemporaries heard it is wishful thinking, since the musical culture in which we are immersed enforces ways of listening upon us that we cannot escape (Young 1988: 232–7). Thus the point of such authenticity is questioned. In response, we may consider not only the possibility that we are in a better position to appreciate historical works than contemporary ones, but also the remarkable flexibility people seem to show in enjoying many different kinds of music from throughout history and the world (S. Davies 2001: 234–7).

Julian Dodd (2020a) argues that there is more than one way to be true to a musical work, and thus to produce an authentic performance: One can comply with the score, or one can be true to the music’s overall integrity or point (136). When the two conflict, interpretive authenticity trumps score-compliance authenticity (147) because the fundamental norm of work-performance practice is to perform it in a way that evinces a subtle or profound understanding of it (163), while score compliance is valued only because it tends to lead to such performances. Andrew Kania responds that it is unclear whether, even by the lights of Dodd’s own theory, Dodd’s central examples are cases of interpretive authenticity trumping score compliance (Kania 2022: 131–2). More importantly, he argues that Dodd’s conception of the music’s overall integrity or point misses the importance of the surface-level details to a work’s meaning or content. Kania suggests, instead, that the fundamental norm of the practice is to evince an understanding of the work through complying with its score (2022: 127, italics altered).

Moving on from authenticity, a second area that may be independent of the fundamentalist debate is that of comparative ontology. (For dispute over this framing issue, see Brown 2011, 2012.) Just as classical works from different historical periods may be ontologically diverse, so may works from different contemporary traditions. Theodore Gracyk has argued that instances of works of rock music are not performances. Rather, the work is instanced by playing a copy of a recording on an appropriate device (1996; cf. Fisher 1998). Stephen Davies has argued that rock is more like classical music than Gracyk acknowledges, with works for performance at the heart of the tradition, albeit works for a different kind of performance (2001: 30–6). Gracyk’s view has been amplified and defended in attempts to find a place for composition, live performance, and performance skill within his basic framework (Kania 2006, Bruno 2013, Bartel 2017, Magnus 2022).

Work on the ontology of jazz has centered on the nature of improvisation, particularly the relation between improvisation and composition (Alperson 1984, 1998; Valone 1985; Brown 1996, 2000; Hagberg 1998; Gould & Keaton 2000; Sterritt 2000; and Young & Matheson 2000; Bresnahan 2015; Love 2016; Magnus 2016). This has been a useful reminder that not all music is the performance of pre-composed works (Wolterstorff 1987: 115–29). However, improvisation can occur within the context of such a work, as in the performance of an improvised cadenza in a classical concerto. Some have argued that there is not as significant a distinction between improvisation and composition as is usually thought (Alperson 1984). Others have argued that all performance requires improvisation (Gould & Keaton 2000). Yet others restrict the possibility of improvisation to certain kinds of musical properties, such as “structural” rather than “expressive” ones (Young & Matheson 2000). However, none of these arguments are compelling. Usually they turn on equivocal use of terms such as “composition” and “performance,” or beg the question by defining improvisation in terms of deviation from a score or variation of a limited set of “expressive” properties.

Though jazz is not necessarily improvisational, and very few jazz performances lack any sort of prior compositional process, the centrality of improvisation to jazz presents a challenge to the musical ontologist. One might argue that jazz works are ontologically like classical works—composed for multiple, different performances—but that they tend to be thinner, leaving more room for improvisation (Gould & Keaton 2000; Young & Matheson 2000). The difficulty is to specify the work without conflating one work with another, since tokening the melody may not be required, and many works share the same harmonic structure. As a result, some argue that the performance is itself the work (Alperson 1984; Hagberg 2002; S. Davies 2001: 16–19). One problem here is parity with classical music. If jazz performances are musical works in their own right, it is difficult to deny that status to classical performances of works, yet this seems to multiply works beyond what we usually think is necessary. A third possibility is that in jazz there are no works, only performances (Brown 1996, 2000: 115; Kania 2011b). This is counterintuitive if “work” is an evaluative term, but it is not obvious that this is the case.

Julian Dodd (2014a) argues that the kinds of considerations adduced in favor of these views confuse questions of ontology with questions of value. Jazz is ontologically like early classical music, according to Dodd: the focus of critical attention is the improvisatory performance rather than the composition it instantiates, but that composition is no less a musical work for that difference in critical emphasis. (See Fisher 2018 for an attempted reconciliation.) Similar considerations might be adduced against the increasingly complicated ontologies of rock referred to above. Such arguments return us to debates about the methodology of musical ontology.

3. Music and the Emotions
The most widely discussed philosophical question concerning music and the emotions is that of how music can express emotions. (For a more extensive introduction, see part II of Gracyk & Kania 2011; for a thorough treatment, see S. Davies 1994.) There is a second group of questions centered around listeners’ emotional responses to music. These include questions about why and how we respond emotionally to music, the value of such responses, and why we choose to listen to music that elicits “negative” responses from us, such as sadness. Theorists typically restrict themselves to “pure” or “absolute” music on the grounds that it is easier to understand how music with an accompanying text, say, could express the emotions evident in the text. However, an important criterion for the evaluation of such music is how appropriately the composer has set her chosen text to music. So an accompanying text is clearly not sufficient for the musical expression of an emotion. Thus, a better reason for initially putting such music to one side is perhaps that the interrelation of music and text, or other elements, is likely to be highly complex, and best approached with as well-developed a theory of the more basic phenomena in hand as possible. (For an extended criticism of this approach, see Ridley 2004: 1–104.)

3.1 Emotions in the Music
Pieces of music, and performances of them, are standardly said to be happy, sad, and so on. Music’s emotional expressiveness is a philosophical problem since the paradigm expressers of emotions are psychological agents, who have emotions to express. Neither pieces of music, nor performances of them, are psychological agents, thus it is puzzling that such things could be said to express emotions.

One radical way to solve the puzzle is to deny that music is emotionally expressive. A major burden of such eliminativism is to explain away the widespread tendency to describe music in emotional terms. This has been attempted by arguing that such descriptions are shorthand or metaphor for purely sonic features (Urmson 1973), basic dynamic features (Hanslick 1854), purely musical features (Sharpe 1982), or aesthetic properties (Zangwill 2007). There are many problems with such views. For one thing, they seem committed to some sort of scheme for reduction of expressive predicates to other terms, such as sonic or musical ones, and such a scheme is difficult to imagine (Budd 1985a: 31–6). For another, anyone not drawn to this theory is likely to reject the claim that the paraphrase captures all that is of interest and value about the passage described, precisely because it omits the expressive predicates (Davies 1994: 153–4).

Conventionalism is the view that music’s expressiveness is a matter of the conventional association of certain musical elements, such as slow tempi, with certain emotional states, such as sadness. Such conventions must play a role in some cases of expression—for instance, cases of particular musical instruments (e.g., the snare drum) being associated with particular situations (e.g., war) and thus emotions (e.g., foreboding). But such conventions seem unlikely to account for all musical expressiveness, since much of that expressiveness seems less arbitrary than conventionalism would suggest. It seems implausible, for instance, that the convention for funeral dirges might just as easily have that they should be quick-paced and in major keys. Even in cases like the snare drum, it seems possible that the instrument was chosen for the battlefield in part because of the expressive character of its sonic profile.

The cliché that music is “the language of the emotions” is often considered as a possible starting point for a theory of musical expressiveness. The idea combines the attractive simplicity of conventionalism with the formalist notion that music’s order is to be understood in terms of syntax. (See Lerdahl & Jackendoff 1983 for a theory along the latter lines.) However, although Deryck Cooke (1959) and Leonard Meyer (1956) are often cited as proponents, it is not clear that anyone holds a full-blown version of the theory. The central problem is the great disparities between language and music, in terms of the ways in which each is both syntactic and semantic (Jackendoff 2011). A serious subsidiary problem is that even if music were about the emotions in the way that language can be, that would not account for music’s expressiveness. The sentence “I am sad” is about the emotions, but it is not expressive of sadness in the way a sad face is, though you could use either to express your sadness. Most people agree that music’s relation to emotion is more like that of a sad face than that of a sentence. (This last criticism is also applicable to Susanne Langer’s theory (1953) that music is about the emotions in a symbolic yet non-linguistic way.)

We now turn to theories that attempt to connect the notion of music’s expressiveness to actual felt emotions. One obvious way to do so is to argue that pieces of music or performances of them are expressions of such emotions—those of the composer or performer. There are two major problems with this “expression theory.” The first is that neither composers nor performers often experience the emotions their music is expressive of as it is produced. Nor does it seem unlikely that a composer could create, or a performer perform, a piece expressive of an emotion that she had never experienced. This is not to deny that a composer could write a piece expressive of her emotional state, but for the expression theory to be an account of musical expressiveness, at least all central cases of expressiveness must follow this model, which is not the case. Moreover, if a composer is to express her sadness, say, by writing a sad piece, she must pen the right kind of piece. In other words, if she is a bad composer she might fail to express her emotion. This brings us to the second major problem for the expression theory. If a composer can fail to express her emotions in a piece, then the music she writes is expressive independent of the emotion she is experiencing. Thus music’s expressiveness cannot be explained in terms of direct expression.

Those usually cited as classic expression theorists include Tolstoy (1898), Dewey (1934), and Collingwood (1938). (A classic critique is Tormey 1971: 97–127.) These theorists have been defended in recent discussions, however, from accusations that they hold the simple view outlined above (Ridley 2003, Robinson 2005: 229–57). Jenefer Robinson has attempted to revive the expression theory, though she defends it as an interesting and valuable use of music’s expressiveness, rather than an account of expressiveness itself (2005: 229–347; 2011).

A second way to link music’s expressiveness with actual felt emotions is through the audience. According to arousalism, the expressiveness of a passage of music amounts to its tendency to arouse that emotion in a competent listener. Arousalism faces several objections. First, some competent listeners seem emotionally unmoved by music (or are at least not moved to the specific emotions expressed by it). But perhaps the arousalist can simply restrict the class of listener to which his theory appeals to those who are so moved. Second, some emotions, such as fear, require a particular kind of intentional object (something threatening), yet there is no such object at hand when we hear fearful music. Thus it seems implausible to claim the music’s fearfulness resides in its arousal of fear in us. But perhaps the arousalist can broaden the class of aroused emotions to include appropriate responses to the expressed emotion, such as pity. Third, in many cases it seems that listeners respond emotionally to the expressiveness of the music. It is not clear that the arousalist can handle such cases non-circularly. (A sophisticated defense of the arousal theory is to be found in Matravers 1998: 145–224, though see the second thoughts in Matravers 2011. For an extended critique, see S. Davies 1994: 104–200.)

Despite the problems of the arousal theory as the whole story of musical expressiveness, there is a growing consensus, thanks largely to the work of Jenefer Robinson (1994, 2005), that our lower-level, less cognitive responses to music must play some role in the emotional expressiveness we attribute to it. However, this role is likely to be a causal one, rather than part of an analysis of what it is for music to be emotionally expressive.

Several theorists have defended accounts of musical expressiveness known variously as resemblance, contour, or appearance theories (e.g., Kivy 1989, though see Kivy 2002: 31–48 for recent qualms; Budd 1995: 133–54; S. Davies 1994: 221–67). The central idea is that music’s expressiveness consists in the resemblance between its dynamic character and that of various typical aspects of people experiencing emotions. The aspects appealed to include the phenomenology of the experience of the emotion, the emotion’s facial expression, the contour of vocal expression or bodily behavior of a person experiencing the emotion. Stephen Davies argues that such theories hold music to be expressive in a literal albeit secondary sense of the term. We say that a piece of music is sad in the same sense in which we say that a weeping willow is sad (S. Davies 2006: 183). Such uses are no more metaphorical than a claim that a chair has arms.

Jerrold Levinson agrees that there is an important resemblance between the contour of music expressive of an emotion and the contour of typical behavioral expressions of that emotion. He objects, however, that such an account cannot be the whole, or even the most fundamental part of the story (Levinson 1996a, 2006b). He drives in a wedge precisely at the point where an appeal is made to the resemblance between the music and typical behavioral expressions. He asks what the manner and extent of the resemblance between the two must be, precisely, in order for the music to count as expressive of some emotion. After all, everything resembles everything else in all sorts of ways, and so one could point out many resemblances between a funeral march and an expression of joy, or for that matter a cup of coffee and sadness. The resemblance theorist must give some account of why the funeral march, and not the cup of coffee, is expressive of sadness and not joy. Levinson claims that the obvious answer here is that the funeral march is “readily hearable as” an expression of sadness. If this is correct, then the resemblance the music bears to emotional behavior is logically secondary—a cause or ground of its expressiveness. The expressiveness itself resides in the music’s disposition to elicit the imaginative response in us of hearing the music as a literal expression of emotion. As a logical consequence, the imaginative experience prompted must include some agent whose expression the music literally is.

In reply to this kind of objection, Stephen Davies has emphasized the role of the listener’s response in resemblance theories. Such responses have always been appealed to by such theories, as evidenced by Malcolm Budd’s talk of “hearing as” (1995: 135–7), and Peter Kivy’s discussion of our tendency to “animate” that which we perceive (1980: 57–9). But Davies now makes the appeal quite explicit and central, devoting as much space to explication of the response-dependent nature of expressiveness as to the role of resemblance (2006). For Davies, the response of the competent listener upon which the expressiveness of the music depends is one of an experience of resemblance rather than imagined expression (2006: 181–2). Matteo Ravasio (2019b) argues that this leads to further problems.

Since Davies’s theory posits at base a contour-recognition experience while Levinson’s posits an imaginative experience of expression, the link between literal expression and musical expressiveness looks closer in Levinson’s theory than in Davies’s. An empirical consequence seems to be that Davies’s theory will predict weaker emotional responses to music than Levinson’s. Whether or not this is an advantage or disadvantage of the theory depends on the empirical facts about how we respond emotionally to music.

3.2 Emotions in the Listener
There are three main questions asked about our emotional responses to pure music, apart from what role they play in expressiveness. The first is analogous to the “paradox of fiction.” It is not clear why we should respond emotionally to music’s expressiveness when we know that no one is undergoing the emotions expressed. The second is a variant of the “paradox of tragedy.” If some music arouses “negative” emotional responses in us, such as sadness, why do we seek out the experience of such music? This leads to the more general question of the value of our emotional responses to music. The first two questions are addressed in this section, and the third in section 5.1.

Peter Kivy (1999) argues that those who report emotional reactions to music are confusing the pleasure they take in the beauty of the music, in all its expressive individuality, with the feeling of the emotion expressed. Though most philosophers appeal to ordinary experience and empirical data to reject the plausibility of Kivy’s position, they admit the problem that motivates it, namely, the conceptual tension between the nature of music and the nature of the emotions we feel in response to it. There is some consensus that emotions are cognitive, in the sense that they take intentional objects—they are about things—of certain kinds. For instance, in order to feel fear, one must believe that something is threatening (the “intentional object” of the emotion). When one listens to a sad piece of music, however, one knows there is nothing literally feeling sad, and thus it is puzzling that one should be made sad by the experience.

Part of the solution is that not all emotional responses (broadly construed) are cognitive (Robinson 1994; 2005: 387–400). For instance, it is no more puzzling that one could be startled by a fortissimo blow to a bass drum than that one could so respond to a thunderclap. Another part of the solution is that the music can be the object of our emotions, as when we are delighted by an effective ending to a long and complex piece.

As for emotional responses to music’s expressiveness, there are at least two possible explanations. One appeals to the phenomenon of “emotional contagion” or “mirroring responses” (S. Davies 1994: 279–307; 2006: 186–8). When surrounded by moping people, one tends to become sad. Moreover, such a “mood” is not about some intentional object. One is not necessarily sad for the mopers, nor whatever they are sad about, if anything. Similarly, when “surrounded” by music that presents an appearance of sadness, one might become sad, but not sad about the music, or anything else (Radford 1991). For critical discussion, see Robinson 2005: 379–412 and S. Davies 2011b.

If our experience of music’s expressiveness necessarily involves imagining that the music is a literal expression of emotion, then our emotional responses to that expressiveness are no more puzzling than emotional responses to other imagined expressive agents, such as fictional characters in novels. The advantage is only slight because the question of how and why we respond emotionally to fictions is itself a philosophical problem of some magnitude. Nonetheless, there are several theories available (see the supplement to the entry on imagination, §2). One difficulty with appealing to a solution to the paradox of fiction is that it is not clear that our emotional responses to the expressiveness of music are the same as those to emotionally expressive characters. For instance, the standard example of an emotional response to music is being made sad by a dirge, while the standard example of emotional response to fiction is (something like) to feel pity for a sad character. If the former is to be explained in the same way as the latter, we would expect listeners to feel pity in response to the funeral march (pity for the persona imagined to be expressing her sadness through it). However, we surely do feel sad (in some sense) in response to tragedy, and it is not obvious that we do not feel pity (or imagined pity, or whatever one’s preferred theory of emotional response to fiction posits) in response to sad music.

Leaving behind the topic of how and why we respond emotionally to music, we turn to the question of why we seek out music that arouses “negative” emotions in us, such as sadness, assuming henceforth that we are in fact aroused to such emotions. (Since this problem is a close analog of the “paradox of tragedy,” some of the references below are to literature not explicitly about music, but the transposition of the arguments to music is not difficult to imagine. (See also the supplement to the entry on imagination, §3.) Most solutions assume that our negative emotional response is a price we are willing to pay for the benefits of engaging with the piece in question. The benefits appealed to include understanding and appreciating the music, including the expressiveness responsible for the negative response (Goodman 1968: 247–51; S. Davies 1994: 311–20; Goldman 1995: 68; Robinson 2005: 348–78).

A different benefit is Aristotelian catharsis, in which our negative emotional response to expressive art results in a psychological purgation of the negative emotions (Aristotle 1987: 6, 1449b21–1450b20). A less therapeutic approach is the suggestion that, since these emotions are without “life implications” (that is, as discussed above, we are not sad about any actual tragic events), we are able to take advantage of our responses to savor these emotions, gain an understanding of them, and be reassured that we have the capacity to feel them (Levinson 1982). Two things that must be explained by any defender of this kind of response are, first, our persistence in seeking out music that elicits negative emotional experiences after we have received the resulting benefit and, second, the enjoyment we seem to take in these negative responses, as opposed to putting up with them for their related benefits.

A different kind of solution to the problem argues that responses such as sadness that are evoked by expressive music are not really negative. Hume (1757) argues, with respect to tragedy, that the pleasure we take in the mode of presentation of the content of an artwork does not simply counterbalance the negative emotion evoked, but rather subsumes and transforms it into a pleasurable feeling. Kendall Walton argues (also with respect to tragedy) that sadness is not in itself negative. Rather, it is the situation to which sadness is the response that is negative. Thus, though we would not seek out the death of a loved one, given the death we “welcome” the sorrow (K. Walton 1990: 255–9). Similarly, we cannot affect the sadness of a musical work by not listening to it, and so we welcome our sorrowful response to it as appropriate. Berys Gaut (2007: 203–26) argues that though sadness is typically aroused by situations we would prefer to avoid, sadness in response to artistic expressiveness is an exception and thus not negative in any paradoxical way. A difficulty for all three solutions is the extent to which they accord with our emotional experience in rejecting the characterization of our sadness as negative.

4. Understanding Music
A central topic in the understanding of narrative art forms, such as literature and film, is what constitutes an acceptable interpretation of a work. One debate concerns whether there is a single correct interpretation of any work or multiple acceptable interpretations. Another concerns the constraints on acceptable interpretations, e.g., the extent to which the artist’s intentions may or should be taken into account.

Though these questions seem equally applicable to musical works (S. Davies 2002a; Dubiel 2011), most of the literature on understanding music has focused on two more specifically musical topics: first, our understanding of basic musical features, such as pitch and rhythm and, second, interpretations of works of the sort given by music theorists. (For more detailed introductions to these and other topics in musical understanding, see S. Davies 2011c and Huovinen 2011.)

Before we turn to those topics, it is worth noting that two distinct activities go by the name of “interpretation” in music (and other performance arts): what might be called performative and critical interpretation (Levinson 1993). While a critical interpretation of a musical work (often called an analysis) is roughly equivalent to an interpretation of a novel—typically expressed linguistically—a performative interpretation is a way of playing or singing the work, typically expressed in a performance of it. It is not easy to clarify the relationship between these two kinds of musical interpretation, but see Levinson 1993, Maus 1999, Thom 2007, Neufeld 2012, and Dodd 2020a.

4.1 Basic Musical Understanding
Animals can hear music in a sense—your dog might be frightened by the loud noise emitted by your stereo. People, by contrast, can understand the music they hear. What constitutes this experience of understanding music? To use an analogy, while the mere sound of a piece of music might be represented by a sonogram, our experience of it as music is better represented by something like a marked-up score. We hear individual notes that make up distinct melodies, harmonies, rhythms, sections, and so on, and the interaction between these elements. Such musical understanding comes in degrees along a number of dimensions. Your understanding of a given piece or style may be deeper than mine, while the reverse is true for another piece or style. My general musical understanding may be narrow, in the sense that I only understand one kind of music, while you understand many different kinds (Budd 1985b: 233–5; S. Davies 2011c: 88–95). Moreover, different pieces or kinds of pieces may call on different abilities, since some music has no harmony to speak of, some no melody, and so on. Many argue that, in addition to purely musical features, understanding the emotions expressed in a piece is essential to adequately understanding it (e.g., Ridley 1993; S. Davies 1994; Levinson 1990d: 30; Scruton 1997; Robinson 2005: 348–78).

At the base of the musical experience seem to be (i) the experience of tones, as opposed to mere sounds of various frequencies, where a tone is heard as being in “musical space,” that is, as bearing relations to other tones such as being higher or lower, or of the same kind (at the octave), and (ii) the experience of movement, as when we hear a melody as leaping up or wandering far afield and then coming to rest where it began. Roger Scruton (1983; 1997: 1–96) argues that these experiences are irreducibly metaphorical, since they involve the application of spatial concepts to that which is not literally spatial. (There is no identifiable individual that moves from place to place in a melody (S. Davies 1994: 229–34).) Malcolm Budd (1985b) argues that to appeal to metaphor in this context is unilluminating since, first, it is unclear what it means for an experience to be metaphorical and, second, a metaphor is only given meaning through its interpretation, which Scruton not only fails to give, but argues is unavailable. Budd suggests that the metaphor is reducible, and thus eliminable, apparently in terms of purely musical (i.e., non-spatial) concepts or vocabulary. Stephen Davies (1994: 234–40) doubts that the spatial vocabulary can be eliminated, but he is sympathetic to Budd’s rejection of the centrality of metaphor. Instead, he argues that our use of spatial and motion terms to describe music is a secondary, but literal, use of those terms that is widely used to describe temporal processes, such as the ups and downs of the stock market, the theoretical position one occupies, one’s spirits plunging, and so on. The debate continues in Budd 2003, Scruton 2004, and S. Davies 2011d.

Davies is surely right about the ubiquity of the application of the language of space and motion to processes that lack individuals located in space. The appeal to secondary literal meanings, however, can seem as unsatisfying as the appeal to irreducible metaphor. We do not hear music simply as a temporal process, it might be objected, but as moving in the primary sense of the word, though we know that it does not literally so move. Andrew Kania (2015) develops a position out of this intuition by emphasizing Scruton’s appeal to imagination while dropping the appeal to metaphor, arguing that hearing the music as moving is a matter of imagining that its constituent sounds move. (See also de Clercq 2007 and Trivedi 2011: 116–18.) Kania explicitly models his theory on the popular Waltonian theory of fiction (K. Walton 1990), though Walton seems to resist the application of his theory to basic musical understanding because of the differences between music and more paradigmatically representational arts (K. Walton 1988: 358–9, 1994: 53–4).

Apart from pitch space and melodic movement, there has been little philosophical discussion of either the nature and understanding of basic musical features such as melody, rhythm, meter, and harmony or how these elements work together in complex musical wholes. But see Roger Scruton 1997: 19–79, 2007; Stephen Davies 2001: 47–71; Hamilton 2007: 119–52; and Cheyne, Hamilton, and Paddison 2020.

It is widely acknowledged that explicit music-theoretical knowledge can aid deeper musical understanding and is essential for the adequate description and understanding of musical experiences—including one’s own (Kivy 1990). However, several philosophers have argued that one need not possess these concepts explicitly (nor the correlative vocabulary) in order to listen with understanding (Budd 1985b; 245–8; S. Davies 1994: 346–9; Levinson 1990d: 35–41). Mark DeBellis (1995: 117–31) argues that understanding fairly basic features of music, such as different kinds of cadences, requires a fused experience in which one applies a concept such as dominant seventh in one’s perception of the musical sounds. Stephen Davies (2011c: 88–94) responds that the serious but untutored listener should be able to develop such concepts, and thus have such experiences. Erkki Huovinen (2008) provides an example intended to cast doubt on this. Suppose that a melody is transposed from C major to D-flat major, but in a lower octave. One listener might hear the melody as reappearing higher, since D-flat is a half-step above C, while another might hear it as lower, since the constituent pitches of the second appearance are all lower than those of the first. Only a listener who understands the sense in which both these claims are true—that the melody has been transposed down a major seventh—truly understands what is going on musically. Yet such concepts of pitch organization … are not usually learned without some tuition (Huovinen 2008: 325).

4.2 Higher-level Musical Understanding
For various art-historical reasons, formalism was the dominant approach to music-theoretic analysis, that is, the critical interpretation of musical works, throughout the twentieth century. (Hamilton 2007: 66–94 & 153–91 provides a useful discussion of the history from a philosophical perspective.) In short, the value of works of music was held to reside primarily in their large-scale harmonic structure.

Jerrold Levinson (1997) makes a case against such “architectonicism” in favor of “concatenationism,” the view that basic musical understanding consists in following the musical and emotional qualities of passages of music, and transitions between them, that are short enough to be apprehended as a single experience (“quasi-hearing”). He qualifies this basic idea considerably, allowing for the experience of previous parts of the piece, and anticipation of future parts, to modify one’s experience of the music in the moment. He also allows that architectonic awareness may play a role in enhancing one’s moment-to-moment experience, and may even play an ineliminable part in the understanding of some pieces. Nonetheless, Levinson maintains that the part played by architectonic knowledge in basic musical understanding is minimal, and that the cases where architectonic knowledge is necessary are very much the exception.

Peter Kivy has taken up the gauntlet on behalf of architectonicism (2001; see also S. Davies 2011c: 95–9). While Kivy acknowledges that the kinds of experiences Levinson champions are necessary to basic musical understanding, he defends the idea that grasping the large-scale form of most pieces of Western classical music, at least, is necessary for an adequate understanding of them. He does not deny that the experience of the form of a piece in listening to it is more intellectual than quasi-hearing, but he rejects Levinson’s argument that it is non-perceptual, and thus marginal to an adequate experience of it as music. Rather, Kivy argues, such experience is a matter of bringing one’s perceptions under sophisticated concepts. (A tactic Kivy does not consider is an attempt to hoist Levinson with his own contextualist petard, arguing that even if architectonic listening is non-perceptual it is a well-established mode of understanding pieces of music in the Western classical music world, and thus that to argue music must be understood primarily perceptually is to beg the question.)

The extent of the disagreement between the architectonicist and the concatenationist is unclear. They agree that the aspect of musical understanding the other emphasizes is a non-negligible component in the full understanding of a musical work. Levinson has been explicit since the first publication of his view that he intends it more as a polemic against and corrective to architectonicism, rather than as a replacement for it (1997: ix–xi; 1999: 485; 2006a). Perhaps that purpose has now been fulfilled, but see Huovinen 2013 for a revival of the debate and an attempted synthesis.

5. Music and Value
5.1 Music’s Artistic Value
Most philosophical discussions of the value of music are implicitly restricted to the artistic value of purely instrumental musical works. To the extent that such discussions are motivated by the abstract nature of such music (see below), it is not clear to what extent they can be extended to musical hybrids such as song. Moreover, as we saw in section 1.2, it is not obvious that all music is art. Perhaps non-art music can be artistically valuable, but it presumably has other values; a complete theory of the value of music would apparently have to account for those values. (Presumably, art music can also have non-artistic value.)

Following the literature, however, the remainder of this subsection considers the artistic value of purely musical works. This is not the place to go into the many disputes about the nature of aesthetic and artistic value. (For an excellent introduction, see Stecker 2003b.) For our purposes, we can note there are two central points about artistic value on which there is some consensus. First, most philosophers take the value of artworks to be intrinsic (or inherent) to them, in the sense that the value of a work is tied essentially to the experience that the work affords. Thus, artworks are not (properly) valued merely instrumentally, as means to some end, but “for” or “in” themselves (Budd 1995: 1–16; S. Davies 1987: 198–200; Scruton 1997: 374–6; Levinson 1992: 15–17).

The question that naturally arises next is what it is about the experience an artwork affords that makes it valuable. That pleasure is a non-negligible part of the answer to this question is the second point upon which there is some consensus (S. Davies 1987: 198–205; Levinson 1992; Kivy 1997b: 212–17). However, concomitant with this consensus is an acknowledgment that simple pleasure taken, say, in the sensuousness of the musical sounds is too trivial to ground the great value widely attributed to music. In looking for other sources, the puzzle that arises is that music is supposed to be an abstract art, par excellence. If this means that music is divorced from everything else that concerns us in the “real world” (that is, extra-musical life), it is puzzling why we should find so valuable the experiences musical works afford.

There are a couple of dimensions to most solutions of the puzzle of pure music’s value. One is the extent to which it is agreed that music really is abstract. To the extent that one thinks that music is not divorced from the real world, one will be able to argue that music’s value is at least no more puzzling than the value of arts more obviously related to the real world, such as literature and representational painting and sculpture. The other dimension to most solutions of the puzzle of pure music’s value is the extent to which one thinks the abstractness of music is the source of its value. Thus, two theorists might agree on the extent to which music is related to the real world (by being expressive, say), yet one locate its primary value in that expressiveness while the other locates it in its abstract, purely formal features.

Unsurprisingly, those who take the experience of music’s expressiveness to be a more intimately emotional one (through being predicated on imaginative engagement with the music, say), tend to emphasize that experience as more central to musical understanding, and thus attribute a larger part of music’s value to its expressiveness. Those, on the other hand, whose theory of the experience of musical expressiveness is more distanced (a matter of noticed resemblance, say), tend to place less weight on this element in their theories of musical value. At one extreme of this spectrum is the position that denies music to be expressive at all, and thus cannot attribute any of music’s value to its expressiveness (most notably Hanslick 1854; see also Zangwill 2004). Most theorists agree, however, that music’s value is to be located in different kinds of experience, including the experience of formal and expressive features; their disagreements are mostly about the relative weight of these different kinds of experiences in a complete account of musical value.

The extent of the disagreement between various parties to this dispute is not clear. Those defending the value of music’s expressiveness tend to claim that its contribution to overall musical value is significant, but many stop short even of according it primary value, and do not argue against the value of formal elements of musical works (Ridley 1995: 192–6; Levinson 1982, 1992: 20–2, 1996a: 124–5; Robinson 2005: 413; Young 2014: 150–4). They content themselves rather with pointing out the ways in which expressiveness can be valuable, focusing largely on the value of the emotional responses such expressiveness elicits in us. These include many of the features discussed above with respect to our interest in listening to music that arouses negative affective states in the listener. To recap, our emotional responses to music’s expressiveness can enable us to savor, understand, and even (to some extent) experience emotions in a “safe” way. They can provide us with a cathartic release, and enable us to participate in a kind of communication with the composer or communion with other members of our musical culture (Levinson 1982, 1996a; Higgins 1991, 2012; S. Davies 1994: 271). Emphasizing this last point, Roger Scruton argues that music’s value is quasi-moral, in that the kinds of music one responds to, or those valued in a particular culture, reflect the state of that individual’s or culture’s “soul” (1997: 380–91; see also S. Davies 1994: 275–6.) Stephen Davies (1987: 207–12) has argued that there are beneficial consequences of an interest in music in general, such as heightened emotional and aural sensitivity, which are not properly valued as consequences of listening to individual pieces, but which lead us to value musical culture as a whole (just as we value kindness for its consequences in general, while rejecting instrumental motivations for kind acts as inappropriate).

By contrast, those who defend the value of formal features tend to argue that the value of those features is primary, and that the value of music’s expressiveness is overrated. Peter Kivy, for instance, argues that expressive properties serve merely to highlight musical structure, as color might be used by the painter to emphasize contour or mass. Other expressive properties serve as structural properties in their own right (1990: 196). (See also Sharpe 2000: 1–83, and Zangwill 2004.)

Alan Goldman (1992) argues against the idea that music is particularly suited to the expression of emotion, claiming that representational arts such as painting and literature are better at this. Moreover, he disputes the grounds of the value of expressiveness given above. For example, he denies that music can teach us much about the emotions, and that we can savor our negative emotional responses to expressive music. Similarly, after an extensive discussion of the nature of musical expressiveness, Malcolm Budd argues that such expressiveness cannot come close to explaining music’s value (1995: 155–7). He points to the facts that much valuable music is not expressive and that the equal expressiveness of different pieces would be outweighed in a comparative evaluation by the differences between them in terms of formal value.

Both Goldman and Budd locate the value of pure music precisely in the abstractness that to some seems the greatest obstacle to explaining that value. Budd (1995: 164–71) points out that we have an extensive interest in abstract forms outside the realm of music, such as those of natural formations and in the decorative arts, and that such forms are capable of possessing valued aesthetic properties, such as beauty, elegance, and so on. Thus, it is no surprise that we value highly the works of an art of abstract forms. Goldman (1992), by contrast, emphasizes the detachment from the world of practical affairs implied by music’s abstractness. The complexity of great musical works demands the active engagement of our cognitive faculties, which we find rewarding, yet not in the pursuit of some practical goal that could be frustrated.

These issues are thrown into sharp relief in the debate over how instrumental musical works could be “profound.” See Kivy 1990: 202–18, 1997b: 140–78, 2003; Levinson 1992; White 1992; Ridley 1995, 2004: 132–65; S. Davies 2002b; Dodd 2014b.

There is no space here to discuss the evaluation of musical works and performances. See S. Davies 1987, Levinson 1990e, and Gracyk 2011.

5.2 Music’s Moral Value
There are musical aspects or elements of many uncontroversially representational art forms, such as song. Jeanette Bicknell (2015: 81–91) and Aaron Smuts (2013) discusses the ethics of song performance. But there has been little discussion, in the analytic tradition, of the relationship between musical and ethical values (as opposed to musical examples of more general ethical concerns, such as cultural appropriation). Kathleen Higgins (1991, 2012) and Roger Scruton (1997: 457–508) argue in very different ways that music is – or should be – central to our thinking about ethics. Garry Hagberg has explored many connections between improvisatory jazz practice, ethics, and politics (2002, 2006, 2008, 2021; see also Higgins 1991: 177). Peter Kivy (2008) argues against music’s capacity to affect our moral knowledge, behavior, or character. Jerrold Levinson (2013: 51–5), Philip Alperson (2014), and James Harold (2016) defend music’s moral efficacy.

The debate over whether an artwork’s moral flaws are artistic flaws has focused almost exclusively on representational (especially narrative) art forms. (Gaut (2007) offers an excellent overview.) Music has largely been ignored because it has been assumed to lack sufficient representational capacity to embody an attitude toward some object. Maria José Alcaraz León (2012), however, argues that music’s emotional expressiveness is enough to apply arguments about whether moral flaws are artistic flaws to pure instrumental music. (For critical discussion, see Kania 2020: 254–5.) Musicologist Susan McClary argues that canonical works of instrumental classical music oppress women by expressing a positive attitude toward narratives of the subjection of feminine elements (e.g., certain musical themes) by masculine ones. (See, for example, McClary 1991: 19–23, 53–79; for critical discussion, see Maus (2011)

1. The Concept of Taste
The concept of the aesthetic descends from the concept of taste. Why the concept of taste commanded so much philosophical attention during the 18th century is a complicated matter, but this much is clear: the eighteenth-century theory of taste emerged, in part, as a corrective to the rise of rationalism, particularly as applied to beauty, and to the rise of egoism, particularly as applied to virtue. Against rationalism about beauty, the eighteenth-century theory of taste held the judgment of beauty to be immediate; against egoism about virtue, it held the pleasure of beauty to be disinterested.

1.1 Immediacy
Rationalism about beauty is the view that judgments of beauty are judgments of reason, i.e., that we judge things to be beautiful by reasoning it out, where reasoning it out typically involves inferring from principles or applying concepts. At the beginning of the 18th century, rationalism about beauty had achieved dominance on the continent, and was being pushed to new extremes by “les géomètres,” a group of literary theorists who aimed to bring to literary criticism the mathematical rigor that Descartes had brought to physics. As one such theorist put it:

The way to think about a literary problem is that pointed out by Descartes for problems of physical science. A critic who tries any other way is not worthy to be living in the present century. There is nothing better than mathematics as propaedeutic for literary criticism. (Terrasson 1715, Preface, 65; quoted in Wimsatt and Brooks 1957, 258)
It was against this, and against more moderate forms of rationalism about beauty, that mainly British philosophers working mainly within an empiricist framework began to develop theories of taste. The fundamental idea behind any such theory—which we may call the immediacy thesis—is that judgments of beauty are not (or at least not canonically) mediated by inferences from principles or applications of concepts, but rather have all the immediacy of straightforwardly sensory judgments. It is the idea, in other words, that we do not reason to the conclusion that things are beautiful, but rather “sense” that they are. Here is an early expression of the thesis, from Jean-Baptiste Dubos’s Critical Reflections on Poetry, Painting, and Music, which first appeared in 1719:

Do we ever reason, in order to know whether a ragoo be good or bad; and has it ever entered into any body’s head, after having settled the geometrical principles of taste, and defined the qualities of each ingredient that enters into the composition of those messes, to examine into the proportion observed in their mixture, in order to decide whether it be good or bad? No, this is never practiced. We have a sense given us by nature to distinguish whether the cook acted according to the rules of his art. People taste the ragoo, and tho’ unacquainted with those rules, they are able to tell whether it be good or no. The same may be said in some respect of the productions of the mind, and of pictures made to please and move us. (Dubos 1748, vol. II, 238–239)
And here is a late expression, from Kant’s 1790 Critique of the Power of Judgment:

If someone reads me his poem or takes me to a play that in the end fails to please my taste, then he can adduce Batteux or Lessing, or even older and more famous critics of taste, and adduce all the rules they established as proofs that his poem is beautiful… . I will stop my ears, listen to no reasons and arguments, and would rather believe that those rules of the critics are false … than allow that my judgment should be determined by means of a priori grounds of proof, since it is supposed to be a judgment of taste and not of the understanding of reason. (Kant 1790, 165)
But the theory of taste would not have enjoyed its eighteenth-century run, nor would it continue now to exert its influence, had it been without resources to counter an obvious rationalist objection. There is a wide difference—so goes the objection—between judging the excellence of a ragout and judging the excellence of a poem or a play. More often than not, poems and plays are objects of great complication. But taking in all that complication requires a lot of cognitive work, including the application of concepts and the drawing of inferences. Judging the beauty of poems and plays, then, is evidently not immediate and so evidently not a matter of taste.

The chief way of meeting this objection was first to distinguish between the act of grasping the object preparatory to judging it and the act of judging the object once grasped, and then to allow the former, but not the latter, to be as concept- and inference-mediated as any rationalist might wish. Here is Hume, with characteristic clarity:

[I]n order to pave the way for [a judgment of taste], and give a proper discernment of its object, it is often necessary, we find, that much reasoning should precede, that nice distinctions be made, just conclusions drawn, distant comparisons formed, complicated relations examined, and general facts fixed and ascertained. Some species of beauty, especially the natural kinds, on their first appearance command our affection and approbation; and where they fail of this effect, it is impossible for any reasoning to redress their influence, or adapt them better to our taste and sentiment. But in many orders of beauty, particularly those of the fine arts, it is requisite to employ much reasoning, in order to feel the proper sentiment. (Hume, 1751, Section I)
Hume—like Shaftesbury and Hutcheson before him, and Reid after him (Cooper 1711, 17, 231; Hutcheson 1725, 16–24; Reid 1785, 760–761)—regarded the faculty of taste as a kind of “internal sense.” Unlike the five “external” or “direct” senses, an “internal” (or “reflex” or “secondary”) sense is one that depends for its objects on the antecedent operation of some other mental faculty or faculties. Reid characterizes internal sense as follows:

Beauty or deformity in an object, results from its nature or structure. To perceive the beauty therefore, we must perceive the nature or structure from which it results. In this the internal sense differs from the external. Our external senses may discover qualities which do not depend upon any antecedent perception… . But it is impossible to perceive the beauty of an object, without perceiving the object, or at least conceiving it. (Reid 1785, 760–761)
Because of the highly complex natures or structures of many beautiful objects, there will have to be a role for reason in their perception. But perceiving the nature or structure of an object is one thing. Perceiving its beauty is another.

1.2 Disinterest
Egoism about virtue is the view that to judge an action or trait virtuous is to take pleasure in it because you believe it to serve some interest of yours. Its central instance is the Hobbesian view—still very much on early eighteenth-century minds—that to judge an action or trait virtuous is to take pleasure in it because you believe it to promote your safety. Against Hobbesian egoism a number of British moralists—preeminently Shaftesbury, Hutcheson, and Hume—argued that, while a judgment of virtue is a matter of taking pleasure in response to an action or trait, the pleasure is disinterested, by which they meant that it is not self-interested (Cooper 1711, 220–223; Hutcheson 1725, 9, 25–26; Hume 1751, 218–232, 295–302). One argument went roughly as follows. That we judge virtue by means of an immediate sensation of pleasure means that judgments of virtue are judgments of taste, no less than judgments of beauty. But pleasure in the beautiful is not self-interested: we judge objects to be beautiful whether or not we believe them to serve our interests. But if pleasure in the beautiful is disinterested, there is no reason to think that pleasure in the virtuous cannot also be (Hutcheson 1725, 9–10).

The eighteenth-century view that judgments of virtue are judgments of taste highlights a difference between the eighteenth-century concept of taste and our concept of the aesthetic, since for us the concepts aesthetic and moral tend oppose one another such that a judgment’s falling under one typically precludes its falling under the other. Kant is chiefly responsible for introducing this difference. He brought the moral and the aesthetic into opposition by re-interpreting what we might call the disinterest thesis—the thesis that pleasure in the beautiful is disinterested (though see Cooper 1711, 222 and Home 2005, 36–38 for anticipations of Kant’s re-interpretation).

According to Kant, to say that a pleasure is interested is not to say that it is self-interested in the Hobbesian sense, but rather that it stands in a certain relation to the faculty of desire. The pleasure involved in judging an action to be morally good is interested because such a judgment issues in a desire to bring the action into existence, i.e., to perform it. To judge an action to be morally good is to become aware that one has a duty to perform the action, and to become so aware is to gain a desire to perform it. By contrast, the pleasure involved in judging an object to be beautiful is disinterested because such a judgment issues in no desire to do anything in particular. If we can be said to have a duty with regard to beautiful things, it appears to be exhausted in our judging them aesthetically to be beautiful. That is what Kant means when he says that the judgment of taste is not practical but rather “merely contemplative” (Kant 1790, 95).

By thus re-orienting the notion of disinterest, Kant brought the concept of taste into opposition with the concept of morality, and so into line, more or less, with the present concept of the aesthetic. But if the Kantian concept of taste is continuous, more or less, with the present-day concept of the aesthetic, why the terminological discontinuity? Why have we come to prefer the term ‘aesthetic’ to the term ‘taste’? The not very interesting answer appears to be that we have preferred an adjective to a noun. The term ‘aesthetic’ derives from the Greek term for sensory perception, and so preserves the implication of immediacy carried by the term ‘taste.’ Kant employed both terms, though not equivalently: according to his usage, ‘aesthetic’ is broader, picking out a class of judgments that includes both the normative judgment of taste and the non-normative, though equally immediate, judgment of the agreeable. Though Kant was not the first modern to use ‘aesthetic’ (Baumgarten had used it as early as 1735), the term became widespread only, though quickly, after his employment of it in the third Critique. Yet the employment that became widespread was not exactly Kant’s, but a narrower one according to which ‘aesthetic’ simply functions as an adjective corresponding to the noun “taste.” So for example we find Coleridge, in 1821, expressing the wish that he “could find a more familiar word than aesthetic for works of taste and criticism,” before going on to argue:

As our language … contains no other useable adjective, to express coincidence of form, feeling, and intellect, that something, which, confirming the inner and the outward senses, becomes a new sense in itself … there is reason to hope, that the term aesthetic, will be brought into common use. (Coleridge 1821, 254)
The availability of an adjective corresponding to “taste” has allowed for the retiring of a series of awkward expressions: the expressions “judgment of taste,” “emotion of taste” and “quality of taste” have given way to the arguably less offensive ‘aesthetic judgment,’ ‘aesthetic emotion,’ and ‘aesthetic quality.’ However, as the noun ‘taste’ phased out, we became saddled with other perhaps equally awkward expressions, including the one that names this entry.

2. The Concept of the Aesthetic
Much of the history of more recent thinking about the concept of the aesthetic can be seen as the history of the development of the immediacy and disinterest theses.

2.1 Aesthetic Objects
Artistic formalism is the view that the artistically relevant properties of an artwork—the properties in virtue of which it is an artwork and in virtue of which it is a good or bad one—are formal merely, where formal properties are typically regarded as properties graspable by sight or by hearing merely. Artistic formalism has been taken to follow from both the immediacy and the disinterest theses (Binkley 1970, 266–267; Carroll 2001, 20–40). If you take the immediacy thesis to imply the artistic irrelevance of all properties whose grasping requires the use of reason, and you include representational properties in that class, then you are apt to think that the immediacy thesis implies artistic formalism. If you take the disinterest thesis to imply the artistic irrelevance of all properties capable of practical import, and you include representational properties in that class, then you are apt to think that the disinterest thesis implies artistic formalism.

This is not to suggest that the popularity enjoyed by artistic formalism during the late 19th and early 20th centuries owed mainly to its inference from the immediacy or disinterest theses. The most influential advocates of formalism during this period were professional critics, and their formalism derived, at least in part, from the artistic developments with which they were concerned. As a critic Eduard Hanslick advocated for the pure music of Mozart, Beethoven, Schumann, and later Brahms, and against the dramatically impure music of Wagner; as a theorist he urged that music has no content but “tonally moving forms” (Hanslick 1986, 29). As a critic Clive Bell was an early champion of the post-Impressionists, especially Cezanne; as a theorist he maintained that the formal properties of painting—“relations and combinations of lines and colours”—alone have artistic relevance (Bell 1958, 17–18). As a critic Clement Greenberg was abstract expressionism’s ablest defender; as a theorist he held painting’s “proper area of competence” to be exhausted by flatness, pigment, and shape (Greenberg 1986, 86–87).

Not every influential defender of formalism has also been a professional critic. Monroe Beardsley, who arguably gave formalism its most sophisticated articulation, was not (Beardsley 1958). Nor is Nick Zangwill, who recently has mounted a spirited and resourceful defense of a moderate version of formalism (Zangwill 2001). But formalism has always been sufficiently motivated by art-critical data that once Arthur Danto made the case that the data no longer supported it, and perhaps never really had, formalism’s heyday came to an end. Inspired in particular by Warhol’s Brillo Boxes, which are (more or less) perceptually indistinguishable from the brand-printed cartons in which boxes of Brillo were delivered to supermarkets, Danto observed that for most any artwork it is possible to imagine both (a) another object that is perceptually indiscernible from it but which is not an artwork, and (b) another artwork that is perceptually indiscernible from it but which differs in artistic value. From these observations he concluded that form alone neither makes an artwork nor gives it whatever value it has (Danto 1981, 94–95; Danto 1986, 30–31; Danto 1997, 91).

But Danto has taken the possibility of such perceptual indiscernibles to show the limitations not merely of form but also of aesthetics, and he has done so on the grounds, apparently, that the formal and the aesthetic are co-extensive. Regarding a urinal Duchamp once exhibited and a perceptual indiscernible ordinary urinal, Danto maintains that

aesthetics could not explain why one was a work of fine art and the other not, since for all practical purposes they were aesthetically indiscernible: if one was beautiful, the other one had to be beautiful, since they looked just alike. (Danto 2003, 7)
But the inference from the limits of the artistically formal to the limits of the artistically aesthetic is presumably only as strong as the inferences from the immediacy and disinterest theses to artistic formalism, and these are not beyond question. The inference from the disinterest thesis appears to go through only if you employ a stronger notion of disinterest than the one Kant understands himself to be employing: Kant, it is worth recalling, regards poetry as the highest of the fine arts precisely because of its capacity to employ representational content in the expression of what he calls ‘aesthetic ideas’ (Kant 1790, 191–194; see Costello 2008 and 2013 for extended treatment of the capacity of Kantian aesthetics to accommodate conceptual art). The inference from the immediacy thesis appears to go through only if you employ a notion of immediacy stronger than the one Hume, for example, takes himself to be defending when he claims (in a passage quoted in section1.1) that “in many orders of beauty, particularly those of the fine arts, it is requisite to employ much reasoning, in order to feel the proper sentiment” (Hume 1751, 173). It may be that artistic formalism results if you push either of the tendencies embodied in the immediacy and disinterest theses to extremes. It may be that the history of aesthetics from the 18th century to the mid-Twentieth is largely the history of pushing those two tendencies to extremes. It does not follow that those tendencies must be so pushed.

Consider Warhol’s Brillo Boxes. Danto is right to maintain that the eighteenth-century theorist of taste would not know how to regard it as an artwork. But this is because the eighteenth-century theorist of taste lives in the 18th century, and so would be unable to situate that work in its twentieth-century art-historical context, and not because the kind of theory she holds forbids her from situating a work in its art-historical context. When Hume, for instance, observes that artists address their works to particular, historically-situated audiences, and that a critic therefore “must place herself in the same situation as the audience” to whom a work is addressed (Hume 1757, 239), he is allowing that artworks are cultural products, and that the properties that works have as the cultural products they are are among the “ingredients of the composition” that a critic must grasp if she is to feel the proper sentiment. Nor does there seem to be anything in the celebrated conceptuality of Brillo Boxes, nor of any other conceptual work, that ought to give the eighteenth-century theorist pause. Francis Hutcheson asserts that mathematical and scientific theorems are objects of taste (Hutcheson 1725, 36–41). Alexander Gerard asserts that scientific discoveries and philosophical theories are objects of taste (Gerard 1757, 6). Neither argues for his assertion. Both regard it as commonplace that objects of intellect may be objects of taste as readily as objects of sight and hearing may be. Why should the present-day aesthetic theorist think otherwise? If an object is conceptual in nature, grasping its nature will require intellectual work. If grasping an object’s conceptual nature requires situating it art-historically, then the intellectual work required to grasp its nature will include situating it art-historically. But—as Hume and Reid held (see section 1.1)—grasping the nature of an object preparatory to aesthetically judging it is one thing; aesthetically judging the object once grasped is another.

Though Danto has been the most influential and persistent critic of formalism, his criticisms are no more decisive than those advanced by Kendall Walton in his essay “Categories of Art.” Walton’s anti-formalist argument hinges on two main theses, one psychological and one philosophical. According to the psychological thesis, which aesthetic properties we perceive a work as having depends on which category we perceive the work as belonging to. Perceived as belonging to the category of painting, Picasso’s Guernica will be perceived as “violent, dynamic, vital, disturbing” (Walton 1970, 347). But perceived as belonging to the category of “guernicas”—where guernicas are works with “surfaces with the colors and shapes of Picasso’s Guernica, but the surfaces are molded to protrude from the wall like relief maps of different kinds of terrain”—Picasso’s Guernica will be perceived not as violent and dynamic, but as “cold, stark, lifeless, or serene and restful, or perhaps bland, dull, boring” (Walton 1970, 347). That Picasso’s Guernica can be perceived both as violent and dynamic and as not violent and not dynamic might be thought to imply that there is no fact of the matter whether it is violent and dynamic. But this implication holds only on the assumption that there is no fact of the matter which category Picasso’s Guernica actually belongs to, and this assumption appears to be false given that Picasso intended that Guernica be a painting and did not intend that it be a guernica, and that the category of paintings was well-established in the society in which Picasso painted it while the category of guernicas was not. Hence the philosophical thesis, according to which the aesthetic properties a work actually has are those it is perceived as having when perceived as belonging to the category (or categories) it actually belongs to. Since the properties of having been intended to be a painting and having been created in a society in which painting is well-established category are artistically relevant though not graspable merely by seeing (or hearing) the work, it seems that artistic formalism cannot be true. “I do not deny,” Walton concludes, “that paintings and sonatas are to be judged solely on what can be seen or heard in them—when they are perceived correctly. But examining a work with the senses can by itself reveal neither how it is correct to perceive it, nor how to perceive it that way” (Walton 1970, 367).

But if we cannot judge which aesthetic properties paintings and sonatas have without consulting the intentions and the societies of the artists who created them, what of the aesthetic properties of natural items? With respect to them it may appear as if there is nothing to consult except the way they look and sound, so that an aesthetic formalism about nature must be true. Allen Carlson, a central figure in the burgeoning field of the aesthetics of nature, argues against this appearance. Carlson observes that Walton’s psychological thesis readily transfers from works of art to natural items: that we perceive Shetland ponies as cute and charming and Clydesdales as lumbering surely owes to our perceiving them as belonging to the category of horses (Carlson 1981, 19). He also maintains that the philosophical thesis transfers: whales actually have the aesthetic properties we perceive them as having when we perceive them as mammals, and do not actually have any contrasting aesthetic properties we might perceive them to have when we perceive them as fish. If we ask what determines which category or categories natural items actually belong to, the answer, according to Carlson, is their natural histories as discovered by natural science (Carlson 1981, 21–22). Inasmuch as a natural item’s natural history will tend not to be graspable by merely seeing or hearing it, formalism is no truer of natural items than it is of works of art.

The claim that Walton’s psychological thesis transfers to natural items has been widely accepted (and was in fact anticipated, as Carlson acknowledges, by Ronald Hepburn (Hepburn 1966 and 1968)). The claim that Walton’s philosophical thesis transfers to natural items has proven more controversial. Carlson is surely right that aesthetic judgments about natural items are prone to be mistaken insofar as they result from perceptions of those items as belonging to categories to which they do not belong, and, insofar as determining which categories natural items actually belong to requires scientific investigation, this point seems sufficient to undercut the plausibility of any very strong formalism about nature (see Carlson 1979 for independent objections against such formalism). Carlson, however, also wishes to establish that aesthetic judgments about natural items have whatever objectivity aesthetic judgments about works of art do, and it is controversial whether Walton’s philosophical claim transfers sufficiently to support such a claim. One difficulty, raised by Malcolm Budd (Budd 2002 and 2003) and Robert Stecker (Stecker1997c), is that since there are many categories in which a given natural item may correctly be perceived, it is unclear which correct category is the one in which the item is perceived as having the aesthetic properties it actually has. Perceived as belonging to the category of Shetland ponies, a large Shetland pony may be perceived as lumbering; perceived as belonging to the category of horses, the same pony may be perceived as cute and charming but certainly not lumbering. If the Shetland pony were a work of art, we might appeal to the intentions (or society) of its creator to determine which correct category is the one that fixes its aesthetic character. But as natural items are not human creations they can give us no basis for deciding between equally correct but aesthetically contrasting categorizations. It follows, according to Budd, “the aesthetic appreciation of nature is endowed with a freedom denied to the appreciation of art” (Budd 2003, 34), though this is perhaps merely another way of saying that the aesthetic appreciation of art is endowed with an objectivity denied to the appreciation of nature.

2.2 Aesthetic Judgment
The eighteenth-century debate between rationalists and theorists of taste (or sentimentalists) was primarily a debate over the immediacy thesis, i.e., over whether we judge objects to be beautiful by applying principles of beauty to them. It was not primarily a debate over the existence of principles of beauty, a matter over which theorists of taste might disagree. Kant denied that there are any such principles (Kant 1790, 101), but both Hutcheson and Hume affirmed their existence: they maintained that although judgments of beauty are judgments of taste and not of reason, taste nevertheless operates according to general principles, which might be discovered through empirical investigation (Hutcheson 1725, 28–35; Hume 1757, 231–233).

It is tempting to think of recent debate in aesthetics between particularists and generalists as a revival of the eighteenth-century debate between rationalists and theorists of taste. But the accuracy of this thought is difficult to gauge. One reason is that it is often unclear whether particularists and generalists take themselves merely to be debating the existence of aesthetic principles or to be debating their employment in aesthetic judgment. Another is that, to the degree particularists and generalists take themselves to be debating the employment of aesthetic principles in aesthetic judgment, it is hard to know what they can be meaning by ‘aesthetic judgment.’ If ‘aesthetic’ still carries its eighteenth-century implication of immediacy, then the question under debate is whether judgment that is immediate is immediate. If ‘aesthetic’ no longer carries that implication, then it is hard to know what question is under debate because it is hard to know what aesthetic judgment could be. It may be tempting to think that we can simply re-define ‘aesthetic judgment’ such that it refers to any judgment in which an aesthetic property is predicated of an object. But this requires being able to say what an aesthetic property is without reference to its being immediately graspable, something no one seems to have done. It may seem that we can simply re-define ‘aesthetic judgment’ such that it refers to any judgment in which any property of the class exemplified by beauty is predicated of an object. But which class is this? The classes exemplified by beauty are presumably endless, and the difficulty is to specify the relevant class without reference to the immediate graspability of its members, and that is what no one seems to have done.

However we are to sort out the particularist/generalist debate, important contributions to it include, on the side of particularism, Arnold Isenberg’s “Critical Communication” (1949) Frank Sibley’s “Aesthetic Concepts” (in Sibley 2001) and Mary Mothersill’s Beauty Restored (1984) and, on the side of generalism, Monroe Beardsley’s Aesthetics (1958) and “On the Generality of Critical Reasons” (1962), Sibley’s “General Reasons and Criteria in Aesthetics” (in Sibley 2001), George Dickie’s Evaluating Art (1987), Stephen Davies’s “Replies to Arguments Suggesting that Critics’ Strong Evaluations Could not be Soundly Deduced” (1995), and John Bender’s “General but Defeasible Reasons in Aesthetic Evaluation: The Generalist/Particularist Dispute” (1995). Of these, the papers by Isenberg and Sibley have arguably enjoyed the greatest influence.

Isenberg concedes that we often appeal to descriptive features of works in support of our judgments of their value, and he allows that this may make it seem as if we must be appealing to principles in making those judgments. If in support of a favorable judgment of some painting a critic appeals to the wavelike contour formed by the figures clustered in its foreground, it may seem as if his judgment must involve tacit appeal to the principle that any painting having such a contour is so much the better. But Isenberg argues that this cannot be, since no one agrees to any such principle:

There is not in all the world’s criticism a single purely descriptive statement concerning which one is prepared to say beforehand, ‘If it is true, I shall like that work so much the better’ (Isenberg 1949, 338).
But if in appealing to the descriptive features of a work we are not acknowledging tacit appeals to principles linking those features to aesthetic value, what are we doing? Isenberg believes we are offering “directions for perceiving” the work, i.e., by singling out certain its features, we are “narrow[ing] down the field of possible visual orientations” and thereby guiding others in “the discrimination of details, the organization of parts, the grouping of discrete objects into patterns” (Isenberg 1949, 336). In this way we get others to see what we have seen, rather than getting them to infer what we have inferred.

That Sibley advances a variety of particularism in one paper and a variety of generalism in another will give the appearance of inconsistency where there is none: Sibley is a particularist of one sort, and with respect to one distinction, and a generalist of another sort with respect to another distinction. Isenberg, as noted, is a particularist with respect to the distinction between descriptions and verdicts, i.e., he maintains that there are no principles by which we may infer from value-neutral descriptions of works to judgments of their overall value. Sibley’s particularism and generalism, by contrast, both have to do with judgments falling in between descriptions and verdicts. With respect to a distinction between descriptions and a set of judgments intermediate between descriptions and verdicts, Sibley is straightforwardly particularist. With respect to a distinction between a set of judgments intermediate between descriptions and verdicts and verdicts, Sibley is a kind of generalist and describes himself as such.

Sibley’s generalism, as set forth in “General Reasons and Criteria in Aesthetics,” begins with the observation that the properties to which we appeal in justification of favorable verdicts are not all descriptive or value-neutral. We also appeal to properties that are inherently positive, such as grace, balance, dramatic intensity, or comicality. To say that a property is inherently positive is not to say that any work having it is so much the better, but rather that its tout court attribution implies value. So although a work may be made worse on account of its comical elements, the simple claim that a work is good because comical is intelligible in a way that the simple claims that a work is good because yellow, or because it lasts twelve minutes, or because it contains many puns, are not. But if the simple claim that a work is good because comical is thus intelligible, comicality is a general criterion for aesthetic value, and the principle that articulates that generality is true. But none of this casts any doubt on the immediacy thesis, as Sibley himself observes:

I have argued elsewhere that there are no sure-fire rules by which, referring to the neutral and non-aesthetic qualities of things, one can infer that something is balanced, tragic, comic, joyous, and so on. One has to look and see. Here, equally, at a different level, I am saying that there are no sure-fire mechanical rules or procedures for deciding which qualities are actual defects in the work; one has to judge for oneself. (Sibley 2001, 107–108)
The “elsewhere” referred to in the first sentence is Sibley’s earlier paper, “Aesthetic Concepts,” which argues that the application of concepts such as ‘balanced,’ ‘tragic,’ ‘comic,’ or ‘joyous’ is not a matter of determining whether the descriptive (i.e., non-aesthetic) conditions for their application are met, but is rather a matter of taste. Hence aesthetic judgments are immediate in something like the way that judgments of color, or of flavor, are:

We see that a book is red by looking, just as we tell that the tea is sweet by tasting it. So too, it might be said, we just see (or fail to see) that things are delicate, balanced, and the like. This kind of comparison between the exercise of taste and the use of the five senses is indeed familiar; our use of the word ‘taste’ itself shows that the comparison is age-old and very natural (Sibley 2001, 13–14).
But Sibley recognizes—as his eighteenth-century forebears did and his formalist contemporaries did not—that important differences remain between the exercise of taste and the use of the five senses. Central among these is that we offer reasons, or something like them, in support of our aesthetic judgments: by talking—in particular, by appealing to the descriptive properties on which the aesthetic properties depend—we justify aesthetic judgments by bringing others to see what we have seen (Sibley 2001, 14–19).

It is unclear to what degree Sibley, beyond seeking to establish that the application of aesthetic concepts is not condition-governed, seeks also to define the term ‘aesthetic’ in terms of their not being so. It is clearer, perhaps, that he does not succeed in defining the term this way, whatever his intentions. Aesthetic concepts are not alone in being non-condition-governed, as Sibley himself recognizes in comparing them with color concepts. But there is also no reason to think them alone in being non-condition-governed while also being reason-supportable, since moral concepts, to give one example, at least arguably also have both these features. Isolating the aesthetic requires something more than immediacy, as Kant saw. It requires something like the Kantian notion of disinterest, or at least something to play the role played by that notion in Kant’s theory.

Given the degree to which Kant and Hume continue to influence thinking about aesthetic judgment (or critical judgment, more broadly), given the degree to which Sibley and Isenberg continue to abet that influence, it is not surprising that the immediacy thesis is now very widely received. The thesis, however, has come under attack, notably by Davies (1990) and Bender (1995). (See also Carroll (2009), who follows closely after Davies (1990), and Dorsch (2013) for further discussion.)

Isenberg, it will be recalled, maintains that if the critic is arguing for her verdict, her argumentation must go something as follows:

Artworks having p are better for having p.
W is an artwork having p.
Therefore, W is so much the better for having p.
Since the critical principle expressed in premise 1 is open to counter-example, no matter what property we substitute for p, Isenberg concludes that we cannot plausibly interpret the critic as arguing for her verdict. Rather than defend the principle expressed in premise 1, Davies and Bender both posit alternative principles, consistent with the fact that no property is good-making in all artworks, which they ascribe to the critic. Davies proposes that we interpret the critic as arguing deductively from principles relativized to artistic type, that is, from principles holding that artworks of a specific types or categories—Italian Renaissance paintings, romantic symphonies, Hollywood Westerns, etc.—having p are better for having it (Davies 1990, 174). Bender proposes that we interpret the critic as arguing inductively from principles expressing mere tendencies that hold between certain properties and artworks—principles, in other words, holding that artworks having p tend to be better for having it (Bender 1995, 386).

Each proposal has its own weaknesses and strengths. A problem with Bender’s approach is that critics do not seem to couch their verdicts in probabilistic terms. Were a critic to say that a work is likely to be good, or almost certainly good, or even that she has the highest confidence that it must be good, her language would suggest that she had not herself experienced the work, perhaps that she had judged the work on the basis of someone else’s testimony, hence that she is no critic at all. We would therefore have good reason to prefer Davies’s deductive approach if only we had good reason for thinking that relativizing critical principles to artistic type removed the original threat of counterexample. Though it is clear that such relativizing reduces the relative number of counterexamples, we need good reason for thinking that it reduces that number to zero, and Davies provides no such reason. Bender’s inductive approach, by contrast, cannot be refuted by counterexample, but only by counter-tendency.

If the critic argues from the truth of a principle to the truth of a verdict—as Davies and Bender both contend—it must be possible for her to establish the truth of the principle before establishing the truth of the verdict. How might she do this? It seems unlikely that mere reflection on the nature of art, or on the natures of types of art, could yield up the relevant lists of good- and bad-making properties. At least the literature has yet to produce a promising account as to how this might be done. Observation therefore seems the most promising answer. To say that the critic establishes the truth of critical principles on the basis of observation, however, is to say that she establishes a correlation between certain artworks she has already established to be good and certain properties she has already established those works to have. But then any capacity to establish that works are good by inference from principles evidently depends on some capacity to establish that works are good without any such inference, and the question arises why the critic should prefer to do by inference what she can do perfectly well without. The answer cannot be that judging by inference from principle yields epistemically better results, since a principle based on observations can be no more epistemically sound than the observations on which it is based.

None of this shows that aesthetic or critical judgment could never be inferred from principles. It does however suggest that such judgment is first and foremost non-inferential, which is what the immediacy thesis holds.

2.3 The Aesthetic Attitude
The Kantian notion of disinterest has its most direct recent descendents in the aesthetic-attitude theories that flourished from the early to mid 20th century. Though Kant followed the British in applying the term ‘disinterested’ strictly to pleasures, its migration to attitudes is not difficult to explain. For Kant the pleasure involved in a judgment of taste is disinterested because such a judgment does not issue in a motive to do anything in particular. For this reason Kant refers to the judgment of taste as contemplative rather than practical (Kant 1790, 95). But if the judgment of taste is not practical, then the attitude we bear toward its object is presumably also not practical: when we judge an object aesthetically we are unconcerned with whether and how it may further our practical aims. Hence it is natural to speak of our attitude toward the object as disinterested.

To say, however, that the migration of disinterest from pleasures to attitudes is natural is not to say that it is inconsequential. Consider the difference between Kant’s aesthetic theory, the last great theory of taste, and Schopenhauer’s aesthetic theory, the first great aesthetic-attitude theory. Whereas for Kant disinterested pleasure is the means by which we discover things to bear aesthetic value, for Schopenhauer disinterested attention (or “will-less contemplation”) is itself the locus of aesthetic value. According to Schopenhauer, we lead our ordinary, practical lives in a kind of bondage to our own desires (Schopenhauer 1819, 196). This bondage is a source not merely of pain but also of cognitive distortion in that it restricts our attention to those aspects of things relevant to the fulfilling or thwarting of our desires. Aesthetic contemplation, being will-less, is therefore both epistemically and hedonically valuable, allowing us a desire-free glimpse into the essences of things as well as a respite from desire-induced pain:

When, however, an external cause or inward disposition suddenly raises us out of the endless stream of willing, and snatches knowledge from the thralldom of the will, the attention is now no longer directed to the motives of willing, but comprehends things free from their relation to the will … Then all at once the peace, always sought but always escaping us … comes to us of its own accord, and all is well with us. (Schopenhauer 1819, 196)
The two most influential aesthetic-attitude theories of the 20th century are those of Edward Bullough and Jerome Stolnitz. According to Stolnitz’s theory, which is the more straightforward of the two, bearing an aesthetic attitude toward an object is a matter of attending to it disinterestedly and sympathetically, where to attend to it disinterestedly is to attend to it with no purpose beyond that of attending to it, and to attend to it sympathetically is to “accept it on its own terms,” allowing it, and not one’s own preconceptions, to guide one’s attention of it (Stolnitz 1960, 32–36). The result of such attention is a comparatively richer experience of the object, i.e., an experience taking in comparatively many of the object’s features. Whereas a practical attitude limits and fragments the object of our experience, allowing us to “see only those of its features which are relevant to our purposes,…. By contrast, the aesthetic attitude ‘isolates’ the object and focuses upon it—the ‘look’ of the rocks, the sound of the ocean, the colors in the painting.” (Stolnitz 1960, 33, 35).

Bullough, who prefers to speak of “psychical distance” rather than disinterest, characterizes aesthetic appreciation as something achieved

by putting the phenomenon, so to speak, out of gear with our actual practical self; by allowing it to stand outside the context of our personal needs and ends—in short, by looking at it ‘objectively’ … by permitting only such reactions on our part as emphasise the ‘objective features of the experience, and by interpreting even our ‘subjective’ affections not as modes of our being but rather as characteristics of the phenomenon. (Bullough 1995, 298–299; emphasis in original).
Bullough has been criticized for claiming that aesthetic appreciation requires dispassionate detachment:

Bullough’s characterization of the aesthetic attitude is the easiest to attack. When we cry at a tragedy, jump in fear at a horror movie, or lose ourselves in the plot of a complex novel, we cannot be said to be detached, although we may be appreciating the aesthetic qualities of these works to the fullest… . And we can appreciate the aesthetic properties of the fog or storm while fearing the dangers they present. (Goldman 2005, 264)
But such a criticism seems to overlook a subtlety of Bullough’s view. While Bullough does hold that aesthetic appreciation requires distance “between our own self and its affections” (Bullough 1995, 298), he does not take this to require that we not undergo affections but quite the opposite: only if we undergo affections have we affections from which to be distanced. So, for example, the properly distanced spectator of a well-constructed tragedy is not the “over-distanced” spectator who feels no pity or fear, nor the “under-distanced” spectator who feels pity and fear as she would to an actual, present catastrophe, but the spectator who interprets the pity and fear she feels “not as modes of [her] being but rather as characteristics of the phenomenon” (Bullough 1995, 299). The properly distanced spectator of a tragedy, we might say, understands her fear and pity to be part of what tragedy is about.

The notion of the aesthetic attitude has been attacked from all corners and has very few remaining sympathizers. George Dickie is widely regarded as having delivered the decisive blow in his essay “The Myth of the Aesthetic Attitude” (Dickie 1964) by arguing that all purported examples of interested attention are really just examples of inattention. So consider the case of the spectator at a performance of Othello who becomes increasingly suspicious of his own wife as the action proceeds, or the case of the impresario who sits gauging the size of the audience, or the case of the father who sits taking pride in his daughter’s performance, or the case of the moralist who sits gauging the moral effects the play is apt to produce in its audience. These and all such cases will be regarded by the attitude theorist as cases of interested attention to the performance, when they are actually nothing but cases of inattention to the performance: the jealous husband is attending to his wife, the impresario to the till, the father to his daughter, the moralist to the effects of the play. But if none of them is attending to the performance, then none of them is attending to it interestedly (Dickie 1964, 57–59).

The attitude theorist, however, can plausibly resist Dickie’s interpretation of such examples. Clearly the impresario is not attending to the performance, but there is no reason to regard the attitude theorist as committed to thinking otherwise. As for the others, it might be argued that they are all attending. The jealous husband must be attending to the performance, since it is the action of the play, as presented by the performance, that is making him suspicious. The proud father must be attending to the performance, since he is attending to his daughter’s performance, which is an element of it. The moralist must be attending to the performance, since he otherwise would have no basis by which to gauge its moral effects on the audience. It may be that none of these spectators is giving the performance the attention it demands, but that is precisely the attitude theorist’s point.

But perhaps another of Dickie’s criticisms, one lesser known, ultimately poses a greater threat to the ambitions of the attitude theorist. Stolnitz, it will be recalled, distinguishes between disinterested and interested attention according to the purpose governing the attention: to attend disinterestedly is to attend with no purpose beyond that of attending; to attend interestedly is to attend with some purpose beyond that of attending. But Dickie objects that a difference in purpose does not imply a difference in attention:

Suppose Jones listens to a piece of music for the purpose of being able to analyze and describe it on an examination the next day and Smith listens to the same music with no such ulterior purpose. There is certainly a difference in the motives and intentions of the two men: Jones has an ulterior purpose and Smith does not, but this does not mean Jones’s listening differs from Smith’s … . There is only one way to listen to (to attend to) music, although there may be a variety of motives, intentions, and reasons for doing so and a variety of ways of being distracted from the music. (Dickie 1964, 58).
There is again much here that the attitude theorist can resist. The idea that listening is a species of attending can be resisted: the question at hand, strictly speaking, is not whether Jones and Smith listen to the music in the same way, but whether they attend in the same way to the music they are listening to. The contention that Jones and Smith are attending in the same way appears to be question-begging, as it evidently depends on a principle of individuation that the attitude theorist rejects: if Jones’s attention is governed by some ulterior purpose and Smith’s is not, and we individuate attention according to the purpose that governs it, their attention is not the same. Finally, even if we reject the attitude theorist’s principle of individuation, the claim that there is but one way to attend to music is doubtful: one can seemingly attend to music in myriad ways—as historical document, as cultural artifact, as aural wallpaper, as sonic disturbance—depending on which of the music’s features one attends to in listening to it. But Dickie is nevertheless onto something crucial to the degree he urges that a difference in purpose need not imply a relevant difference in attention. Disinterest plausibly figures in the definition of the aesthetic attitude only to the degree that it, and it alone, focuses attention on the features of the object that matter aesthetically. The possibility that there are interests that focus attention on just those same features implies that disinterest has no place in such a definition, which in turn implies that neither it nor the notion of the aesthetic attitude is likely to be of any use in fixing the meaning of the term ‘aesthetic.’ If to take the aesthetic attitude toward an object simply is to attend to its aesthetically relevant properties, whether the attention is interested or disinterested, then determining whether an attitude is aesthetic apparently requires first determining which properties are the aesthetically relevant ones. And this task seems always to result either in claims about the immediate graspability of aesthetic properties, which are arguably insufficient to the task, or in claims about the essentially formal nature of aesthetic properties, which are arguably groundless.

But that the notions of disinterest and psychical distance prove unhelpful in fixing the meaning of the term ‘aesthetic’ does not imply that they are mythic. At times we seem unable to get by without them. Consider the case of The Fall of Miletus—a tragedy written by the Greek dramatist Phrynicus and staged in Athens barely two years after the violent Persian capture of the Greek city of Miletus in 494 BC. Herodotus records that

[the Athenians] found many ways to express their sorrow at the fall of Miletus, and in particular, when Phrynicus composed and produced a play called The Fall of Miletus, the audience burst into tears and fined him a thousand drachmas for reminding them of a disaster that was so close to home; future productions of the play were also banned. (Herodotus, The Histories, 359)
How are we to explain the Athenian reaction to this play without recourse to something like interest or lack of distance? How, in particular, are we to explain the difference between the sorrow elicited by a successful tragedy and the sorrow elicited in this case? The distinction between attention and inattention is of no use here. The difference is not that the Athenians could not attend to The Fall whereas they could attend to other plays. The difference is that they could not attend to The Fall as they could attend to other plays, and this because of their too intimate connection to what attending to The Fall required their attending to.

2.4 Aesthetic Experience
Theories of aesthetic experience may be divided into two kinds according to the kind of feature appealed to in explanation of what makes experience aesthetic: internalist theories appeal to features internal to experience, typically to phenomenological features, whereas externalist theories appeal to features external to the experience, typically to features of the object experienced. (The distinction between internalist and externalist theories of aesthetic experience is similar, though not identical, to the distinction between phenomenal and epistemic conceptions of aesthetic experience drawn by Gary Iseminger (Iseminger 2003, 100, and Iseminger 2004, 27, 36)). Though internalist theories—particularly John Dewey’s (1934) and Monroe Beardsley’s (1958)—predominated during the early and middle parts of the 20th century, externalist theories—including Beardsley’s (1982) and George Dickie’s (1988)—have been in the ascendance since. Beardsley’s views on aesthetic experience make a strong claim on our attention, given that Beardsley might be said to have authored the culminating internalist theory as well as the founding externalist one. Dickie’s criticisms of Beardsley’s internalism make an equally strong claim, since they moved Beardsley—and with him most everyone else—from internalism toward externalism.

According to the version of internalism Beardsley advances in his Aesthetics (1958), all aesthetic experiences have in common three or four (depending on how you count) features, which “some writers have [discovered] through acute introspection, and which each of us can test in his own experience” (Beardsley 1958, 527). These are focus (“an aesthetic experience is one in which attention is firmly fixed upon [its object]”), intensity, and unity, where unity is a matter of coherence and of completeness (Beardsley 1958, 527). Coherence, in turn, is a matter of having elements that are properly connected one to another such that

[o]ne thing leads to another; continuity of development, without gaps or dead spaces, a sense of overall providential pattern of guidance, an orderly cumulation of energy toward a climax, are present to an unusual degree. (Beardsley 1958, 528)
Completeness, by contrast, is a matter having elements that “counterbalance” or “resolve” one another such that the whole stands apart from elements without it:

The impulses and expectations aroused by elements within the experience are felt to be counterbalanced or resolved by other elements within the experience, so that some degree of equilibrium or finality is achieved and enjoyed. The experience detaches itself, and even insulates itself, from the intrusion of alien elements. (Beardsley 1958, 528)
Dickie’s most consequential criticism of Beardsley’s theory is that Beardsley, in describing the phenomenology of aesthetic experience, has failed to distinguish between the features we experience aesthetic objects as having and the features aesthetic experiences themselves have. So while every feature mentioned in Beardsley’s description of the coherence of aesthetic experience—continuity of development, the absence of gaps, the mounting of energy toward a climax—surely is a feature we experience aesthetic objects as having, there is no reason to think of aesthetic experience itself as having any such features:

Note that everything referred to [in Beardsley’s description of coherence] is a perceptual characteristic … and not an effect of perceptual characteristics. Thus, no ground is furnished for concluding that experience can be unified in the sense of being coherent. What is actually argued for is that aesthetic objects are coherent, a conclusion which must be granted, but not the one which is relevant. (Dickie 1965, 131)
Dickie raises a similar worry about Beardsley’s description of the completeness of aesthetic experience:

One can speak of elements being counterbalanced in the painting and say that the painting is stable, balanced and so on, but what does it mean to say the experience of the spectator of the painting is stable or balanced? … Looking at a painting in some cases might aid some persons in coming to feel stable because it might distract them from whatever is unsettling them, but such cases are atypical of aesthetic appreciation and not relevant to aesthetic theory. Aren’t characteristics attributable to the painting simply being mistakenly shifted to the spectator? (Dickie 1965, 132)
Though these objections turned out to be only the beginning of the debate between Dickie and Beardsley on the nature of aesthetic experience (See Beardsley 1969, Dickie 1974, Beardsley 1970, and Dickie 1987; see also Iseminger 2003 for a helpful overview of the Beardsley-Dickie debate), they nevertheless went a long way toward shaping that debate, which taken as whole might be seen as the working out of an answer to the question “What can a theory of aesthetic experience be that takes seriously the distinction between the experience of features and the features of experience?” The answer turned out to be an externalist theory of the sort that Beardsley advances in the 1970 essay “The Aesthetic Point of View” and that many others have advanced since: a theory according to which an aesthetic experience just is an experience having aesthetic content, i.e., an experience of an object as having the aesthetic features that it has.

The shift from internalism to externalism has meant that one central ambition of internalism—that of tying the meaning of ‘aesthetic’ to features internal to aesthetic experience—has had to be given up. But a second, equally central, ambition—that of accounting for aesthetic value by grounding it in the value of aesthetic experience—has been retained. The following section takes up the development and prospects of such accounts.

2.5 Aesthetic Value
To count as complete a theory of aesthetic value must answer two questions:

What makes aesthetic value aesthetic?
What makes aesthetic value value?
The literature refers to the first question sometimes as the aesthetic question (Lopes 2018, 41–43; Shelley 2019, 1) and sometimes as the demarcation question (van der Berg 2020, 2; Matherne 2020, 315; Peacocke 2021, 165). It refers to the second as the normative question (Lopes 2018, 41–43; Shelley 2019, 1; Matherne 2020, 315).

2.5.1 The Aesthetic Question
The prevailing answer to the aesthetic question is aesthetic formalism, the view that aesthetic value is aesthetic because objects bear it in virtue of their perceptual properties, where these encompass visual, auditory, gustatory, olfactory, and tactile properties. Aesthetic formalism rose to prominence when and because artistic formalism did, during the late 19th and early 20th centuries (see Section 5.1). Because everyone then took artistic value to be a species of aesthetic value, artistic formalism could gain prominence only by dragging aesthetic formalism in its train. But whereas artistic formalism has since fallen from favor, aesthetic formalism has held its ground. The explanation, arguably, has to do with the way aesthetic formalism honors the conceptual link between the aesthetic and the perceptual. Any adequate answer to the aesthetic question must meet what we may call the perceptual constraint, that is, it must plausibly articulate the sense in which aesthetic value is perceptual. Aesthetic formalism does this in the clearest possible terms.

Versions of aesthetic formalism come in varying strengths. Its strongest versions hold objects to have aesthetic value strictly in virtue of their perceptual properties (Bell 1958/1914; Danto 2003, 92). Weaker versions either allow objects to have aesthetic value in virtue of their non-perceptual content so long as that content expresses itself perpetually (Zangwill 1998, 71–72) or require merely that objects paradigmatically have aesthetic value in virtue of their perceptual properties (Levinson 1996, 6). All versions of aesthetic formalism struggle, one way or another, to accommodate our long-standing practice of ascribing aesthetic value to objects that do not address themselves primarily to the five bodily senses. Consider works of literature. We have been ascribing aesthetic value to them for as long as we have been ascribing aesthetic value to artworks of any kind. How might the aesthetic theorist square her theory with this practice? A first approach is simply to dismiss that practice, regarding its participants as linguistically confused, as applying terms of aesthetic praise to objects constitutionally incapable of meriting it (Danto 2003, 92). But given how extremely revisionist this approach is, we ought to wait on an argument of proportionately extreme strength before adopting it. A second approach allows that literary works bear aesthetic value, but only in virtue of their sensory properties, such as properties associated with assonance, consonance, rhythm, and imagery (Urmson 1957, 85–86, 88; Zangwill 2001, 135–140). But this approach accounts for a mere fraction of the aesthetic value we routinely ascribe to works of literature. Suppose you praise a short story for the eloquence of its prose and the beauty of its plot-structure. It seems arbitrary to count only the eloquence as a genuine instance of aesthetic value. A third approach treats literary works as exceptional, allowing them, alone among works of art, to bear aesthetic value in virtue of their non-perceptual properties (Binkley 1970, 269; Levinson 1996, 6 n.9). The difficulty here is to explain literature’s exceptionality. If literary works somehow bear aesthetic value in virtue of non-perceptual properties, what prevents non-literary works from doing the same? Moreover, to whatever degree we allow things to have aesthetic value in virtue of their non-perceptual properties, to that degree we sever the connection the formalist asserts between the aesthetic and the perceptual and so undermine our reason for adopting aesthetic formalism in the first place.

We might be forced to choose from among these three formalist approaches to literature if aesthetic formalism constituted the only plausible articulation of the sense in which aesthetic value is perceptual, but it doesn’t. Instead of holding that aesthetic value is perceptual because things have it in virtue of their perpetual properties, one might hold that aesthetic value is perceptual because we perceive things as having it. This would be a corollary of the immediacy thesis as defined in Section 1.1. If, as that thesis holds, aesthetic judgment is perceptual, having all the immediacy of any standard perceptual judgment, then aesthetic properties are perceptual, grasped with all the immediacy of standard perceptual properties. That aesthetic properties are thus perceptual is Sibley’s point in the following:

It is of importance to note first that, broadly speaking, aesthetics deals with a kind of perception. People have to see the grace or unity of a work, hear the plaintiveness or frenzy in the music, notice the gaudiness of a colour scheme, feel the power of a novel, its mood, or its uncertainty of tone. (Sibley 2001, 34, emphasis in original)
Sibley says that people have to see the grace or unity of a work and they have to feel the power of a novel. He doesn’t say that they have to see the properties in virtue of which a work has grace or unity or feel the properties in virtue of which a novel has power: the properties in virtue of which a work has grace or unity need not be perceptual and the properties in virtue of which a novel has power presumably will not be. Thus the literature problem, over which formalism stumbles, does not arise for Sibley, nor for anyone else committed to the immediacy thesis, including Shaftesbury (Cooper 1711, 17, 231), Hutcheson (1725, 16–24), Hume (1751, Section I), and Reid (1785, 760–761), among others. For the immediacy theorist, the aesthetic value we ascribe to literary works is aesthetic because we perceive literary works as bearing it.

2.5.2 The Normative Question
The prevailing answer to the normative question is aesthetic hedonism, the view that aesthetic value is value because things having it give pleasure when experienced. Aesthetic hedonism achieved prominence in the 19th century, roughly when aesthetic formalism did. Schopenhauer played a pivotal role in bringing it to prominence by reassigning disinterested pleasure from the role it had been playing in aesthetic judgment to the role of grounding aesthetic value (Schopenhauer 1818 [1969], 195–200). Bentham (1789, ch. 4) and Mill (1863 [2001]; ch. 2) arguably played larger roles by popularizing value hedonism, that is, the view that pleasure is the ground of all value. But whereas value hedonism no longer holds much sway in ethics, and Schopenhauer no longer exerts much influence in aesthetics, aesthetic hedonism has held its ground. The explanation presumably has to do with the apparent ease with which aesthetic hedonism explains why we seek out objects of aesthetic value. Any adequate answer to the normative question must meet what we may call the normative constraint, that is, it must plausibly identify what a thing’s having aesthetic value gives us reason to do. Aesthetic hedonism, locating that reason in the pleasure taken in experiencing aesthetically valuable objects, does this in the clearest possible terms.

Advocates of aesthetic hedonism include Schopenhauer 1818 [1969], Clive Bell 1914 [1958], C. I. Lewis 1946, Monroe Beardsley 1982, George Dickie 1988, Alan Goldman 1990, Kendall Walton 1993, Malcolm Budd 1995, Jerrold Levinson 1996, 2002, Gary Iseminger 2004, Robert Stecker 2006, 2019, Nick Stang 2010 and Mohan Matthen 2017. It is only quite recently that any sustained opposition to hedonism has arisen, a fact that may go some way toward explaining why hedonists, as a rule, see no need to argue for their view, opting instead to develop it in light of objections an imagined opposition might make.

Beardsley, for instance, leads with this simple formulation of hedonism:

The aesthetic value of an object is the value it possesses in virtue of its capacity to provide aesthetic gratification. (Beardsley 1982, 21).
But he then anticipates a fatal objection. Sometimes we undervalue aesthetic objects, finding them to have less value than they actually have; other times we overvalue aesthetic objects, finding them to have greater value than they actually have. The simple formulation above is consistent with undervaluation, since it is possible to take less aesthetic pleasure from an object than it has the capacity to provide, but inconsistent with overvaluation, since it is impossible to take greater aesthetic pleasure from an object than it has the capacity to provide (Beardsley 1982, 26–27). To remedy this problem, Beardsley appends a rider:

The aesthetic value of [an object] is the value [it] possesses in virtue of its capacity to provide aesthetic gratification when correctly and completely experienced (Beardsley 1982, 27, italics in original).
Suppose we refer to the italicized portion of this formulation as the epistemic qualification and the non-italicized portion as the hedonic thesis. The epistemic qualification renders the hedonic thesis consistent with overvaluation, given that you can misapprehend an object such that you take greater aesthetic pleasure from it than it has the capacity to provide when apprehended correctly and completely.

Beardsley’s version of aesthetic hedonism has served as a model for subsequent versions (Levinson 2002, n. 23); at least all subsequent versions consist of an epistemically qualified hedonic thesis in some form. Beardsley’s version, however, seems open to counter-example. Consider Tony Morrison’s Beloved, for instance, or Cormac McCarthy’s Blood Meridian. Taking pleasure from works designed to cause shock, horror, despair, or moral revulsion may seem perverse; surely, it may seem, such works do not have whatever aesthetic value they have in virtue of any pleasure they give. One way to accommodate such cases is to cast aesthetic pleasure as a higher-order response, that is, a response that depends on lower-order responses, which in some cases might include shock, horror, despair, and moral revulsion (Walton 1993, 508; Levinson 1992, 18). Another way is to broaden the field of experiences that may ground aesthetic value. Though pleasure as a rule grounds aesthetic value, in exceptional cases certain non-hedonic yet intrinsically valuable experiences—which may include horror, shock, despair, and revulsion—may also do so (Levinson 1992, 12; Stecker 2005, 12). The literature refers to this latter, broadened variety of hedonism as aesthetic empiricism; it hasn’t settled on a name for the former variety, but we may call it tiered hedonism, given the varying levels of response it takes aesthetic experience to comprise.

Yet another objection, anticipated by hedonists, holds hedonism to imply the heresy of the separable experience (Budd 1985, 125). It is a commonplace that for any object bearing aesthetic value nothing other than it can have just the particular value it has, excepting the improbable case in which something other than it has just its particular aesthetic character. The worry is that hedonism, given that it regards aesthetic value as instrumental to the value of experience, implies that for any object bearing aesthetic value something wholly other from it, such as a drug, might induce the same experience and so serve up the same value. The hedonist’s usual reply is to assert that aesthetic experience is inseparable from its object, such that for any aesthetic experience, that experience is just the particular experience it is because it has just the particular aesthetic object it has (Levinson 1996, 22–23; Budd 1985, 123–124; S. Davies 1994: 315–16; Stang 2012, 271–272).

Actual opposition to hedonism did not materialize until the present century (Sharpe 2000, Davies 2004), and most all of that during the past decade or so (Shelley 2010, 2011, 2019; Wolf 2011; Lopes 2015, 2018; Gorodeisky 2021a, 2021b). Why the opposition took so long to show up is a good question. It is tempting to think its answer resides in the obvious truth of the hedonist’s central premise, namely, that aesthetically valuable objects please us, at least in general. Anti-hedonists, however, have taken no interest in denying this premise. One useful way to think of the dialectic between hedonists and their opponents is to regard each as grasping one horn of an aesthetic version of the Euthyphro dilemma, where hedonists hold things to have aesthetic value because they please and anti-hedonists hold things to please because they have aesthetic value (Augustine 2005/389–391, De vera religione §59; Gorodeisky 2012a, 201 and 2021b, 262). Seen this way, the fact that aesthetically valuable things please tells not at all in favor of the hedonist; indeed, it is precisely this fact that the anti-hedonist thinks the hedonist cannot explain.

For instance, Wolf, in the context of an extended, nuanced case against value welfarism, argues that aesthetic hedonism cannot account for the fact that Middlemarch is a better novel than the Da Vinci Code,given that most people apparently like the latter better, presumably because it gives them greater pleasure (Wolf 2011, 54–55; see also Sharpe 2000, 326). The hedonist has a ready reply in the claim that all standard versions of hedonism are now epistemically qualified, that while most people may derive greater pleasure from the Da Vinci Code, a fully informed reader—that is, a reader who gives both texts a correct and complete reading—will not, assuming Middlemarch to be the better novel. But it’s not clear how much appeal to the epistemic qualification ultimately helps the hedonist. The anti-hedonist will want to know what best explains the fact that a fully informed reader will derive greater pleasure from Middlemarch (Wolf 2011, 55; D. Davies 2004, 258–259; Sharpe 2000, 325). Suppose we say that it owes to the fully informed reader’s grasping the superiority of Middlemarch’s structure, the higher quality of its prose, the greater subtlety and depth of its character development, and the greater penetration of the insights it affords (Wolf 2011, 55). Wouldn’t we then be saying that it owes to her grasping the greater aesthetic value of Middlemarch? Wouldn’t that be part of what a fully informed reader is fully informed about?

Of course, the hedonist may allow Middlemarch to be aesthetically better because of its superior structure, prose, character development, and insight; to allow this, from her point of view, is simply to allow that these are the elements in virtue of which a fully informed reader will derive greater pleasure. But here it would be good if the hedonist had an argument. Otherwise, the anti-hedonist will rightly wonder how it is that a correct and complete experience of Middlemarch will be an experience of every value-conferring feature of Middlemarch yet not an experience of the value conferred by those features. She will rightly wonder whether the hedonist fails to honor her own commitment to externalism about aesthetic value; she will rightly wonder, in other words, whether the hedonist fails to distinguish between a valuable experience and an experience of value, just as the internalist about aesthetic value fails to distinguish between a coherent and complete experience and an experience of coherence and completeness.

Earlier we attributed the appeal of hedonism to the apparent ease with which it explains our seeking out objects of aesthetic value. Anti-hedonists take that ease to be apparent merely. Some anti-hedonists, for instance, argue that at least some aesthetically valuable objects offer up pleasure only on condition that we do not seek it (Lopes 2018, 84–86; Ven der Berg 2020, 5–6; see also Elster 1983, 77–85). Lopes puts the point this way:

Sometimes an agent has an aesthetic reason to act and yet they could not be motivated to act out of a hedonic desire that would be satisfied by their so acting. To get any pleasure, they must act out of non-hedonic motives. Strolling through the Louvre, they happen upon the Chardins, and they look at them. So long as they do not look seeking pleasure, they get the pleasure that the paintings afford (Lopes 2018, 85–86).
Lopes’s choice of example is not arbitrary. There are particular art-critical reasons for thinking that Chardins will frustrate the hedonically motivated viewer (Fried 1980, 92; cited in Lopes 2018, 85), and Lopes is careful to claim that only “some aesthetic pleasures are essential by-products of acts motivated by other considerations” (Lopes 2018, 85). But it’s not as if Lopes’s claim is specific to Chardins. Consider again Wolf’s assertation that most readers take greater pleasure from The Da Vinci Code than from Middlemarch. If that assertion is correct, as it plausibly is, perhaps this is because (a) most readers read for pleasure, and (b) The Da Vinci Code affords pleasure to readers who read for it, whereas (c) Middlemarch withholds pleasure from such readers, affording pleasure instead on readers who read in pursuit of some non-hedonic good.

There is an apparent tension, moreover, between the hedonist’s reliance on the epistemic qualification and her claim that pleasure rationalizes our aesthetic pursuits. Consider the less-than-fully-informed reader who overvalues The Da Vinci Code and undervalues Middlemarch. The epistemic qualification is designed to allow the hedonist to explain how this might occur: such a reader takes greater pleasure from The Da Vinci Code, and less (or lesser) pleasure from Middlemarch, than she would were she fully informed. The epistemic qualification, moreover, allows the hedonist to explain why the uninformed reader has aesthetic reason not to undervalue Middlemarch: she is missing out on pleasure that would be hers if only she gave Middlemarch a fully informed reading. But the hedonist struggles to explain why the uninformed reader has reason not to overvalue the Da Vinci Code. If The Da Vinci Code gives the reader greater pleasure when she overvalues it, not only has she no aesthetic reason to be fully informed, she has aesthetic reason not to be. It therefore seems that if pleasure rationalized our hedonic pursuits, we would take ourselves to have reason to experience aesthetic objects in whatever way maximizes our pleasure. To the degree that we instead take ourselves to have reason to experience aesthetic objects completely and correctly—to the degree that we instead take ourselves to have reason to experience aesthetic objects as having the aesthetic values they in fact have—suggests that pleasure is not the aesthetic good we’re after (Shelley 2011).

But if pleasure is not the aesthetic good we’re after, what is? Part of hedonism’s perceived inevitability over the past century or so has owed to our inability even to imagine alternatives to it. If opposition to hedonism has been slow to materialize, alternatives have been slower still. To date, the only fully realized alternative to hedonism is Lopes’s network theory of aesthetic normativity, articulated and defended in his ground-breaking Being for Beauty: Aesthetic Agency and Value (2018).

Earlier we noted how Lopes challenges the hedonist on her own terms, objecting that she cannot adequately explain why we seek out objects of aesthetic value, given that aesthetic pleasure is at least sometimes an essential by-product of our seeking after something else (2018, 84–86). Lopes’s deeper challenge, however, targets the hedonist’s very terms. Aesthetic considerations rationalize a very great variety of aesthetic acts, according to Lopes: appreciating objects of aesthetic value is one such act, but so too is hanging a poster one way rather than another, selecting this book rather than that one for a book club, building out a garden this way rather than that, conserving one video game rather than another, pairing this dish with this wine rather than that one, and so on ad infinitum (2018, 32–36). If a theory of aesthetic value is to accommodate such a vast range of aesthetic acts, without singling out any one as more central than the others, it will have to conceive of aesthetic normativity as a species of some very general kind of normativity. Lopes, accordingly, conceives of aesthetic normativity as a species of the most generic form of practical normativity; that aesthetic acts ought to be performed well follows from the premise that all acts ought to be performed well for the simple reason that they are acts (2018, 135–137). As Lopes puts it: “Aesthetic values inherit their practical normativity from a basic condition of all agency—agents must use what they have to perform successfully” (2018, 135). Just which competencies an aesthetic agent may call upon to perform successfully on any given occasion depends on the particular role they happen to be playing in the particular social practice in which they happen to be performing (2018, 135). It is from the fact that all aesthetic activity necessarily takes place within the domain of some particular social practice that the network theory of aesthetic value takes its name (2018, 119).

In holding aesthetic agents to be performing the greatest variety of aesthetic acts on the greatest variety of items in coordination with one another, the network theory departs radically from hedonism. But, as Lopes himself observes, the network theory follows after hedonism in one fundamental way: inasmuch as both theories “answer the normative question but offer nothing in answer to the aesthetic question,” both “are consistent with any stand-alone answer to the aesthetic question” (2018, 48). The claim that the normative and aesthetic questions admit of stand-alone answers implies that aesthetic value is a species of the genus value in a standard species-genus relation, such that what makes aesthetic value value has no bearing on what makes it aesthetic and vice-versa. It therefore also implies that aesthetic value is not a determinate of the determinable value, such that what makes aesthetic value aesthetic is very thing that makes it value.

Do answers to the normative and aesthetic questions stand alone or stand together? If we have not yet registered the urgency of this question, perhaps that is because no one has yet fully articulated, let alone defended, a theory of aesthetic value according to which aesthetic value is a determinate form of value. Such a theory appears to be implicit, however, in Shelley 2011, Watkins and Shelley 2012, Gorodeisky and Marcus 2018, Gorodeisky 2021a, and Shelley 2022. The position common to these authors has been dubbed the Auburn view (Van der Berg 2020, 11). It answers the aesthetic question, and therein the value question, by holding an item’s having aesthetic value to rationalize its appreciation in a distinctively self-reflexive way, such that part of what you perceive when you appreciate an aesthetically valuable item is that it ought to be appreciated as you appreciating it (Shelley 2011, 220–222; Watkins and Shelley 2012, 348–350; Gorodeisky and Marcus 2018, 117–119; Gorodeisky 2021a, 200, 207; Shelley 2022, 12). The network theorist may object that the Auburn view privileges acts of appreciation as surely as hedonism does, but such an objection, from the Auburn perspective, begs the question. It is in assuming that the normative and aesthetic questions admit of stand-alone answers that the network theorist grants herself the freedom of passing on the aesthetic question, and it is in passing on the aesthetic question that she grants herself the freedom of treating each of a very great variety of aesthetic acts as equally central. It is in assuming that aesthetic value is a determinate of the determinable value, meanwhile, that the Auburnite places herself under the necessity of answering the aesthetic question, and it is in seeking an answer to the aesthetic question that she places herself under the necessity of singling out appreciation as aesthetically central. The network theorist and the Auburnite agree that the aesthetic question deserves an answer sooner or later (Lopes 2018, 46). They disagree, crucially, about whether it deserves an answer sooner rather than later.

The network theory and the Auburn view hardly exhaust the options for non-hedonic theories of aesthetic normativity: Nguyen 2019, Matherne 2020, Peacocke 2021, Kubala 2021, and Riggle 2022 all represent promising new directions. Yet every new theory of aesthetic value, hedonic or not, must follow after the network theory or the Auburn view in regarding answers to the normative and aesthetic questions as stand-alone or stand-together. A lot hangs on the decision to follow one path rather than the other. Perhaps it’s time we attend to it.

1. Introduction
1.1 Why Study Animal Communication?
Broadly speaking there are two reasons why animal communication is studied: as a way of better understanding human communication, and as a way of understanding animals.

Recent discussions have skewed towards the former approach (Lloyd 2004; Tomasello 2008; Bar-On 2013; Scott-Phillips 2015; Moore 2017a), often motivated by the idea that understanding animal communication can inform the study of language evolution. The idea underlying this research is we can think of animal forms of communication as involving potentially simpler forms of the kinds of communication in which humans engage. Models of the mechanisms that support animal communication might then be used to model how human communication has grown in complexity from its more animalistic origins. Points of continuity and discontinuity, particularly the latter, can be used to help identify what has changed in evolutionary history, and may also give us a basis for reasoning about the conditions that drove the evolution of human features of communication.

Thinking of this project in purely functional terms, modelling the transitions from simple to complex forms of communication, comes with a number of risks. The assumptions that human communication is more complex than animal communication and that human and animal forms of communication are built on the same cognitive foundations may both be false. With increased understanding of the natural world, we are learning that highly complex minds can come in forms very different from our own (Godfrey-Smith 2016). Nonetheless, through the study of common ancestry, we can use models of animal communication to inform the study of human minds.

In the study of phylogenetic development—that is, the biological development and diversification of organisms over historical time—a reasonable assumption is that behaviours present in closely related species were also present in the common ancestor of those species (Sober 2005, 2012). Put another way, if two closely related species share similar traits, it is reasonable to assume that these traits derive from a common ancestral trait, or are ‘homologous’ (Ruse & Travis 2009, Alphabetical guide). While this assumption is defeasible, it’s cladistically more parsimonious to suppose that similar behaviours in closely related species evolved once in an ancestral lineage rather than twice, independently, in later lineages. So if gestural communication is present in all extant great ape species (humans, bonobos, chimpanzees, gorillas, and orangutans), then this is evidence, albeit defeasible, that gestural communication was also present in the last common ancestor of these species around 16mya. The argument from cladistic parsimony generalises to consideration of the mechanisms that support similar behaviours in closely related clades. Where similar behaviours are present in neighbouring clades, then this is evidence (albeit defeasible evidence) that these behaviours are supported by common mechanisms (Sober 2012).

Appeals to common ancestry thus provide a method for reconstructing the phylogenetic development of human communication. Were reconstructing the evolution of human communication the only reason to study animal communication, this would give more reason to study the communication of closely related species, like chimpanzees and bonobos, than more distant ones—like dolphins, dogs, and birds. But if there are similar mechanisms at work in more distantly related species, then we can still gain insight into the potentially phylogenetically ancient foundations of human communication; or into the ways that convergent evolution can support the independent emergence of functionally similar traits in distantly related clades. Such traits may turn out to be ‘analogous’ to those present in the hominin lineage. Unlike homologous traits, analogous traits are similar not because of a shared ancestry, but because, for example, they arose in response to similar environmental pressures (Ruse & Travis 2009, Alphabetical guide).

Of course, self-knowledge is not the only reason to study animal communication. Some philosophers reject the anthropocentrism of thinking that we should study animals to better understand ourselves (Monsó 2021). We may also want to understand animal communication as a means of understanding them—either because doing so is intrinsically interesting, or with some further purpose in mind. When looking at animal communication as a way of understanding animals, the focus is not on the differences and similarities with human communication, but rather on the intrinsic properties of animal communicative systems, minds and behaviours. Studying the communicative interactions that take place within and between animal species in their natural habitats can tell us a great deal about the lives that they live, the ways in which they interact, and the ways in which we might better interact with them. Studying minds radically different from our own can also tell us something about minds in general, and the very different forms that cognition can take.

There may also be practical incentives to study the minds of creatures less closely related to us—not least, for example, domesticated species, and species kept as companion animals. A better understanding of the communication of the animals with whom we share our cities and homes might enable us to improve their living conditions and give them the lives that they deserve (Donaldson & Kymlicka 2011). For example, knowing how to interpret cats’ behaviour, and how cats are likely to interpret us, could enable us to live more harmoniously with them, improving their standard of living, while helping us to build deeper and more meaningful relationships with them. Meanwhile, by better understanding the communication of farm animals, we may better understand when they are suffering and when they are content, facilitating the raising of healthier, happier livestock. Finally, by better understanding the minds of wild animals, we may be better able to educate humankind about the lives they lead, and thus motivate our peers to care about these species. In turn, this might support initiatives designed to protect their natural habits from destruction.

While both human and animal-centric approaches are important, in this entry we will look at animal communication primarily via competing accounts of its differences and similarities with human communication, i.e., within the framework of language evolution. We do not wish to downplay the importance of animal-centric approaches. Rather, the evolutionary approach reflects our own research backgrounds. Furthermore, this comparative approach is the one on which most philosophical debates have focused—and, therefore, which lends itself to a more systematic treatment in a philosophy entry. It also means that, although we try to diversify our examples, many examples are taken from the primate literature. Given our close evolutionary relationship, scholars have often preferred looking to primates to reconstruct the evolution of human language.

1.2 Varying approaches to semantics, syntax, pragmatics and cooperation
This entry is organised into four main sections: semantics, syntax, pragmatics and cooperation.

Since the categories of semantics, syntax and pragmatics are foundational to the study of human communication, we use them to present different accounts of the similarities and differences between human and animal communication. While the meanings of these terms are not always a matter of consensus, in this entry we use them in a manner consistent with the literature on human communication. Thus, semantics is the study of the meaning or information carried by individual signs, as in the study of word meaning (§2). Syntax is the study of the way in which individual signs can be combined into structured, meaningful strings of signs, as when words are combined into sentences (§3). Pragmatics is the study of the ways in which signs are used and interpreted in context. For example, an utterance of the sentence “Leave me alone now” conveys a different proposition, depending on who utters it, and when (§4).

Section 5 focuses on the extent to which animal communication is cooperative, and introduces a series of debates that are key both for understanding recent work on language evolution, and for better understanding interactions between animals.

As will become apparent, the usage of technical terms such as semantics, syntax, pragmatics and cooperation varies considerably in the animal communication literature. This is partly because different subfields of animal communication research have developed independently, and because philosophers and cognitive scientists have used the same words in different ways. Different uses of the same words sometimes also relate to issues of ideology. For example, it may depend on whether an author takes a ‘booster’ or a ‘scoffer’ position (see Andrews & Huss 2014; Andrews & Monsó 2021 for discussion). What we call ‘booster’ views tend to elaborate human-like interpretations of animal behaviours, emphasising similar cognitive abilities in human and non-human species. In contrast, scoffer views lean towards simpler interpretations that emphasise cognitively undemanding processes. Proponents of different approaches often use the same words in different ways, and without acknowledging their idiosyncratic use. This can make navigating the literature in animal communication challenging. In the course of this entry, we’ll illustrate the different ways in which technical terms have been used, and set out to show the relationships between competing views.

2. Semantics
Semantics is the study of the meaning or information carried by individual signs, as in the study of word meaning. A general and vigorously debated approach to the question of animal semantics is to examine what animal signals mean, and whether they could be said to refer.

2.1 Functional reference
The theory of functional reference (Marler, Evans, & Hauser 1992) contends that there is evidence of primitive forms of reference in animal communicative behaviours. ‘Functionally referential’ calls refer to objects or events in the animal’s environment. This makes them possible evolutionary precursors of words. In claiming that animal signals have a referential capacity, the theory of functional reference challenges the classic ‘motivational’ view of animal communication (Darwin 1872 [1998]), according to which animal signals are more like emotional expressions (e.g., laughter, or cries) than words, and have no referential function.

The textbook example of functional reference is the alarm calls of vervet monkeys. As reported by Seyfarth, Cheney, and Marler (1980), vervet monkeys produce three acoustically distinct types of alarm calls in response to three different types of predators: leopards, eagles, and snakes. The receivers of these calls are likely to adopt escape strategies that are consistent with the presence of these predators, as if they interpret the calls to mean “leopard!”, “eagle!” or “snake!”. Leopard alarm calls increase the likelihood that vervet monkeys will run up into trees; eagle alarm calls lead to more individuals looking skywards, before running into bushes; and when they hear snake alarm calls, individuals are more likely to look down and stand bipedally. These behavioural responses are seemingly consistent with vervet calls having some word-like referential capacity.

Within the theory of functional reference, the referentiality of animal signals is defined as “functional” in the sense of being neutral about the mental processes that support animal calls (Marler, Evans, & Hauser 1992). What makes functionally referential animal signals similar to words—and, potentially, their evolutionary precursors—is the fact that they are taken by their recipients to stand for objects or events in the environment. Since claims about functional reference are neutral with respect to the mechanisms that support call production, this theoretical framework can be used to study the various ways in which animals provide members of their own and other species with information about their shared environment. Thus it is a valuable tool for studying communication between animals. It is also well suited for characterising the findings of observational (e.g., ethological) studies, which may be ill-suited to supporting conclusions about the mechanisms underlying communication.

According to early formulations of the functional reference view, animal signals are functionally referential when they are (i) stimulus-specific—i.e., produced by animals in response to specific objects or events in the environment (the ‘production criterion’); and (ii) context-independent—i.e., capable of eliciting appropriate responses in the recipients in the absence of contextual clues (the ‘perception criterion’) (Marler, Evans, & Hauser 1992; Macedonia & Evans 1993). However, both the formulation of these criteria and the general utility of the functional reference framework have been challenged.

2.1.1 Criticisms of functional reference
The theory of functional reference has been challenged by a number of scholars (e.g., Rendall, Owren, & Ryan 2009; Wheeler & Fischer 2012; Scarantino 2013). Wheeler and Fischer (2012) develop a two-part objection. First, based on empirical evidence they suggest that functional referential signals are at best a marginal phenomenon in animal communication. In most cases, they argue, animal signals are neither stimulus-specific nor context-independent: animals tend to produce the same types of signals in response to different stimuli (making them non-stimulus-specific); and communicative signals are usually interpreted by animals in light of contextual clues (making them non-context-independent). Ironically, they argue that stimulus-specificity does not even seem to apply to vervet monkeys’ alarm calls, because only calls given by males are well characterised by the hypothesis that there are three distinct types of alarm calls (Price et al. 2015). Second, Wheeler and Fischer argue that even where signals are functionally referential, often they are not voluntarily produced—undermining the proposal that they are an evolutionary precursor of linguistic signs (see also Fischer & Price 2017). This view is supported by neurological evidence suggesting that primates may lack the neural system which is responsible for voluntary vocal control in humans (Fischer & Hammerschmidt 2020). In light of these objections Wheeler and Fischer argue that animal psychologists should overcome their preoccupation with functional reference and instead search for continuities between human and non-human communication in the interpretation, not the production, of signals. They propose to abandon the functional reference framework in favour of a receiver-centred approach to animal semantics (see §4.1).

2.1.2 In defence of functional reference
Against Wheeler & Fischer (2012), Scarantino (2013) and Scarantino & Clay (2015) defend the explanatory value of the functional reference framework. They argue that the problem is not with the framework itself, but only with the existing characterisation of functional reference. They point out that while context-independence and stimulus-specificity don’t always apply to cases of animal communication, they don’t apply to cases of human linguistic reference, either. Examples of this include indexicals like ‘I’ and ‘you’, ‘today’ and ‘tomorrow’, and ‘this’ and ‘that’. Such terms are produced in a variety of circumstances, and so lack stimulus-specificity. Their interpretation therefore requires taking into account contextual clues. Regardless, indexicals have a referential function. This shows that referential capacity is not dependent upon either stimulus specificity or context-independence. Scarantino argues that the failure of animal signals to meet these criteria is therefore insufficient to show that they do not refer, and no reason to deny that such signals could be evolutionary precursors of words.

Scarantino also argues that animal signals don’t need to be stimulus-specific to be adaptive. This is because the cost of false positive calls (e.g., calls given in the absence of a predator) may be much less costly than false negatives (signals not given in the presence of predator). For example, a receiver who responds to a false-positive eagle alarm call with eagle-avoidance behaviour does not incur damaging costs. It is more risky not to engage in eagle-avoidance behaviour when an eagle is present. Thus, in many cases it will be adaptive if eagle calls are given to stimuli other than eagles.

Drawing on the example of indexicals, Scarantino (2013) proposes a revised characterisation, according to which

Signals can functionally refer by virtue of contextual cues … and in the absence of a strong correlation with their referents …. (Scarantino 2013: 1012)

Unlike the original production criterion (Macedonia & Evans 1993), Scarantino’s ‘contextual information criterion’ admits weak correlations between signals and referents, allowing signals to be produced in a variety of circumstances, rather than being stimulus-specific. On this formulation, a signal X carries information about a state Y iff “Xs are correlated with Ys (weakly or strongly)” (Scarantino 2013: 1014). In contrast to Macedonia & Evans’ (1993) perception criterion, Scarantino also suggests a ‘contextual perception criterion’, according to which:

X’s presentations in context C reliably cause responses adaptive to Ys in the absence of Ys.

He argues that calls functionally refer to things if they statistically correlate with them, and if receivers have developed an adaptive response to that correlation. This means that animal behaviours functionally refer only if recipients respond to them in ways that are adaptive. This is also possible via the integration of contextual clues, in contrast to Macedonia and Evans (1993).

On this approach, functional reference becomes a modified form of ‘natural meaning’ (Grice 1957; Scarantino 2015). On Grice’s account, something X naturally means that Y if the presence of Xs entails the presence of Ys. Against Grice, Scarantino argues that it is sufficient for X to naturally mean Y that it reliably indicates the presence of Y. Thus he presents ‘natural meaning’ as a statistical relationship between two states of affairs (Scarantino 2015)—e.g., a call, and the thing to which that call is a response. Signals carry information about the states with which their production is associated, and the probability of which is changed by the occurrence of the calls (i.e., uncertainty reduction). For example, the probability of an eagle being present is raised by an eagle alarm call, such that the latter carries predictive information about (or reduces uncertainty about) the presence of the former. Significantly, Scarantino’s theory of information is neutral about what mechanisms underpin these correlations. The change in probability occurs regardless of what psychological processes govern the production of signals.

Scarantino’s revised account remains controversial. Wheeler and Fischer (2015) object that his rehabilitated characterisation is too broad to be useful in the study of language evolution, because many intuitively non-communicative features of animals can potentially statistically correlate with states of affairs in a context, and elicit adaptive responses, such that they could be said to refer to them (see Palazzolo 2024 for discussion).

Despite their differences, Wheeler and Fischer’s framework of meaning attribution and Scarantino’s revised account of functional reference are united in one important respect: they both argue that the interpretation of signals that are not produced voluntarily can serve as a point of continuity between human and animal communication, and thus is of value for the study of language evolution. In section 4.1, we discuss criticism of this claim by some philosophers (Bar-On & Moore 2017; Bar-On 2021).

Whether or not it identifies a significant point of continuity with linguistic reference, it should be noted that the framework of functional reference has been very productive in animal communication research. Forms of functional reference have been discovered in a wide range of animal species, including monkeys, prairie dogs, meerkats, chickens and bees (see Townsend & Manser 2013; Gill & Bierema 2013). Since the studies of von Frisch (1965 [1967]), for example, it has been observed that bees’ waggle dances communicate information about the direction, distance and abundance of a food source with respect to the hive. Additionally, prairie dogs have been shown to use four alarm call variants that vary consistently with different predator types, including hawks, humans, coyotes, and dogs. Alarm calls also vary based on specific physical attributes of the predator (Slobodchikoff et al. 2009). While these findings would not support claims about the psychological states of call producers, they can be classified as functionally referential without fear of misrepresenting the minds of their producers. Moreover, regardless of the mechanisms underlying these interactions, the functional reference framework has been used to show that many animal communication systems are used to provide receivers with information about the environment.

2.2 Do animals know the meaning of words?
Whether or not the concept of functional reference can be rehabilitated for the study of language evolution, some have argued that, for at least some species, animal researchers may have no need for it (Palazzolo 2024)—because the animal kingdom contains cases of reference proper. If that is right, we can look to these cases to better understand the origins of linguistic reference. Here ‘reference proper’ means signals that are under the voluntary control of agents, and are used to refer to objects in the environment. Such signals may indicate a capacity to refer that is shared with humans, and potentially evidence for word-like signals in animal communication.

In the discussion that follows we use examples not only of cases where animal signals seem to refer, but also cases where animal signals seem to be used with stable meanings comparable to the words of a natural language. This approach mirrors one found in the animal communication literature, where cases of potential reference have been subsumed into broader debates about whether animals can know the meanings of words. If animals do not know the meanings of words, then they cannot use them to refer. However, whether animals understand word meanings will depend on what this knowledge of meaning entails, and as the following section will make clear, this is not a matter of consensus.

2.2.1 Arguments for animal knowledge of meaning
Intuitively compelling cases of animal reference can be found in both word-like features of the communicative repertoires of wild animals, and in the communicative systems of animals reared in human environments. With respect to the former, wild populations of great apes use their gestures with stable semantic properties. The purported meanings of these gestures have been studied and compiled (e.g., Hobaiter & Byrne 2014). Since great ape gestures are paradigmatically used to talk about actions (e.g., to make utterances like “Stop!” or “Groom me!”), these gestures figure less in debates about reference, because the term ‘reference’ is used by comparative psychologists only where signs are noun-like. (In contrast, philosophers use the term with a broader and more technical scope—as when describing the reference of a proposition in terms of its truth value.) Nonetheless, these gestures are also candidates for having meanings in the same manner as words.

Potential cases of knowledge of meaning have also been identified in animals who interact regularly with humans, including great apes trained to use and understand either sign-language (Fouts & Fouts 1993), or specially adapted lexigrams (Savage-Rumbaugh, Shanker, et al. 1998); a parrot, Alex, who has demonstrated a remarkable aptitude for using and understanding human words (Pepperberg 1981); and a dog, Rico, who can seemingly understand hundreds of human words, including object names (Kaminski, Call, & Fischer 2004).

Enculturated animals are raised in human-like environments and given species-atypical exposure to human interaction (see Berio & Moore 2023, for discussion). While enculturation projects have met with mixed success (contrast Terrace 2019 with Fouts & Fouts 1993), some have presented highly impressive findings of the communicative development of great apes (e.g., Savage-Rumbaugh 1986; Savage-Rumbaugh, Shanker, & Taylor 1998). For example, the bonobo Kanzi was raised in an environment where he interacted daily with human researchers led by Sue Savage-Rumbaugh. While Kanzi was not taught to use lexigrams (symbols on a keyboard that when pressed play the sounds of words), he learned to do so at a young age by watching his human caregivers’ unsuccessful attempts to teach his adoptive mother. He can reportedly understand a couple of thousand words of English (although some counting methods report lower numbers (Call 2011), and he communicates fluently using a lexigram board that contains around 450 signs, using perhaps 30–40 of these daily in the production of his own utterances (Savage-Rumbaugh 1986). These cases raise the questions of whether animals can understand the meanings of words; and what this understanding consists in.

2.2.1 Arguments against animal knowledge of meaning
One possible answer to the question “Do animals know the meanings of words?” is given by Berwick and Chomsky (2016). On their view, animals cannot understand word meanings, because what constitutes meaning is the mapping of a sign to a concept. They argue that since chimpanzees lack a human-like conceptual system, they cannot map signs to concepts in the required way, and so cannot know the meanings of words. While they don’t say much about what they take concept possession to consist in, they support their argument by citing an early study by Petitto and colleagues (2005), which discusses Nim, a chimpanzee who was raised by Terrace and colleagues in a human environment, where he was taught to use American Sign Language. Petitto argues that although Nim could produce the gestures he was trained to use:

Nim didn’t actually learn about words, and didn’t even have the human concept for “apple”. For Nim, an “apple” was the object associated with the knife in the draw that cut the apple, the place that apples were found, and so on[.] (Berwick & Chomsky 2016: 146)

They also cite approvingly the work of Petitto (Petitto 2005: 85–87), who argues that Nim’s patterns of word-use show that “chimps do not really have names for things at all … only a hodge-podge of loose associations” (ibid.). If Nim had no concept of apple, then he could not know the meaning of the gesture ‘apple’, since this requires a form-concept mapping.

Berwick and Chomsky’s (2016) argument deserves a more substantial engagement than can be attempted here. Still, in response to it, two points are worth making. First, some philosophers have argued that animals do have conceptual knowledge (Glock 2000; Finkelstein 2007), even if the contents of their concepts differ from our own. If this is right, an account of knowledge of meaning grounded in concept possession might plausibly be defended for animal communicators. Second, the conclusion that Nim’s gestures show his concepts to be un-human-like seems to be motivated at least in part by his producing gestures in seemingly inappropriate contexts—for example, by gesturing ‘apple’ in the presence of a knife. This raises questions about how behaviours and concepts should be connected. Even if there were a consensus view of what concept possession consists in (and there is not), an account of the kinds of gestural behaviour that would constitute evidence of the concept possession needed for knowledge of meaning is independent of this. Berwick and Chomsky don’t consider what patterns of sign-use would indicate knowledge of meaning, but without an answer to this question, it’s unclear what Nim’s verbal behaviour shows.

While the view that knowledge of meaning consists of knowing a word-concept mapping is popular among cognitive scientists (e.g., Bloom 2000), it is less central to philosophical accounts of meaning—not least because questions about the relationship between language-use and concept possession can seem prohibitively difficult to answer. Some philosophers of language have instead tended to equate knowledge of meaning with knowing how to use words to pursue certain kinds of communicative goals, and understanding others’ uses of words. For example, Wittgenstein famously held that “for a large class of cases … the meaning of a word is its use in the language” (1953: 43). This has often been taken to entail that knowing the meaning of a word consists in knowing how to use it—something that could seemingly be granted to animals who know how to use words to fulfil their communicative goals. On such an account, there may be no reason to deny knowledge of meaning to at least some animals. For example, Nim’s voluntarily gesturing a sign for “Apple” when looking at a knife used to cut apples need not be evidence of a confused concept of apple, so much as a case of a hungry chimpanzee requesting an object in its absence (“I want an apple!”). (This ability for absent reference was, until recently, taken to be uniquely human—although it has now been identified in chimpanzees (Lyn et al. 2014; Bohn, Call, & Tomasello 2015).)

A similar explanation of knowledge of meaning also can be identified in the work of Grice (1989), who argued that for a word to have a ‘standing’ (i.e., conventional) meaning is for communicators to use that word to express certain kinds of communicative intentions. Currently influential approaches to identifying the meanings of great ape gestures draw influence from Gricean and Wittgensteinian approaches, by identifying their meanings of great ape gestures with the goals with which these gestures are produced. In turn, the content of the communicative goal is inferred from the agent’s apparent satisfaction with the results of their gesturing (see Hobaiter & Byrne 2014). While legitimate questions arise about whether animals can be credited with the ability to express communicative intentions (see §4.2), if they can, it’s not clear what further reasons one might have for denying them knowledge of meaning—even if their utterances indicate no evidence of syntax, phonology, morphology, or myriad other features of human language (contra Petitto 2005).

Perhaps some would object that specifying knowledge of meaning without reference to concept possession is also problematic. At least implicitly, Terrace (2019), director of the Nim project, raises such a concern. He worries that agents who lack concepts could nonetheless use words to manipulate others, without understanding them, in the same way that one might manipulate the keys on a keyboard to guide a character in a computer game. Such concerns motivate him to deny that Nim knew the meanings of words. He argues that manipulation is particularly likely in the kinds of requesting behaviour in which chimpanzees engage, because words are here very closely tied to behaviour (like the receipt of an object). This leads to a pattern in which creatures can uncomprehendingly repeat words, without knowing their meanings, because they are rewarded for doing so. He argues that an ability to use words to share information about or interest in something would be better evidence of knowledge of meaning, since in such cases there is no direct reward for uttering. This raises another problem, though. For all that we might like such evidence, chimpanzees seem to be largely unmotivated to communicate solely to share information (see §5). This doesn’t entail they lack knowledge of word meaning though. It shows only that our basis for attributing to them knowledge of meaning lacks one compelling kind of evidence.

Our view is that the arguments for denying knowledge of word meanings to non-human great apes are unpersuasive. Nonetheless, we don’t propose to settle the question of whether animals know the meanings of words here. Rather, we acknowledge that this area of research would benefit from further philosophical attention.

3. Syntax
3.1 What is syntax?
In the literature on human communication, syntax refers to the ability to combine meaningful semantic units (like words) into larger, meaningful strings with a hierarchical structure (like sentences). This capacity is critical to human communication, and it underpins much of its characteristic expressive power. It’s thanks to our capacity to combine words into sentences that we can express an unimaginably large number of different thoughts using a limited set of linguistic elements.

The prevailing view in the literature on language evolution holds that the capacity for syntax is uniquely human. Berwick & Chomsky (2016), for example, argue that syntax distinguishes our minds from the minds of animals. On their view, syntax (which they sometimes call ‘language’) is not specifically a feature of communication, but of thought. They argue that, unlike animal minds, human minds possess concepts (although what they mean by ‘concepts’ is not entirely clear). These concepts are said to be bound together using syntactic rules, to create hierarchically organised thoughts. Thoughts can then be ‘externalised’ via the ‘sensorimotor interface’ (the system for producing and understanding speech), for the purposes of communication. Nonetheless, on their view syntax is a feature of thought, which underwent natural selection for its role in thought and planning, independently of any communicative function.

According to Berwick and Chomsky (2016), human syntax is made possible by a computational ability, Merge, which combines two objects (a, b) to generate a structure {a, b}. Merge incorporates two operations: it combines elements, and imposes a hierarchical structure on them, which in turn constrains the interpretation of the string. To say that Merge imposes hierarchical structure means that its outputs are rule-governed compositions in which units modify some units but not others. For example, in a phrase like ‘very old house’, ‘very’ modifies ‘old’ but not ‘house’: [[very old] house]. A string of units is hierarchical, in other words, if some units within that string are grouped together with some other units, to form a larger unit within the string—for example, when words are bound into noun phrases, which can be combined with verbs to make sentences. Hierarchical structure is often contrasted with linear order, since the binding of hierarchical elements need not correspond to the order in which they occur in a sequence (see §3.3 for discussion).

The outputs of Merge are also taken to be in principle unbounded, which means that there is no principled limit to the number of combinations that can be produced. There may be practical limits on the complexity of the hierarchical structures agents can represent, because of limitations on their working memory or attention. However, these are considered to be failures of performance, and not a reflection on the underlying combinatorial competence, which is unbound in its capacity to combine elements (Chomsky 1980).

3.2 The production of syntactically complex signals by animals
The literature on animal communication identifies three different types of combinations in wild animal communication systems: ‘phonological syntax’, ‘combinatorial syntax’ and ‘compositional syntax’ (Hurford 2012).

Phonological syntax is a rule-based combination of units without meaning. For instance, studies have shown that Bengalese finches and Nightingales exhibit specific patterns in the arrangement of their song elements, although these elements do not seem to possess semantic information (Berwick, Okanoya, et al. 2011).

Combinatorial syntax is a combination of meaningful units where the meaning of the whole is not a function of the meanings of its parts. An example of combinatorial syntax in animals is putty-nosed monkeys’ ‘pyow-hack’ sequences (Arnold & Zuberbühler 2012). Putty-nosed monkeys use pyows as terrestrial alarm calls and hacks as eagle alarm calls. When they are used in sequence they elicit group travel. Since group travel seems to be unrelated to the individual meanings of hacks and pyows, pyow-hack messages seem not to be constructed using the semantic features of these constituent calls. Rather, it seems like the putty-nosed monkeys have a limited call repertoire and have found a way to combine two calls from that limited repertoire to convey a third, unrelated message.

Compositional syntax is a combination of meaningful units where the meaning of the whole depends on the meanings of its parts and—according to classical views of syntax—the way the parts are syntactically combined. It is compositional syntax that characterises the sentences of natural languages, and evidence of which in animals would best demonstrate the similarity of animal and human forms of communication.

Suzuki and colleagues argue that they have found evidence of such abilities in Japanese tits, whose ‘ABC-D’ calls are thought to meet the criteria for compositional syntax (Suzuki, Wheatcroft, & Griesser 2018). In Japanese tits, ‘ABC’ calls are general alert calls, with a meaning akin to [/threat!/]. ‘D’ calls serve to recruit group members (e.g., [/come here!/]). ‘ABC-D’ calls, together, form mobbing sequences: these sequences are used by Japanese tits to recruit conspecifics to mob a stationary predator, and are responded to by conspecifics by gradually approaching the sender and scanning the surrounding environment. Based on this evidence, Suzuki and colleagues conclude that the compound meaning of ‘ABC-D’ calls is directly connected to the meanings of its parts, being something akin to ‘ABC-D’ = [/threat!/ + /come here!/]. Moreover, they consider the fact that Japanese tits do not respond to reversed, artificial ‘D-ABC’ sequences as evidence that they are sensitive to the order of the calls, and that the calls have a hierarchical structure.

In terms of understanding the evolution of human syntax, compositional syntax is thought to be the most relevant form of animal combination. However, a debate exists in the literature about the similarity of putative cases in animals and humans. Proponents of ‘scoffer’ accounts, such as Bolhuis et al. (2018), downplay the significance of seemingly compositional syntax in animals, arguing that these cases are qualitatively distinct from human syntax. Against Bolhuis and colleagues, Townsend, Engesser, et al. (2018) argue that animal compositional combinations are the evolutionary precursors of human syntax.

This disagreement is motivated by different views of what is essential to syntax. Bolhuis et al. (2018) count hierarchy and unbounded generativity as essential features of human syntax, and argue that there is no evidence of these features in animal combinations. They claim that animal combinations lack internal structure (i.e., they are nothing more than just ‘summations’ of individual meanings), and that while human syntax is unbounded in its nature, animal signals are fixed and limited in their combinatorial possibilities. That’s because, while sentences of natural languages can be bound indefinitely (for example, by conjoining any number of sentences with ‘and’), there is very little evidence of long strings of signals in the animal kingdom (i.e., there is no evidence of boundless Merge). For example, more sober analyses of the utterances produced by enculturated chimpanzees suggest that for the most part they produce strings of only two or three gestures or symbols (Rivas 2005). Other data suggest that there is no combinatorial use of gestures by wild chimpanzees (Hobaiter & Byrne 2011). However, against Bolhuis and colleagues, we would point out that while data show limited evidence of complex combinatoriality in great apes, this is not a valid basis from which to conclude that human communication alone is characterised by boundless combinatoriality. That’s because such a claim turns on an illegitimate comparison of performance and competence (Chomsky 1980). That is, it turns on a comparison of what humans can do in principle (but not in practice) with what animals can do in practice. This is not a comparison of like with like. A more cautious conclusion would hold just that there is no evidence of hierarchical syntax or complex combinatoriality (that is, long and varied strings of signs) in non-human species.

Against such a sceptical view, Townsend, Engesser, and colleagues (2018) have argued that there is more continuity between compositionality in animals and human syntax than has often been assumed. However, this account is based on a weaker understanding of what human syntax requires. On this view, syntactic structures can include combinations of semantic elements in which the meanings of the whole are determined by the meanings of the parts, but where the parts need not be hierarchically structured. The capacity for combining units also need not be unbounded to qualify as syntactic. According to Townsend and colleagues, the absence of hierarchy and generativity in animal combinations does not pose a significant challenge for continuity claims, because human language also contains examples of non-hierarchical and non-generative structures which, they claim, are nonetheless intuitively syntactic. Townsend et al. illustrate their claim by providing examples of phrases like ‘duck and cover’, which they take to be non-hierarchical, and ‘gimme a break’, which they take to be non-generative, since it is ordinarily not embedded into longer syntactic strings. Using these criteria, Townsend et al. argue that there is evidence of syntax in Pied babblers (Engesser, Ridley, &, Townsend 2016), Japanese tits (Suzuki, Wheatcroft, & Griesser 2018), and potentially in chimpanzees (Leroux et al. 2023). However, whether one is satisfied by this argument will depend on whether or not one is willing to accept the accompanying arguments for lowering the threshold of what counts as evidence of syntax.

Even if one is willing to accept a lower threshold for evidence of syntax, Schlenker, Coye, and colleagues (2023; see also Schlenker, Chemla, et al. 2016) argue that many purported cases of compositional syntax in animals can be given deflationary interpretations. For example, they argue that call sequences like the ABC-D calls found in Japanese tits (Suzuki, Wheatcroft, & Griesser 2018) can be viewed as separate, successive utterances, rather than as complex syntactic units. Schlenker and colleagues (Schlenker, Coye, et al. 2023) refer to such cases as possessing only “trivial compositionality”.

In cases of trivial compositionality, Schlenker and colleagues argue that the meaning of animal sequences can be explained not by appeal to syntactic rules, but by instead appealing to pragmatic mechanisms of competition among signals—which they characterise in terms of Informativity and Urgency principles. The Informativity principle establishes that more informative utterances should be preferred over less informative utterances (Schlenker, Chemla, et al. 2016: 19). The Urgency principle is a variant of the Informativity principle and

mandates that calls that provide information about the nature/location of a threat … must come before calls that don’t. (Schlenker, Chemla, et al. 2016: 33)

According to Schlenker, Chemla, et al. (2016: 37), the Urgency principle explains, for example, why a sequence of pyows followed by a small number of hacks (i.e., pyow-hack sequences) signals group movement in putty-nosed monkeys. Given that, if there was an eagle, hacks would have come first in the sequence, the fact that they don’t suggests that the non-ground movement signalled by the sequence is non-threat related and thus, most likely, group movement. Bar-On has recently criticised some aspects of this proposal (Bar-On forthcoming).

3.3 The comprehension of syntactically complex signals by animals
If evidence of syntactic complexity in wild animals is underwhelming, findings drawn from the study of enculturated great apes may prove to be more compelling. As previously discussed (see §2.2), studies of the communicative abilities of enculturated chimpanzees and bonobos have consistently found that they produce strings of signs; and are capable of understanding longer strings of human speech. While studies of utterance production by Kanzi and others show an ability to produce strings of two or three signs that are seemingly more complex than anything seen in wild apes, they present no evidence of hierarchical syntax (Berio & Moore 2023). However, although Kanzi does not produce grammatically structured utterances, he can track relatively subtle grammatical differences. In a detailed study of Kanzi’s ability to understand syntactic complexity, Savage-Rumbaugh, Murphy, and colleagues (1993) report that in testing he responded differentially to utterances that were semantically similar but syntactically different (see Truswell 2017, for discussion). This includes utterances like:

Put the tomato in the oil.
Put some oil in the tomato.
In cases like the former, Kanzi is reported to have put the tomato in the oil as requested; and in the latter, to have poured oil into a bowl with the tomato. Truswell has recently argued that these data suggest that Kanzi tracks not only the semantic properties of utterances, but also syntax-relevant properties like linear order (Truswell 2017). However, he also shows that Kanzi struggles with some simple, non-linear grammatical forms, where word order is not sufficient to generate correct interpretations of the sentence. For example, when asked to ‘Fetch the tomato and the oil’, Kanzi typically brings only one or the other. Truswell argues that this shows that Kanzi is unable to understand hierarchical syntactic relations like binding two nouns to the same verb (2017). That is, he cannot represent the internal structure of sentences, where this differs from the order of words in those sentences. Rather, he just decodes words in the order they are presented.

This finding suggests that humans have a capacity for hierarchical syntax that may not be possessed by even enculturated great apes. It also raises the question of whether there is evidence of any ability to master non-linear grammars in any animal species. In this context an early study on captive bottlenose dolphins (Herman, Richards, & Wolz 1984) provides stronger evidence for hierarchical processing. In this study, two bottlenose dolphins were instructed in an artificial language to perform specific actions in relation to named objects and modifiers. While one dolphin was trained in the use of a linear grammar (‘A take to B’), the other was trained to use a non-linear grammar (e.g., ‘to B, A take’ rather than ‘A take to B’). Since the dolphin was able to master these constructions, albeit imperfectly, it may be that dolphins are not limited to tracking linear order. However, since this is a single study of one animal, it is possible to draw only limited conclusions about what it shows. This is especially so since Herman’s study does not report in full the sentences on which dolphins were tested, making a more detailed analysis of its performance impossible.

Thus, for now, it can be concluded only that there is no real evidence of any ability for hierarchical syntax in the animal kingdom, either in the production or in the comprehension of utterances. More studies will be needed before strong conclusions can be drawn. Nonetheless, in recent years a clear set of theoretical frameworks have emerged within which putative cases of syntactic complexity can be studied and evaluated. Methods for operationalising these theoretical insights, and testing hypotheses empirically, are still being developed.

4. Pragmatics
The study of pragmatics relates to the use and interpretation of meaningful signs. However, what exactly this is taken to mean is controversial.

4.1 Carnapian pragmatics
As noted in the discussion of functional reference (see §2.1), animal vocal signals have often been thought non-voluntarily produced, and so crucially unlike language-use (Tomasello 2008; Wheeler & Fischer 2012). Consequently, language evolution researchers have sometimes maintained that these signals are uninteresting from the perspective of language evolution research. Others have argued that we can nonetheless find an analogue of some features of language in the context-dependent interpretation of signals, whether or not these are voluntarily produced (Wheeler & Fischer 2012). Such cases might be treated as instances of pragmatic interpretation. Since many (e.g., Tomasello 2008; Scott-Phillips 2017; Moore 2017a) have hypothesised that pragmatics plays a foundational role in the evolution of language, studying the pragmatic features of animal communication might shed light not only upon interactions between animals, but language origins too. This view has been defended not only by Wheeler & Fischer (2012), but by Scarantino (2017; Scarantino & Clay 2015).

Scarantino’s ‘Theory of Affective Pragmatics’ “focuses on what emotional expressions mean in a context” (Scarantino 2017: 166; see also Scarantino, Hareli, & Hess 2022), and the ways in which emotional expressions direct others’ behaviours, allowing for analogues of descriptive, commissive, imperative and expressive speech acts. He argues that in the non-verbal communication of humans and animals, emotional expressions play a richer proto-linguistic role than previously acknowledged: “much of what we can do with language we can also do with nonverbal emotional expressions” (2017: 165). On his view, an angry frown in the appropriate context can amount to describing a target behaviour as unacceptable, demanding that the behaviour stop, and as expressing disappointment, among other things. By showing how emotional expressions can perform the function of illocutionary force (for example, by showing whether an utterance conveys a request or an order), Scarantino proposes to contribute to an explanation of language evolution, by showing how key elements of speech act theory are already present in the animal kingdom.

Scarantino’s approach emphasises studying the contextual interpretation of animal signals for understanding the evolution of language. It is part of a body of pragmatics-influenced work on language evolution that has been labelled ‘Carnapian pragmatics’, after the philosopher Rudolf Carnap. As Bar-On and Moore define it, Carnapian pragmatics

is the study of the variation (and derivation) of the significance of sentence (or signal) types with the context of production. (Bar-On & Moore 2017: 296)

Proponents of Carnapian pragmatics (e.g., Seyfarth & Cheney 2003; Fitch 2010; Wheeler & Fischer 2012; Arnold & Zuberbühler 2013; Scarantino & Clay 2015; Seyfarth & Cheney 2017) argue that the informational contents of animal signals are context-dependent, in the same manner as linguistic terms like indexicals. For example, putty-nosed monkeys produce eagle alarm calls (‘hacks’) in the presence of eagles, but they also produce these calls in non-predatory situations, such as in response to falling trees and baboon fights (Arnold & Zuberbühler 2013). When eagle calls are given in these non-predatory contexts, putty-nosed monkeys do not respond by enacting characteristic flee behaviours (as they would for eagles), suggesting that the informational contents of eagle calls are different in different contexts, and that receivers integrate contextual information in interpreting the calls. Scarantino and Clay (2015) identify four main categories of the kinds of contextual clues they think likely influence the interpretation of animal communication:

identity cues, which contain information about the identity of the signaller (e.g., status, age, kinship, reliability);
behavioural cues, which contain information about the activity of the signaller during signal production (e.g., gaze and body orientation);
environmental cues, which contain information about events occurring in the environment; and
sequence-placement cues, which contain information about the signal sequence (e.g., other signals produced in adjacent periods of time).
The concept of information at work in Carnapian pragmatics corresponds to a loose version of Grice’s notion of natural meaning (Grice 1957; Scarantino 2015; see §2.1). It is the kind of meaning that allows us to make inferences about some parts of the world based on our perception of other parts. On Scarantino’s account, identity cues (like the pitch of a caller’s voice) might (naturally) mean that a call is being given by one member of a group, rather than others; and contextually salient behavioural cues, like the caller’s line of sight at the time of the call, naturally indicate that the call was produced in response to some features of the environment, rather than others.

Different versions of Carnapian pragmatics make different claims about the role of information in guiding the contextually variant responses of the animals who perceive and interpret signs. Information can be used either as a proximate or as an ultimate explanatory construct (Kalkman 2017; Mayr 1961). As a proximate explanatory construct, information is something that recipients represent on a psychological level, explaining how recipients respond to communicative signals. As an ultimate explanatory construct, information accounts for the evolution of recipients’ responses, without necessarily being psychologically represented by them. In other words, when information plays an ultimate explanatory role, the fact that signals correlate with, i.e., carry information about, determinate states of affairs explains why determinate responses have been selected. Whereas according to Wheeler and Fischer (Wheeler & Fischer 2012) animals respond to communicative signals by mentally representing the signals’ informational contents, Scarantino thinks the information extracted is not necessarily psychologically represented by animals (Scarantino 2013, 2017; Scarantino & Clay 2015).

There are theoretical benefits of a Carnapian pragmatic approach to animal communication and language evolution. It can explain communicative interactions between animal communicators, and identifies continuities between animal and human communication even where the mechanisms of signal production in animals and humans differ. Some scholars have nonetheless criticised the relevance of Carnapian pragmatics to language evolution research. According to Bar-On and Moore (2017; Bar-On 2021; Moore 2017d), Carnapian pragmatics fails to isolate the right point of continuity with language to constitute a foundation for language evolution research. They argue that if we accept that language develops on the back of a capacity to act with and interpret intentionally communicative behaviour, it is unclear how we can hope to shed light on its evolution by focusing on a notion of meaning—natural meaning—the interpretation of which may implicate quite difference psychological processes from those needed for the interpretation of communicative goals. Bar-On (2021) argues that Carnapian pragmatics sets the explanatory bar too low. Context-dependent interpretation, she argues, marks continuity between animal and human communication, but this continuity “seems hardly sufficient by itself to illuminate the origins of distinctively human communication” (Bar-On 2021: 4), since the sense in which animals are said to extract information from communicative signals is the same in which a person extracts information about fire from (non-communicative) signs of smoke. In that case, she argues, work on Carnapian pragmatics in animal communication cannot tell us much about the evolution of language—at least if we think that language evolution required the interpretation of specifically communicative acts.

4.2 Gricean pragmatics
Some authors have adopted a ‘Gricean’ approach to describing the psychological states that support at least some kinds of (voluntary) animal communication (Gómez 1994; Brinck 2004; Moore 2017a). These approaches take their name from the philosopher Paul Grice, whose work attempted to specify necessary and sufficient conditions for an agent to act with communicative intent (in his words, actions possessed of non-natural meaning, or ‘meaningNN’). While Grice’s work has been highly influential in the study of human communication, it has often been considered ill-suited to the characterisation of the communication of animals, because the mental states Grice identified as characteristic of communication are thought to implicate psychological states that cannot plausibly be attributed to non-human minds. In Grice’s own words, communicative intentions are “plainly too sophisticated a state to be found in a language-destitute creature” (1986: 85).

The authors who argue that animals may be Gricean communicators accept Grice’s characterisation of communicative intentions, but reject his conclusion that communicative intentions cannot be attributed to animals (Gómez 1994; Moore 2016). This is because they deny that Grice’s characterisation of the cognitive prerequisites of meaningNN are entailed by his analysis of the intentional character of communication. This idea is controversial.

On Grice’s account, what distinguishes actions possessed of meaningNN from other kinds of actions is the intentions with which they are performed. Variations of his analysis of his account have been widely, if not universally, accepted (see Neale 1992; Sperber & Wilson 1995; Tomasello 2008; Scott-Phillips 2015). The following characterisation is derived from Neale’s (1992) modification of Grice’s (1957) account.

A speaker S acts with communicative intent if and only if she performs an utterance (x) for an interlocutor H intending:

(1)
H to produce a particular response r, and
(2)
H to recognise that S intends (1),
and additionally

(3)
S has no further intention that H be deceived about (1) and (2).
Together clauses (1), (2) and (3) are necessary and sufficient for acting with communicative intent. On this formulation, (1) specifies the goal that a communicator, S, aims to achieve through her utterance of x. Usually this is specified as either (i) an intention to produce a belief in H, or (ii) to have them perform some action α (although there may be other options [Moore 2017a]). For example, if I leave my empty wine glass on the table where you can see it, with the goal that you see and refill it, my intention (1) would be to have you refill my glass. While the first clause intention is necessary for an action to be communicative, Grice argued that it is not sufficient. That’s because many intuitively non-communicative actions can also be performed with intentions like (1). For example, I might surreptitiously leave my empty glass in view in the hope that you’ll see it, but without drawing attention to this for fear of seeming rude. This is consistent with (1), but Grice argued that such cases are intuitively not communicative.

For Grice, what truly distinguishes communicative acts from many other types of intentional act is their overtness. Successful communication is a public act: we know when someone is communicating with us. This is not the case in the example of me discreetly moving my glass, since here my host might be entirely unaware of my surreptitious goal. The openness of communication is captured by the addition of (2). I might fulfil (2) not only by leaving my glass where you can see it, but by deliberately drawing your attention to my glass. Here I not only have an intention like (1), but I also intend that my interlocutor recognise that I have this intention. The addition of clause (2) rules out cases where I try to have you refill my glass surreptitiously, and thereby captures the openness of communication.

Clause (3) blocks certain cases (Neale 1992) that many commentators have thought constitute counterexamples to Grice’s analysis. Typically they turn on cases where a speaker has a higher order intention that undermines their possession of (1) and (2), and so threatens the sufficiency of (1) and (2) for an account of communicative intentions. While many have thought this justifies the insertion of a blocking clause like (3), it need not be entertained by speakers (or hearers) to do its work, and so doesn’t add any complexity to the psychological states involved in Gricean communication.

4.2.1 Rehabilitating the Gricean account
A myriad of objections have been raised to the possibility that non-humans could be Gricean communicators. The most common concern is that Gricean communication is socio-cognitively demanding, because Gricean communication requires higher order metarepresentations of others’ mental states. For example, in the case of an utterance that is produced to change others’ beliefs, Grice’s analysis seems to require entertaining a fourth order metarepresentation like (i) S intends that (ii) H believe that (iii) S intends that (iv) H believe that p (Dennett 1983; see also Planer 2017; Scott-Phillips 2015; Sperber 2000; Sterelny 2017; Thompson 2014; and Gómez 1994; Brinck 2004; and Moore 2017a, for criticism of this view). Given that even twelve-year-old children struggle to understand fourth order meta-representations (Liddle & Nettle 2006), and since there is evidence of first order belief understanding in only a few animal species (Krupenye et al. 2016), these requirements seem to preclude the possibility of Gricean communicators in the animal kingdom.

Further concerns have also been raised, including that Gricean communication requires syntactically complex propositional thought (Bar-On 2013); that Gricean communication requires uniquely human forms of joint action (Tomasello 2008; Jankovic 2014; see Moore 2018a; see also §5.2); and that it requires a motivation to share information about mental states that seems to be missing from the animal kingdom (Bar-On 2013; Tomasello 2008; Scott-Phillips 2015; Scott-Phillips & Heintz 2023; see Moore 2017c for discussion; see also §5).

Proponents of the view that animals can be Gricean communicators argue for the claim not by attributing rich metarepresentational and cooperative abilities to animals, but by arguing against the assumption that Gricean communication is socio-cognitively difficult. For example, several proponents of the Gricean view have argued that Grice’s clause (2) can be fulfilled by the role of eye contact in communicative interaction, and that consequently subjects need not be capable of higher order metarepresentations to be able to act and interpret Gricean intent. They argue that if communicators engage their interlocutors in mutual eye contact as a means of addressing their communicative acts to them, as great ape species do (Gómez 1996), then their first clause intentions (1) will be public in a manner sufficient for the fulfilment of (2) (Moore 2017a; see also Gómez 1994; Brinck 2004). Moore (2017b) additionally argues that clauses (1) and (2) specify functional features of communicative acts, and their psychological correlates. For example, it’s because utterances are ordinarily causally inefficacious that they must be directed to the attention of their intended interlocutors, in the manner described by (2), so that interlocutors are encouraged to make inferences about the contents of agents’ communicative goals. As a result, he thinks, Gricean forms of communication may be present in many animal species, even if such creatures can produce and interpret only a very limited repertoire of Gricean acts.

Additional attenuations of the complexity of Gricean communication can also be made. For example, it has been argued there may be Gricean communicators whose communication consists only of imperative-like utterances, produced to solicit others to act (Moore 2017b; although see Scott-Phillips & Heintz 2023 for a contrary view); who engage in only limited forms of collaborative action, if any (Moore 2018a); whose utterances are not even propositionally structured (Moore 2021); and that there may be signature limits on the interpretational abilities of great ape communicators, despite their being Gricean communicators (Graham, Rossano & Moore 2024). On this development of the ‘minimally’ Gricean view, what is essential is only that communicative acts are produced with intentions characterised by clauses (1), (2) and (3), as described above, and that interpreters are capable of interpreting such intentions.

4.2.2 Objections to the ‘minimally’ Gricean View
Many object to even ‘minimally’ Gricean approaches to explaining animal communication.

Planer & Sterelny (2021) have argued that since folk psychology is a human construct, and not likely to be reflective of cognitive processes that support human communication, then we ought not to suppose that folk psychological theories of communication play any interesting role in explaining our communication. A similar point has been made by Dennett (2017; see also Azzouni 2013; Planer forthcoming), who argues that while Grice’s characterisation of communication is broadly right, we ought not to think of the states Grice described as needing to be represented by communicators. (As an analogy, consider that someone could catch a falling tennis ball without being able to represent the mathematical description of its trajectory.) The latter objection has something in common with Gricean approaches to animal communication, in that both views argue that common interpretations of Gricean psychology have been intellectualised. If Grice’s intentions need no longer be represented by subjects, or need not be represented in the ways often thought, then it’s no longer clear why the cognition of communicative intentions would be prohibitively difficult. (If agents need not represent the elements of Gricean intentions, then it becomes less clear why anyone would consider them too cognitively difficult for animals to understand. But perhaps humans alone have undergone the processes of natural selection that would enable us to track the features of Gricean intentions (Sperber & Wilson 2002; Azzouni 2013, especially p.348).)

Perhaps the most common objection to applications of a Gricean framework to animal communication is that the de-intellectualised reading of Grice is no longer recognisably Gricean. In response, Moore argues that his account satisfies clauses (1)–(3), discussed above, and that this is all that being a Gricean communicator requires (Moore 2017b). While recognising that animals are limited in comparison to humans in the complexity of the communicative intentions they can entertain and interpret, this does not necessitate giving up the Gricean framework for studying animal interactions. Instead, we can use the Gricean approach to develop a coherent, continuous theoretical framework within which to make sense of continuities between human and animal communication, while also allowing us to track points of difference. These include differences in the syntactic complexity of human and animal communication, and the additional resources that more sophisticated (e.g., human) agents can bring to pragmatic interpretation—including, for example, their ability to reflect on higher order mental states to help them disambiguate the contents of others’ utterances.

4.3 Intermediary pragmatics
Among those who accept that Gricean accounts of communication are cognitively demanding in ways that makes them unsuitable for application to animal communication, some have developed alternative theoretical accounts of intentional communication that can be used to characterise the interactions of non-humans. In different ways, such approaches have been developed by Millikan (1984, see also 2017), Green (2007), Bar-On (2013, 2021, forthcoming), Planer (2017), and Sterelny (2017), among philosophers, and Warren & Call (2022) and Scott-Phillips & Heintz (2023) among cognitive scientists. Common themes in their work include the idea that animal communication can be voluntary, goal-directed, and that hearers may sometimes make inferences about speakers’ goals—but where this can be achieved without Gricean demands on metarepresentation and Theory of Mind. Some of these authors have focused specifically on the development of accounts of pragmatic interpretation that are motivated by the rejection of both Gricean and Carnapian approaches. Bar-on (forthcoming) has called such accounts ‘intermediary pragmatics’.

Despite thinking that Gricean approaches are too cognitively demanding to support an account of the communicative interactions of languageless creatures (Bar-On 2013: 345), Bar-On thinks Grice was right that an account of pragmatic inference in animals must be “psychologically mediated” in the manner of human communication, at least if it is to play a role in explaining language evolution. Her intermediary pragmatics covers a class of behaviours that can be voluntarily produced and are psychologically mediated, and whose interpretation depends upon understanding speakers’ intentions, yet where the relevant intentions are not characterised in Gricean terms (Bar-On forthcoming),

Bar-On’s account is intended to accommodate communicative interactions between minded agents who lack a theoretical knowledge of mental states but who can nonetheless engage in processes of mutual interpretation. Often these types of interactions are made possible by the presence of expressive behaviours which show agents’ psychological states, including facial expressions and bodily postures, and that make subjects’ mental states perceptually available to observers. (see Bar-On 2013). They are said to be ‘Janus-faced’, insofar as they reveal both the states of the world to which a signaller is attending, and the signaller’s attitude or response towards those states. For example, a chimpanzee who leaps away from a Gaboon viper can be understood by an observer as being both directed towards and fearful of that snake. Although expressive behaviours are not always under intentional control, some can be brought under voluntary control. Moreover, they may be present when agents produce voluntary signals, in a manner that facilitates interpretation of them. In Bar-On’s words, this gives expressive signals

a proto-pragmatic life of their own qua communicative acts that are not underwritten by Gricean intentions. (Bar-On 2013: 368)

Bar-On emphasises that whether signal interpretation involves intermediary pragmatic interpretation is independent of how signals were learned. What’s key is that the communicative use of a signal relies on a receiver’s capacity to integrate contextual information, including arguably an uptake of the caller’s psychological state, as this is shown by their expressive behaviours. This can also occur even when signals are unlearned and produced inflexibly.

Another account of animal communication that falls under the banner of ‘intermediate pragmatics’ is Armstrong’s theory of representational coordination (Armstrong 2023), which he uses to model the ‘minded’ communicative interactions of primates living in relatively complex social groups. Like Bar-On, he emphasises that these forms of animal communication can be psychologically mediated, without being Gricean.

On Armstrong’s account, ‘minded communication’ is characterised in terms of its being flexibly (i.e., voluntarily) produced, generating responses that are also under the voluntary control of receivers, and as involving signals that are produced in order to coordinate the representational mental states of agents. Senders and receivers act flexibly based on their representations of their environment, and their expectations about the outcomes of their actions, including the perceived costs and benefits of their actions. Armstrong identifies the (biologically inherited) alarm calls of vervet monkeys as a plausible instance of minded communication. These calls succeed when senders and receivers both entertain representations of the same features of the world—like the presence of predator.

4.4 Concluding remarks on pragmatics
An outstanding theoretical debate for accounts of animal pragmatics concerns the extent to which existing views are inconsistent. There is good reason to think they are not. For example, proponents of Gricean and intermediate views accept that some calls are not under intentional control, and that the interpretation of these calls can be modelled by Carnapian approaches. Their objection, is rather, that these approaches are not suitable for characterising stages in the relatively recent evolution of language. Similarly, proponents of Gricean and intermediary pragmatics agree on many features of animal communication. It may be that their disagreement is partly terminological, concerning what is worthy of the name ‘Gricean’. This isn’t the only point of difference, though. For example, Moore places more emphasis than Bar-On on the ways in which utterances are addressed to others, and the psychology of this address (see §4.2). This may make their views compatible, but suited for describing slightly different cases—depending on whether communicative acts were deliberately addressed to their intended recipients. This would, potentially, make the transition to Gricean communication in phylogeny a case of the address of voluntary expressive acts, like those characterised by Bar-On (2013), being gradually brought under psychological control.

One point on which all would agree is that we currently don’t know enough about animal abilities for pragmatic interpretation, in any species, either with respect to the contextual interpretation of involuntarily produced signals, or the intention-dependent interpretation of voluntary signs. Some suggestive cases have been published, including studies of pointing comprehension in numerous species (Tomasello, Call, & Gluckman 1997; Hare & Tomasello 2005; Nawroth, Martin, & McElligott 2020). Nonetheless, more empirical research on contextual variation in the interpretation of both voluntarily and non-voluntarily produced signs would provide philosophers with welcome opportunities to theorise about the nature and limitations of these abilities.

5. Cooperation in Animal Communication
A final issue to consider concerns the extent to which animal communication is cooperative. The cooperative foundations of human communication have been thought key to explaining the evolution of language (Tomasello 2008), and some hold that only for humans do we have good evidence of voluntary, cooperative communication—performed for the purposes of sharing information, like the location of food. For example, Tomasello writes:

Communicating information helpfully … is extremely rare in the animal kingdom, even in our closest primate relatives[.] (Tomasello 2008: 5)

Scepticism regarding animal cooperative communication may be motivated by the idea that prosocial behaviour is biologically maladaptive. Prosocial behaviour—that is, behaviour in which one individual pays a cost to benefit another—has long been thought to be potentially difficult to explain within the framework of Darwinian natural selection (Hamilton 1964; Axelrod & Hamilton 1981; Axelrod 1984). If sharing information facilitates another’s survival, and natural selection is a matter of survival of the fittest, then an individual who shares information to benefit another may undermine its own survival prospects. There are several problems with this claim, though. First, what is meant by cooperative activity must be explained. Secondly, we ought not overstate the degree of empirical support for claims about the ‘selfish’ nature of animal communication.

5.1 Signalling theory
A minimal notion of cooperation is at work in signalling theory, a highly influential approach to communication inspired by David Lewis’ work Convention (1969). Versions of this view are defended by Millikan (1984, 2017), Green (2007), Skyrms (2010), Planer & Sterelny (2021), and Planer & Godfrey-Smith (2021), among others. Signalling theory frames the communication of biological species using the tools of evolutionary theory (Skyrms 2010). It views communication as a dynamic process of coadaptation between a sender and a receiver, where senders and receivers mutually shape their behaviours over time.

Often presented as an alternative to Gricean approaches (e.g., Planer & Sterelny 2021), signalling theory makes only modest demands on agent psychology, and makes no references to speakers’ intentions. This makes it suitable for characterising the communication of many biological species, including cells and bacteria, whose interactions are unlikely to be well characterised by intentionalist theories of communication. It is sometimes also adopted by authors who are sceptical that folk psychological explanations of behaviour map neatly onto a mechanistic account of the mind (ibid.). While often used to frame accounts of biologically coevolved pairs of signals and responses (Tinbergen 1952, Maynard-Smith & Harper 2003), its application is also not restricted to such cases. Signals may also be designed by processes of cultural evolution (Millikan 1984), copied (Planer & Godfrey-Smith 2021), or even improvised (Planer & Sterelny 2021), so long as there is some process by which they are designed and selected. However, to the extent that signalling theory dispenses with reference to speakers’ intentions, it may be unsuitable for characterising signals the interpretation of which is intention-dependent.

In the classic set-up devised by Skyrms (2010), senders and receivers are viewed as asymmetrical agents. The sender can perceive the world, but is only able to act in ways visible to the receiver. The receiver can act but cannot perceive the world. In this scenario selective pressures can lead to the emergence and stabilisation of signalling systems. Signallers can evolve to produce signs in response to perceived states of affairs, transmitting information to receivers; and receivers can evolve to respond to signals, since it is adaptive for them to learn about states of the world they cannot perceive. The essence of communication, according to signalling theory, lies in coordination between the receiver’s actions and states of the world (act-state coordination), including the sender’s actions (act-act coordination) (Planer & Godfrey-Smith 2021). This coordination is exemplified by the receiver attending and responding to what the sender perceives, such as the presence of a predator or a source of food, or what the perceiver is doing. For example, based on this framework, play signals can be seen as enabling coordination between senders and receivers during play (Bekoff 1975); and aggressive displays as enabling their recipients to coordinate with senders’ aggressive states of mind (Hinde 1981).

One key issue in signalling theory concerns the stability of honest signalling (Maynard-Smith & Harper 2003; Searcy & Nowicky 2005). In cases where senders can benefit by deceiving receivers, the signalling system is at risk of collapse—because receivers who are too often deceived will stop responding to signals. Many cases of deception have been documented in animal communication. For example, Photuris fireflies mimic the flashing mating signals of female Photinus fireflies to prey on the males (Lewis & Cratsley 2008).

A number of explanations have been offered to explain the stability of signalling systems. Some scholars have underlined common, cooperative interest as a stabilising factor in the emergence and maintenance of signalling systems within and between species (Planer & Godfrey-Smith 2021; Millikan 2004, 2017). When it is in the interests of both senders and receivers that receivers appropriately respond to the states of affairs signalled by the signals, there is little incentive for signallers to deceive, and signals stabilise. However, there may also be circumstances when signalling systems can stabilise even where agents’ interests do not overlap (Planer & Godfrey-Smith 2021). Planer & Sterelny (2021) also argue that communicating in small groups reduces the problem of dishonest signalling, because where there are multiple senders, and so multiple sources of information, attempts at deceiving become more risky, because they are more likely to be discovered.

Other authors have emphasised the adaptive value of signals that are hard to fake (Green 2007, 2009). These are relatively common in the animal kingdom. ‘Indices’ are signals that are difficult to fake because they are connected to agents’ physical characteristics. For example, tigers leave scratch marks on trees corresponding to their body size. The higher the marks on a tree, the larger a tiger must be to have left them—providing nearby competitors with reliable estimates of the animal’s size. ‘Handicaps’ are signals that are hard to fake because they are costly for the signaller. For example, the tail of a peacock is large and heavy, hindering the peacock’s mobility and potentially diminishing their chance of survival. Carrying a big tail is a reliable indicator of health, because only strong peacocks can bear the energetic cost.

One recent application of signalling theory is what Green calls ‘organic meaning’, by which he aims to bring together all instances of meaning in communication (Green 2019). On Green’s account, organic meaning is the transfer of information between a sender and a receiver that is the product of design. Natural design, learning mechanisms, and intentional design are all possible ways in which the signal can provide receivers with information: the notion of design encompasses, in Green’s account, evolutionary, cultural evolutionary, and intentional tools. In this respect Green’s approach is similar to Millikan’s account of intentional signs (1984, 2017). When a signal is specifically designed to convey information about an agent’s psychological states (including emotions, intentions, beliefs and desires), it is considered, by Green, a case of expression (Green 2007).

Providing receivers with information gives a broad-brush explanation of why communicative acts are performed. Green’s account of organic meaning can therefore be seen as providing a unified theoretical framework for the study of communication, since it can be applied to many communicative interactions in both animals and humans. An eagle alarm call is, like the utterance of a sentence like “There’s an eagle”, produced to provide receivers with information about eagles; and there is a sense in which both kinds of signal were designed for this end. At the same time, Green’s framework is very general: his notion of design is neutral about the biological, cultural, and psychological processes underlying signal production. Thus, for all that Green’s theory can help us to understand the properties that many communicative acts have in common, it has little to say about other features of communicative behaviour that are important for understanding the nature and evolution of communication in animals and humans, and which are not included in this account (Palazzolo forthcoming).

5.2 Communication as a form of joint action
While there is a weak, non-psychological notion of cooperation at work in signalling theory, it is not the kind of cooperation thought central to human communication by some cognitive scientists, and characterised by Tomasello as “human cooperative communication” (Tomasello 2008). (While Tomasello takes his view to be the same as Gricean communication, we don’t assume that here.)

Tomasello’s claim that communicating “helpfully … is extremely rare in the animal kingdom” (Tomasello 2008: 5) incorporates two independent notions of cooperation. The first concerns the motivations with which agents communicate. Tomasello distinguishes between communicating to share information and communicating to make requests or give orders. The former function, which includes utterances like “There are strawberries by the river”, can be produced for reasons that are intended to benefit the intended recipient, without necessarily benefiting the signaller (i.e., helpfully). It is paradigmatically (although not always) performed using assertion-like speech acts. Helpful utterances are contrasted with utterances produced to benefit the sender, like “Give me that food!”. These are paradigmatically (although not always) performed using directive speech acts.

The second sense of cooperation to which Tomasello appeals characterises human communication as a form of ‘shared intentionality’ (Bratman 1999: part 2; Jankovic 2014). This term describes the action characteristic of agents who voluntarily engage in collaborative activity. Shared intentionality is often thought to be psychologically demanding in respects comparable to Gricean communication (Butterfill 2012; Blomberg 2015).

Tomasello uses the term ‘human cooperative communication’ to describe a Gricean (or ‘ostensive-inferential’ [Sperber & Wilson 1995]) psychological framework for communication that, he thinks, is made possible only by the co-presence of communication that is both helpful, and a form of joint action (see Moore 2018a for discussion). He holds that communication is a form of shared intentionality because, at least in human communication, Gricean forms of pragmatic interpretation are pervasive (Sperber & Wilson 1995). Since a speaker’s message must be inferred from what they say, a signaller must craft a message to communicate their goal, and their interlocutor must spend time and effort attending to and interpreting the signaller’s message. Tomasello also proposes a connection between helpful, informative communication and the kinds of Gricean pragmatic interpretation that he thinks essential for explaining language evolution. He argues that Gricean communication arose in evolutionary history only when speakers and hearers became willing to invest time and effort interpreting one another’s utterances, and that they did this only when they expected their interlocutors to provide them with helpful information (Tomasello 2008). As a result, Tomasello thinks the psychological framework that is characteristic of Gricean communication evolved in phylogeny only when agents started to communicate to help others. Since chimpanzees communicate largely to make requests, and not to share information, Tomasello argues they cannot be Gricean communicators. This requires motivational (not to mention cognitive) states not present in the animal kingdom. This argument purports to explain why chimpanzees are poor at understanding informative pointing (Tomasello 2006, 2008; Herrmann & Tomasello 2006). Tomasello and colleagues argue that chimpanzees are fundamentally competitive, not cooperative (Hare & Tomasello 2004). Meanwhile domestic dogs, who have been bred to help humans, fare much better at understanding helpful points (Hare & Tomasello 2005).

A number of issues could be raised with this view. First, as Section 4.2 makes clear, Grice’s analysis of meaningNN was specified to incorporate imperative utterances. So Tomasello may be wrong to think that only unselfish communicators can be Gricean communicators (Moore 2017c). Furthermore, it may be that while some forms of communication (e.g., conversation) require ‘shared intentionality’, not all do. If Gricean communicative acts are not always difficult to interpret then, where the interpretational demands are reduced, it may be possible for interlocutors to grasp one another’s messages without effortful interpretation. In such circumstances, the collaborative demands on communication would decrease (ibid.). Nonetheless, Tomasello may be right that historical increases in the motivation to attend to and engage with an interlocutor were driven by agents’ expecting to benefit from communicated information. In turn, this may have driven improvements in pragmatic interpretation, and language evolution, even if these factors are independent of whether agents are Gricean communicators. On such a story, one would expect to find more impressive feats of pragmatic interpretation in attentive species, like domestic dogs, who do understand informative pointing (Hare & Tomasello 2005), and perhaps even individual differences between members of the same species that correlate with social attention (Benítez-Burraco, Ferretti, & Progovac 2021; Berio & Moore 2023). This would be a valuable avenue for future research.

Nonetheless, Tomasello’s second claim—that cooperative communication is uniquely human—is built on a very limited sample of animal communication. In part, this is because relatively little is known about the intentional communication and interpretation of signals by many species. Even for well understood species, like dogs and chimpanzees, there is a great deal to learn. For example, since Tomasello’s 2008 book, compelling evidence of voluntary, helpful communication has been found in chimpanzees, with the discovery that they call to warn ignorant others of the presence of sleeping snakes (Crockford, Wittig, & Zuberbühler 2017; Moore 2019). For other species, even highly intelligent ones like dolphins, we know almost nothing about their natural communication. As we learn more about the animal kingdom, we may gather more evidence of voluntary, pro-social communication.

Existing theoretical frameworks for interpreting animal communication may also underestimate the extent to which it is produced with helpful, informative goals. For example, Tomasello’s claim about the rarity of helpful communication concerns only voluntary signals. He is not seeking to characterise evolutionarily conserved alarm calls that may not be fully under voluntary control, like the alarm calls of vervet monkeys (Wheeler & Fischer 2012; but see Cheney & Seyfarth 2018). As such, the question of whether these calls are cooperative (in the way he thinks rare) does not arise. If it were subsequently discovered that such calls are produced under voluntary control, the question of whether they are helpful would reappear. In recent years, we have learned that chimpanzee vocalisations are the subject of much more voluntary control than was recently thought to be the case. As we learn more about the ecology of wild animals, and better understand the function of their calls, claims about the motivations underlying calls may therefore be reevaluated.

6. Concluding Remarks
While philosophical work on animal communication is theoretically disunified, common themes recur in the literature, including questions about voluntary production, the psychological correlates of signalling behaviours and their interpretation, concerns about whether or not animal communication is cooperative, and the extent to which it might be syntactically complex. Additionally, different approaches may not always be incompatible, so much as complementary lenses for characterising different communicative phenomena across the animal kingdom.

At the same time, for all that accounts may be complementary, disagreements about the interpretation of data do arise. Different explanatory accounts reflect not only the different kinds of communication in the animal kingdom, but also competing philosophical commitments. In their interpretations of animal behaviour, some scholars emphasise richer, more human-like interpretations (‘booster’ views—e.g., Gricean vs. non-Gricean accounts of animal communication: compare Moore 2017a with Scott-Phillips & Heintz 2023), while others advocate for leaner, deflationary interpretations (‘scoffer’ views—e.g., Chomskian accounts of animal semantics). Disagreements may reflect a more general set of considerations about whether human and animal minds should be characterised in terms that are continuous, or discontinuous; and attitudes towards continuity-based explanations may in turn reflect different valuations of the explanatory principles that we should bring to bear on the interpretation of animals minds.

Competing parsimony principles encourage contrasting explanations of communicatively relevant behaviours in humans and animals. For example, eye contact is sometimes interpreted as important for, and so evidence of, Gricean communication in humans (Gómez 1994; Moore 2016). Whereas accounts motivated by cladistic parsimony (Sober 2005) interpret eye contact in great apes as evidence of similar communicative mechanisms in non-humans, those sympathetic to Morgan’s canon (Morgan 1894; see Andrews & Monsó 2021 for discussion) may prefer a deflationary interpretation of the same behaviour (Tomasello 2008; Scott-Phillips 2015). Nonetheless, the existence of fundamentally different approaches to the explanation of behaviour remains a feature of animal communication research. As new data on animal communicative abilities are collected, they will further constrain the empirically tenable claims that can be made. Much current research has taken primates as model species, and there may be much more to learn from different species, including cetaceans and eusocial insects. With the advent of new AI-driven technologies for interpreting animal communication, moreover, we may be on the cusp of thrilling new discoveries (Rutz et al. 2023). Nonetheless, the need for data to be interpreted, and the existence of competing explanations of the same behaviours, will ensure that philosophers have an important contribution to make to the characterisation of non-human communication.

1. “Comparative Philosophy of Religion” and Comparable Terms
1.1 Meanings of “Comparative Philosophy of Religion”
“Comparative philosophy of religion” has two main meanings. On the one hand, it can denote the comparative philosophical study of two or more religions. This meaning is typified by Franklin Gamwell when he defines comparative philosophy of religion as “critical reflection that asks: What most general understandings of the similarities and differences among religious activities are valid?” or, more succinctly, “What are the most general similarities and differences among religions?” (Gamwell 1994: 22). On the other hand, the term can denote the comparative study of two or more philosophies of religion. Timothy Knepper, for instance, compares what he calls “traditions of philosophy of religion,” under which heading he includes, as representative examples, East Asian, South Asian, Mediterranean/Abrahamic, African, Indigenous American, and European/Academic philosophies of religion (Knepper 2023: 15).

Since the distinction between a religion, or a religious idea, and a philosophy of religion, or a philosophical idea about religion, is not always sharp, there will be occasions when there is a merging of the two meanings of “comparative philosophy of religion” that have just been outlined. As Victoria Harrison remarks, “the global philosophical project … will inevitably involve the practitioner with religious ideas simply because the world’s philosophical traditions are permeated with them” (2020: 29). If, for example, one were to compare the ideas of Śaṅkara (c. 8th century CE) with those of Thomas Aquinas (1225–1274 CE)—as some scholars have done (e.g., Willman-Grabowska 1938; Smet 2013)—would one be comparing religious ideas or philosophical ones? The answer is apt to depend on exactly which ideas one is concerned with. On the face of it, however, there is unlikely to be only one answer, for both Śaṅkara and Aquinas are commonly regarded as religious as well as philosophical thinkers. Furthermore, some would argue that the very distinction between religion and philosophy is a product of European modernity (e.g., Howard 1996; King 1999: 4–5).

In principle, comparative philosophy of religion could involve comparing ideas from two or more philosophical or religious thinkers from within the same cultural tradition. For example, the views of al-Fārābī (870–950 CE) on the relation between reason and revelation might be compared or contrasted with those of Ibn Rushd (1126–1198 CE) (see, e.g., Kurmanaliyeva 2021), even though each of these thinkers belongs to the tradition of Islamic philosophical theology. More often, however, comparative philosophy of religion compares ideas from thinkers or schools of thought located in different traditions. For this reason, the terms “cross-cultural philosophy of religion” (Clayton 2006; Maharaj 2018) or “intercultural philosophy of religion” (Garsdal 2012; Mosima 2022) are sometimes used in place of “comparative philosophy of religion.”

1.2 Descriptive and Normative Approaches
The term “cross-cultural philosophy of religion” has occasionally been preferred to “comparative philosophy of religion” on the grounds that “comparative” has become associated with a “descriptive or phenomenological approach” whereas cross-cultural philosophy of religion is a normative enterprise that seeks to evaluate the truth-claims of various religions (Dean 1995: 3–4). Although there is indeed a notable divergence between approaches that emphasize description and classification, on the one hand, and those that emphasize normative evaluation and construction, on the other, it would be misleading to assume that the terms “comparative” and “cross-cultural” are used universally to designate these respective approaches. Some philosophers of religion readily embrace the term “comparative philosophy of religion” while nonetheless regarding philosophy as being necessarily concerned with “evaluative questions of meaning, truth, and value” (Knepper 2017: 1–2; see also Braak 2020: 21).

1.3 Dialogue Rather than Comparison?
Some works of comparative philosophy of religion are composed in explicitly dialogical form (see 2.2 below). Even when the style of textual composition is not dialogical, however, works of comparative philosophy of religion may be regarded as dialogical in an extended sense of the term. Gamwell describes comparative philosophy of religion as “interreligious dialogue that has become critical reflection” (1994: 21); as he sees it, the comparative enterprise involves bringing different religious voices into implicit dialogue with one another and critically reflecting upon their similarities and differences (22). John Clayton, following Wilhelm Halbfass, understands his own comparative exercises as the pursuit of “dialogic comparison by constructing imaginary conversations between major thinkers” (Clayton 2006: 102; compare Halbfass 1997: 307). For both Halbfass and Clayton, these imagined conversations are “between major thinkers of the European and Indian traditions” (Clayton 2006: 102), but in principle they could be between thinkers from any place or time.

Raimundo Panikkar preferred the term “dialogue” to “comparison” because he held that “comparison” implies, per impossibile, adopting a detached and neutral standpoint from which to observe and evaluate the merits of two or more positions (1980: 357, 358). Panikkar’s favoured image is that of an “encounter” between dialogue partners, who meet one another on an equal footing (1999: 26). If the exchange of ideas proceeds in terms of reasons and arguments, then Panikkar calls this “dialectical dialogue”; if it takes a more directly interpersonal form—getting to know the other as a “you”—then Panikkar calls it “dialogical dialogue” (ibid.). Even if it remains difficult to transfer this model of verbal interaction to the written page, its emphasis on mutual understanding and reciprocal progress towards a shared goal—without simply glossing over genuine differences—evokes a sensibility that authors such as Halbfass and Clayton have sought to emulate.[1]

2. Comparative Philosophy of Religion in Historical Perspective
2.1 Early Sources
How far back we should assign the origins of the branch of philosophy known as “philosophy of religion” is a contested matter. As some have observed, philosophical arguments and speculations relevant to religion are traceable to the earliest known Western philosophers in ancient Greece (Oppy and Trakakis 2009). Similar claims have been made about other ancient traditions, such as those of India and China, where the origins of philosophy were bound up with methods of “self-cultivation,” as indeed they were in ancient Greece and Rome (Gowans 2021; Machek 2024). There are thus good reasons for regarding philosophy of religion as having emerged alongside, or as part of, philosophy tout court.

So, too, are there good reasons for viewing philosophy of religion as having had a comparative dimension from ancient times onwards. We see this in, for example, early doxographies in ancient Greece and Rome. A doxography is a text that provides an overview of the key doctrines or tenets of one or more philosophers, thinkers, or schools of thought.[2] In addition to ancient Greek and Roman sources, doxographies are also available from medieval India, compiled by figures in the Brahmanical, Buddhist, and Jain traditions. Given the fluidity between philosophy and religion in the ancient and medieval periods, both the Greco-Roman and the Indian doxographies commonly amount to works of comparative philosophy of religion. They typically place divergent views in juxtaposition to one another, often in a partisan way—for example, ranking systems of thought on a scale from least to most credible—but sometimes in ways that are designed simply to highlight salient similarities and differences. One illustrative example from the ancient Greco-Roman world is Cicero’s De Natura Deorum (“On the Nature of the Gods,” 45 BCE), which takes the form of a dialogue between representatives of Epicureanism, Stoicism, and Academic Scepticism on theological and related topics (Cicero DND). A further example is Stromateis (“Patchworks,” c. late 2nd to early 3rd centuries CE), attributed to Clement of Alexandria, which lays out several Christian themes (faith, marriage, martyrdom, God’s ineffability, sin, the nature of Christ) while contrasting Christian views with those of Greek philosophers, poets, and other writers (Clement of Alexandria S).

Indian doxographies include Madhyamaka-hṛdaya-kārikā (“Verses on the Heart of the Middle Way”) by the Mādhyamika Buddhist Bhāviveka (8th century CE); Ṣaḍ-darśana-samuccaya (“Collection of the Six Views”) by the Jain philosopher-monk Haribhadra (8th century CE); and Sarva-siddhānta-saṃgraha (“Compilation of All Philosophical Conclusions,” c. 10th–14th centuries CE) by a representative of the Advaita Vedānta school who has been traditionally, albeit almost certainly apocryphally, identified as Śaṅkara (see, e.g., Raṅgācārya 1909). Despite structural, stylistic, and sectarian differences between these texts, it has been argued by certain interpreters that they share a driving soteriological purpose: readers are “trained to elevate [their] view, through a systematic dialogue with competing opinions,” and to thereby make progress towards a liberated state of wisdom (Bouthillette 2020: 21).

2.2 The Dialogue Form
Composing texts in dialogue form has been a prevalent means of undertaking comparisons in both European and Indian philosophical traditions, for dialogues enable different philosophical or religious viewpoints to be juxtaposed with one another. An example from ancient India is the dialogue depicted in the Bṛhadāraṇyaka Upaniṣad (c. 8th century BCE) between the female sage Gārgī and the male sage Yājñavalkya. Gārgī pushes her questioning about the foundation of the universe so far that Yājñavalkya ends the discussion by telling her that if she asks too many questions, her “head will shatter apart!” (Olivelle 1996: 40). Further examples featuring characters that embody different viewpoints or social positions include the respective dialogues between a Brahmin named Soṇadaṇḍa and the Buddha in the Buddhist Dīgha Nikāya (c. 1st century BCE) and between a king named Janaka and a female ascetic named Sulabhā in the Brahmanical epic Mahābhārata (c. 4th century BCE to c. 4th century CE). In the first of these, the Buddha convinces Soṇadaṇḍa that morality and wisdom rather than caste status are the essential qualities of a Brahmin (Shulman 2017: 379); in the second, Sulabhā argues that spiritual liberation can be attained only through renunciation and that, for this reason, a king cannot be liberated (Black 2015).

A distinction may be made between didactic forms of dialogue, whose purpose is to show the superiority of the position of one of the interlocutors, and contemplative or impartial dialogues, which are more even-handed in their presentation of the competing positions. Instances of the didactic variety include some of the dialogues by Plato, such as Phaedo and Republic, in which the character Socrates appears to be “a Platonic mouthpiece” (Morgan 1992: 233); other characters act as foils, whose questions are responded to by Socrates and whose counterclaims serve only to show the more compelling force of Socrates’ arguments. Instances of contemplative dialogues include Cicero’s De Natura Deorum (mentioned in 2.1 above), the style of which influenced David Hume’s Dialogues Concerning Natural Religion (1779; see 2.3 and 5.3 below). Clayton characterizes this contemplative style as “a kind of invitation to a conversation that is projected beyond the text at hand,” “an invitation to participate in a process of philosophizing” (Clayton 2006: 104).

2.3 Modern European Comparative Philosophy of Religion
David Tracy has argued that the figures who are primarily responsible for giving rise to philosophy of religion “as an autonomous and modern discipline” are David Hume, Immanuel Kant, and G. W. F. Hegel in the eighteenth and early nineteenth centuries, and that each of these three figures pursued a fundamentally comparative approach (Tracy 1990: 12–13).[3] In the case of Hume, the comparative method is explicit in his The Natural History of Religion (1757 [1956]) and implicit in the dialogical form of his Dialogues Concerning Natural Religion (1779) (Tracy 1990: 19). The purpose of the former of these works is to show that religion has its origins not in reason but in human nature, with its hopes and fears. In developing the argument, Hume examines different types of polytheistic and monotheistic religion, formulating an evolutionary theory of how, notwithstanding some toing and froing between the two, monotheism superseded polytheism. The Dialogues, by contrast, examine reasons for and against holding a belief in God, with a particular focus on arguments that have come to be known as “teleological” or “design” arguments. By giving voice to divergent viewpoints through invented characters, Hume brings the particularities of each position into relief.

In the case of Kant, Tracy points to several factors that indicate his “interest in comparativist issues”: these include Kant’s lectures on Eastern religions; his curiosity with reports by travellers and explorers; remarks in his Opus postumum (OP) on Zoroaster and Job; and “his insistence, in Religion Within the Limits of Reason Alone [1792], that his philosophical analysis of religion applied not only to Christianity but to all the religions” (Tracy 1990: 19). Tracy admits, however, that Kant’s principal concern in the latter work is to provide a “philosophical elucidation of the Christian religion” (1990: 21), a concern that restricts the scope of Kant’s comparative interests.

Hegel, too, gives pride of place to Christianity, “The Consummate Religion” (Die vollendete Religion) (Hegel LPR: Part 3). For Hegel (as paraphrased by Thomas Lewis), “The consummate religion is the one in which religion’s object is not simply the object itself, ‘God,’ but also the consciousness of this object”—and Hegel maintains that it is in Christianity that “God and consciousness of God” are unified (Lewis 2011: 205). Hegel’s comparative analysis of religions such as Buddhism, Hinduism, and Judaism, along with the religions of China, ancient Egypt, Greece, and Rome, occurs in Part 2 of his Lectures on the Philosophy of Religion, in which he devises a typology of “Determinate Religion” (LPR: Part 2). As Tracy contends, “at his elucidatory best,” Hegel was at the forefront of “developing a comparative hermeneutics of the historical religions” (Tracy 1990: 25). At the same time, however, Hegel was prone to ignore such factors as “historical context,” “internal developments and differences in distinct strands of a religious tradition,” and “the religions as living religions” (Tracy 1990: 25). Thus, although Hegel was a pioneer in comparative philosophy of religion, he left room for improvement in his methods of analysis.

2.4 Twentieth- and Twenty-First-Century Developments
Influential figures in comparative philosophy of religion from the twentieth century onwards—even if not all of them would identify primarily as philosophers—include Nishida Kitarō (1870–1945), Sri Aurobindo (1872–1950), Sarvepalli Radhakrishnan (1888–1975), Wilfred Cantwell Smith (1916–2000), Raimundo (aka Raimon) Panikkar (1918–2010), John Hick (1922–2012), Ninian Smart (1927–2001), Keith Ward (b. 1938), Robert Cummings Neville (b. 1939), and Arvind Sharma (b. 1940). For reasons of space, the exposition here will focus on Nishida, Aurobindo, Radhakrishnan, and Smart, who together represent a diversity of approaches. (For more on Panikkar, see 1.3 above; for more on Hick, see 3.3 below.)

Nishida was an independently minded Japanese philosopher who drew upon ideas from both Western and Asian philosophical and religious sources. Regarding religion as “the ultimate view of the world and the most important question” (quoted in Yusa 1987: 63), Nishida developed a philosophy of religion that, while invoking Christian and Buddhist ideas, is not reducible to one tradition or the other. Key themes for Nishida include the notions of “absolute nothingness” and the “absolute present,” each of which is connected with what Nishida understood the Zen Buddhist state of enlightenment or “seeing one’s nature” (kenshō) to consist in (Nishida 1945 [1987: 108]). Although, for Nishida, religion amounts to the human quest for eternal life, he maintained that eternity is to be found not in a state of existence after death, but in the durationless present instant. Borrowing imagery from Christian theologians such as Nicholas of Cusa, Nishida describes this “eternal present” as an infinite circle or sphere: because it “has no circumference, every point, every act of consciousness, is a center radiating in infinity” (Nishida 1945 [1987: 53–54]). Having been one of the main founders of the Kyōto School of philosophy, Nishida has inspired subsequent generations of Japanese philosophers, some of whom, such as Abe Masao (1915–2006) and Ueda Shizuteru (1926–2019), have themselves made significant contributions to comparative philosophy of religion and Buddhist-Christian dialogue (see, e.g., Mitchell 1998; Davis 2022).

Aurobindo Ghose, better known as Sri Aurobindo, was a visionary philosopher for whom the integration of what he viewed as the materialistic tendencies of Western thought and the spiritual tendencies of Asian, especially Indian, thought was central to his philosophical project. He developed a conception of spiritual discipline that he termed “integral Yoga,” which he regarded as a synthesis of the various systems of yoga that have been advanced in India over many centuries (Aurobindo 1999: chap. 5). This discipline is “integral” insofar as its aim is to integrate the bodily, mental, and divine aspects of one’s life, and “to liberate them into their highest possibilities” (1999: 19). Aurobindo’s philosophy has frequently been termed “integral philosophy” (e.g., Banerjee 2012; Prince 2017) since it, too, seeks to integrate elements from diverse sources. His facility with Western as well as Indian philosophical and religious ideas enables Aurobindo to draw upon both in formulating his own constructive vision; for example, he identifies the concept of “Supreme Brahman” with “that which in Western metaphysics is called the Absolute” (Aurobindo 2005: 338). Aurobindo conceived of philosophy as a spiritual discipline, “an effort at inner perfection of the being” (2005: 912). In common with later thinkers such as Pierre Hadot (1995), he views this spiritual orientation as being present in ancient Greek and Roman schools of philosophy (such as the Pythagorean, Stoic, and Epicurean schools), as well as in certain strands of “later Christian or Neo-pagan” thought; but, again like Hadot, he regards this orientation as having been lost in modern Western philosophy, wherein “the spiritual urge and the intellectual reason” have largely “parted company” (Aurobindo 2005: 912). For this reason, Aurobindo accentuates the benefits of a “fusion” between “the old Eastern and the new Western knowledge” as a means of investigating how that which is eternal and infinite gives rise to, or manifests as, time and space (2005: 122).

Sarvepalli Radhakrishnan was both a philosopher and a politician. Among other positions, he held the Spalding Chair of Eastern Religion and Ethics at the University of Oxford from 1936 to 1952 and was President of India from 1962 to 1967. His interest in comparative philosophy and religion is evident from the titles of some of his books, such as East and West in Religion (1933), Eastern Religions and Western Thought (1939), and East and West: Some Reflections (1955). Radhakrishnan’s view of religion is comparable to the later religious pluralism of John Hick (3.3 below). “Religious experience is not the pure unvarnished presentment of the real in itself,” he writes, “but is the presentment of the real already influenced by the ideas and presuppositions of the perceiving mind” (Radhakrishnan 1927: 24). In some places, Radhakrishnan, like Hick, implies that all religions—or all the major ones—are on an equal footing when it comes to conceptualizing reality or the divine truth: “While all traditions are of value, none is finally binding” (Radhakrishnan 1937: 120). Elsewhere, he gives pride of place to the Hindu philosophical school of Advaita Vedānta, which, he claims, “is not a religion, but religion itself in its most universal and deepest significance” (1927: 23). The “idealist view of life,” of which Advaita Vedānta is a paradigm case, has, however, taken many forms in different times and places—forms which, despite their “variations and oppositions,” share “the same spirit” (1937: 16). Radhakrishnan was a strong advocate of cooperation between Western and Asian societies in both the practical and the intellectual domains. “The separation of East and West is over,” he wrote in 1955, “The history of the new world, the one world, has begun. It promises to be large in extent, varied in colour, rich in quality” (1955: 131).

Ninian Smart was a major figure in twentieth-century philosophy of religion and in the study of religions more broadly. His approach was comparative from the outset; for example, his first book was a comparative study of Christian and non-Christian discourse (1958), and his second takes the form of an imagined conversation between six representatives of different religious traditions: a Jew, a Christian, a Muslim, a Hindu, a Sri Lankan Theravāda Buddhist, and a Japanese Mahāyāna Buddhist (Smart 1960). Smart held that “philosophers of religion … cannot ignore the comparative study of religions” because seeking the truth of religion requires comparing the reasons for favouring one purported revelation over others (1960: 11). Smart’s notable contributions to comparative philosophy of religion include his phenomenological method, his multidimensional analysis of “the sacred,” and his expansive notion of a philosophy of worldviews. Notwithstanding Smart’s concern with religious truth in some of his works, his phenomenological method, adapted from the earlier phenomenological tradition of Edmund Husserl and others, involves “bracketing” questions of truth while describing religious phenomena in sufficient depth to convey “what it is like” to participate in religious activities (Smart 1973: 33, 75). Such a method, Smart maintains, has the potential to facilitate widening the scope of philosophy of religion; by “stepping back” from any specific religious commitment, the phenomenologist may describe and compare multiple religions (1973: 7). Smart’s multidimensional analysis goes beyond a fixation on theoretical or doctrinal aspects of religion, taking account also of other “dimensions of the sacred” (1996), such as the ritual, mythic, experiential, ethical, social, artistic, and political dimensions. Religions may be compared in relation to each of these (and other) dimensions. Finally, Smart’s promotion of the study of worldviews encourages the comparative investigation of human systems of belief and practice in general, including those such as nationalism and secular humanism, rather than focusing solely on religions (Smart 1981, 2000). This approach of Smart’s is one that continues to be developed further by others (e.g., Davies 2022; Stenmark 2022); it is also becoming increasingly popular in educational settings (see O’Grady 2022).

In addition to specific authors such as those mentioned above, it should be noted that the twentieth and twenty-first centuries have also produced eminent events, projects, journals, and book series that have made substantial contributions to comparative philosophy of religion. Notable events include the series of East–West Philosophers’ Conferences sponsored by the Department of Philosophy at the University of Hawai‘i, beginning in 1939. Out of this series grew the journal Philosophy East and West, founded in 1951. Although the focus of the journal is not specifically religion, many of its articles will be of interest to philosophers of religion.

In the 1990s and in 2001, two book series in comparative philosophy of religion were published by State University of New York Press. The first series, titled “Toward a Comparative Philosophy of Religions,” was led by Frank Reynolds and David Tracy of the University of Chicago Divinity School; it produced four edited volumes and nine single-authored monographs between 1990 and 1999. The second series was titled “The Comparative Religious Ideas Project.” Based at Boston University, the project produced three mutually complementary volumes in 2001, edited by Robert Neville (2001a,b,c).

Since 2012, the Comparison Project based at Drake University, Des Moines, Iowa, has hosted series of lectures and conferences in which different religious and philosophical perspectives are offered on issues of religious importance. Publications produced by the project include edited volumes on ineffability (Knepper and Kalmanson 2017), death and dying (Knepper, Bregman, and Gottschalk 2019), miracles (Zwier, Weddle, and Knepper 2022), and mysticism (Weed 2023).

From 2020 to 2023, the Global Philosophy of Religion Project, funded by a grant from the John Templeton Foundation, was led by Yujin Nagasawa at the University of Birmingham, UK. Outputs included special journal issues, videos, and a major open-access edited volume titled Global Dialogues in the Philosophy of Religion (Nagasawa and Zarepour 2024).

Besides Philosophy East and West, other relevant journals include Sophia: International Journal of Philosophy and Traditions (founded in 1962), Dao: A Journal of Comparative Philosophy (founded in 2001), and Comparative and Continental Philosophy (founded in 2009), as well as the various journals that specialize in philosophy of religion.

3. Synthesizing Approaches to Comparison
A broad distinction can be drawn between two different orientations in comparative philosophy of religion. On the one hand are synthesizing approaches, which emphasize similarities between religious or religiously relevant philosophical ideas that derive from distinct traditions. On the other hand, there are heterogenizing approaches, which emphasize dissimilarities between such ideas. Although the differences between these alternative orientations are indeed largely a matter of emphasis, their respective emphases are often correlated with specific methodological preferences and aspirations.[4] This and the next section give representative examples to illustrate the two orientations in question.

3.1 Arthur Schopenhauer
The work of Schopenhauer (1788–1860) exemplifies a synthesizing approach to comparative philosophy of religion inasmuch as it draws upon ideas and doctrines from various religious and philosophical traditions—most notably Platonism, Kantian idealism, Indian Vedānta, and Buddhism—for the purpose of developing or augmenting what Schopenhauer describes as his own “organic” system of thought (1818 [1969: xii]). Schopenhauer’s philosophical productiveness flourished at a time—the early nineteenth century—when many texts from Asia, especially India, were reaching European readers for the first time; the efforts of translators and philologists were generating what came to be known as the “Oriental Renaissance” (Schwab 1950). Schopenhauer especially admired the ancient Indian scriptures known as the Upaniṣads, which he read in a Latin translation (which was itself rendered from a Persian edition rather than from the original Sanskrit); this edition, he declared, “has been the consolation of my life and will be that of my death” (1851 [1974: 397]).[5]

While incorporating references to Buddhist, Vedāntic, Platonic, and Kantian sources into his work, Schopenhauer viewed his own philosophical contribution as going beyond or perfecting those sources. For example, despite concurring with Buddhist and Vedāntic injunctions to renounce attachments and cultivate a desireless state of mind, Schopenhauer thought that proponents of these philosophies remained too attached to the promise of a positive state beyond renunciation: they were prone to fool themselves with “meaningless words, such as reabsorption in Brahman, or the Nirvana of the Buddhists,” whereas, for Schopenhauer, we should not be afraid to affirm that “the final goal” is “nothingness” (1818 [1969: 411]). Thus, Schopenhauer was not an uncritical appropriator of his sources: he was a constructive metaphysician who was pioneering in his openness to religious and philosophical ideas from outside his own nineteenth-century Germanic context.

3.2 Perennial Philosophy
The term philosophia perennis, “perennial philosophy,” is often assumed to have been “coined by Leibniz” (Huxley 1945 [1947: 1]; Bilimoria 2003: 360 n. 1). Although Leibniz does speak of perennis quaedam Philosophia (“a certain perennial philosophy”) in a letter to Nicolas-François Rémond in 1714 (Leibniz PS: 625), the term goes back at least as far as the Italian humanist theologian Agostino Steuco (1497–1548), who published a treatise titled De perenni philosophia in 1540 (Schmitt 1966: 506–507). From the early twentieth century onwards, proponents of the idea of a perennial philosophy (or “perennialists,” for short) have maintained that multiple philosophies and religions share a common core of doctrines that are grounded in a transcultural religious or mystical experience. Aldous Huxley, for example, characterized the perennial philosophy in terms of its metaphysical, psychological, and ethical components. Metaphysically, there is a “divine Reality” underlying all things; psychologically, there is a component of the soul that is at least similar and perhaps identical to that divine Reality; and ethically—or, we might say, soteriologically—the goal of life is to achieve knowledge of the Reality or “Ground of all being,” which is simultaneously transcendent and immanent (Huxley 1945 [1947: 1]). Together, these components constitute the “Highest Common Factor” at the heart of all theologies (ibid.).

Any attempt to substantiate the claim that ostensibly diverse religions, philosophies, or theologies in fact share common teachings or are simply different paths to the same destination inevitably requires comparative inquiry. Huxley quotes passages from sources as varied as the Christian mystics Meister Eckhart and William Law, the Brahmanical Chāndogya Upaniṣad and Vivekacūḍāmaṇi, the Daoist Zhuangzi, and the Mahāyāna Buddhist Laṅkāvatāra Sūtra (Huxley 1945 [1947: 8–14]). While admitting that differences of doctrine obtain between these sources, Huxley’s approach is to minimize the differences by seeking interpretations that accentuate commonalities. For example, in the case of the apparent divergence between Hindu affirmations of an eternal self (ātman) and Buddhist denials of any such self, Huxley proposes that these respective positions are reconcilable by prioritizing the specifically Advaita (nondualist) Vedānta doctrine that only the nonpersonal or cosmic “Self” is eternal and a certain understanding of Mahāyāna Buddhism according to which there is a “Universal Mind,” which is comparable to the “Self” of Advaita (Huxley 1945 [1947: 15–16]).

Perennialism—especially under the name “Perennial Psychology” (Forman 1998: 28)—remains prominent in the study of mysticism, where it takes the form of opposition to a competing view called contextualism. Contextualists (also termed, by their opponents, constructivists) maintain that mystical experiences are necessarily “mediated” or “shaped” by concepts that mystics inherit from their cultural environment (Katz 1978: 26). In response, perennialists assert that there really is a mystical state of consciousness that transcends conceptual mediation and is common to multiple traditions. To identify this “wakeful though contentless” state, Robert Forman coined the term “Pure Consciousness Event (PCE)” (1990: 8). Both sides in the debate engage in comparative analysis of relevant religious sources, though Forman (1990: 28) also appeals to a purportedly mystical experience of his own.

3.3 Religious Pluralism
Following some terminology coined by Alan Race (1983), philosophical or theological theories about religious diversity are frequently divided into three main categories: exclusivism, inclusivism, and pluralism.[6] In brief, exclusivists hold that only one religion is the true one that leads to salvation; inclusivists hold that only one religion is wholly true but non-adherents of that religion may partake of enough truth (or right action, etc.) to be saved; and pluralists hold that there is some sense in which more than one religion is both true and salvific. Holding any of these positions—and claiming to be justified in holding it—presupposes some knowledge of more than one religion. It is thus unsurprising that debates between exclusivists, inclusivists, and pluralists typically involve interreligious comparison. The most thoroughgoing comparativists tend to be the religious pluralists, for developing a credible argument that more than one religion is true and salvific requires extensive comparative analysis.

By far the best-known religious pluralist is John Hick, who argued that, as far as metaphysical truth, soteriological efficacy, and ethical rectitude are concerned, there is parity between all the “great world faiths” (or “great world religions”) (e.g., Hick 2010: 153; Hick 2004: xxxiii et passim). For Hick, the latter category includes Hindu, Buddhist, Christian, Jewish, and Muslim traditions; he also occasionally mentions other traditions, such as Daoism, Confucianism, and Sikhism (e.g., 2004: 2, 39). He draws a broad distinction between these “great” traditions, on the one hand, and the various forms of “archaic” or “primal” religion, on the other (2004: xiii, 23). So-called archaic religions are “pre-axial,” in the sense that they are characteristic of human religiosity prior to what Karl Jaspers dubbed the “axis of world history,” which he located in the period between 800 and 200 BCE, with 500 BCE being its fulcrum (Jaspers 1953: 1). Hick identifies small-scale indigenous religions of the present day as being continuous with those “archaic” religions; instead of being directed towards a salvific end, these remnants of pre-axial religions are concerned merely with maintaining “fragile human life on an even keel” (2004: 23).[7]

According to Hick, what distinguishes the “post-axial” or “great” traditions from the “pre-axial” or “archaic” ones is not only their global spread but also their soteriological ambitions: they all aim at “salvation/liberation/enlightenment” (2004: xl)—a state of ultimate human fulfilment—and they all affirm some supreme reality. Although the names and ways of conceptualizing this reality vary—Trinity, Allāh, Adonai, Brahman, Śūnyatā—there is, Hick contends, a single “transcategorial (or ineffable) Real” behind all these conceptions (xix). Borrowing vocabulary from Kant, Hick claims that the Real is noumenal whereas the sundry conceptions of it are phenomenal appearances (xix). Hick’s pluralism is thus a synthesizing approach insofar as it prioritizes the search for a unifying element that all the “great” religions have in common.[8]

3.4 Problem-Solving Approaches
Among the approaches to comparative philosophy of religion that are, to some extent, responses to the kind of pluralism advocated by Hick are what might be called problem-solving approaches. Yujin Nagasawa explicitly contrasts his preferred version of global philosophy of religion with those of Hick and Ninian Smart. Although the latter two philosophers had sought to incorporate interreligious perspectives into their work, they still operated with the assumption that philosophy of religion ought to be concerned with establishing “the validity of particular worldviews or traditions” (Nagasawa 2017: 45). Nagasawa’s alternative proposal involves a reorientation away from the comparative evaluation of existing systems of thought and practice, and towards collective reflection upon common philosophical or existential problems. “It would be fruitful,” he writes, “if philosophers from distinct traditions were to share their resources and tackle the common problems together” (2017: 45). As an example of a common problem, Nagasawa cites the problem of evil, his thought being that this problem might be responded to more proficiently by combining the efforts of, among others, Christian, Muslim, Jewish, Hindu, and Buddhist philosophers than by trying to solve it from only one religious or philosophical standpoint (46). Although there have been instances in which a philosopher draws upon ideas from ostensibly disparate traditions—such as Carlo Filice’s effort to supplement Abrahamic monotheisms with the idea of reincarnation (Filice 2006)—what Nagasawa has in mind is something more collaborative.[9] One way of pursuing such a collaborative venture is in the form of dialogue, where an initial proposal is made by one philosopher and then responded to by others, building up a multiperspectival analysis of a given topic (see, e.g., Nagasawa and Zarepour 2024).

4. Heterogenizing Approaches to Comparison
4.1 Internalist Pluralism
“Internalist pluralism” is a term coined by Victoria Harrison to designate an approach to the analysis of religious diversity that is inspired by Hilary Putnam’s theory of internal realism. Putnam contrasts his “internalist perspective” with an “externalist” one (1981: 49). The latter maintains that, first, the world is made up of “some fixed totality of mind-independent objects”; second, “the way the world is” is amenable to a single “true and complete description”; and third, truth consists in correspondence “between words or thought-signs and external things and sets of things” (49). The internalist view, by contrast, affirms that the question of what objects the world comprises makes sense only within some specific “theory of description” or “conceptual scheme” (1981: 49, 52).

Applying Putnam’s internal realism to the study of religions, Harrison contends that if the question of what exists, or what is real, cannot be addressed in a way that is “conceptual-scheme neutral,” then the meaningful discussion of whether, or what, “religious realities” exist can occur only internally to some specific “conceptual scheme or, what we might call, a ‘faith-stance’” (Harrison 2006: 292). For Harrison, “faith-stance” is not a synonym of “religion”; rather, any given religion may be constituted by several more-or-less overlapping faith-stances—or, in other words, by several more-or-less overlapping conceptual schemes (2012: 76). Nonetheless, a deliberate consequence of Harrison’s view is that what at first may appear to be disagreements between distinct religions are merely instances of members of the religions talking past one another, because each party in the purported dispute is operating from within a distinct conceptual scheme. Thus, for example, if a Hindu affirms that Śiva is the true god, whereas a Roman Catholic denies this and instead affirms that the true god is the Trinity of Father, Son, and Holy Spirit, these competing affirmations amount to a mere difference rather than to a genuine disagreement. From the perspective internal to the community of worshippers of Śiva, it is indeed the case that Śiva is the true god; and from the perspective internal to Roman Catholicism, it is the case that the Holy Trinity is the true god. There would be disagreement here only if the two communities shared the same conceptual scheme, but, Harrison contends, they do not (Harrison 2006: 293).

An implication of Harrison’s internalist pluralism for comparative philosophy of religion is that diverse religions, or faith-stances, may be compared, and their respective particularities highlighted, without any insinuation being made that there is some ultimate reality, transcendent of all conceptual schemes, to which religious concepts and beliefs are accountable. A potential objection might take the form of the observation that, in many cases, religious disputes do seem to involve genuine disagreement rather than mere differences. Even if we admit that when they affirm their respective beliefs, the Hindu and the Christian, the Buddhist and the Muslim, are operating with different concepts—perhaps even from within different conceptual schemes—it remains the case that each of them has much in common with the others: they all share a human form of life, and that involves sharing many concepts. Further work may thus be needed to show how, in view of this shared human framework, it may nevertheless be the case that apparent disagreements over religious matters are not genuine disagreements at all.[10]

4.2 Radical Pluralism
In the context of philosophy of religion, the term “radical pluralism” has become associated principally with the Wittgenstein-influenced philosopher D. Z. Phillips. (But see also Bilimoria 1991; Jeanrond and Rike 1991.) In a posthumously published essay, Phillips (2007) uses the terms “radical pluralism” and “radical plurality” to identify both the situation in which many people in the modern world find themselves—immersed in cultures that exhibit a radical diversity of religious and other ideological perspectives—and a distinctive philosophical approach to the analysis of this condition of diversity. Like internalist pluralism, the philosophical approach in question is comparative and nonreductive; but unlike internalist pluralism, it makes no claims to the effect that the various religious or ideological perspectives constitute a set of distinct and nonoverlapping conceptual schemes. A radical pluralist approach is “contemplative” rather than metaphysical in its aspirations, prioritizing the understanding of religious and nonreligious points of view in their particularities instead of seeking to establish a general theory about the nature of religion, the truth of religious beliefs, or the efficaciousness of religious practices.

Developing Phillips’s ideas further, Mikel Burley has combined philosophical analysis with the use of ethnographic and literary sources to expand the range of religions and religious phenomena to which philosophical attention can fruitfully be given (esp. Burley 2020). While admitting that the primary purpose of the resultant methods is to describe rather than evaluate, Burley maintains that description can itself serve a critical function. Not only can it bring out the complexity and diversity of phenomena that may previously have been assumed to be largely homogeneous—thereby disabusing us of misplaced assumptions about the phenomena in question—but description of a variety of beliefs, practices, or forms of life also exposes the contingency of those of oneself and one’s culture, calling into question the naturalness or necessity of one’s attitudes and norms.[11]

It has also been argued that the sort of radical pluralist approach recommended by Phillips provides a basis for the pursuit of interreligious dialogue. According to Randy Ramal, it can supply this basis by disclosing the “unreflective and primal religious reactions” that may reasonably be regarded as giving rise to diverse religious concepts across various religious traditions (2019: 136–137). To illustrate the point, Ramal suggests that the human primal reaction of feeling shame at being seen naked by those other than one’s most intimate acquaintances may lie at the root of certain religious attitudes towards nudity. Although significantly different attitudes are displayed by, for example, Christians and Digambara Jain monks, a recognition of basic human reactions may help to overcome the tendency to see “only incommensurability between their different forms of life” (Ramal 2019: 154). The overriding goal of a radical pluralist approach is thus to draw attention to differences where they obtain but without unduly rejecting the possibility that common aspects of our shared humanity underlie the plurality of expressions of religiosity.

5. Comparative Studies of Specific Religious Issues
Comparative philosophy of religion is a potentially vast subfield of inquiry. To illustrate its potential, there are numerous examples that could be cited of comparative philosophy of religion being done. This section mentions a representative sample.

5.1 Personal Identity, the Self, and Death
One rich vein for religiously relevant comparative philosophical investigation is the cluster of questions concerning personal identity and the notion of a self. These questions often bear upon the issue of what, if anything, persists of a human being once the physical body has expired. A pioneering work in this connection is John Hick’s Death and Eternal Life (1976), which comprises an extensive survey of various conceptions of death, postmortem continuation, and what it might be that survives. The principal traditions expounded by Hick include those of Christianity, Hinduism, and Buddhism, his ambition being to advance “a possible eschatology” (1976: chap. 22) in which, synthesizing elements from the diverse traditions, he tentatively puts forward his own best estimate of what happens to us after death. In brief, his conclusion is that some form of reincarnation is plausible, facilitating “moral and spiritual growth of one and the same self through many lives” (457), and that this growth leads ultimately to a final life or state of being, to which Hick is willing to apply, without any demarcation, terms such as “Vision of God,” “nirvāṇa,” “eternal consciousness of the ātman [‘self’] and its relation to Ultimate Reality” (464).[12]

More recently, the potential of fruitful cross-cultural comparisons relating to concepts of selfhood and subjectivity has been explored, notably by specialists in Indian and Buddhist philosophy, analytic philosophy of mind, and phenomenology. Typifying such interdisciplinary work is the volume Self, No Self? (Siderits et al. 2011), which, though not styled overtly as philosophy of religion, nonetheless grapples with questions of profound importance for religious practitioners. These include the question of whether, if being conscious of something is necessarily accompanied by self-consciousness or self-awareness, this would constitute “evidence for the existence of a self” (Siderits et al. 2011: 1). Such questions quickly take us into, for example, long-running disputes between Buddhist and non-Buddhist philosophers in the Indian and Asian context more broadly.[13]

5.2 Comparative Religious Ethics
In a comparative study of Xunzi (third century BCE) and Augustine of Hippo (354–430 CE), Aaron Stalnaker makes the perceptive observation that the two most salient challenges faced by works of comparative ethics are, first, to “bring distant ethical statements into interrelation and conversation,” and second, to “simultaneously preserve their distinctiveness within the interrelation” (Stalnaker 2006: 17; see also Cline 2013: 64). These challenges could well be said to apply to comparative philosophy—and a fortiori to comparative philosophy of religion—more generally.

Comparative studies in ethics or moral philosophy frequently have relevance to philosophy of religion, not least because, in many religious traditions, cultivating a virtuous character or performing morally right actions are among the means—and are sometimes the primary means—of progressing along the spiritual path. Some comparative works in this area identify two or more named representatives of distinct yet comparable ethical positions. Lee Yearley (1990), for example, provides a sustained comparative analysis of the positions of the fourth-century Confucian philosopher Mencius (Mengzi) and the thirteenth-century Dominican philosopher and theologian Thomas Aquinas. With particular attention to their respective theories of virtue and conceptions of courage, Yearley’s approach combines descriptive exposition with constructive synthesis. He aims to “chart similarities within differences and differences within similarities” while also arriving at “normative conclusions” that emerge from the comparison (1990: 1).

A similar approach is exhibited by Asher Walden (2015), who selects four philosophers from ostensibly disparate historical and cultural contexts—namely, Zhu Xi (twelfth-century China), Schopenhauer (nineteenth-century German Confederation), Śāntideva (eighth-century India), and Nishida Kitarō (twentieth-century Japan)—and compares their respective responses to the question of what justifies moral judgment. Notwithstanding the differences between the four philosophers under examination, Walden finds in each of them the affirmation of compassion as “a kind of meta-virtue” that furnishes the “basis for all the other virtues” (2015: viii). The fact that there is some degree of confluence between philosophers from diverse times and places is, of course, not in itself an argument for the truth of the claims that they make, and Walden does not suppose that it is. Nevertheless, the four-way comparative analysis deployed by Walden is one effective means of showing how a similar solution to a problem can be arrived at from different angles.

The concept of compassion (karuṇā) also has a prominent place in Ok-sun An’s book-length treatment of the relation between this concept as it occurs in early Buddhism and the notion of benevolence (jen or ren 仁) in Confucianism (An 1997). By means of interpretive exposition and comparative analysis, An calls into question oversimplifying assumptions, notably the assumptions that early Buddhism is solely concerned with individual liberation from the cycle of rebirth and that Confucianism is exclusively directed towards self-effacing service of the social order.[14]

5.3 Religion and (or beyond) Rationality
Since philosophy is a discipline concerned in large part with giving reasons and formulating arguments, it is little surprise that central among the preoccupations of philosophy of religion has been the construction or evaluation of reasons and arguments for certain religious beliefs, typically presented in propositional form.[15] Works in comparative philosophy of religion also often involve the comparison of arguments or “acts of religious reason-giving” (Knepper 2023: 58). John Clayton (2006), for example, undertakes a comparison of the respective arguments against natural theology in David Hume’s Dialogues Concerning Natural Religion (1779) and Rāmānuja’s eleventh- or twelfth-century commentary on the Brahma Sūtra. Clayton finds similarities in the reasons of these philosophers for rejecting purported rational proofs of the existence or nature of the divine. Through the character of Philo, Hume expresses scepticism that any knowledge of God can be gained via inference or perceptual experience. Rāmānuja, likewise, denies that Brahman is knowable by these means; in doing so, he anticipates Hume’s principal objections to the “design argument” (Clayton 2006: 132). Unlike Hume, however, Rāmānuja maintains that knowledge of Brahman is received from scripture, “which rests on endless unbroken tradition” (Rāmānuja VS [1904: 25], quoted in Clayton 2006: 111).

Along with Rāmānuja, other philosophers who are sympathetic to religion while denying that religious beliefs are rationally supportable include Zhuangzi (4th century BCE) and Søren Kierkegaard (1813–1855). Karen Carr and Philip Ivanhoe (2000) argue that each of these latter two philosophers, in his own way, presents us with a form of “antirationalism.” By this, Carr and Ivanhoe mean not that rationality is entirely rejected, but that it is found to be “not only inadequate but potentially inimical to a proper appreciation of the truth” (2000: 118). While there is implicit agreement between Zhuangzi and Kierkegaard that reason cannot lead us to ultimate truth (or salvation), the respective “positive prescriptions” of these two thinkers diverge (2000: 119). Zhuangzi proposes leaping into and harmonizing one’s life with the dao—the “boundless Way” (120). Kierkegaard’s leap is the leap of Christian faith, in which one wholeheartedly commits one’s life to God. By means of their joint study, Carr and Ivanhoe exemplify a way of not only bringing Daoist and Christian perspectives into constructive comparative dialogue, but of doing so through the collaboration of scholars with different areas of expertise.

5.4 Concepts of Belief, Knowledge, and Witchcraft
Comparative studies involving African philosophies are growing in prevalence, and many of these are relevant to philosophy of religion. (See, e.g., Okafor 1997; Agada 2022; Stacey 2022.) One of the most long-term and impressive projects in this area remains the investigation of Yorùbá epistemological concepts carried out from 1974 to 1984 by Barry Hallen and J. Olubi Sodipo (1997). Deploying a method that they termed “collaborative analysis” (1997: 121), Hallen and Sodipo undertook extended conversations with respected figures in Yorùbá society known as oníṣẹ̀gùn (“masters of medicine”). Data were gathered and analyzed concerning the criteria that apply to the use of terms in the Yorùbá language that are typically translated into English as “knowledge,” “belief,” and “witch.” The conclusion of the study was that assumptions on the part of previous Anglophone researchers about the supposed universality of the concepts expressed by the latter English terms “have led to fundamentally false interpretations and analyses of Yoruba thought” (1997: 122).

Without denying the semantic overlap between the relevant English and Yorùbá vocabulary, Hallen and Sodipo argue that propositional attitudes such as those expressed by the English phrases “I believe that …” or “I know that …” ought to be viewed as culturally relative (124). Similarly, in the case of the Yorùbá term àjẹ́, which has routinely been translated into English as “witch,” Hallen and Sodipo maintain that this translation is misleading insofar as it tends to carry with it assumptions that are foreign to the Yorùbá context. When an African social group is attributed with the belief in witchcraft, Hallen and Sodipo observe, “The Western intellectual’s attitude is more or less a ‘Thank goodness we don’t believe in that anymore’, and that a society that does is primitive, sick and inhuman” (118). By contrast, for the Yorùbá spokespeople with whom Hallen and Sodipo conversed, àjẹ́ has a range of meanings that include someone who uses their medicinal abilities “for the welfare and benefit of mankind” (117). Perceptively, Hallen and Sodipo note that discovering the breadth of the concept of àjẹ́ ought to prompt those who regard “witchcraft” as expressing “a conceptual and cultural universal” to reflect upon the range of meanings that “witch” can have, and has had, in Western contexts (117); what remains problematic, as Hallen and Sodipo see it, is the uncritical application of potentially misleading translations without due attention to cultural specificities.

6. Challenges for Comparative Philosophy of Religion
6.1 The Eurocentric Legacy
One type of complaint against comparative philosophy of religion is that it all-too-often involves projecting or imposing culturally European—or, more broadly, Western—categories onto other cultures while assuming that those categories are universal and normative. An equivalent complaint has long been raised against the enterprises of “comparative theology” and “comparative religion,” which have been accused of assuming some version of Protestant Christianity to be the paradigm of what a religion is and then looking around to see the extent to which other religions satisfy, or fail to satisfy, the criteria laid down by that paradigm (Hedges 2022: 53). In the case of comparative philosophy of religion, Purushottama Bilimoria, from the perspective of postcolonial theory, identifies the standard Eurocentric categories as including, among others, “God (the Absolute or the Transcendent), Creation, the Problem of Evil, the Afterlife, Immortality, Sin, Redemption, Purpose, and the End” (Bilimoria 2003: 343). By assuming that these are the categories—or, at any rate, the primary categories—in terms of which religions, and philosophical analyses of religions, ought to be compared and appraised, comparative philosophers of religion (so the accusation goes) have biased their inquiry in favour of Western forms of Christianity from the outset.

One possible response to the charge of Eurocentrism (or Eurohegemony—cf. Masuzawa 2005: 29) would be to point out that neither Christianity as a whole nor Protestant Christianity in particular is solely Western, still less solely European. Christianity is itself a global phenomenon, having originated in the Middle East and spread across all the inhabited continents of the world. To conflate Christian categories with Western or European categories is thus itself a category mistake. The proponent of the charge could reply, however, that it is specifically Western forms of Christianity that tend to be presupposed in much philosophy of religion, part of the problem being that Western philosophers of religion have given insufficient attention to the diversity of Christianities, let alone the numerous other religions that exist. A consequence of this presupposition is that it is not merely Christian categories that have predominated in comparative philosophy of religion, but, more narrowly, a subset of Western Christian categories.

Even so, regardless of whether the charge is one of Eurocentrism, Western-centrism, or Christian-centrism, it does not amount to a charge against the viability of comparative philosophy of religion per se; it can be construed as a call for reform and revision—an insistence that participants in this field of study should critically interrogate their own conceptual categories and assumptions. This is precisely the call made by, for example, Sonia Sikka and Ashwani Kumar Peetush when, with reference not only to comparative philosophy of religion but to philosophy of religion across the board, they maintain that “philosophy of religion cannot be made more inclusive simply by inserting a wider number of ‘religions’ into the category slots of the subject as currently constituted. The shapes of the slots themselves need to be altered to fit varieties of beliefs and practices configured differently than Christianity” (Sikka and Peetush 2021: 2).

The demand for greater inclusivity is sometimes phrased in terms of “decolonization.” Leah Kalmanson (2017), for instance, utilizes the terms “dharma” (with reference particularly to Buddhism) and “dao” (with reference to Daoism) and raises the question of why these and other non-English terms should not be prioritized over the term “religion” when undertaking comparisons in philosophy of religion. In deploying the terms “dharma” and “dao,” Kalmanson aims not at “diversification but decolonization”; she intends to counter “the realities of ongoing power differences in academia” through her choice of words that do not contribute to “hegemonic practices” (2017: 255). Such moves, away from concepts expressed in European languages and towards the recognition of non-European “ways of knowing,” accords with broader academic trends that seek “to deconstruct and decentre the Eurocentric image of the world” (Afolayan, Yacob-Haliso, and Oloruntoba 2021).

6.2 Doing Violence to the Integrity of Traditions?
A potential objection that might be targeted most specifically at the kind of problem-solving approach to comparative philosophy of religion advocated by Chakrabarti and Weber (2016) and by Yujin Nagasawa (2017) is that such an approach fails to respect the integrity of religious or philosophical traditions. Chakrabarti and Weber envisage research projects in which the emphasis is placed on “solving hitherto unsolved problems” in philosophy without making any claim to be providing “‘correct exposition’” of the traditions from which ideas are being borrowed (Chakrabarti and Weber 2016: 22). The danger of this blasé attitude to accurate exposition is that ideas may end up being borrowed in ways that uproot them from the very cultural, religious, and philosophical contexts that give them the sense that they have.

The charge of doing violence to the integrity of traditions resembles the charge of “cultural appropriation,” which is held to occur when members of one culture appropriate, in the sense of illicitly adopt, ideas or practices from another culture. Cultural appropriation is widely regarded as especially pernicious when those who are doing the appropriating belong to a culture that is economically and politically more powerful than the one from which the ideas or practices are being appropriated. One thing that practitioners of comparative or cross-cultural philosophy of religion can do to avoid being guilty of illicitly appropriating ideas from other cultures is to give due attention to the cultural contexts in which the ideas they are discussing have their original place. Another option is to pursue Nagasawa’s aim of developing collaborative ventures in which conceptual and theoretical resources are shared by philosophers from different traditions to address common issues (see 3.4 above). Although this emphasis on collaboration circumvents the obvious danger of simply appropriating ideas from multiple traditions without bothering to expound the ideas correctly, it nonetheless presupposes the feasibility of combining ideas from disparate contexts without thereby diluting or distorting their respective meanings. It also presupposes that there are “common problems” which take sufficiently similar forms across diverse religious and philosophical traditions to be amenable to collective solutions. The fruitfulness of such collaborative philosophizing ought not to be prejudged, but will no doubt be shown through exemplary cases.

Before assuming that what has come to be designated as cultural appropriation is in every case malign, it should be acknowledged that views differ on this matter among certain marginalized or subordinated groups themselves. For example, notwithstanding many protests concerning the adoption by outsiders of the ceremonial items or practices of Native American peoples, “a significant minority” of these peoples welcome participation in “the red road” (that is, Native American ways of life) for the engendering of a more harmonious relationship with the earth (Taylor 1997: 187; see also Brunk and Young 2009: 96). This is among the vital lessons that comparative philosophy of religion, when done well, can teach us: that religious and philosophical traditions are rarely, if ever, homogeneous phenomena—they are likely to be internally complex and variegated.

6.3 The Entanglements of Traditions
The charge that there is anything suspect about bringing ideas from different religious or philosophical traditions into relation or into dialogue with one another becomes still less forceful when one acknowledges the extent to which these “traditions” have already undergone processes of mutual influence and intermingling over the long course of history. As the editors of a volume on world philosophy put it, “the notion of hermetically sealed traditions in parallel development is largely a historical fiction” (Edelglass and Garfield 2011: 4). A similar contention is made by Omedi Ochieng in a book on the “good life” in African philosophy: against those who assume that “Western”—or, as Ochieng prefers, “North Atlantic”—philosophy is the paradigm tradition of philosophy that was then exported to other countries and continents, Ochieng argues that “the North Atlantic canon” is itself “inextricably bound and indeed constituted by the presence of Africans, Asians, Arabs, Native Americans, and so on” (Ochieng 2017: 5). By this, Ochieng means that even in texts where the peoples heralding from places outside the North Atlantic region are not overtly referred to, such texts are nonetheless written with an implicit awareness of the lives and ideas of those peoples. Through the notion of a mutually constitutive relationship, Ochieng seeks to avoid oversimplified representations such as that of different “orders of incommensurable discourses” or, at the other extreme, traditions that are “subsumable or reducible to one another” (2017: 5–6).

The recognition of the “entanglement” (Chakrabarti and Weber 2016: 5) or “intertwinement” (Ochieng 2017: 6) of traditions need not vitiate the project of comparative philosophy of religion, but it does necessitate a degree of subtlety on the part of those who carry out the exercise. A balance must be struck that, as Ochieng recommends, avoids the extremes both of treating traditions—whether religious or philosophical—as incomparably alien to one another and of regarding them as mutually indistinguishable. It is possible to engage in comparison without assuming that what are being compared run on entirely separate tracks.

6.4 The Difficulty of Acquiring Expertise in Multiple Traditions
A final challenge for comparative philosophy of religion—although it is perhaps the first challenge faced by anyone who attempts to undertake this kind of philosophy—is the sheer difficulty of gaining sufficient expertise in more than one religion, or in more than one tradition of philosophizing about religion, to do justice to the subject matter under investigation. Clayton remarks that “The ideal would be, from intimate knowledge of several traditions, to develop a reflective style that is global and not simply bi-cultural”; he is quick to add, however, that this ideal “is just that — an ideal” (Clayton 2006: 101). In other words, no matter how much any one philosopher may aspire to develop extensive knowledge of multiple traditions, it is unlikely that this will be widely achieved; thus two-way (bicultural or bi-religious) comparisons may have to suffice for most budding comparative philosophers. This is especially true of the contemporary era, when there are career-related pressures for academic philosophers to become hyperspecialized in only one or two areas of philosophy, lest they fail to keep up to speed with the rapidly growing literature in their subfield.

Nonetheless, those who call for an expansion or diversification of philosophy of religion—regardless of whether they apply the term “comparative philosophy of religion” to that expansive endeavour—rarely demand that individuals should become experts in multiple religions or philosophical traditions. What is normally proposed is that the field of philosophy of religion as a whole should expand its parameters, the aim being for the field to become more welcoming of a variety of perspectives and topics of inquiry. The result might be that, collectively, philosophers of religion could legitimately claim that their branch of philosophy takes into account the whole gamut of religions—the “spectrum of worldviews” (Vroom 2006)—or at least a representative selection of them, rather than only a small minority or an unduly abstract conception of “theism.” Comparative philosophy of religion is indeed a collective enterprise, for it is only through the participation of many contributors that a rich understanding of the phenomenon of religion, and the plurality of religions, can be cultivated

1. Meritocracy: A Brief History
By tradition, Michael Young is credited with coining “meritocracy” for his 1958 satire, The Rise of the Meritocracy. In fact, the term appeared in print two years earlier: In Jean Floud’s “Sociology and Education”, Alan Fox’s “Class and Equality”, and Paul Lamartine Yates’s “Fairer Shares”. Young claimed to have invented it, which is certainly possible given that all four were English academics who moved in similar, leftist circles. While only Young explained what he meant by “meritocracy” in any detail (and his sentiments towards it were mixed), for these academics, the term had a negative connotation.

Now it has been claimed that “meritocracy” first appeared in Hannah Arendt’s “1954” article “The Crisis in Education”. And there are copies of this article, so dated, circulating on the Internet which include the term. However, “The Crisis in Education” came out in 1958 (and was based on “a lecture delivered at Bremen, May 13, 1958”). Further, “meritocracy” does not appear in that original version of Arendt’s article. It does appear in edited reprints of it (e.g., Arendt 1961).

Only the briefest survey of the history of meritocracy can be provided here. For the ideas that government should be populated by the meritorious, and that a just distribution is merit-based, are ubiquitous. As Louis Pojman says,

it is interesting to observe how deeply the notion of justice as desert or merit is embedded in human history. It seems a prereflective, basic idea of primordial or Ur-justice. One finds it grounded in every known culture and religion. (1999: 90)

(Pojman surveys some history; Wooldridge 2021 is more comprehensive.)

There is an Eastern meritocratic tradition which has its roots in Confucius (551–479 BC). This tradition has influenced political and social institutions in Asia and beyond and remains vibrant (§3.1). (Meritocratic notions are found elsewhere in ancient Chinese thought, too; e.g., the Mohists [c. 400 BC] sought to “elevate the worthy” into government for utilitarian reasons. See Pines 2013.)

The core ideas of this tradition are found in Confucius, Mencius (372–289 BC), and Xunzi (c. 310–c. 235 BC). In short: The purpose of government is to promote the well-being and virtue of the people. That requires that political power be wielded not on the basis of noble blood—the prevailing system—but virtue and talent. Political leaders serve as role models and sage decision-makers, and to do that they must be meritorious.

Such a system will create hierarchies. For these meritocrats, that is not a problem. Indeed, it is natural and welcome:

That things are unequal is a matter of fact…. If you rank them the same, it will bring confusion to the world. If a roughly finished shoe sells at the same price as a finely finished one, who would make the latter? … How can one govern a state in this way? (Mencius, 3A.4, trans. Bai [2020: 103])

The most famous realization of the Eastern meritocratic tradition was the Imperial Examinations, which began in China during the Sui Dynasty (AD 581–618). Until that point, entry into the state bureaucracy was mainly controlled via nepotism and aristocratic influence. (Although there was some openness to granting political power to competent and virtuous people, even if they came from the lower class, since the Qin Dynasty [226–206 BC]. For a discussion of meritocratic practices before the Imperial Examinations, see Wang 2017.) The Imperial Examinations replaced, to some extent, that route to power with a single, impartial, rigorous examination, which was open to the public. Although the Imperial Examinations were discontinued in the early twentieth century, similar civil service examinations proliferated, and today are used world-wide (including in China).

The Eastern meritocratic tradition is largely concerned with governance. It does not hold that other social goods, like non-political jobs or income, should be distributed on the basis of merit. And its justification is largely consequentialist: People will be more virtuous, and better cared-for, if they are ruled by the meritorious. Although some meritocratic institutions, like the Imperial Examinations, might have laudable side-effects like improving social mobility, they are not generally justified on those grounds.

Plato’s (c. 428–c. 348 BC) meritocratic political theory (found primarily in the Laws, Republic, and Statesman) is similarly focused on governance. His argument for meritocracy and against democracy is simple: Managing a state is hard. It requires specific skills, like bravery, sobriety, graciousness, and love of wisdom. These skills are not found among the common people or the wealthy. If political power were entrusted to them, the “ship of state” (Republic 488a–89c) would run aground. Not to mention, the sailors—democratically-elected leaders—are always squabbling. Only a “true pilot”—a philosopher-king—can safely guide his ship to its destination. (See also, e.g., Republic 412a-e, 473c-d, and 484a ff.)

How Plato justifies meritocracy is a debated matter of interpretation. On one interpretation, meritocracy is desirable for its good consequences; to wit, it brings justice and happiness to the state (and, by analogy, citizens’ souls). On another interpretation, meritocracy constitutes justice and happiness, which are intrinsically desirable. (On this interpretive issue, see, e.g., Brown 2003 [2017].)

Aristotle (384–322 BC) is different in that his concern (in the Nicomachean Ethics and the Politics) is the distribution of social goods generally—not just political offices. And his justification for merit-based distribution is squarely deontological. (At least, that is a common interpretation. On Aristotle’s theory of distributive justice, see, e.g., Keyt 1991.)

Justice is, for Aristotle, giving people what they deserve, and this happens when they are rewarded in proportion to their merit. (This view is arguably presaged by Plato in the Laws [757c] and the Republic [331e ff.]) Indeed, for Aristotle this is not just correct but obvious: “All men agree that what is just in distribution must be according to merit [ἀξία]” (NE, 1131a, trans. Ross [1925]).

Aristotelian desert defines a notion of equality, known as proportional equality. (It is most frequently studied within social psychology, under the heading equity theory.) What Aristotle seeks to equalize are the ratios of merits to rewards between persons.

For example, suppose that there are 100 units of some good to be distributed among 3 persons. Persons A and B are equally meritorious; C is twice as meritorious as they are. Justice is done by giving 25 units of the good to A, 25 units to B, and 50 units to C. Note that an equal distribution is just only in the special case in which all recipients are equally meritorious.

Now, what is merit? For Aristotle, this is determined by the nature of the thing being distributed:

When a number of flute players are equal in their art, there is no reason why those of them who are better born should have better flutes given to them … the superior instrument should be reserved for him who is the superior artist. (Politics, 1282b, trans. Jowett [1885])

Meritocratic ideas are found in Islamic philosophy, in which scholars developed political theories compatible with divinely revealed Islamic law (Sharī’a). For example, Al-Fārābī (also known as Alpharabius, AD c. 870–c. 950) sought a political system which would bring happiness and perfection to the people living under it. Democracy could not do this (although it had, for al-Fārābī, some admirable features). What is required, rather, is (i) a ruler who is a hybrid philosopher-king and prophet-imām, with qualifications drawn from both Platonic and Islamic thought, and (ii) an elaborated hierarchy between citizens. Similar ideas may be found in the work of Ibn Sīnā (Avicenna, AD c. 980–1037), Ibn Bājja (Avempace, AD c. 1085–c. 1139), and Ibn Rushd (Averroes, AD 1126–1198).

Francesco Patrizi of Siena (AD 1413–1494) argued that merit—understood as virtue—was a precondition for the legitimate exercise of political power. For Patrizi, a meritocratic state is justified, stable, and functional. Further, the state is responsible for inculcating virtue in its citizens so that they are sufficiently meritorious to participate in government. This requires, among other things, a public literacy program. Patrizi designed his political institutions to ensure that (i) only meritorious citizens (i.e., the educated and experienced) would be chosen as magistrates and senators, and (ii) wealthy and powerful families could not corrupt the political process. (On the almost-forgotten Patrizi, see Hankins 2023.)

Meritocracy was an important Enlightenment value. Thinkers in Europe and elsewhere sought grounds for regarding people as individuals (rather than undifferentiated group members) and replacing monarchical politics.

For instance, Article VI of the Declaration of the Rights of Man and of the Citizen (1789) says:

All citizens, being equal in the eyes of the law, shall be equally eligible to all dignities, public positions and occupations, according to their ability, and without distinction except that of their virtues and talents.

This is almost precisely the meritocratic rule for distributing jobs (§4.2).

Napoleon lived up to this principle, adopting the slogan la carrière est ouverte aux talents—careers open to talents—and ascribing his success (not entirely, of course) to the meritocratic nature of his reign.

Across the Atlantic, Thomas Jefferson desired a “natural aristocracy” for his new nation, in which hierarchies would reflect “virtue and talents” rather than “wealth and birth”. Indeed, Jefferson regarded this natural aristocracy as “the most precious gift of nature, for the … government of society” (1813).

There is also a meritocratic ideal of justice associated with the United States. This is the American Dream, expressed by the person who coined the phrase thus:

It is not a dream of motor cars and high wages merely, but a dream of a social order in which each man and each woman shall be able to attain to the fullest stature of which they are innately capable, and be recognized by others for what they are, regardless of the fortuitous circumstances of birth or position. (James Adams 1931: 404)

The suggestion is that a just state is one in which there is equal opportunity and people are judged on their merits (§4).

2. Conceptual Issues
2.1 What is merit?
“Merit” connotes worth, quality, virtue, excellence, and more. If we are to build a society upon merit, as meritocrats desire, it seems necessary to understand exactly what merit is. Yet conceptual analysis of merit is nascent (see Clavero García 2023; Vlastos [1962] also offers some comments).

One thing that is clear is that merit is a contextual phenomenon, as Aristotle suggested (§1). We cannot answer the question of whether some person (book, painting, etc.) is meritorious unless we have a context in mind. If, in the middle of a discussion about the all-time great baseball players, one asks, “was Albert Einstein meritorious?”, the appropriate answer is “no”. To be sure, we talk about people being meritorious simpliciter. We say things like, “Einstein was a meritorious man”. But in these cases we understand the context implicitly.

It is also possible to broadly condemn a person while conceding his merit within a narrow context. One may say that Hitler had merit as an artist without making any commitments to his merit in other contexts, or to his overall merit.

A crucial conceptual issue is the relationship between merit and its real-world effects. Especially when it comes to governance (§3), meritocracy is frequently justified by the good outcomes it creates. And this much seems incontrovertible: All else equal, a meritorious politician will make higher-quality decisions than an unmeritorious one.

But this is not necessarily true. Merit, which is internal, is distinct from the outcomes which issue from it. The outcomes are external, although they are sometimes used as evidence of merit. A Nobel Prize in physics is good evidence that Jones is a meritorious physicist. But it is no guarantee: Jones could have stolen the research that won him the Prize, falsely publishing it under his own name.

As Hume puts in the Treatise:

The external performance has no merit. We must look within to find the moral quality. This we cannot do directly; and therefore fix our attention on actions, as on external signs. But these actions are still considered as signs; and the ultimate object of our praise and approbation is the motive, that produc’d them. (1739–40: 3.2.1)

An example, which we will return to, illustrates the importance of the merit-outcomes distinction. Suppose that Daryl and John are applying for jobs at the widget factory. Daryl is more skilled than John, works faster, is more careful, more collegial, and so on. But this factory is filled with racists and Daryl belongs to the disfavored race. As a result, Daryl would perform worse—make fewer widgets per hour—than John would. (This is a case of taste discrimination—Becker 1957.)

Observe that, conceptually, Daryl remains more meritorious than John even though hiring John would generate better outcomes. Those who support hiring John rather than Daryl—utilitarians, say—would not claim otherwise. They would simply say that here there are good reasons to hire the less meritorious applicant.

Ronald Dworkin once held a contrary view:

If a black skin will, as a matter of regrettable fact, enable another doctor to do a different medical job better, then that black skin is by the same token “merit” as well. (1985: 299)

But later he recanted (as Segall [2012] points out):

I do not mean … that black color is in itself a virtue or an aspect of merit…. We do not count a person’s height as a virtue or a merit. But someone who is tall may just for that reason be better able to contribute, on a basketball court, to one of a university’s traditional goals, and in the same way, though for sadder reasons, someone who is black may for that reason be better able to contribute to its other goals, in the classroom and dormitory and in the course of his or her later career. (2000: 404)

The meritocrat must decide whether merit-based distribution is desirable on consequentialist or categorical grounds. If the former, then meritocracy will be valuable only contingently. For at least in principle, merit-based distribution may lead to suboptimal outcomes. On other hand, meritocrats who say that merit-based distribution is categorically desirable—because, for example, it gives people what they deserve (§4)—must concede that their system will not always produce the best results.

2.2 Merit and desert
Merit’s closest conceptual cousin is desert, the concept underlying commonplace claims like “Joe deserves the job” and “workers deserve higher wages”. As we shall see (§4.1), some meritocrats explicitly invoke desert in their theories of justice. And desert is implicit in much other work on meritocracy. (Seminal research on desert includes Feinberg 1963, Kleinig 1971, and Sher 1987.)

There is no consensus about the precise link between merit and desert. Thomas Mulligan (2018b) argues that merit is an important basis for desert and thereby has moral force. Jeppe von Platz (2022) uses “desert” to describe an agent’s character and “merit” to characterize the real-world effects (e.g., achievements) of that character. John Lucas (1980) uses the terms in just the opposite way. Owen McLeod says that merit is “quite a specific kind of desert” (1999: 67). Pojman disagrees: “Merit is a broader concept, the genus of which desert is the species” (1999: 86). No attempt has yet been made to evaluate these disparate views, let alone reconcile them. Observe, too, that merit and desert are sometimes used synonymously—we might say that Sam “deserves the prize” or, apparently equivalently, Sam “merits the prize”.

Two of desert’s conceptual features are especially relevant to meritocracy. First, desert is a pre-institutional notion. What a person deserves is not, and cannot be, determined by the rules (organizations, practices, etc.) governing distribution. Rather, desert should determine those rules.

Imagine a race in which all blonde runners get a 10 second head start. The race is run, and a blonde beats a brunette by a nose. Institutionally—within the rules of this race—the blonde should get the medal. But she does not deserve it. The brunette deserves the medal; she was fastest. For the desertist, the brunette ought, morally, to receive it. The blonde is merely “entitled” to the medal. Further, for the desertist, this is a bad race; its rules ought to be changed so that institutional entitlements line up with deserts.

In contrast, a libertarian view of justice denies that there is a deeper, fiducial standard against which the institution can be judged (§5.4). So long as all the runners freely chose to participate in this race (and weren’t misled about the rules, etc.) the blonde ought, morally, to receive the medal. The fact that rules do not ensure that the fastest runner receive the medal is, for the libertarian, irrelevant to justice. (For discussion of desert-based versus entitlement-based arguments, see Olsaretti 2003a.)

Second, desert is often thought to contain principles of aboutness and fitness. The aboutness principle holds that the basis for desert must be “about” (somehow construed) the subject of a desert-claim for that claim to be bona fide. One cannot, for example, deserve prison on the basis of someone else’s crimes. One common construal of aboutness is responsibility—if a person is not responsible for a crime, he cannot deserve prison for it.

Arguments abound about the influence of luck on people’s character and achievements. Luck plausibly severs aboutness and thereby people’s claims to deserve on the basis of their merit. If Jones is the most meritorious applicant because of his hard work, he has a strong case to deserve the job. If Jones is meritorious because he had the good luck of being raised in a rich family, things are murkier.

The fitness principle holds that there is a natural connection between the basis for desert and the object being awarded. If a person commits a crime, he deserves prison—not a medal. Prison fits crime; a medal is unfitting.

As will be discussed in §4, meritocrats debate what the appropriate understanding of “merit” is when it comes to distributing political offices, jobs, income, and other goods. Does a just, meritocratic wage reflect a person’s skill? His effort? The contribution he makes? Or is “merit” conceptually primitive, unable to be defined in any of these terms?

2.3 Equal opportunity
A classic example of meritocracy (perhaps first used by Lyndon Johnson in a 4 June 1965 address at Howard University) is a footrace. Justice is done—the race is fair—only if the medal is given to the runner who crosses the finish line first (and not, say, to the runner with the lightest skin). However, that is a necessary, not a sufficient, condition for justice. For if some runners had a head start—if there was unequal opportunity—then the race was unjust, and the “winner” has no moral claim on the medal. But if the medal is awarded purely on the basis of merit, and against a background of equal opportunity, then the winner deserves that medal, and justice has been done.

In a meritocracy there is an “equal starting line” (or, to use another common, athletic metaphor, a “level playing field”) from which people compete for scarce social goods. That equal starting line, when coupled with a merit-based distributive rule, provides a full theory of distributive justice. (For more on the connection between meritocracy and equal opportunity, see Arneson 2002 [2015], Daniels 1978, Mulligan 2018b, and Goldman 1977.)

Sometimes the aforementioned idea of equal opportunity is referred to as “fair” or “substantive” equal opportunity, and the merit-based distributive rule as “formal” equal opportunity. When things are put in those terms, a meritocracy is simply a society in which there is equal opportunity (fair and formal).

While the equal starting line metaphor is handwavy, equal opportunity has been made rigorous (see Roemer 1998). And the ideal has clear ramifications for public policy, such as estate/inheritance taxes (so people don’t accrue wealth on the basis of family circumstances instead of merit) and public education (so that the children of poor families receive the same quality education as the children of the rich).

There are two salient debates within the equal opportunity literature important to meritocracy. The first is whether there is a moral difference between (i) social advantage, like being born into a rich family, and (ii) natural advantage—like intelligence (important: insofar as it is genetically- rather than environmentally-derived). The meritocrat is committed to nullifying the former through equal opportunity, but what about the latter? (Nullifying natural advantage would consist in providing extra resources to those who are naturally disadvantaged.)

The second debate involves the extent to which the state may interfere in family affairs to establish equal opportunity (see Fishkin 1983). Even with robust “external” measures (estate taxes, public education), different families will show different degrees of care for their children. That will lead to some inequality of opportunity.

Indeed, different kinds of care—not just parental attention versus neglect—may lead to inequalities of opportunity. One family may inculcate a love and aptitude for music in their child; another family may stress sports. The philosophical issues here are to explain what is problematic and what is not, and to draw the line between the government’s interest in establishing equal opportunity and the liberty of parents to raise their children as they see fit.

3. Meritocratic Governance
This section and the following one are the core of this entry. They address the two principal senses in which meritocracy has arisen within philosophy.[1] This section considers meritocracy as a form of government.

Terminologically, these systems are referred to as “political meritocracies” in the Eastern philosophical literature and “epistocracies” in the Western literature. The latter term is due to David Estlund (2003) and stresses the superior knowledge—episteme—which meritocratic political rulers possess. This entry follows the former usage.

Three broad questions face proposals for meritocratic governance. The first asks what constitutes merit or, equivalently, “who are the meritocrats?” The meritocratic class could consist of citizens who are competent (somehow defined); who are more likely than others to produce good political results (which could be different from the class of competent citizens—§2.1); who are best able to represent their constituents; or something else.

The second question asks, “how should the meritocrats rule?” It is not enough to show that there is a well-defined meritocratic class. A particular form of government, harnessing the meritocrats, must be elaborated.

The third question asks, “is meritocracy justifiable?” That is, proponents of meritocracy must defend their system against the charge that it is unfair. Discussion of these challenges is delayed until §5.

With one deontological exception (to be discussed), meritocratic political systems are justified on consequentialist grounds. Meritocrats claim, that is, that their systems would produce better political outcomes—more justice and prosperity, say—than prevailing political systems do.

Many contemporary meritocrats are motivated by a perception that contemporary democracy is dysfunctional. They adduce a range of empirical research: voters don’t know basic political facts (e.g., Somin 2013); they treat politics as a sport, in which what is important is not achieving good social outcomes or even promoting their own interests but that their “team” win (Lenz 2012); they are afflicted by motivated reasoning, seeking out evidence to confirm existing beliefs and generating specious grounds to ignore disconfirming evidence (Flynn, Nyhan, & Reifler 2017); and more. (The relevant research was pioneered by Converse [1964]. Brennan [2016] provides a contemporary survey.)

3.1 New Confucian meritocracy
In recent years, scholars have looked to the Confucian tradition (§1) to inspire and ground political theories. (See, e.g., Bai 2020; Bell 2006 and 2015; Bell & Li 2013; Bell & Wang 2020; Chan 2014; and Jiang 2013. The reader may also consult recent special issues of Culture and Dialogue [2020, volume 8, issue 2] and Philosophy & Social Criticism [2020, volume 46, issue 9], devoted to New Confucian meritocracy.) Incidentally, there has been insufficient interaction between the epistocracy literature and this one. That is an intersection ripe for research.

This literature is part political theory and part comparative politics. New Confucian meritocrats frequently point to China’s stability and economic success and contrast it with contemporary democratic dysfunction. That said, it should not be thought that the above-cited scholars, nor New Confucian meritocrats broadly, are apologists for the Chinese Communist Party. They are not.

These theories incorporate some liberal democratic features while rejecting others, like robust freedom of speech or the “one person, one vote” principle. All deny the truth and usefulness of regarding citizens as equals when it comes to voting. New Confucian meritocratic theories are, thus, best understood as hybrids of classical Confucianism and contemporary democratic theory.

They vary in their particulars. For example, Daniel Bell (2015), drawing from an ideal informing contemporary Chinese politics, calls for “democracy at the bottom, experimentation in the middle, and meritocracy at the top” (2015: 9). Bell’s meritocracy is purely political (he rejects meritocratic distribution of the sort discussed in §4), and mainly applicable to the highest political offices. Nevertheless, the political system is structured to funnel the most meritorious citizens to its apex (by using, e.g., examinations for public officials).

Tongdong Bai (2020), drawing from Mencius, endorses the “liberal” part of liberal democracy but not the democratic part. He argues for a government that is “for the people, of the people, but not by the people” (2020: 32). In Bai’s hybrid regime, liberal features like the rule of law and human rights do not emerge from Western values of individuality and equality but from classical Confucian values. Bai concedes that, so grounded, these features

may be more contextual and less absolute than the rights derived from an asocial and autonomous [i.e., Western] conception of the individual. (2020: 259)

Democracy should be rejected, according to Bai, because it is less legitimate than a meritocratic alternative. Political authority derives from service to the people, and democracy is not doing that well (because of, e.g., the aforementioned voter ignorance/irrationality). Bai invokes a notion common among meritocrats: There are real differences in virtue, intelligence, etc. between people; these differences render us appropriate for different positions in social and political hierarchies; and that sorting is in fact desirable (see also Bell & Wang 2020).

The idea that liberal features might emerge from Confucian principles has been most fully explored by Joseph Chan (2014), whose perfectionistic theory appeals to the Confucian conception of the good life. Chan describes this conception as one that

takes material well-being, moral self-cultivation, and virtuous social relationships as constituents … with the ideal of sagehood as the highest good. (2014: 44)

Chan’s preferred political system is one in which this account of the good life is best promoted. In his view, such a system will contain both liberal features, such as human rights, and meritocratic features. As regards the latter, Chan recommends a bicameral legislature, with one chamber chosen democratically and the other filled meritocratically (elite citizens selecting from a pool of experienced public servants).

Like Bai, Chan’s affinity for liberal features, like human rights, is not categorical. We do not possess rights because we are human; we possess them because they are instrumentally useful in promoting the Confucian good life. In fact, for Chan they are ever more contingent than that: They are merely a “fallback apparatus” for the non-ideal circumstances we find ourselves in. In ideal circumstances, in which all citizens were virtuous and able to resolve disputes through mediation, human rights would be unnecessary, even destructive.

In addition to the broad challenges that New Confucian meritocrats, qua meritocrats, face (§5), there are detractors within the Confucian tradition. Some “Confucian democrats” argue that democratic political participation is essential for cultivating Confucian virtues (see, e.g., Angle 2012, Hall & Ames 1999, and Tan 2004). These virtues include humaneness (ren, 仁), wisdom (zhi, 智), righteousness (yi, 義), ritual propriety (li, 禮), and integrity (xin, 信)—the “Five Constant Virtues”.

Sungmoon Kim’s (2017 and 2018) pragmatic Confucian democracy holds that democracy has instrumental power which meritocracy lacks. Democracy better promotes

legitimacy and order acquired through an effective and sustained coordination of complex social, economic, and political interactions among citizens who have profound moral and economic disagreement. (2018: 6)

Democracy, that is, is better able to cope with the disagreement and value-pluralism which marks contemporary political life.

Elena Ziliotti (forthcoming) argues on epistemic grounds: Because social well-being is an essential Confucian value, and because democracy is a better instrument toward that end than meritocracy is, democracy is more faithful to the Confucian tradition.

3.2 Restricted suffrage
A natural meritocratic approach is to limit political power to citizens who are sufficiently competent. American women did not secure a right to vote until 1920, with the passage of the Nineteenth Amendment to the Constitution. John Adams explains his reasoning why:

Their delicacy renders them unfit for practice and experience in the great businesses of life, and the hardy enterprises of war, as well as the arduous cares of state. (1776)

Unsurprisingly—given its history—restricted suffrage has found little philosophical purchase. But it’s worth remembering that we continue to deprive classes of people of political power without outcry. Children, for example, cannot vote. In Adams’ words, they “have not judgment or Will of their own”. (López-Guerra [2014] argues for a full expansion of the suffrage, to include children.)

Jason Brennan (2011) is the salient exception to philosophers’ resistance to restricted suffrage. He argues that citizens have a right “not to be subject to high stakes decisions made by incompetent and morally unreasonable people” (2011: 702), and that this right is violated under universal suffrage.

Brennan analogizes electorates to juries: We would think a defendant’s rights had been violated if he were convicted by an ignorant, irrational, or morally unreasonable jury. And since real-world electorates are, according to Brennan, ignorant, irrational, and morally unreasonable, those affected by their decisions find their rights violated.

Brennan’s argument is distinctive not only because it defends restricted suffrage but because it gives a deontological justification for political meritocracy. The other justifications surveyed in this section are consequentialist. While such a justification for restricted suffrage might be given, Brennan’s concern is the alleged rights-violations that universal suffrage inflicts.

3.3 Plural voting
Perhaps the most famous meritocratic proposal in the Western literature is John Stuart Mill’s (1859a, 1859b, 1861) plural voting. Mill’s proposal integrates his liberal desire for universal suffrage with an anti-egalitarian streak:

If it is asserted that all persons ought to be equal in every description of right recognised by society, I answer, not until all are equal in worth as human beings. It is the fact, that one person is not as good as another; and it is reversing all the rules of rational conduct, to attempt to raise a political fabric on a supposition which is at variance with fact. (1859b: 23)

(Notice how similar this sentiment is to Mencius’ [§1].)

Mill’s proposal is simple: Everybody gets a vote (thereby satisfying universal suffrage) and some people get more than one (because they are, in some sense, of greater “worth”). Mill offers several justifications for plural voting (see Dale Miller 2015), including—unsurprisingly for the utilitarian Mill—that it will produce better political consequences.

An immediate challenge facing the plural voting proponent is how to specify voting weights. Mill (1859b: 25–26) gives one potential specification:

Unskilled laborers: 1 vote
Skilled laborers: 2 votes
Foremen and “superintendents of labor”: 3 votes
Farmers, manufacturers, and traders: 3–4 votes
Professionals (e.g., lawyers, doctors, clergymen, “literary men”, artists, “public functionaries”): 5–6 votes
University graduates and members of “learned societies”: At least as many votes as professionals.
While this assignment has prima facie plausibility, Mill does not provide a rigorous defense of it. It is surely sub-optimal (why 3 votes for foremen? Why not 2? Or 3.5?) And perhaps its prima facie plausibility is misleading. Maybe professionals possess biases which laborers do not, thereby making the former less likely than the latter to vote well. (The same may be said of Harwood’s [1998] proposal.)

To overcome this difficulty, Mulligan (2018c) advances a statistical approach to plural voting which attempts to rigorously derive optimal voting weights from voting history. And Trevor Latimer’s (2018) “egalitarian” plural voting proceeds in two stages: The first operates under “one person, one vote” and determines voting weights; the second determines the substantive political question using those (generally unequal) weights.

Two technical notes: First, some forms of plural voting may de facto restrict the suffrage. For example, suppose that there are four voters. Voters A, B, and C have 2 votes each. Voter D has 1 vote. There are no voter coalitions in which D’s vote affects the result. He is effectively disenfranchised. The flip-side of this is that plural voting is compatible with democrats’ treasured “one person, one vote” principle: If voters are equally competent, a plural voting system will grant them an equal number of votes.

Second, there is no unique assignment of voting weights. For example, all weights in Mill’s system may be multiplied by 2, with the same results.

3.4 Limited epistocracy
The aforementioned proposals would radically change political practice. As such, they invite a criticism that they are insufficiently democratic (§5.3). This has led some philosophers to develop “limited epistocracies” which would improve political performance without straying too far from the democratic status quo.

Perhaps, for example, we can provide extra political influence to citizens who know “basic political facts” (Gibbons 2021)—facts which are both politically relevant and uncontroversial, like candidates’ policy platforms. Or perhaps “specialized institutions” (Jeffrey 2018), like the World Health Organization, can be granted unilateral—but narrow or temporary—political power via the democratic process.

There is no obvious dividing line between democracy and political meritocracy. All contemporary democracies seek to harness expertise, albeit to different extents and through different processes. The U.S. Senate, for example, was envisioned as a “portion of enlightened citizens” (Madison 1787: Tuesday, June 26) to serve as a bulwark against the “fickleness and passion” of the more democratic House of Representatives. Institutions like that plausibly qualify as limited epistocracies and might be defended on those grounds.

3.5 Other approaches
Although Brennan has written in support of restricting the suffrage (§3.2), his preferred form of governance is, apparently, what he calls government by simulated oracle (see Brennan 2016):

Every citizen may vote. When citizens vote, they (a) indicate their policy preferences or their preferred political outcomes, while (b) indicating their demographic information, and (c) taking a test of basic political knowledge. The government then uses data sets (a), (b), and (c) to determine, statistically, what a fully informed electorate would want, while correcting for the influence of race, income, sex, and/or other demographic factors on the vote. In short, government-by-simulated-oracle estimates what a demographically identical but fully informed electorate would want, and then implements that instead of what the uninformed electorate in fact wants. (Brennan 2018: 55–56)

What ought to count is not voters’ expressed preferences—which are affected by ignorance, irrationality, and the other dysfunctions which so trouble him and other meritocrats—but their enlightened preferences. If I cast a vote for X rather than Y because I hold false beliefs or am biased, then perhaps my vote should accrue to Y rather than X. For Y is what I would vote for, if not for my ignorance or irrationality.

While there has been significant work on enlightened preferences in economics and political science (e.g., Althaus 2003, Caplan 2007, and Gilens 2012), Brennan has not explored this system in any detail. (Ahlstrom-Vij [2022] does so, and thinks the system qualifies as democratic, not meritocratic.) One challenge is that it’s unclear what is meant by demographic bias. Our political preferences are shaped by myriad elements of our identity, including our demographics. Evangelical Protestants are much more opposed to abortion than adherents of other religions (Pew 2022). Is this bias of the sort that must be neutralized? Or a predictable and bona fide consequence of a deeper ideology?

A second strategy for dealing with the voter ignorance/irrationality problem is distinguishing two political classes and assigning them different roles. On the one hand there are regular citizens, who are responsible for setting political goals and determining their society’s values. That is done democratically. On the other hand, there are legislators and bureaucrats. They are responsible for pursuing, in the manner they deem best, the ends identified by the regular citizens.

The ignorance/irrationality problem is thus putatively solved: While the latter task requires expertise which the public does not have, the former task does not. Indeed, perhaps the former task is enabled by the folk wisdom which legislators/bureaucrats lack. One is reminded of William F. Buckley’s quip:

I would rather be governed by the first 2,000 people in the telephone directory than by the Harvard University faculty. (Quoted in Meyer 1961: 143)

This approach, which has come to be known as values-only voting (Beerbohm 2012; Christiano 1996 & 2008), puts the public and legislators/bureaucrats in a principal-agent relationship. For instance, the public may decree, via the democratic process, that the economy ought to be more equal. That goal is adopted by the legislators/bureaucrats, who choose and implement the policies which, in their superior judgment, will best promote it. In doing so, they can avoid pitfalls which the general public might not, like levying a luxury tax whose burden falls on workers.

As with Brennan’s government by simulated oracle, there is a dividing line problem here: What counts as an end and what counts as a means and can they be distinguished? Dimitri Landa and Ryan Pevnick give the example of a public that seeks to “minimize the innocent loss of life” (2020: 10). In response, legislators dutifully ban guns and abortion. It seems like a large portion of the public would be dissatisfied with how “its vision” was carried out. Landa and Pevnick also point out that under values-only voting, citizens may be unable to exert sufficient oversight—an example of a principal/agent problem which may afflict this division of labor.

Another proposal, most fully explored by Claudio López-Guerra (2011, 2014, 2020), uses lotteries to reduce political influence from the public broadly to a proper subset of it (see also Guerrero 2014; Landemore 2020; and Saunders 2010 & 2012). In López-Guerra’s envisioned system (which he does not unreservedly endorse and which, he says, qualifies as democratic), there is universal suffrage in the sense that virtually all citizens are eligible to vote. But for any given election, not all do. Some citizens are chosen at random to participate. The rest are disenfranchised (for that election). The chosen citizens engage in an “exhaustive informative program designed to acquaint them with the alternatives regarding the ballot” (López-Guerra 2011: 212). Then they cast their votes. That program ensures that all citizens who actually exercise political influence are well-informed.

In this way, all citizens are potential meritocrats, and the meritocratic class—which changes from election to election—is determined purely at random. All citizens, regardless of intelligence, race, age, etc. have an equal chance to exercise political influence.

A potential problem is the loss of aggregative power when the electorate is reduced in this way. The primary justification for this system is epistemic quality: We would get better political outcomes under it, according to López-Guerra, relative to the democratic status quo. But one important argument in favor of the status quo (§5.3) is that a large group of relatively incompetent voters may outperform a small group of relatively competent voters. Under López-Guerra’s system, the electorate is smaller but competence is higher. Absent modeling it is unclear how it would perform relative to democracy.

4. Meritocratic Justice
In its second sense, meritocracy is a theory of justice. It is a competitor to egalitarianism (in its various forms—strict, luck, Rawlsian, etc.), utilitarianism, libertarianism, and the other theories of justice. A meritocrat in this sense is someone who believes that a just state is a meritocracy.

Little work has been done on the relationship between meritocracy’s two senses—an approach to governance and a theory of justice (although see Mulligan 2022)—and it is unclear what, if any, connection there is between them. It certainly seems coherent to believe (e.g.) both (i) social goods should be distributed on the basis of merit and (ii) we should have a democratic, not a meritocratic, approach to politics.

Now, theories of justice across the aforementioned traditions may tentatively endorse meritocratic principles. For these principles may be instrumentally useful in promoting their preferred ideal of justice. For example, it is plausible that merit-based hiring (§4.2) promotes the general welfare, to some extent. Thus, a utilitarian may endorse meritocracy of that sort, instrumentally.

As Adam Swift and Gordon Marshall put this view,

a meritocratic allocation of individuals to occupations can be justified on the grounds that a society in which people are doing what they are best able to do will be optimally productive, but a meritocratic allocation of rewards to individuals can not be justified on the grounds that such an allocation gives people what they deserve. (1997: 44)

(See also Daniels 1978.)

This is certainly a defensible view of meritocracy’s allure, and it appears to be backed up empirically. As Roland Bénabou puts it,

the analysis generally validates the common intuition that meritocracy, appropriately defined, is desirable … on grounds of efficiency. (2000: 319)

But this instrumental connection between merit and good consequences is contingent (§2.1). The most vocal proponents of meritocracy hold that there is a deontological requirement to distribute on the basis of merit.[2] And so any good consequences are, at best, a happy side-effect of adherence to a moral rule. But why does such a requirement exist?

4.1 Justification
While not endorsing it, Swift and Marshall previewed the principal answer to that question: In a meritocracy, people get what they deserve. And because, it is argued, justice is giving people what they deserve, meritocracy is just. Meritocrats thus follow in the Aristotelian tradition (§1) of seeking to match social goods, like jobs and income, with facts about the people who desire them, like their qualifications or economic contributions.

Like desert-based approaches to justice broadly, meritocracy has not been popular within contemporary philosophy. But there have been defenders. David Miller (1999) gives “two cheers” to the ideal.[3] This qualification is rooted in Miller’s pluralistic view of justice. He identifies three “modes of human interaction”, with desert (meritocracy) governing one of them (viz. “instrumental association”). (Principles of equality and need govern the other two.)

Miller appeals to Aristotelian proportional equality (§1) to ground the desertist portion of his theory. Understanding “merit” as social contribution, he argues that a just society rewards people in proportion to their contributions (or, in the case of jobs, the qualities that will enable them to make contributions).

Hiring by merit is the policy that in general brings about the closest correspondence between individuals’ contributions and their rewards…. Nepotism or discrimination is unfair because it predictably creates a state of affairs in which there is a discrepancy between deserts and income rewards. Moreover, the best-qualified candidate who is passed over can legitimately complain that she is the victim of an injustice through being prevented from earning rewards commensurate with her potential contribution. (Miller 1999: 166)

Mulligan’s (2018b) meritocratic theory of justice is, in contrast to Miller’s, monistic. That is, Mulligan claims that justice is a matter of desert, and only a matter of desert. And doing justice to people—giving them what they deserve—is about establishing equal opportunity and judging them on their merits alone.

Mulligan advances several justifications for meritocracy, but most salient is meritocracy’s intuitive appeal. People feel that meritocratic distribution is just, and this sentiment appears stable across race, gender, socioeconomic class, political persuasion, and culture (cf. §6). The research adduced comes from equity theory (§1), experimental economics (e.g., Almås, Cappelen, & Tungodden 2020; Cappelen, Sørensen, & Tungodden 2010; Frohlich, Oppenheimer, & Kurki 2004), the child development literature (Baumard, Mascaro, & Chevallier 2012; Kanngiesser & Warneken 2012; Sloane, Baillargeon, & Premack 2014), evolutionary psychology (Aarøe & Petersen 2014; Baumard, André, & Sperber 2013; Petersen 2012), neuroeconomics (Cappelen, Eichele, et al. 2014; Vostroknutov, Tobler, & Rustichini 2012), and other fields of empirical study.

Other justifications for meritocratic norms have been given, independent of comprehensive theories of justice. George Sher (1987) gives one which is grounded in autonomy (sometimes put in terms of respect or dignity). When we distribute a scarce good on the basis of merit, we appeal only to attributes which constitute persons, and in particular those persons who are competing for the good. These attributes include skills, talents, and preferences. Meritocratic distribution thus provides people maximal control over their lives (or shows them maximal respect/dignity).

When we hire by merit, we abstract from all facts about the applicants except their ability to perform well at the relevant tasks…. We treat them as agents whose purposeful acts can make a difference in the world…. Selecting by merit is a way of taking seriously the potential agency of both the successful and the unsuccessful applicants. (Sher 1987: 121)

(See also Mason 2006 and Varga 2016. Dobos 2016 provides an overview of justifications for merit-based hiring.)

Another idea is that the social good itself—its very nature—points to merit as the morally proper basis for distribution. This Aristotelian notion (§1) is today more commonly put in terms of “fittingness” or “relevant qualifications”.

The idea may be elaborated in conceptual terms (see Sher 1987 and Williams 1973). It is morally fitting to give the job at the widget factory to the applicant who is best at making widgets, a fact which may be discerned from the concept of widget-making (cf. Williams: “The proper ground of distribution of medical care is ill health: this is a necessary truth” [1973: 240]).

Put differently, there is a conceptual connection between social goods and merit. There is no such connection between social goods and the other commonly-cited grounds for distribution, such as maximizing productivity or treating people equally. While in those cases connections doubtless exist and may seem weighty, they are external. They do not participate in our understanding of the social good itself.

The fittingness of merit-based distribution might be regarded as primitive and thus neither in need of nor amenable to further justification. As Joel Feinberg puts it,

I am not sure how, if at all, these judgments of moral appropriateness are to be verified; but I suspect that they resemble certain aesthetic judgments—for example that crimson and orange are clashing colors. (1963: 92)

4.2 The meritocratic distribution of jobs
Meritocratic hiring is often described using the language of discrimination. It is unjust, according the meritocrat, to discriminate against applicants for a job on any ground other than merit:

According to a widely held view, when there are a number of applicants for an available job, justice demands that the job be offered to the best-qualified applicant. We express this by saying that … the principle involved is one of hiring by merit. This is the principle that condemns discrimination on grounds of sex, race, or religion when hiring employees, as well, of course, as good old-fashioned nepotism. (David Miller 1999: 156)

This is the moral principle seemingly at work (as Schmidtz [2006] points out) in Martin Luther King, Jr.’s famous “I Have a Dream” speech, in which King yearns that his children “not be judged by the color of their skin but by the content of their character”. For the meritocrat, racial discrimination is morally wrong because all non-merit-based discrimination is wrong.

The principle has been operationalized. In “blind auditions”, pioneered by symphony orchestras, applicants play behind screens so that the jury cannot discover their race, sex, appearance, etc. and can only assess the quality of the performance.

In the United States, the Civil Rights Act of 1964 was defended, in part, on meritocratic grounds (see Kershnar 2003). The Act prohibits discrimination on the basis of race, color, religion, national origin, and sex. (The U.S. Supreme Court later decided—in Bostock v. Clayton County—that discrimination on the basis of sexual orientation and gender identity runs afoul of the Act’s injunction against sex-based discrimination, and so is illegal.)

Lacking a theory of merit (§2.1), it is not always clear which features of applicants count as merits and which do not. In toy cases—say, hiring a new bricklayer—things are simple. A bricklayer must be strong, reliable, precise in his work, and so on. Race, gender, and appearance are obviously irrelevant to bricklaying.

In the real world, things are murkier. One example of this is “reaction qualifications” (Wertheimer 1983). These are

qualifications that count as such because of the reactions of recipients, where the recipients are those with whom the successful candidate will interact as a result of filling the relevant position. (Mason 2017: 49)[4]

The taste discrimination case considered in §2.1 involves a reaction qualification which is not a bona fide merit. Racist customers may react positively to a saleswoman of their preferred race. But her race is not a merit. On the other hand, customers will buy more widgets from a saleswoman who is personable, and that is a merit.

Between these there are difficult cases. Suppose the saleswoman is beautiful, and her beauty entices customers to buy from her when they otherwise would not. Is beauty a merit in the context of selling widgets? In the context of modeling? Working at McDonalds? Is being a woman a merit in the context of gynecology (because many women would prefer a female doctor)? A satisfying conceptual analysis of merit would distinguish meritocratic reaction qualifications from non-meritocratic reaction qualifications.

A salient and philosophically interesting issue is affirmative action. Some forms of affirmative action do not appear to conflict with meritocratic hiring. For example, making special efforts to solicit applicants from historically underrepresented groups and then judging those applicants (along with everyone else) on the basis of merit seems compatible.

But the crux of affirmative action—quotas and preferential treatment—is incompatible with meritocratic hiring. As Robert Fullinwider (2002 [2018]) says, “the aims of real world affirmative action make race and ethnicity (and sometimes gender) salient, not personal desert or merit”. (See also Nagel 1973.)

Affirmative action thus helpfully puts the question to meritocratic justice. For some, affirmative action’s incompatibility with meritocracy reveals that affirmative action is unjust. For others, this incompatibility is evidence that meritocracy is an erroneous view of justice.

Three notes on this. First, meritocrats’ resistance to affirmative action should be viewed in light of their commitment to equal opportunity (§2.3). Their argument is not that there are no racial injustices, but that the proper remedy is bolstering equal opportunity rather than quotas / preferential treatment.

Second, affirmative action again illustrates the cleavage between merit and consequences. It might be the case that hiring on the basis of race or gender produces better consequences, owing to, for instance, the benefits of a diverse workforce. For the meritocrat, that is irrelevant—it remains unjust, because discriminatory.

Third, all that said, meritocratic hiring and affirmative action are not necessarily incompatible. Suppose, for example, that there exists “implicit bias” against some group—that is, selectors unconsciously regard members of that group as less meritorious than they actually are. If so, then by showing “preference” to members of this group, selectors would merely nullify the bias and ensure that every candidate is judged on his merits. Obviously, whether implicit bias exists is an empirical issue. As of now, it is a hotly debated one (see, e.g., Jussim et al. forthcoming).

4.3 The meritocratic distribution of income
Meritocrats most commonly hold that economies ought to compensate people on the basis of their contributions.[5] That is, when it comes to the distribution of income (and thus wealth, being merely a stock of unspent income), “merit” should be interpreted as economic contribution. (For discussion of the matters arising in this section, see Dekker 2010, Hsieh 2000, Mankiw 2010, David Miller 1989 and 1999, Mulligan 2018b, Riley 1989, Sheffrin 2013, Von Platz 2022, and Weinstein 2011.)

Imagine a garden which produces a harvest (the “output”) as a result of citizens’ contributions to it—seeding, watering, weeding, fertilizing, and so on (“inputs”). The meritocrat holds that each citizen deserves a share of the harvest proportional to her contribution to it. If Lane contributes twice as much during the growing season as Rory, then Lane deserves twice as much in return. (This is, again, Aristotle’s notion of proportional equality.)

Before we examine this metaphor—its complexities and whether it is apposite in the first place—it is worth noting that this distributive principle is idiosyncratic, politically. To many, the idea that people who contribute more should be paid more, an obviously inegalitarian idea, sounds conservative. And it has been defended by conservatives (e.g., Mankiw [2013]).

Yet this is at the very same time the rule favored by Marx (in “Critique of the Gotha Program”) for his penultimate, socialist phase of history. This is, in part, why it is fair to say that “Marx is more a meritocrat than Rawls, Nielsen, Dworkin, and most contemporary liberal political philosophers” (Pojman 1999: 93).

An obvious question for this distributive view is how to interpret “contribution”. For some scholars, the proper index is willingness-to-pay (WTP)—the maximum price a person will pay for some good or service. Thus, if a person P produces X, by aggregating the WTP for X across consumers we obtain a measure of P’s contribution.

A slightly different interpretation relies on the concept of consumer surplus. Observe that if a consumer pays exactly her WTP for X, in a sense she has received no benefit. For at that price she is, by definition, indifferent between buying X and saving her money. Whereas, if there is a large difference between her WTP and X’s price, then her welfare (as measured in dollars) increases when she buys X.[6] That increase is the consumer surplus.

The typical person’s WTP for a diamond ring is high and WTP for a jug of water is low. But plausibly the producer of the latter contributes more than the producer of the former.

Standard (neoclassical) economic theory also provides an interpretation of contribution, as marginal product. This is the change in economic output a person’s economic participation creates, holding all else fixed. In simple models, this in fact is how economies remunerate. In these models, compensation equals contribution.

Still, it is important that compensation be proportional to contribution, since, in general, total output will not equal the sum of marginal products. (It’s true only for the special case of constant returns to scale.) But in all cases, proportional compensation is possible.

All of these interpretations of “contribution” rely on the standard idea that economic value is subjective—that goods and services are valuable because, and only insofar as, they are desired by consumers. That might be disputed. Perhaps producers of firearms and social media make no contribution at all or indeed are destructive. That possibility is not captured in any of the aforementioned interpretations, and would require elaboration by a meritocrat so inclined.

Another question is how to disentangle individuals’ contributions from the collective economic effort. In particular, people’s contributions emanate not only from their labor, but from capital as well.

Suppose a worker produces 100 widgets per day in a factory. On his own, the worker could produce nothing. Without workers, the factory would sit idle. How many of those 100 widgets reflects the worker’s contribution? How many reflect the contribution of the capitalist who owns the factory?

This entanglement problem speaks to the essential role that equal opportunity plays in a meritocracy. If the capitalist inherited the factory from his father, it is hard to see why he should be rewarded on meritocratic grounds. His contributions do not reflect his merit. If, in contrast, the capitalist bought the factory himself, with money he earned via his economic contributions, that seems meritocratic.

An issue which has arisen in the literature, which is empirical rather than philosophical, is how well actual economies approximate this meritocratic ideal. One important way they do not is the presence of economic rent (see Lamont 1997 and Mulligan 2018a).

Classically, economic rents were payments for “free gifts of nature”, like unimproved land. Imagine a wild orchard controlled by O, who charges people for the right to harvest it. That portion of O’s income is economic rent. The orchard makes its contribution—bears fruit—whether O receives an income or not. This is obviously different from typical compensation, which is necessary to bring factors of production into use. If you want a person to make widgets, you have to pay him. Economic rents are, thus, payments to a person unrelated to his economic contribution. And unlike typical forms of income, economic rents can be taxed without loss of economic efficiency.

In contemporary economies, economic rents are diverse. They include income that (i) executives receive by gaining control over their own pay-setting (see, e.g., Bebchuk & Fried 2004); (ii) is obtained through luck (Bertrand & Mullainathan 2001); (iii) is connected to unproductive activity (think: hedge funds that exploit technical inefficiencies in markets, Bivens & Mishel 2013); and (iv) attractive people make because they are attractive—the beauty premium (Hamermesh & Biddle 1994).

Typically, when economists and philosophers object to economic rent it is on the grounds that it is inefficient. For the meritocrat, it is worse than that: It is unjust.

The most famous opponent of economic rent is Henry George, who states his opposition in recognizably meritocratic terms:

When all rent is taken by taxation for the needs of the community, then will the equality ordained by nature be achieved. No citizen will have an advantage over any other citizen save as is given by his industry, skill, and intelligence; and each will obtain what he fairly earns. Then, but not till then, will labour get its full reward, and capital its natural return. (1879: book VIII, chapter III, last paragraph)

One might wonder: Just how unequal would a meritocracy be? While the precise distribution of jobs, income, and wealth will depend on the particulars of the meritocratic theory, meritocracy would be egalitarian by contemporary standards. Observe that, in a meritocracy, differences in merit may arise in only two ways: differences in natural traits and differences in individual choice (about which skills to develop, what career to pursue, how much to work, etc.) (A meritocrat could even hold that equal opportunity requires nullifying differences in natural traits—§2.3—leaving individual choice as the sole source of inequality.)

In addition, in a meritocracy there is little to no inheritance of wealth. This is for the same reason that there is no inheritance of hereditary titles and their concomitant privileges: It violates equal opportunity. Inherited wealth also severs the critical connection between contribution and income. If one doesn’t deserve some wealth—which one doesn’t, if it’s inherited—then one doesn’t deserve the investment income it produces.

Further, the largest divergences between contribution and income are seen at the top of the distribution. Economic rents, for instance, are extracted by the very rich. Meritocratic policies to remedy the problem of rent have the effect of redistributing wealth from the top of the distribution downward.

5. Objections
All philosophical theories garner objections. Meritocracy is unusual in that its critics come from all over: egalitarians and libertarians; liberals and conservatives; leftists and reactionaries.

5.1 Rawls
In A Theory of Justice, Rawls assures his readers that his theory would not produce a meritocratic society. That is not to say that there is no common ground between Rawls and meritocrats. Both agree that equal opportunity is an essential element of a just society.[7] But Rawls pairs equal opportunity not with a meritocratic distributive rule, but with his Difference Principle. A just society, according to Rawls, will respond to merit only insofar as that benefits the worst-off members of society. Conceivably, by allowing meritorious citizens to earn more than non-meritorious citizens, we can grow the social pie and thereby enable greater redistribution to the worst-off. If that is the case, and only if that is the case, will Rawls’ theory pay any heed to merit. But merit’s role in Rawlsian distribution will always be mild, instrumental, and contingent.

Rawls has four other objections to meritocracy. The first targets desert-based theories of justice broadly. Rawls claims that no one deserves anything because all bases for desert originate in “fortunate family or social circumstances”. A person is intelligent, for instance, either because she has a naturally high IQ or because she was raised in an environment that cultivated that trait. Either way, that kind of “fortune” undermines desert-based distribution. (Marx makes a similar argument in “Critique of the Gotha Program”.)

Second, Rawls regards meritocracy as unworkable. It may just be practically impossible to track people’s merits in sufficient detail to enable merit-based distribution.

Third, perhaps meritocracy is only justified by “comprehensive doctrines”, and does not emerge from free and equal people in a system of cooperation (Rawls 1993). If that is so (and if Rawlsian public reason is sound), then that is a problem. But Margaret Holmgren (1986) and James Sterba (1974) argue that Rawlsian contractors would in fact choose a desert-based system of justice, like meritocracy.

Fourth, Rawls says that meritocracy is insufficiently democratic. This is interesting because later in A Theory of Justice he suggests an openness to meritocratic governance:

Now the ship of state is in some ways analogous to a ship at sea; and to the extent that this is so, the political liberties are indeed subordinate to the other freedoms that, so to say, define the intrinsic good of the passengers. Admitting these assumptions, plural voting may be perfectly just. (1971: 233)

5.2 Relational egalitarianism
By definition, egalitarians regard the ideal of equality as morally salient. Meritocrats, on the other hand, regard equality as irrelevant or even inimical to justice. (Unless we are talking about Aristotelian proportional equality.)

One important class of equality-based objections to meritocracy comes from relational egalitarians like Elizabeth Anderson (1999) and Harry Brighouse (1996), who argue that it is morally important that people be able to relate to each other as equals. That seems threatened in a meritocracy, in which differences in merit create differences in political power, social goods, or both. How could an unmeritorious person regard a meritorious person as an equal, especially when the latter is wealthier, or has more votes, than the former? Mightn’t there be problems of oppression, domination, and hierarchy in a meritocracy? Don’t meritocrats even celebrate hierarchies?

Relational egalitarianism is used to defend democratic political arrangements. Brighouse, for example, advances the “equal availability of political influence [EAPI]”, which includes the “one person, one vote” principle:

The argument for EAPI is that guaranteeing that equal influence will be available to them over our collective circumstances is a requisite of expressing respect for our fellow citizens. (1996: 123)

Thus for Brighouse, a meritocratic political arrangement (that, e.g., violated “one person, one vote”) would obstruct citizens’ mutual respect, and therefore be morally unacceptable. Analogous objections to meritocracy would be lodged by other relational egalitarians, with specifics depending on the particular relational egalitarian theory.

5.3 Democratic theory
Unsurprisingly, democrats object to meritocratic politics. There are three main classes of objection.

For epistemic democrats (e.g., Goodin & Spiekermann [2018] and Landemore [2012]), democracy is valuable and legitimate because of its ability to make correct (e.g., just) decisions. They either resist meritocrats’ claims (§3) about the ignorance and irrationality of the democratic voter or, more commonly, reject the inference from individual dysfunction to collective dysfunction. This is the most direct objection to meritocracy given that nearly all arguments for meritocratic governance are epistemic in character.

The most commonly-adduced argument for the “wisdom of the [democratic] crowd” is Condorcet’s Jury Theorem (Condorcet 1785). In its simplest form, the theorem considers a group of voters choosing between two alternatives (e.g., a Democrat and a Republican). Each voter has a probability of choosing the “correct” (e.g., more just) candidate. That probability is shared and >50%. Assuming votes are statistically independent and the group uses “one person, one vote”, Condorcet’s theorem tells us that (i) the larger the group gets, the more likely it is to choose correctly and (ii) the probability that the group chooses correctly goes to 100% as the number of voters goes to infinity.

The meritocrat may avail himself of three broad rejoinders here. First, he may deny the relevance of the model on the grounds that its assumptions are violated in the real world. (Statistical independence is particularly troublesome given the many ways voters interact.) Second, he may concede that the collective performance of democracy is good for Condorcetian reasons, but insist that meritocracy does better. For it too may enjoy benefits from aggregation. Third, he may reply that the theorem itself commends unequal political influence: When some citizens are more competent than others, “one person, one vote” is (generally) suboptimal. The group does better if more competent voters are given more influence (see, e.g., Nitzan & Paroush 1985).

Epistemic democrats have drawn on other theoretical grounds. Perhaps “diversity trumps ability” (Hong & Page 2004): Democracy effectively harnesses diversity within contemporary electorates, and thereby does better, epistemically, than meritocracy does. Or perhaps while democratic voters do frequently err, as meritocrats claim, those errors cancel out to allow an accurate minority to prevail—the “miracle of aggregation” (Surowiecki 2004).

Procedural democrats take a different tact. For them, what justifies democracy and rules out meritocracy is adherence to certain morally necessary procedures. For (pure) proceduralists, whether meritocracy “tracks the truth” or makes decisions better than democracy does is irrelevant (if indeed these notions make sense at all).

If, for example, some voting procedure—like “one person, one vote”—is required by justice, and democracy embodies this procedure while meritocracy rejects it, no further analysis is necessary: Democracy is justified and meritocracy is not. Many relational egalitarian arguments (§5.2) are proceduralist, and other kinds of proceduralist theories have been developed (see, e.g., Habermas 1992 [1996] and Waldron 1999).

Finally, Estlund (2008) has advanced an influential objection which is a hybrid of the epistemic and proceduralist approaches—epistemic proceduralism. Estlund argues against pure proceduralist approaches on the grounds that if procedural fairness were all we cared about, democracy would be no better than simply flipping a coin. In both cases, all citizens have an equal chance of affecting an election (because, in the latter case, none has any chance at all). So there must be an epistemic component to political justification.

On the other hand, the fact that some meritocratic system might do better than democracy is insufficient to justify it. Our political system, Estlund argues, must be “generally acceptable” to all reasonable citizens (i.e., this is a public reason argument). According to Estlund, of all the generally acceptable systems, democracy does best.

5.4 Libertarianism
The conflict between meritocracy and libertarianism is most obvious when one considers right-libertarian theories, like Robert Nozick’s (1974). But conflict exists, too, for left-libertarian theories that have some common ground with meritocracy, like an affinity for equal opportunity (e.g., Otsuka’s [2003]). (For a full discussion, see Mulligan 2018d.)

To begin with, the meritocrat’s distributive rule—hire, compensate, etc. on the basis of merit—violates a libertarian right to contract. For libertarians, business owners are free to hire whomever they want. They are not obligated to hire the most meritorious applicant. An owner may wish to hire on the basis of race, or gender, or with an eye toward maximizing profits. She may wish to hire a friend or family member. So long as owner and employee enter into their contract freely (and without fraud and the other typical caveats), libertarian justice is done.

A meritocratic government may enforce an alignment between contribution and compensation. But that requires government interventions into market exchanges which are unacceptable to the libertarian. These interventions could include, for example, high top marginal income tax rates and limits on executive compensation in order to disincentivize economic rent (§4.3).

Most libertarians also reject equal opportunity, and certainly the demanding form required under meritocracy. In a meritocracy, extensive redistribution enables (among other things) education and healthcare for the children of the poor. Coercive taxation is part and parcel of redistribution. Equal opportunity may also require that the government confiscate and redistribute estates. All of this is problematic from the libertarian perspective. (Although see Bird-Pollan 2013 and Braun 2010 for arguments that libertarianism is compatible with estate taxes.)

Friedrich Hayek (1960) explicitly criticizes merit-based distribution. He gives two arguments. First, he correctly observes that a meritocratic economy may not be optimally efficient.

We do not wish people to earn a maximum of merit but to achieve a maximum of usefulness at a minimum of pain and sacrifice and therefore a minimum of merit. (1960: 96)

Hayek’s point is that one way to distribute (the right way, to his mind) is with an eye toward maximizing the economic surplus; another way is to distribute on the basis of merit. This objection does not rest in a Nozickian freedom of contract but in libertarianism’s classical liberal tradition, which typically appeals to the consequentialist benefits of free markets.

Second, Hayek objects to the idea of a “merit czar” who would monitor market activity and intervene to enforce merit-based distribution. That would be tyrannical. However (as Schmidtz & Boettke [2012 [2021]]) point out), this is not a normative objection to meritocracy but an objection to central planning. Indeed, Hayek’s argument can be turned around: Perhaps we should prefer market economies to central planning on the grounds that the former does a better job than the latter at recognizing merit.

One final objection, sometimes attributed to Hayek, is that meritocracy is heartless. In the actual world, the objection goes, “losers” can somewhat justifiably attribute their condition to having grown up poor or to external factors, like racial discrimination. Those are psychologically useful excuses. But in a meritocracy, in which there is equal opportunity and people are judged on their merits, those excuses are unavailable.

5.5 Other objections
Meritocracy promises efficiency benefits and other good consequences, but only contingently. Meritocracy is not a utilitarian theory, and focused utilitarian objections have been lodged against it (see, e.g., Durlauf 2008).

Meritocracy strikes some as insufficiently attentive to the needs of the poorest citizens; it is not a prioritarian theory (Wilson 2003). (Although if the poor are underpaid given their merit, and the rich are overpaid, as many meritocrats claim, then meritocracy will do better than the status quo from the prioritarian point-of-view. Meritocratic equal opportunity will also have an enormous effect.) Richard Arneson (1999) rejects Rawls’s Fair Equality of Opportunity (§5.1) as an unacceptable “compromise with meritocracy” because it constrains the prioritarian Difference Principle.

Some scholars make what is essentially an empirical argument, denying the existence of an elite class of citizens on which meritocratic governance can rely (Gunn 2019; Hannon 2022; Mendéz 2022; Reiss 2019). If the “meritocrats” are not more knowledgeable than common people, or if they suffer from unique and damaging biases, then, whatever its theoretical virtues, meritocracy cannot be operationalized.

6. The Public Debate
There’s been a flurry of recent, public-facing work on meritocracy. This work addresses meritocracy as a theory of justice (§4), and is largely critical (e.g., Carneval et al. 2020; Littler 2018; Mandler 2020; Markovits 2019; and Sandel 2020).

The public debate tends to be convoluted for two reasons. First, commentators often fail to make clear what they mean by “meritocracy”. The meritocratic ideal is more or less compelling depending on how it is defined (e.g., with robust equal opportunity or without). To avoid talking past each other, it is critical that commentators have a common definition in mind.

Second, one sees the classic conflation of the normative and the positive. This entry is concerned with the normative question: Ought we live in a meritocracy? (Or, almost equivalently, is meritocracy just?)

But then there is the positive question: Is the world meritocratic? Do people enjoy equal opportunity? All else equal, do poor children and rich children face equal prospects? Are jobs and income being distributed on the basis of merit? Or are non-meritocratic features—race, gender, family connections, appearance, luck, and so on—playing roles as well?

It is useful to partition commentators on meritocracy along the normative/positive dimensions. Some commentators (e.g., Mankiw [2013]) believe that meritocracy is both desirable and largely realized in the actual world. Others (Mulligan [2018b]) think that meritocracy is desirable but that we do not live in one. Still others (Markovits [2019]) say that we live in a meritocracy and that this is a bad thing. Finally, there are some (Gheaus [2015]) who think that meritocracy is neither achieved nor a worthy ideal in the first place.

Further complicating matters is the way perceptions of merit affect the public’s normative evaluation of policy. Consider affirmative action. While divisive, many supporters of affirmative action and many opponents appear to agree morally: Both want the most meritorious applicant to be hired. What they disagree about is whether affirmative action contributes to or detracts from this shared goal. Supporters think that affirmative action nullifies racial bias and other forms of disadvantage, ensuring that the most meritorious applicant gets hired. Opponents of affirmative action think that the policy violates meritocratic hiring by giving some applicants advantage (and others, perforce, disadvantage) on the basis of race (see, e.g., Reyna et al. 2005).

As Suhay, Tenenbaum, and Bartola describe things,

Even controlling for partisanship and various demographic characteristics, perceptions of whether the U.S. economy is meritocratic are strongly associated with people’s views on taxation, social welfare policy, affirmative action, and presidential candidates…. If citizens could develop a shared understanding of the ways in which the American economy fails to deliver meritocratic outcomes, perhaps they would demand the two parties find common ground on policies designed to combat inequality. (2022: 9 ff.)

The way the public perceives social and economic realities—as meritocratic or not—appears to play a crucial role in their moral assessment of those realities.

A curious feature of the debate is how both opponents and supporters of meritocracy appeal to the same facts in making their cases. Michael Sandel (2020), for example, attacks today’s culture of “credentialism” (also known as “pedigree”), in which a diploma from an elite college is a de facto requirement for entry into elite professions. Frequently, a less meritorious but credentialed person (from, say, Harvard) is preferred to a more meritorious but uncredentialed person (UMass). Credentialism is, by Sandel’s lights, a feature of meritocracy.

Mulligan (2018b) also attacks credentialism, arguing that meritocracy is the solution to it rather than its cause. A Harvard education is not markedly better than a UMass education, but the returns to a Harvard education are enormously better than the returns to a UMass education. The returns to a Harvard education are, thus, largely rent (§4.3), and so credentialism is unmeritocratic.

The meritocracy debate is, to put it mildly, unsettled. This is a reflection of its philosophical richness. While meritocratic ideas have been expressed and implemented for millennia, we still struggle to say exactly what meritocracy is and if it is desirable. We do not have full answers to those questions. But perhaps we are now, at least, beginning to understand them.

1. Evolution, Development, and Culture
Research in comparative cognition takes place against a backdrop of evolutionary, developmental, and socioecological considerations. Natural selection leads to the convergence and divergence of cognitive traits over evolutionary time. Cognitive traits might converge because two species face similar socioecological problems, such as navigating a similar foraging environment. Alternatively, two species might share cognitive abilities because they have inherited them from a shared ancestor or have developmental modules in common. Finally, cognitive abilities interact with evolution in ways that not only alter a species trajectory through phenotypic space, but their evolvability (Brown 2013). Considerations such as these help researchers predict and explain cognitive and behavioral abilities across taxa:

Only by investigating proximate (mechanism and ontogeny) and ultimate (phylogeny and function) causes can we fully understand the nature and origin of behavior. (Krupenye & Call 2019: 16)

This section presents several key ways in which evolutionary, developmental, and socioecological considerations shape methods in comparative cognition.

1.1 Convergent Evolution
The evolution of wings is a paradigm case of convergent evolution. Wings have the function of sustaining flight and have evolved in many different organisms, including birds, bats, and insects. The structures comprising wings differ across these groups—bat wings consist of extended digits, bird wings evolved from an extended forelimb, and insect wings are outgrowths of exoskeleton. Although wings in these groups differ in their underlying structures, they share features like rigidity, which allow them to perform the same function—producing lift and enabling flight. Similarities in traits such as these can be explained in part by appealing to shared selection pressures.

Adaptive considerations such at these guide theorizing in comparative cognition. In this case, a “psychological trait is treated as a design problem” (Ereshefsky 2007: 670). One determines the function that a psychological trait serves and asks what selection pressures might have led to that evolutionary outcome. For example, research on western scrub jays suggests that they have episodic-like memory or the ability to remember the “what, where, and when” features of specific events (Clayton et al. 2001). Scrub jays are “scatter-hoarders”, hiding food in multiple places for later recovery. Caching behavior such as this enables individuals to survive in environments with fluctuating food supplies. When recovering their caches, scrub jays remember where and when they have cached a specific food item. For example, they avoid searching for perishable food (like a worm) if its window of freshness has elapsed (Clayton & Dickinson 1998). Recent work on cuttlefish suggests that they face similar foraging challenges to scatter-hoarding birds. They live in environments with variable food supplies and appear to keep track of what they have eaten, as well as where and when they ate (Jozet-Alves, Bertin, & Clayton 2013; Schnell, Clayton, et al. 2021a). Cuttlefish are cephalopod mollusks and diverged from vertebrates like scrub jays over 550 million years ago (Figure 1). Given this phylogenetic distance, if cuttlefish and western scrub jays share the capacity for episodic-like memory, this cognitive trait may have evolved independently in these two taxa as a common solution to similar ecological problems.

a phylogenetic tree: link to extended description below
Figure 1. Distantly related organisms may share similar cognitive abilities because they face similar socioecological selection pressures over evolutionary time. Image adapted from Schnell, Amodio, Boeckle, and Clayton (2021b: 4). [An extended description of figure 1 is in the supplement.]

Alexandra Schnell and colleagues argue that studying phylogenetically distant species like chimpanzees, corvids, and cephalopods, allows researchers to better understand the selection pressures that give rise to “complex cognition” like episodic-like memory, future planning, causal reasoning, and imagination (Schnell et al. 2021b; see also van Horik et al. 2012, Powell et al. 2017, Amodio et al. 2019). For example, the Social Intelligence Hypothesis holds that complex cognition is a product of selection pressures that arise from living in complex social groups (see Byrne & Whiten 1988). However, many cephalopods live short and solitary lives. If these cephalopods do have cognitive capacities such as causal reasoning, these may have evolved in response to selective pressures emerging from something other than complex social environments. Focusing on socially complex vertebrates like chimpanzees and corvids alone makes it “difficult to uncouple the effects of ecological and social pressures on cognitive evolution” (Schnell et al. 2021a: 172). If it can be shown that organisms such as corvids and cephalopods (e.g., the octopus) have the same cognitive capacities (e.g., causal reasoning), then researchers might be better placed to infer the environmental demands that led to the emergence of adaptations in these distantly related taxa.

1.2 Homology and Development
There are several approaches to determining what counts as a homologous trait. The “phylogenetic approach” holds that two traits are homologous when they are derived from a common ancestor (Brigandt 2007). Humans and chimpanzees have similar physical-cognitive abilities like tool use (Herrmann et al. 2007). Under the phylogenetic approach, these abilities are homologous insofar as they were inherited from the evolutionary ancestor that humans and chimpanzees shared 6–8 million years ago. The “developmental approach” to homology holds that two traits are homologous when they’re produced by the same developmental module (Ereshefsky 2012). Mammalian vertebrae, arthropod limbs, and bird feathers are often viewed as homologues in this sense. Some hold that homology is best understood as having both phylogenetic and developmental components (Ereshefsky 2007, 2012). Under this view, a developmental module imposes proximate constraints on how a homologous trait is constructed, while evolution explains why that developmental module is found across taxa (namely, through common descent).

Some philosophers argue that psychologists should focus on identifying homologous rather than convergent traits, given their interest in the mechanisms responsible for behavior (see Matthen 2007; Clark 2010). For example, Paul Griffiths (1997, 2007a, 2007b) argues that identifying cognitive traits as convergent is epistemically more demanding than identifying cognitive traits as homologous. Explanations that appeal to convergent evolution often adopt a lock-and-key model of adaptation where a trait is viewed as a solution to an existing socioecological problem (e.g., episodic-like memory as a solution to the foraging problem that western scrub jays face today). However, Griffiths argues that it is unlikely that minds evolved in response to contemporary socioecological problems. Instead, the structure and organization of an organism’s phenotype and niche coevolve. Moreover, what counts as a “problem” depends on many factors, such as resource constraints and the developmental plasticity of an organism. Griffiths writes:

Problems whose solutions cannot be developmentally dissociated must be solved as a single problem and so are not separate problems from the standpoint of adaptive evolution. (2007b: 203)

To provide a compelling case of convergent evolution, one must take such constraints under account. In the case of complex cognitive traits, researchers often know little about the resource and developmental constraints at play in an organism’s evolutionary history. In this way, identifying cognitive traits as convergent may be epistemically demanding.

1.3 Culture
In addition to evolutionary and developmental factors, comparative cognition researchers aim to understand how cultural factors affect cognitive capacities. Philosophers and scientists have also argued that understanding animal cultures has important implications for conservation efforts (Brakes et al. 2019) and animal welfare (Fitzpatrick & Andrews 2022). Broadly, culture can be defined as

information transmitted between individuals or groups, where this information flows through and brings about the reproduction of, and a lasting change in, the behavioral trait. (Ramsey 2017: 348; see also Ramsey 2013; Andrews 2015 [2020]: chapter 8; and entry on cultural evolution)

For example, the skills required to use a tool effectively might be transmitted through social learning (such as copying), creating a lasting change in a recipient’s subsequent behavioral abilities and reproductive fitness. Cultural transmission has been described as a form of “soft inheritance” or the idea that organisms can inherit phenotypic variation that is the result of non-genetic effects (Mayr 1982). Eva Jablonka and colleagues argue that many animal traditions are transmitted in this way (Avital & Jablonka 2000; Jablonka & Lamb 2008). For example, the behavioral innovation of opening milk bottles spread quickly through Eurasian blue tit populations in the early twentieth century. Studies suggest that this innovation spread through a mixture of local enhancement (naïve birds learning that milk bottles are a source of food by spending time near birds capable of exploiting this food source) and observational learning (naïve birds copying the behavior of experienced innovators) (Aplin, Sheldon, & Morand-Ferron 2013).

One advantage of understanding culture in terms of soft inheritance is that some of the methods and models employed in the study of biological evolution can be applied to the study of culture (Mesoudi, Whiten, & Laland 2006). Rachael Brown (2017a) also argues that animal traditions are important for understanding genetic evolution. For example, recent studies suggest that the diversification of beak morphologies in Galápagos finches is the result of behavioral foraging innovations spread through cultural transmission. The presence and spread of these behavioral innovations (e.g., using one’s beak to puncture the skin and drink the blood of sea birds, as in the case of “vampire finches”) may have been required to allow sufficient selective pressure for morphological adaptation to occur. Despite the links between culture and genetic evolution, there remains disagreement regarding whether the modern synthesis in evolutionary biology should be extended to include processes such as soft inheritance (see Pigliucci 2007; Laland et al. 2015). Nevertheless, research on animal culture is flourishing with observational and experimental studies revealing both its cognitive underpinnings and effects (see Whiten 2022 for a recent review).

1.4 Cognition in the Wild and Captivity
As noted, comparative cognition is a field that draws on methods from a variety of disciplines, including ethology, experimental psychology, and neuroscience. Philosophers and scientists have debated the relative merits of these methods for understanding animal minds. A central method in ethology is fieldwork on wild animals, for instance, while experimental psychology relies primarily on laboratory studies on captive animals. Wild and captive animals often lead different kinds of lives. For example, captive chimpanzees tend to have regular access to food, extensive experience with human objects (including objects designed for enrichment), and live in a relatively small space. Wild chimpanzees typically live in territories that are many square kilometers in size, spend much time foraging, and must overcome life-threatening problems not typically found in captivity, such as competition with neighboring groups and predators (Boesch 2022). In comparative cognition, many researchers stress the importance of observing animals in their natural environment. From an ethological perspective, this is crucial for understanding how animal minds evolved because “it is in this situation that natural selection acts” (Healy & Hurly 2003: 326).

Other researchers note that control conditions like those found in the laboratory are necessary for investigating animal minds. For example, Heyes and Dickinson (1990) argue that identifying the mental states responsible for a given action requires determining

what the animal would have done if its circumstances had been different in certain, specifiable respects from those in which the action actually occurred. (1990: 88; but see Allen & Bekoff 1997: chapter 9)

Observing animals in their natural environment often precludes varying the environment in systematic ways, while laboratory studies are designed to control for alternative explanations and nuisance variables (see section 2). Some researchers also argue that “unnatural” environments might direct development and learning in ways that supports the emergence of new or enhanced cognitive capacities. Captive great apes, for example, develop problem-solving and communicative abilities not found in their wild conspecifics, such as tool use, pointing, and sign language (Tomasello & Call 2008; Bandini & Harrison 2020). Studying animals outside of their natural environment might provide insight into their cognitive potential when appropriately scaffolded by the environment.

Overall, most researchers acknowledge that a plurality of methods is needed for understanding animal minds. For example, Michael Tomasello and Josep Call write regarding primate cognition research that,

fieldwork is primary. It tells us what animals do; it sets the problem. But then if we wish to figure out what is the nature of the cognitive skill, if any, underlying some activity in the wild, we need experiments. (2008: 451)

Kristin Andrews documents different possible sources of bias in the field and laboratory. For example, in the field, ethograms might lead to confirmation bias, while in the laboratory, the importance of the relationships between human experimenters and study participants is often underemphasized (see Andrews 2020: 42–61). Andrews concludes that comparative psychologists should aim to employ and integrate a variety of methods for studying animal minds, rather than seek to eliminate bias. Colin Allen and Marc Bekoff (1997) similarly emphasize the need for an interdisciplinary approach:

Science is not likely to make complete contact with the nature of animal minds at any single point—many methods will be useful, and competing hypotheses should be evaluated. (1997: 180)

2. Eliminating Alternative Explanations
Comparative cognition researchers often test hypotheses about animal minds through behavioral studies or experiments. These studies are designed to determine whether a species, group, or individual animal behaves as one would expect on the assumption that a given hypothesis is true. Often these hypotheses specify to some degree the cognitive processes thought to underlie a given suite of behaviors. As Shettleworth notes, researchers seek

not just to confirm that animals are (or are not) capable of doing something “clever” but to discover how they do what they do. (Shettleworth 2013: 4)

In this section, we consider the role that statistical nulls, alternative explanations, epistemic values, and non-epistemic values play in the evaluation of hypotheses in comparative cognition.

2.1 Null Hypotheses in Comparative Cognition
A central element of experimental work in the sciences involves controlling for extraneous or “nuisance” variables. Comparative cognition is like other sciences in employing experimental and statistical methods to control for such variables (Bausman & Halina 2018; Dacey 2023). The aim of an experiment is generally to determine whether there is a relationship between the independent and dependent variables. For example, crows drop nuts onto roads and retrieve the cracked nuts (Shettleworth 2010a). Are they doing this because they’ve learned that cars can be used as “nutcrackers”? Or has the behavior of dropping nuts from a height evolved over many generations (perhaps before the advent of cars)? As a first step towards answering these questions, one might experimentally investigate whether the presence of approaching cars on a road (the independent variable) affects nut-dropping behavior in crows (the dependent variable) (Cristol et al. 1997). To detect this effect, however, one must control for the “noise” created by extraneous variables—i.e., those variables that are also likely to affect the dependent variable. In the case of foraging crows, extraneous variables may include time of day, season, proximity to nut trees, etc. In an experiment, the statistical null hypothesis typically holds that any differences observed in the dependent variable can be attributed to extraneous variables and thus there is no evidence that the independent variable has had an effect (see Sani & Todman 2006). Whether an observed difference in the dependent variable can be attributed to the independent variable (i.e., whether the difference is statistically significant) depends on one’s test statistic, which reflects the variability of the data due to known extraneous variables. If proximity to nut trees can explain the difference observed in nut-dropping behavior, for example, then there is insufficient evidence to conclude that nut-dropping behavior has been affected by the presence or absence of approaching cars.

The term “null hypothesis” is sometimes used more broadly to refer to an alternative or competing hypothesis, rather than a statistical null hypothesis. For example, associative learning, behavior reading, and hypotheses that deny animals “special” human-like cognitive abilities are often referred to as “null hypotheses” (see Hanus 2016; Dickinson 2012; Andrews & Huss 2014; Mikhalevich 2015). These hypotheses are typically contrasted with those that attribute complex or human-like cognitive abilities to animals like causal reasoning or theory of mind. One problem with this broad use is that the term “null” suggests that a hypothesis should be epistemically privileged (in the sense that it must be rejected before accepting any alternative hypothesis) when in many of these cases it is not clear the purported null should be privileged in this way. As Andrews and Huss (2014) write:

the onus is on the skeptic to explain why the skeptical hypothesis and not the optimistic hypothesis that animals do have psychological properties is the proper null hypothesis. (2014: 720–721)

Statistical null hypotheses are epistemically privileged in the sense that they must be rejected before one can conclude that the variable of interest (the independent variable) has had an effect. This inference strategy is justified in the context of statistical hypothesis testing due to the nature of experimental design and inferential statistics (Bausman & Halina 2018). However, the features that justify this strategy in the statistical case are not present in hypothesis evaluation more generally (the latter lacks a test statistic, for example). Instead, one must supply compelling reasons for preferring one hypothesis (such as associative learning) over another (such as causal reasoning). Such reasons may be theoretical (e.g., that one hypothesis has epistemic virtues like predictive power that the other lacks) or empirical (e.g., that one hypothesis already has independent empirical support, while the other does not). The next three sections discuss hypothesis evaluation in comparative cognition in this broader sense. For additional discussion of statistical null hypotheses, null modeling, and default models, see Bausman 2018, Zhang 2020, and Dacey 2023.

2.2 Cognitive and Associative Explanations
As noted above, to provide compelling evidence that an animal has cognitive capacities like episodic memory or theory of mind, researchers aim to eliminate plausible alternative explanations for behavior. This research strategy is not unique to comparative cognition but is found across the sciences. For example, Julian Reiss argues that a hypothesis is warranted insofar as one has eliminated alternative hypotheses. That is, the strength of the warrant depends on how many alternatives have been eliminated and how compelling or salient those alternatives are (Reiss 2015). In comparative cognition, associative learning is regularly advanced as a salient alternative that must be eliminated before concluding that an animal has complex cognition. As Starzak and Gray (2021) write,

Over and over again the familiar refrain is, “do animals have complex human-like cognitive abilities or can their behavior be explained in terms of simpler processes such as associative learning?”. (2021: 2)

What is associative learning? Broadly, associative learning is a class of learning mechanisms characterized by a change in association between two or more variables. Two common forms of associative learning are classical (Pavlovian) conditioning and operant (instrumental) conditioning. In classical conditioning, a stimulus comes to elicit a response in an organism because it has become associated with another stimulus. For example, drawing on the studies of the Russian psychologist Ivan Pavlov, dogs naturally salivate in response to the taste of food (this response does not require training or conditioning, so is an unconditioned response to an unconditioned stimulus). However, one can pair another stimulus, like the sound of a bell, with the arrival of food. Over time, dogs will learn to associate the food with the sound of the bell, such that the sound of the bell will become sufficient on its own to elicit salivation (the sound has become a conditioned stimulus leading to a conditioned response). In operant conditioning, an organism’s behavior changes in response to the consequences of that behavior. For example, a cat might behave in many ways while interacting with a puzzle box (which, say, contains food the cat likes) with some behaviors resulting in the cat successfully opening the puzzle box by accident. Over time, the successful behaviors will be strengthened, and the unsuccessful behaviors weakened, such that the cat will be able to quickly open the puzzle box as a result of operant conditioning alone. The tendency for behaviors to be strengthened or weakened in response to their positive and negative consequences respectively is known as Thorndike’s law of effect after the American psychologist Edward Thorndike.

It is often possible to formulate plausible associative learning accounts that can accommodate data originally believed to support hypotheses like causal reasoning or theory of mind (for examples, see Taylor, Medina, et al. 2010; Heyes 2012; Halina 2022). In many cases, this is taken to undermine the original interpretation of the data because associative learning is taken to be preferred as an explanation of animal behavior over capacities that require “complex” or human-like cognitive abilities (Buckner 2011; Hanus 2016). One justification for this preference is that associative learning is “simpler” than alternative cognitive explanations and thus should be preferred all else being equal (see section 2.3). Philosophers have argued, however, that appealing to simplicity alone in this context is not enough. Instead, one must show that the associative and cognitive explanations in question can in fact be ordered by complexity and that there are good reasons for preferring the simpler explanation in a particular case (e.g., because the more complex cognitive ability presupposes or requires the simpler associative ability) (Heyes 2012; Meketa 2014; Dacey 2016, 2017). A second justification for preferring associative learning as an explanation is that it is phylogenetically widespread. If associative learning is phylogenetically widespread, then it is reasonable to assume that many animals will use it to solve physical and social cognition tasks. Irina Mikhalevich (publishing as Meketa 2014) refers to this as the “taxonomic ubiquity argument” (2014: 737). One concern with this approach is that if it is standard practice to believe that associative learning trumps complex cognition (in cases where both are consistent with the data), then this practice might itself result in associative learning appearing more taxonomically ubiquitous. Thus, relying on such results to justify associative learning as a preferred hypothesis appears to beg the question (Meketa 2014, but see Heyes 2012).

The above discussion presumes that associative learning and complex cognition are mutually exclusive—that one or the other, but not both, are needed to explain a behavior of interest. One explanation for this assumption is that it is simply part of typical definitions of complex cognition and associative learning. For example, Amanda Seed and colleagues note that complex cognition is often “defined by exclusion, rather than by some positive assessment of the mechanisms underpinning it” (Seed, Emery, & Clayton 2009: 402). Such an approach identifies a flexible or novel behavior as best explained by complex cognition when it “cannot easily be explained in terms of simple conditioning, or hardwired action patterns” (Seed et al. 2009: 410). Under this view, complex cognition and associative learning are mutually exclusive by definition. However, researchers have expressed concerns with the associative-cognitive distinction (Allen 2006; Buckner 2017). One concern is that associative learning models are now sophisticated enough to capture paradigm cases of cognitive processes (see Buckner 2011, forthcoming; Dickinson 2012). Another concern is that cognition does not lend itself to precise definition or clear categorization. Allen (2017), for example, advances a “relaxed pluralism” about cognition, allowing for multiple incompatible accounts. Those who reject the associative-cognitive distinction often urge researchers to focus on more specific capacities instead. As David Papineau and Cecilia Heyes write,

research should refocus on specific explanations of how animals do specific things, rather than on the presence or absence of some general or ideal form of rationality that contrasts with associative mechanisms. (2006: 187)

Dacey (2016) also argues that the concept of “association” is best understood as a “highly abstract filler term” that can be implemented by a wide range of cognitive mechanisms (2016: 3763). Understood this way, associative learning and complex cognition are not mutually exclusive: both may be needed to explain a given behavior.

2.3 The Role of Epistemic Values
Epistemic values can be broadly characterized as those features (of a theory or a theory in relation to evidence) that scientists value because they’re believed to lead to epistemic goods like truth and understanding. Heather Douglas distinguishes between those epistemic values that are minimal criteria versus ideal desiderata. Minimal criteria are those values that are epistemically necessary: they are “genuinely truth assuring” and their absence indicates “something is wrong with our theory” (Douglas 2013: 799). These include features like internal consistency and empirical adequacy. In contrast, ideal desiderata are not required, but are useful and often provide assurance that we are on the right track or that, if we’re not on the right track, we will find out sooner rather than later. Ideal desiderata include values like simplicity, unification, and novel prediction. For example, a simpler theory may be easier to use and a theory capable of making novel predictions might assure researchers that the theory is not overfitting the available data (Douglas 2009a, 2009b; Douglas & Magnus 2013).

Comparative cognition researchers also appeal to epistemic values when evaluating theories and hypotheses. Researchers minimally expect theories to be internally consistent and empirically adequate. When two competing theories are both consistent with the available empirical data, researchers evaluate them with respect to other epistemic values. For example, in the context of chimpanzee theory of mind research, Tomasello and Call (2006) note that two hypotheses—theory of mind and learned behavioral rules—account for the available experimental data. However, they argue that theory of mind provides a unified explanation of the existing data, while the claim that chimpanzees rely on learned behavioral rules requires positing a unique behavioral rule for each experimental result. They also express concern that behavioral rules are ad hoc. Fletcher & Carruthers (2013) concur, maintaining that

the behavior-rule account is only capable of “predicting” new findings after they are discovered, postulating a novel behavior-rule for the purpose. (2013: 88)

Here, we find researchers arguing in favor of one explanatory theory over another based on epistemic values like predictive power, unification, and coherence.

One epistemic value that has received a lot of attention from scientists and philosophers working in comparative cognition is simplicity or parsimony (Dacey 2016). As we saw in the previous section, the epistemic value of simplicity is often attributed to associative learning, leading to debates about whether associative learning is truly simple and, if so, what this means for theory choice. However, another reason why simplicity has received a lot of attention is its connection to Morgan’s Canon—a methodological principle widely adopted in research on animal cognition. This principle holds that when there are two or more plausible explanations for an animal’s behavior, psychologists should favor the explanation that appeals to “lower” rather than “higher” psychical faculties (Fitzpatrick 2008).

Many philosophers have rejected Morgan’s Canon as a useful methodological principle. First, they argue that what counts as “sophisticated” is often ambiguous (Sober 2005; Fitzpatrick 2008; Meketa 2014). Simplicity has been used to distinguish between sensory and conceptual reasoning, stimulus-response mechanisms and conscious thought, associative and non-associative learning. Moreover, in all these cases, the contrast seems problematic (Andrews & Huss 2014). Second, if Morgan’s Canon is interpreted as no more than the dictum that “simpler is better or more likely to be true”, then it is a poor research guide. There are numerous parsimony considerations one can make in comparative research (ontological parsimony, explanatory parsimony, evolutionary parsimony): often these considerations pull in different directions and rarely do they favor the conclusion urged by Morgan’s Canon (Sober 2005; Fitzpatrick 2008; Dacey 2016). Finally, philosophers of science have argued that justifying simplicity as a virtue is context dependent—that is, it is not a virtue that applies across the board (see Longino 2008). As Elliott Sober writes:

When a scientist uses the idea [of parsimony], it has meaning only because it is embedded in a very specific context of inquiry. Only because of a set of background assumptions does parsimony connect with plausibility in a particular research problem. What makes parsimony reasonable in one context therefore may have nothing in common with why it matters in another. (Sober 1990 [1994: 140])

If Sober is correct, then determining whether one should prefer the simpler explanation will depend on the case at hand. Insofar as Morgan’s Canon is a general methodological principle, meant to hold across a wide range of disparate cases or a “blanket bias towards endorsing lower explanations”, it should be rejected, according to this view (Fitzpatrick 2008: 243). Comparative cognition researchers have reached similar conclusions. For example, Tomasello and Call (2006) write,

we are not strong proponents either of parsimony (unless one clearly defines the criteria for parsimony) or of Morgan’s Canon—certainly not as substitutes for grappling with data when there is plenty of it. (2006: 381)

It is worth noting that not all accounts of Morgan’s Canon characterize it as a simplicity principle. For example, Simon Fitzpatrick and Grant Goodrich (2017) argue that when one looks at Conwy Lloyd Morgan’s own formulation of the canon, it does not take the form of a simplicity principle. Indeed, Morgan explicitly rejected simplicity as a criterion for choosing between competing explanations. Instead, he held that one should choose the explanation that best coheres with our observations and broader background knowledge. One such piece of background knowledge for Morgan was that “higher” faculties evolve from “lower” ones; thus, the former will be rarer in nature than the latter, and this should inform our choice of explanation. Similarly, Adrian Currie (2021) argues that Morgan’s Canon is best understood as holding that evolutionary ancient and highly evolvable traits are more likely to be found across the tree of life. Thus, explanations that appeal to such “lower” traits should be preferred over those that do not. Under this view, whether a cognitive trait is simple or complex is not relevant—it is its expected taxonomic distribution and evolvability that matters.

2.4 The Role of Non-Epistemic Values
Philosophers have argued that non-epistemic values, such as practical and ethical ones, play an important role in science. Such values are needed to evaluate the risk of uncertainty associated with a hypothesis (see Rudner 1953; Douglas 2009a). Hypotheses are not deductively entailed by the evidence. Instead, one must determine the appropriate trade-off between false positive and false negatives for any given test. A test with a high bar for hypothesis acceptance will result in more false negatives, while a test with a low bar for hypothesis acceptance will result in more false positives. Determining the right balance between errors often requires taking non-epistemic factors into account. For example, if a false negative has consequences we wish to avoid as a society (e.g., death due to lack of treatment), while a false positive for the same test does not (e.g., the treatment is harmless and has negligible economic costs), then we should err on the side of the false positive. Of course, often the calculus is not this simple and numerous social and economic factors must be considered.

The results of comparative cognition research are used to inform laws and welfare policies concerning animals. For example, in December 2013, a group of lawyers, scientists, and policy experts filed a petition for a writ of habeas corpus in a New York State Supreme Court (Grimm 2013). A writ of habeas corpus is a court order to “produce the body”. It requires any person or institution holding a prisoner to bring the captive to court and justify her imprisonment and treatment. The writ was filed on behalf of Tommy, a male chimpanzee. At the time of the filing, Tommy was seen living alone in a dark shed. If recognized by the court, the writ would require Tommy’s holder to justify Tommy’s captivity and treatment. This was the first time a habeas corpus had been filed on behalf of a nonhuman animal and, if successful, would represent the first case of an animal being given the right not to be treated as property in the United States. The case on behalf of Tommy was made in part by drawing on cognitive evidence. The plaintiffs argued that the cognitive abilities of chimpanzees are such that solitary confinement causes harm. Numerous comparative cognition researchers and philosophers have testified in support of this case (See Nonhuman Rights Project: Client, Tommy (Chimpanzee); Andrews, Comstock, et al. 2018). Thus, how we treat and think we ought to treat animals often depends on our knowledge of their cognitive abilities (Bekoff & Gruen 1993). Such knowledge can be used to prevent negative states of mind, such as loneliness, anxiety, and distress, as well as restore and promote positive mental states.

Should the methods of comparative cognition take non-epistemic values into account? Jonathan Birch (2018) argues that when there are “clear policy applications in view” comparative cognition researchers should adjust their standards to reflect the moral consequences of error (2018: 1028). Birch advances a criterion to help determine when an animal welfare scientist (X) should accept the hypothesis that some species (S) has a mental state (M), given a particular policy context (P) (Birch 2018). Under this view, a welfare scientist should accept that some species has a mental state in a particular policy context P if and only if the expected sum of the possible welfare outcomes given the scientist’s background knowledge and the decision to affirm the hypothesis that S has M in P is greater than the expected sum of the possible welfare outcomes given the scientist’s background knowledge and the decision not to affirm the hypothesis that S has M in P. One concern with precautionary approaches such as this one is that it is challenging to agree on where to set the burden of proof in any given case. For example, Birch (2017) proposes to set the evidential bar for animal sentience at “at least one credible indicator of sentience in at least one species of that order” (2017: 5). Other researchers, however, have objected that this evidential bar is either too weak or too strong. For example, Michael Woodruff (2017) argues that this evidential bar is too weak and should be raised to include many more independent indicators of sentience to decrease uncertainty regarding the principle’s level of scientific support. In contrast, Rachael Brown (2017b) argues that Birch’s evidential bar is too strong for those situations in which there is no statistically significant evidence of a single credible indicator of sentience, but instead “multiple, weak, but convergent, lines of evidence that a species is sentient” (2017b: 2). Despite these differences, there is general agreement that expected welfare consequences should affect evidential standards in those areas of comparative cognition that have clear policy implications, and that the right evidential standard must be determined on a case-by-case basis (see also Benz-Schwarzburg, Monsó, & Huber. 2020; Crump et al. 2022).

3. Methodological Challenges
3.1 Anthropomorphism
A perennial concern in animal cognition research is whether researchers are being “anthropomorphic”. Shettleworth defines anthropomorphism as

the attribution of human qualities to other animals, usually with the implication it is done without sound justification. (Shettleworth 2010b: 477)

The term “human qualities” refers to those properties that we readily accept as characteristic of humans. These may include cognitive abilities such as future planning, empathizing, insightful problem solving, and reliving past experiences. In comparative cognition, researchers may attribute such states to animals based on the available empirical evidence. In our everyday lives, we also often attribute human-like states to animals (Serpell 2005). In both cases, there’s a question whether one’s attributions are correct or not.

Concerns surrounding anthropomorphism have dramatically influenced the methods and conclusions drawn from animal studies throughout the twentieth and twenty-first centuries. Behaviorism within animal cognition research, for example, can be understood in part as a response to concerns about anthropomorphism (Wynne 2007). For those worried that we are misattributing human-like cognitive states to nonhuman animals, one solution is to focus on describing observed relationships between environmental cues and behavior instead. Although traditional behaviorism is widely rejected today, there are contemporary scholars who hold that behaviorism had something right in its unwillingness to anthropomorphize. As Clive Wynne (2004) warns:

Old-time behaviourism may have imposed excessive constraints on animal psychology. But the reintroduction of anthropomorphism risks bringing back the dirty bathwater as we rescue the baby. (2004: 606)

Should we be concerned about anthropomorphism in comparative cognition? One reason to be concerned is that there are empirical studies showing that humans have the tendency to over-attribute mental states to objects in their environment. For example, in one classic study, the psychologists Fritz Heider and Marianne Simmel (1944) showed human participants a video of three shapes moving in various directions and speeds. Despite the objects being two-dimensional shapes, almost all participants described the scene in anthropomorphic or human-like terms (e.g., as the shapes “fighting” or “chasing” one another). Contemporary studies confirm that humans are quick to attribute mental states to objects and agents based on behavior and other cues (like the presence of eyes) (Fiala, Arico, & Nichols 2011, 2014; Arico et al. 2011). As Dacey (2017) argues, the human tendency to anthropomorphize may serve as a fast and frugal heuristic allowing one to quickly anticipate the behavior of other agents. However, if this heuristic activates even when no psychological agent is present, then this may lead to numerous false positive in animal cognition research. Dacey argues that the best methodological approach is not a general prohibition against the attribution of human-like mental states to animals, however, but rather the application of methods known to effectively combat implicit bias, like making counter-stereotypical information salient. For example, selecting targets that are relatively unlikely to be anthropomorphized (such as insects) and asking researchers to imagine such targets behaving intelligently may help counter intuitive anthropomorphism (Dacey 2017: 1158–1161).

A second argument in favor of avoiding the attribution of human-like mental states to animals highlights that there are competing explanations that can account for the behaviors in question—explanations that do not appeal to sophisticated cognitive abilities. For example, Shettleworth (2010b) discusses the cases of animal insight, theory of mind, and mental time travel. Research suggests we find these abilities in animals such as chimpanzees and crows. However, Shettleworth argues that we should resist this conclusion because there are alternative, non-anthropomorphic, explanations for the behaviors observed in these animals. For example, we can explain the apparent insightful problem-solving behavior found in crows as part of their natural behavioral repertoire or as being driven by cues in the environment. And we can explain the apparent theory of mind abilities in chimpanzees as instead arising from a set of learned and innate rules about what to expect in social situations (see section 2). Crucially, in addition to arguing that sophisticated mental abilities might not provide the best explanations for animal behavior, Shettleworth argues that such abilities might also not provide the best explanation for human behavior. She writes that empirical research

increasingly reveals an unexpected role in human behavior for simple, unconscious and sometimes irrational processes shared by other animals. Greater appreciation of such mechanisms in nonhuman species would contribute to a deeper, more truly comparative psychology. (Shettleworth 2010b: 477)

Buckner (2013) additionally argues that humans have an inflated sense of their own cognitive aptitudes; thus, using this sense as a guide for evaluating other animals “loads the deck against animal mentality” (2013: 853). He calls this tendency “anthropofabulation” which combines anthropocentrism (next section) with an exaggerated sense of human intelligence.

Some researchers argue that anthropomorphism has scientific benefits. For example, “heuristic anthropomorphism” holds that we can use our intuitive understanding of humans and animals to generate concrete hypotheses about animal behavior and then test those hypotheses empirically (de Waal 1999). In other words, we can use our experience of being human—that is, of being a human animal—to help us generate hypotheses about what it might be like to be another animal, such as a crow or dog. Crucially, however, the idea is not to simply impose a human perspective on other animals, but to take what is known about an animal’s behavior, evolutionary history, ecological context, etc. into account. The idea is to do this critically; that is, in a conjectural or provisional way, which leaves the proposed hypothesis open to testing, revision or rejection. As de Waal (1999) writes:

While we should be reluctant to postulate capacities for which there is no evidence anywhere in a species’ behavior, charges of anthropomorphism are meaningless without a precise critique of the hypotheses under consideration. In a Darwinian framework, there is no good reason to avoid concepts merely because they derive from the behavior of the species to which we belong. Application of these concepts to animals not only enriches the range of hypotheses to be considered, but it also changes the view of ourselves: the more human-like we permit animals to become the more animal-like we become in the process. (1999: 272).

Andrews (2016, 2020) also argues for the importance of human folk psychology in comparative cognition research. Folk psychology can be broadly understood as our human commonsense understanding of psychological phenomena (see entry on folk psychology as a theory). Folk psychology is a form of anthropomorphism insofar as it involves applying human qualities to other animals. Andrews argues that folk psychology is methodologically important for grouping animal behaviors together into types. For example, in a now classic study, Whiten and Byrne (1988) collected reports of tactical deception in nonhuman primates. “Deception” is a folk psychological term used to indicate the human act of deceiving or tricking another individual. However, despite its folk-psychological origin, Andrews argues that this term provided a useful starting point for individuating and categorizing behaviors. Such categories were then analyzed, updated, and refined based on empirical evidence. Identifying robust behavioral types in this way is in turn important for investigating the cognitive mechanisms responsible for behavior (Andrews 2016a).

3.2 Anthropocentrism
The term “anthropocentrism” describes the tendency to locate human beings at the “center”. Anthropocentrism can broadly be understood as the claim that humans are special or exceptional in some way. Some researchers hold that concerns about anthropomorphism (see previous section) arise from a place of anthropocentrism: “Cries of anthropomorphism are heard particularly when a ray of light hits species other than our own” (de Waal 1999: 256). In other words, the belief that humans are special gives rise to a bias against attributing human qualities to other animals. Brian Keeley (2004) argues that historically, particularly in the theological context, some traits have been taken to belong exclusively or categorically to one group, such as humans or gods. For example, one might hold that only humans have souls. In this case, to attribute a soul to a nonhuman animal is to make a category mistake: nonhuman animals are simply not the types of things that can have souls. Such an attribution will always be false. Keeley contrasts this “categorical anthropomorphism” with “situational anthropomorphism” (2004: 529, see Fisher 1996). While categorical anthropomorphism involves mistakenly attributing a quality to something that simply cannot possess that quality, situational anthropomorphism involves mistakenly attributing a quality to an agent or system, but this quality is something that the agent or system could possess in principle. If cognitive capacities like insight and episodic memory are products of evolution and development, then there is no reason in principle why other animals should not have them. If on the other hand, such capacities are products of cultural inheritance involving language, we should not expect to find them in nonlinguistic species. In either case, it is an empirical question, in the same way determining whether an animal is omnivorous or land-dwelling is an empirical question. In the same way that researchers should be concerned about anthropomorphism and false positive attributions of mental states to animals, one should be concerned about anthropocentrism and false negatives—the failure to attribute human-like qualities to animal when the animal in fact possesses them (Sober 2005, 2012). Such false negatives have been termed “anthropodenial” and “anthropectomy” in the literature (de Waal 1999, Andrews & Huss 2014).

3.3 Underdetermination
A major challenge in comparative cognition is that claims about cognition are often underdetermined by behavioral evidence. As Tomasello and Call note, “the exact same behavior may be underlain by very different cognitive mechanisms” (2008: 451). Broadly, a hypothesis is underdetermined when the available evidence fails to indicate what we should believe about that hypothesis (see entry on underdetermination of scientific theory). For example, if two hypotheses are equally supported by the available data, we might not be able to choose between them (contrastive underdetermination). Or if a hypothesis is found to be incompatible with an empirical result, we might not know whether to reject that hypothesis or some other background assumption instead (holist underdetermination). Problems of underdetermination are found throughout the sciences. However, this problem is particularly salient in the cognitive sciences, given the opaque and complex nature of cognitive systems.

We encountered an example of contrastive underdetermination when discussing cognitive and associative accounts of behavior (section 2.2). There we saw that some competing hypotheses appear to be equally well supported by the empirical data: for example, causal reasoning and associative learning accounts of problem-solving behaviors in corvids (see Taylor, Medina, et al. 2010). If it is true that, “associative hypotheses can be constructed post-hoc for every experimental outcome” (Starzak & Gray 2021: 4), then simply finding that one’s causal-reasoning hypothesis fits a particular experimental outcome will not be sufficient to accept it over the available associative hypotheses. Instead, one must appeal to other factors, like epistemic values (section 2.3) to determine hypothesis choice.

Another major source of underdetermination in comparative cognition is that the structure and function of target cognitive phenomena are often uncertain and open to revision. For example, since the 1970s, a significant amount of research has been dedicated to determining whether nonhuman great apes like chimpanzees have “theory of mind” (ToM) or the ability to attribute mental states to other agents. In their classic paper initiating this research program, David Premack and Guy Woodruff write:

we speculate about the possibility that the chimpanzee may have a “theory of mind”, one not markedly different from our own. (Premack & Woodruff 1978: 515)

However, they add that a chimpanzee’s ToM may differ from human ToM in important respects—e.g., in the type of mental states inferred. Moreover, throughout work on animal ToM, researchers’ understanding of the target phenomenon and relevant background assumptions have changed in response to new findings. For example, rather than rejecting the hypothesis that chimpanzees attribute perceptual states to other agents, researchers have interpreted some negative results as due to other factors (e.g., lack of ecological validity or poor experimental design) (Hare et al. 2000; Kaminski et al. 2004; Bräuer et al. 2007). This has then led to proposals regarding what additional experimental controls are needed to successfully detect a relationship between the independent and dependent variables (see section 2.1). Philosophers have noted that such revised understandings of the target phenomenon play an important role in the biological and cognitive sciences (Bechtel 2008; Bechtel & Richardson 1993 [2010]). Nevertheless, revising the phenomenon in this way leads to underdetermination: in the face of conflicting data, it is unclear whether researchers should reject the target hypothesis or revise it (an instance of holistic underdetermination).

3.4 Signatures and Dimensions
One way to overcome problems of underdetermination is to provide additional constraints on hypothesis construction and evaluation. There have been several recent proposals in the literature on how to do this. For example, Alex Taylor and colleagues argue that comparative cognition researchers are currently too focused on whether animals succeed at a particular experimental task (Taylor, Bastos, et al. 2022). In their view, the problem with this approach is that it fails to adequately constrain the hypothesis space—there are simply too many plausible hypotheses that could account for such success. Given this, researchers should instead seek to identify

the full range of information processing patterns including errors, limits, and biases (whether neutral, adaptive, or maladaptive) shown by an agent, so as to constrain the cognitive hypothesis space effectively. (Taylor, Bastos, et al. 2022: 3)

Taylor and colleagues refer to this as “signature testing” (in contrast to “success testing”). A “signature” is any pattern of evidence that constrains the hypothesis space with respect to a phenomenon of interest (it can be weakly or strongly diagnostic depending on how much it constrains the hypothesis space). A successful hypothesis should be able to account for all signatures of a cognitive process, not just an animal’s successful performance on an experimental task.

Starzak and Gray (2021) similarly urge researchers to develop more fine-grained accounts of how to conceptualize cognitive phenomena. For example, with respect to the cognitive phenomenon of causal understanding, they write:

in thinking about the nature of causal understanding we should think about the extent to which organisms can differ with respect to the kind of information they can pick up; with respect to the different sources of causal information they can exploit; with respect to the way they can process this information and integrate different types of information or information stemming from different sources; and with respect to the flexibility with which they can use this information to guide behavior. (2021: 9)

Like signature testing, this multidimensional approach is more nuanced than asking whether an animal “has causal understanding” tout court. It also helps address the issue that associative learning and complex cognition are not necessarily mutually exclusive (section 2.2). Rather than asking whether an experimental result is best explained by appealing to associative learning or causal understanding, one can appeal to both accounts: associative learning might explain how causal information is acquired in some cases and cognitive models might explain how causal information is integrated. Researchers have advocated for a similar multidimensional approach in the context of work on behavioral innovation (Brown 2022) and animal consciousness (Birch, Schnell, & Clayton 2020, see section on consciousness in entry on animal cognition). The upshot is that a more fine-grained approach to cognition and behavior may help constrain the hypothesis space in such a way that avoids major problems of underdetermination.

3.5 Reproducibility
In psychology, reproducibility and replication typically refer to redoing an experiment to assess its reliability. If a study is reliable, then running the study again should produce the same results. If a replication fails, then this may mean that the original result was a product of measurement error, sampling error, imprecise manipulation, questionable research practices, or other factors (for an overview, see Romero (2019) and the entry on reproducibility of scientific results). Efforts to replicate studies have increased over the past two decades across a wide range of fields, including medicine, computer science, and psychology (Bohannon 2014). This has led to what some describe as a “replication crisis” because a surprising number of studies have failed to replicate. For example, an effort to replicate 100 studies by 270 psychologists as part of the Open Science Collaboration found that only 38% of the original results were reproduced unambiguously, with some attempted replications finding an effect opposite to that of the original study (Bohannon 2015). Findings such as these have led researchers to ask whether comparative cognition also suffers from a replication crisis, and if so, what can be done to improve the field (Brecht et al. 2021). In a recent survey, for example, comparative cognition researchers were asked their views on replications (Farrar, Ostojić, & Clayton 2021). Out of 210 respondents, the majority agreed (34.8%) or strongly agreed (54.8%) that replications are important to perform in animal cognition research. The majority also disagreed (55.5%) or strongly disagreed (23.6%) that enough replications were already performed in the field.

Despite the above survey results, comparative cognition has been described as “an absolute beacon for replication efforts” (Beran 2018: 2). Beran (2018) notes that a standard in the field has been to conduct a series of experiments with the first experiment consisting of a replication of the study that inspired the work and subsequent experiments dedicated to extending that experiment (2018: 2). Halina (2021a) also argues that replications in comparative cognition are common. She adopts Edouard Machery’s resampling account of replication (Machery 2020), showing how under this view successful replications occur frequently in areas such as chimpanzee theory of mind research. If replication success were a clear indicator of reliability, then this would be good news for comparative cognition. The picture is however complicated by several factors. First, failed replications are difficult to interpret. Often a replication study will differ from the original study in several respects: in such cases, it is possible to attribute failure to these differences (what Colaço, Bickle, and Walters (2022) refer to as “mismatch explanations”). In chimpanzee theory of mind research, for example, failed replications have regularly been explained by appealing to changes in the experimental setting (Halina 2021a). As we saw in section 3.3, revisions to background assumptions are an important part of science. However, such revisions mean that failed replications are often not interpreted as undermining reliability (Nosek, Spies, & Motyl 2012). As Alexandria Boyle (2021) argues, for this and other reasons, replications in comparative cognition are

poorly placed to deliver clear judgments about the reliability of comparative cognition’s methods or its scientific bona fides. (2021: 296, see also Feest 2019)

Another factor complicating the picture is the “file-drawer problem”, which refers to the phenomenon that studies that fail to find statistically significant results may be relegated to the file drawer (i.e., not published or communicated to the larger scientific community). In the survey cited above, comparative cognition researchers were also asked “What percent of the studies that you have performed have been published and/or you think will be published?” (Farrar, Ostojić, & Clayton 2021). The median response was 80% with a large spread (out of 210 responses, 23 said that they published 50% or fewer of their studies, while 17 reported publishing all their studies). Twenty-nine respondents cited negative or uninteresting results as the reason for not publishing (2021: 18). The file-drawer problem combined with mismatch explanations of failed replications may create an impression of reliability via the reporting of many successful replications when in fact the record is mixed.

If replications on their own are not a route to more robust research, what else could help? Beran (2018) emphasizes the importance of pre-registration. Pre-registration involves publishing the methods and statistical analyses that one will use in a study before data collection. This prevents one from adjusting or “massaging” elements of the experimental design and data analyses with the aim of getting a positive result. Farrar, Voudouris, and Clayton (2021) also advance several methods that comparative cognition researchers could use to assess the reliability of small sample research, such as statistically modeling variation. More broadly, Felipe Romero (2020) argues that major changes to scientific incentive structures are needed: in particular, a shift away from rewarding novelty and towards rewarding replication and confirmation work. Along these lines, Brecht et al. (2021) note that while there are still many disincentives to conducting replication studies in comparative cognition, the field is working towards improving this. For example, the journal Animal Behavior and Cognition has committed to publishing pre-registered studies (including replications) regardless of the results. In addition, several new global consortiums (such as ManyPrimates, ManyBirds, and ManyDogs) have formed with the explicit aim of assessing reliability, encouraging transparency, supporting large collaborations, and fostering other open science practices (see Other Internet Resources).

4. Comparative Cognition and AI
There has been a large amount of collaborative work between comparative cognition and artificial intelligence (AI) research over the past decade. On the one hand, formal models developed in AI can be used to predict and explain animal behavior in ways that move beyond folk psychological accounts. On the other hand, the methods of comparative cognition are well placed to inform AI research, given the diversity of behavior and information-processing abilities found across the tree of life. We’ll consider both aspects here, while also highlighting why animal-AI inferences should be handled with care.

Colin Allen (2014) argues that comparative cognition would benefit greatly from developing mathematically rigorous formal models. As we have seen throughout this entry, comparative cognition researchers often rely on intuitive, natural language concepts for constructing accounts of animal minds like causal reasoning, mental time travel, imagination, and self-recognition (see Schnell et al. 2021b). Regarding this approach Allen (2014) writes:

The conceptual framework guiding most work in comparative animal cognition (whether by ethologists or psychologists) is insufficiently formalized to support rigorous science in the long run. (2014: 82)

One concern with more formal approaches, however, is that they will fail to “scale up” to predict and explain the behavioral phenomenon that are of interest to many comparative cognition researchers, such as natural social and physical interactions. Work in AI is starting to show that there are ways of closing this gap, however. For example, Peter Battaglia and colleagues advance a formalized mental model in the form of an “intuitive physics engine” (IPE) analogous to the machine physics engines used in interactive video games (Battaglia, Hamrick, & Tenenbaum. 2013, see also Ullman et al. 2017). The IPE is probabilistic and oversimplifies the nature of objects, such as their geometry and mass density distribution, but has been developed to explain how people quickly make inferences about physical scenes in a dynamic and noisy world. Battaglia and colleagues found that this formal model does indeed capture people’s intuitions and prediction about physical scenes (such as “will this tower of blocks fall?”) across a wide range of complex and novel scenarios. Moreover, the model captures not just successful predictions, but also other signatures of human judgment like illusions and biases (see section 3.4).

The above work uses AI to explain human cognition and behavior. However, such methods are also being applied to nonhuman animals. For example, much of contemporary AI depends on the tools of reinforcement learning (RL). These techniques involve linking states of the environment and an agent’s actions in such a way that allows the agent to maximize future rewards. The tools of RL were originally inspired by animal learning research (Hassabis et al. 2017); however, they have since been developed by AI researchers in ways that allow fresh insights into animal behavior. For example, the temporal-difference (TD) model has been used to explain a wide range of results from animal classical conditioning studies (see Sutton & Barto 1998: chapter 14). Similarly, Buckner (2018) draws on work on Deep Convolutional Neural Networks (DCNNs) to explain the relationship between sensory experience and representations of abstract categories in humans and animals—a longstanding question in philosophy of mind. Halina (2021b) also shows how one can understand aspects of animal insightful problem solving (namely, mental scenario building) through Monte Carlo tree search. Finally, Bohn et al. (2022) advance a Bayesian computational model of great ape communication, which they show accurately predicts the communicative interactions of real-world chimpanzees living semi-wild in the Chimfunshi Wildlife Orphanage in Zambia. These are a few examples of researchers drawing on AI for formal models that can be successfully applied to capture animal minds and behavior (see also van der Vaart et al. 2012).

A major aim of AI research has been to build machines that “learn and think like people” (Lake et al. 2017). Currently, there are many AI systems that match or exceed humans on various tasks, like the ability to play Chess and Go, and even make scientific discoveries (Shevlin et al. 2019). However, how to build a machine with domain-general intelligence or “common sense” remains elusive. This challenge has led some researchers to argue that animal cognition research offers the best path towards building thinking machines. Animals exhibit many of the “building blocks” of human common sense, such as an understanding of objects and their affordances, space, and causality (Shanahan et al. 2020). Through the application of RL techniques, it is also possible to train artificial agents in 3D virtual environments analogous to the real world. Using this approach, one can combine different RL architectures and training environments with the aim of encouraging the development of domain-general abilities. As Murray Shanahan and colleagues write,

animal cognition supplies a compendium of well understood, nonlinguistic, intelligent behaviour; it suggests experimental methods for evaluation and benchmarking; and it can guide environment and task design. (2020: 863; see also Crosby 2020)

Work such as this is already underway. For example, the Animal-AI Testbed applies experimental protocols developed in comparative cognition to test AI (Crosby, Beyret, & Halina 2019; Crosby, Beyret et al. 2020). In 2019, the testbed included 300 tasks grouped into 12 categories such as spatial elimination, delayed gratification, numerosity, and tool use tasks. Konstantinos Voudouris and colleagues (2022) compared AI performance on this testbed with children aged 6–10. They found that children and AIs performed similarly on basic navigational tasks, but that children outperformed AIs on more complex tasks like object permanence and detour tasks.

There is much to be gained from animal-AI comparisons. Such work may represent the beginning of a transformation in the field of comparative cognition—one that brings artificial systems into the fold. It may also lead to the development of cognitive models that bridge the gap between intuitive accounts of capacities like imagination and causal reasoning on the one hand, and mathematical and computational models on the other. However, when applying “rich psychological concepts” like awareness, episodic memory, and theory of mind to AI, one should also proceed with caution (Shevlin & Halina 2019). Some such concepts have normative dimensions, for example, indicating a potential moral agent or moral patient. These normative dimensions are important to acknowledge before adopting a term in the context of AI, particularly if that term is used differently in the two contexts. AI findings may also dramatically alter our understanding of some cognitive capacities. Rather than adopting existing cognitive concepts, it may be fruitful in some cases to develop a radically new approach in the context of AI. If successful, such an approach could then be imported into comparative cognition and potentially revolutionize our understanding of animal minds.

1. Motivations
There are many reasons for philosophical interest in nonhuman animal (hereafter “animal”) consciousness:

First, if philosophy often begins with questions about the place of humans in nature, one way humans have attempted to locate themselves is by comparison and contrast with those things in nature most similar to themselves, i.e., other animals. At least in the West, the traditional — and perhaps still intuitive to many people — way of thinking about consciousness is as primarily an innate endowment of humans, which other animals may or may not share in virtue of being sufficiently like us. Within the traditional Biblical cosmology, while all animals were said to have arisen through divine intentional creation, humans were the only ones created in the likeness of the deity, and thus enjoyed a special, privileged role in the intended workings of the cosmos — including, for example, access to an eternal afterlife not overpopulated with fleas, ants and snails. (See Lewis, 2009 Ch 9 for an in-depth treatment of the problem of animal consciousness in relation to Christian theology.) However, within a modern biological worldview, while humans may be unique in certain (perhaps quite important) respects, we are only one species of animal among many — one tip of one branch of the phylogenetic tree of life, and enjoy no particular special status.

From an evolutionary perspective, consciousness is a trait that some animals have (at least humans have it). Salient questions include: Is it a late evolved, narrowly distributed trait, or an older more broadly shared trait? And, did it evolve only once, or a number of times independently? From this view point, the question “Are (non-human) animals conscious?” is rather strange, because, for example, it implicitly groups bats together with rabbits (as ‘nonhuman’ animals) in contrast to humans. In reality, rabbits are more closely related to humans than they are to bats (Nishihara et al. 2006), so framing the question this way embeds a false presupposition. Of course, it is consistent with an evolutionary perspective that humans are the only conscious animals. This would imply that consciousness was acquired through a recent evolutionary event that occurred since the split of our ancestral lineage from that of our closest non-human relatives, chimpanzees and bonobos (see section 6 for discussion of such hypotheses). But such a view requires support; though perhaps intuitive to some, its choice as a default position is arbitrary.

Second, there is a lot at stake morally in the question of whether animals are conscious beings or “mindless automata”. (See article on the Moral Status of Animals.) Many billions of animals are slaughtered every year for food, use in research, and other human purposes. Moreover, before their deaths, many — perhaps most — of these animals are subject to conditions of life that, if they are in fact experienced by the animals in anything like the way a human would experience them, amount to cruelty. Arguments that non-human animals are not conscious therefore effectively double as apologetics for our treatment of animals. When the question of animal consciousness is under consideration, our guilt or innocence as a civilization for an enormous body of cruelty may hang in the balance. However, some philosophers have argued that consciousness per se does not matter for the treatment of animals, and therefore either that a) even if animals are not conscious, they may deserve moral consideration, or b) even if animals are conscious, they may not deserve moral consideration. (For more discussion of the ethical issues, see Singer 1990 [1975]; Regan 1983; Rollin 1989; Varner 1998, 2012; Steiner 2008.)

Third, while theories of consciousness are frequently developed without special regard to questions about animal consciousness, the plausibility of such theories has sometimes been assessed against the results of their application to animal consciousness (and, similarly, to human infants). This raises questions about the relative epistemic weight of theoretical considerations (e.g. philosophical arguments for a given theory of consciousness) against particular case judgments or intuitions about whether a given creature is conscious. For example, Searle (1998) argues that our intuitive, commonsense attributions of intentional and emotional states to dogs carries more epistemic weight than philosophically motivated skeptical concerns. In contrast, Carruthers (1989) asserts that his own arguments that nonhuman animals (even dogs) lack consciousness are sufficiently weighty that we are morally obligated to eradicate or ignore our sympathetic feelings toward such creatures. Should our theories of consciousness be constrained by our intuitive attributions of consciousness to animals (or, e.g., babies), or should the former override the latter?

Fourth, the problem of determining whether animals are conscious stretches the limits of knowledge and scientific methodology (beyond the breaking point, according to some). The so-called “cognitive revolution” that took place during the latter half of the 20th century has led to many innovative experiments by comparative psychologists and ethologists probing the cognitive capacities of animals. The philosophical issues surrounding the interpretation of experiments to investigate perception, learning, categorization, memory, spatial cognition, numerosity, communication, language, social cognition, theory of mind, causal reasoning, and metacognition in animals are discussed in the entry on animal cognition. Despite this work on cognition, the topic of consciousness per se in animals has remained controversial, even taboo, among many scientists, while other scientists from a variety of disciplinary backgrounds (e.g. neuroscience, animal behavior, evolutionary biology) have developed novel ways of approaching the subject (see Boly et al. 2013 for a review). The 2012 Cambridge Declaration on Animal Consciousness indicates that many scientists agree that “the weight of evidence indicates that humans are not unique in possessing the neurological substrates that generate consciousness.” However, other scientists, including Marian Stamp Dawkins, who has been prominent in the science of animal welfare (Dawkins 1985, 1993), are not ready to endorse the claim, writing that, “The mystery of consciousness remains. The explanatory gap is as wide as ever and all the wanting in the world will not take us across it” (Dawkins 2012, pp. 171–172).

Many philosophers and scientists have either argued or assumed that consciousness is inherently private, and hence that one’s own experience is unknowable to others. While language may allow humans to cross this supposed gap by communicating their experience to others, this is allegedly not possible for other animals. Despite the controversy in philosophical and scientific circles, it remains a matter of common sense to most people that some animals do have conscious experiences. Most people, if asked why they think familiar animals such as their pets are conscious, would point to similarities between the behavior of those animals and human behavior — for example, animals seem to visibly express pleasure and displeasure and a variety of emotions, their behavior seems to be motivated by seeking food, comfort, social contact, etc., they seem aware of their surroundings and able to learn from experience. Similarity arguments for animal consciousness thus have roots in common sense observations. But they may also be bolstered by scientific investigations of behavior and the comparative study of brain anatomy and physiology, as well as considerations of evolutionary continuity between species. Neurological similarities between humans and other animals have been taken to suggest commonality of conscious experience; all mammals share the same basic brain anatomy, and much is shared with vertebrates more generally. Even structurally different brains may be neurodynamically similar in ways that enable inferences about animal consciousness to be drawn (Seth et al. 2005).

As well as generic arguments about the connections among consciousness, neural activity, and behavior, a considerable amount of scientific research directed towards understanding particular conscious states uses animals as proxies for humans. The reactions of many animals, particularly other mammals, to bodily events that humans would report as painful are easily and automatically recognized by most people as pain responses. High-pitched vocalizations, fear responses, nursing of injuries, and learned avoidance are among the responses to noxious stimuli that are all part of the common mammalian heritage, and similar responses are also observable in organisms from a wide range of taxonomic groups (see section 7.1 below).

Much of the research that is of direct relevance to the treatment of human pain, including on the efficacy of analgesics and anesthetics, is conducted on rats and other animals. The validity of this research depends on the similar mechanisms involved[1] and to many it seems arbitrary to deny that injured rats, who respond well to opiates for example, feel pain.[2] Likewise, much of the basic research that is of direct relevance to understanding human visual consciousness has been conducted on the very similar visual systems of monkeys. Monkeys whose primary visual cortex is damaged even show impairments analogous to those of human blindsight patients (Stoerig & Cowey 1997) suggesting that the visual consciousness of intact monkeys is similar to that of intact humans. Scientific demonstrations that members of other species, even of other phyla, are susceptible to the same visual illusions as we are (e.g., Fujita et al. 1991) suggesting that their visual experiences are similar.

It is often argued that the use of animals to model neuropsychiatric disorders presupposes convergence of emotional and other conscious states and further refinements of those models may strengthen the argument for attributing such states to animals. An interesting reversal of the modeling relationship can be found in the work of Temple Grandin, Professor of Animal Science at Colorado State University, who uses her experience as a so-called “high-functioning autistic” as the basis for her understanding of the nature of animal experience (Grandin 1995, 2004).

Such similarity arguments are, of course, inherently limited in that it is always open to critics to exploit some disanalogy between animals and humans to argue that the similarities don’t entail the conclusion that both are sentient. Even when bolstered by evolutionary considerations of continuity between the species, the arguments are vulnerable, for the mere fact that humans have a trait does not entail that our closest relatives must have that trait too. There is no inconsistency with evolutionary continuity to maintain that only humans have the capacity to learn to play chess. Likewise for consciousness. Povinelli & Giambrone (2000) also argue that the argument from analogy fails because superficial observation of quite similar behaviors even in closely related species does not guarantee that the underlying cognitive principles are the same, a point that Povinelli believes is demonstrated by his research into how chimpanzees use cues to track visual attention (Povinelli 1996).

Perhaps a combination of behavioral, physiological and morphological similarities with evolutionary theory amounts to a stronger overall case[3]. However, a convincing argument will likely also require motivation in terms of a well developed theory of the structure and function of consciousness as a cognitive process — a route that many recent participants in the debate on animal consciousness have pursued (see section 6).

2. Concepts of Consciousness
The term “consciousness” is notoriously ambiguous and difficult to define. Having origins in folk psychology, “consciousness” has a multitude of uses that may not be resolvable into a single, coherent concept (Wilkes 1984). Nevertheless, several useful distinctions among different notions of consciousness have been made, and with the help of these distinctions it is possible to gain some clarity on the important questions that remain about animal consciousness.

Two ordinary senses of consciousness which are not in dispute when applied to animals are the sense of consciousness involved when a creature is awake rather than asleep[4], or in a coma, and the sense of consciousness implicated in the basic ability of organisms to perceive and thereby respond to selected features of their environments, thus making them conscious or aware of those features. Consciousness in both these senses is identifiable in organisms belonging to a wide variety of taxonomic groups (see, e.g., Mather 2008).

A third, more technical notion of consciousness, access consciousness, has been introduced by Block (1995) to capture the sense in which mental representations may be poised for use in rational control of action or speech. This “dispositional” account of access consciousness — the idea that the representational content is available for other systems to use — is amended by Block (2005) to include an occurrent aspect in which the content is “broadcast” in a “global workspace” (Baars 1997) which is then available for higher cognitive processing tasks such as categorization, reasoning, planning, and voluntary direction of attention. Block believes that many animals possess access consciousness (speech is not a requirement). Indeed, some of the neurological evidence cited by Block (2005) in support of the global workspace is derived from monkeys. But clearly an author such as Descartes, who, we will see, denied speech, language, and rationality to animals, would also deny access consciousness to them. Those who follow Davidson (1975) in denying intentional states to animals would likely concur.

There are two remaining senses of consciousness that cause more controversy when applied to animals: phenomenal consciousness and self-consciousness.

Phenomenal consciousness refers to the qualitative, subjective, experiential, or phenomenological aspects of conscious experience, sometimes identified with qualia. (In this article we also use the term “sentience” to refer to phenomenal consciousness.) To contemplate animal consciousness in this sense is to consider the possibility that, in Nagel’s (1974) phrase, there might be “something it is like” to be a member of another species. Nagel disputes our capacity to know, imagine, or describe in scientific (objective) terms what it is like to be a bat, but he assumes that there is something it is like.

For many authors, Nagel’s formulation of phenomenal consciousness as “what it’s like” serves as a reference point for what’s at stake in the debate on animal consciousness — in investigating whether a group of animals are conscious, the crucial question is whether there is ‘something it is like’ to be those animals, i.e. whether there is a subjective experience of life or being for them, a proprietary perspective that individuals have on their own perceptual, cognitive and emotive processes.

Though some authors (including Nagel himself) have argued that the very subjectivity of phenomenal consciousness makes it exceedingly difficult or even impossible to investigate scientifically, particularly in other species, others have proceeded by developing structural and/or functional theories of consciousness, and using these to argue for a particular hypothesis about the distribution of consciousness among animals. Such theories will be discussed below, in sections 5 and 6.

Self-consciousness refers to a subject’s awareness of itself, but is also a notoriously ambiguous term — there are importantly distinct senses in which a subject can be self-aware (see for example the SEP article on Phenomenological Approaches to Self-Consciousness). These include: an awareness of one’s body as a physical object, or as the medium of one’s own perception and action (i.e. bodily self-awareness); awareness of one’s own mental states (i.e. mental or experiential self-awareness); awareness of one-self as perceived by others, or as a member of a social group such as a family, team, or institution (i.e. social self-awareness); awareness of one-self as a persistent character in the narratives told by oneself and others (i.e. narrative self-awareness). This list is far from exhaustive, and further, each listed notion is subject to further disambiguation. Hence, although on many theories self-consciousness is tightly related to phenomenal consciousness, proposals to this effect can vary greatly in their meaning and their implications for which animals might be conscious.

The remainder of this article deals primarily with the attribution of consciousness in its phenomenal sense to animals, although there will be some discussion of access consciousness, self-consciousness and theory of mind in animals, especially where these have been related theoretically to phenomenal consciousness — as, for instance, in Carruthers’ (1998a,b, 2000) argument that a particular sort of mental self-representation is required for phenomenal consciousness.

3. Historical Background
Questions about animal consciousness in the Western tradition have their roots in ancient discussions about the nature of human beings, as filtered through the “modern” philosophy of Descartes. It would be anachronistic to read ideas about consciousness from today back into the ancient literature. Nevertheless, because consciousness is sometimes thought to be a uniquely human mental phenomenon, it is important to understand the origins of the idea that humans are qualitatively (and “qualia-tatively”) different from animals.

Aristotle asserted that only humans had rational souls, while the locomotive souls shared by all animals, human and nonhuman, endowed animals with instincts suited to their successful reproduction and survival. Sorabji (1993) argues that the denial of reason to animals created a crisis for Greek thought, requiring a “wholesale reanalysis” (p. 7) of the nature of mental capacities, and a revision in thinking about “man and his place in nature above the animals” (ibid.). The argument about what is reasoning, and whether animals display it, remains with us 25 centuries later, as evidenced by the volume Rational Animals? (Hurley & Nudds 2006). The Great Chain of Being derived from early Christian interpretation of Aristotle’s scale of nature (Lovejoy 1936) provides another Aristotelian influence on the debate about animal minds.

Two millennia after Aristotle, Descartes’ mechanistic philosophy introduced the idea of a reflex to explain the behavior of nonhuman animals. Although his conception of animals treated them as reflex-driven machines, with no intellectual capacities, it is important to recognize that he took mechanistic explanation to be perfectly adequate for explaining sensation and perception — aspects of animal behavior that are nowadays often associated with consciousness. He drew the line only at rational thought and understanding. Given the Aristotelian division between instinct and reason and the Cartesian distinction between mechanical reflex and rational thought, it’s tempting to map the one distinction onto the other. Nevertheless, it may be a mistake to assimilate the two. First, a number of authors before and after Darwin have believed that conscious experience can accompany instinctive and reflexive actions. Second, the dependence of phenomenal consciousness on rational, self-reflective thought is a particularly strong and contentious claim (although it has current defenders, discussed below).

Although the roots of careful observation and experimentation of the natural world go back to ancient times, study of animal behavior remained largely anecdotal until long after the scientific revolution. Animals were, of course, widely used in pursuit of answers to anatomical, physiological, and embryological questions. Vivisection was carried out by such ancient luminaries as Galen and there was a resurgence of the practice in early modern times (Bertoloni Meli 2012). Descartes himself practiced and advocated vivisection (Descartes, Letter to Plempius, Feb 15 1638), and wrote in correspondence that the mechanical understanding of animals absolved people of any guilt for killing and eating animals. Mechanists who followed him (e.g. Malebranche) used Descartes’ denial of reason and a soul to animals as a rationale for their belief that animals were incapable of suffering or emotion, and did not deserve moral consideration — justifying vivisection and other brutal treatment (see Olson 1990, p. 39–40, for support of this claim). The idea that animal behavior is purely reflexive may also have served to diminish interest in treating behavior as a target of careful study in its own right.

A few glimmers of experimental approaches to animal behavior can be seen in the late 18th century (e.g., Barrington 1773; White 1789), and soon thereafter Frédéric Cuvier worked from 1804 until his death in 1838 on the development of sexual and social behavior in captive mammals. By the mid 19th century Alfred Russel Wallace (1867) was arguing explicitly for an experimental approach to animal behavior, and Douglas Spalding’s (1872) experiments on instinctual feeding behaviors in chicks were seminal. Still, the emergence of experimental approaches had very little to say about consciousness per se, though Spalding’s work can be seen as a contribution to the discussion about instinct and reason.

In the same vein of instinct vs. reason, Darwin in the Origin of Species wrote, “It is a significant fact, that the more the habits of any particular animal are studied by a naturalist, the more he attributes to reason, and the less to unlearnt instinct” (1871, Book I, p.46). He devoted considerable attention in both the Origin and in the Descent of Man to animal behavior, with the obvious goal of demonstrating mental continuity among the species. To make his case, Darwin relied heavily on anecdotes provided by his correspondents — a project infamously pursued after Darwin’s death by his protégé George Romanes (1882). Darwin also carried out experiments and was a keen observer, however. In his final work he describes experiments on the flexibility of earthworm behavior in manipulating leaves, which he took to show considerable intelligence (Darwin 1881; see also Crist 2002).

The idea of behavioral flexibility is central to discussions of animal mind and consciousness. Descartes’ conception of animals as automata seems to make phenomenal consciousness superfluous at best — a connection whose philosophical development was traced by T.H. Huxley (1874). Huxley reported a series of experiments on a frog, showing very similar reflexive behavior even when its spinal cord had been severed, or large portions of its brain removed. He argued that without a brain, the frog could not be conscious, but since it could still do the same sort of things that it could do before, there is no need to assume consciousness even in the presence of the entire brain, going on to argue that consciousness is superfluous. (The argument is somewhat curious since it seems to show too much by making the brain itself superfluous to the frog’s behavior!)

Still, for those (including Huxley) who became quickly convinced of the correctness of Darwin’s theory of evolution, understanding and defending mental continuity between humans and animals loomed large. In his Principles of Psychology (1890), William James promoted the idea of differing intensities of conscious experience across the animal kingdom, an idea that was echoed by the leading British psychologist of his day, Conwy Lloyd Morgan in his 1894 textbook An Introduction to Comparative Psychology. Morgan had been very skeptical and critical of the anecdotal approach favored by Darwin and Romanes, but he came around to the Darwinian point of view about mental continuity if not about methodology. To address the methodological deficit he introduced his “double inductive” method for understanding the mental states of animals (Morgan 1894). The double induction consisted of inductive inferences based on observation of animal behavior combined with introspective knowledge of our own minds. At the same time, to counteract the anthropomorphic bias in the double inductive method, Lloyd Morgan introduced a principle now known as Morgan’s canon: “in no case may we interpret an action as the outcome of the exercise of a higher psychical faculty, if it can be interpreted as the outcome of the exercise of one which stands lower in the psychological scale” (Lloyd Morgan 1894, p.53).

double-induction
Lloyd Morgan’s Double Induction Method from his 1894 textbook

Even though the double inductive method is now mainly of historical interest, Morgan’s canon lives on. Questions about quite what the canon means and how to justify it are active topics of historical and philosophical investigation (e.g., Burghardt 1985; Sober 1998, 2005, 2012; Radick 2000; Thomas 2001 (Other Internet Resources), Fitzpatrick 2008). The questions include what Lloyd Morgan means by ‘higher’ and ‘lower’, to what extent the principle can or should be justified by evolutionary considerations, and whether the canon collapses to a principle of parsimony, a version of Ockham’s razor, or some general principles of empirical justification. Despite current uncertainty about what it really means, Morgan’s canon, interpreted (or, perhaps, misinterpreted; Thomas 2001, Other Internet Resources) as a strong parsimony principle, served a central rhetorical role for behavioristic psychologists, who sought to eliminate any hint of Cartesian dualism from comparative psychology.

Behaviorism dominated American psychology in the early part of the 20th century, beginning with Thorndike’s (1911) experiments on animals learning by trial and error to escape from the “puzzle boxes” that he had constructed. But even Thorndike’s famous “law of effect” refers to the animal’s “satisfaction or discomfort” (1911, p.244). It was with the radical anti-mentalism of John B. Watson (1928) and B.F. Skinner (1953), both of whom strongly rejected any attempts to explain animal behavior in terms of unobservable mental states, that American psychology became the science of behavior rather than, as the dictionary would have it, the science of mind and behavior.

At the same time, things were progressing rather differently in Europe, where ethological approaches to animal behavior were more dominant. Ethology is part natural history with an emphasis on fieldwork and part experimental science conducted on captive animals, reflecting the different styles of its two seminal figures, Konrad Lorenz and Niko Tinbergen (see Burkhardt 2005). Initially, “innate” behaviors were the central focus of Lorenz’s work. According to Lorenz, it is the investigation of innate behaviors in related species that puts the study of animal behavior on a par with other branches of evolutionary biology, and he demonstrated that it was possible to derive the phylogenetic relations among species by comparing their instinctive behavioral repertoires (Lorenz 1971a). In pursuing this direction, Lorenz and Tinbergen explicitly sought to distance ethology from the purposive, mentalistic, animal psychology of Bierens de Haan and the lack of biological concern they detected in American comparative psychology (see Brigandt 2005). Like Lloyd Morgan, the ethologists rejected Romanes anecdotal approach, but they also criticized Lloyd Morgan’s subjectivist approach.

In the 1970s, Donald Griffin, who made his reputation taking careful physical measurements to prove that bats use echolocation, made a considerable splash with his plea for a return to questions about animal minds, especially animal consciousness. Griffin (1978) coined the term “cognitive ethology” to describe this research program, which is based in naturalistic observations of animal behavior and the attempt to understand animal minds in the context of evolution. Fierce criticism of Griffin emerged both from psychologists and classically trained ethologists. Griffin emphasized behavioral flexibility and versatility as the chief source of evidence for consciousness, which he defined as “the subjective state of feeling or thinking about objects and events” (Griffin & Speck 2004, p. 6). In seeing subjectivity, at least in simple forms, as a widespread phenomenon in the animal kingdom, Griffin’s position also bears considerable resemblance to Lloyd Morgan’s. Burghardt reports that “considerable discomfort with subjectivism” (Burghardt 1985, p. 907) arose during the Dahlem conference that Griffin convened in an early discipline-building exercise (Griffin 1981). Griffin’s subjectivist position, and the suggestion that even insects such as honeybees are conscious, seemed to many scientists to represent a lamentable return to the anthropomorphic over-interpretation of anecdotes seen in Darwin and Romanes. This criticism may be partly unfair in that Griffin does not repeat the “friend-of-a-farmer” kinds of story collected by Romanes, but bases his interpretations on results from the more sophisticated scientific literature that had accumulated more than a century after Darwin (e.g., Giurfa et al. 2001). However, the charge of over-interpretation of those results may be harder to avoid. It is also important to note the role played by neurological evidence in his argument, when he concludes that the intensive search for neural correlates of consciousness has not revealed “any structure or process necessary for consciousness that is found only in human brains” (Griffin & Speck 2004). This view is widely although not universally shared by neuroscientists.

Griffin’s behavior-based methodology for studying animal consciousness has also been dismissed as anthropomorphic (see Bekoff & Allen 1997 for a survey). But such criticisms may have overestimated the dangers of anthropomorphism (Fisher 1990) and many of the critics themselves rely on claims for which there are scant scientific data (e.g., Kennedy 1992, who claims that the “sin” of anthropomorphism may be programmed into humans genetically). At the same time, other scientists, whether or not they have explicitly endorsed Griffin’s program, have sought to expand evolutionary investigation of animal consciousness to include the neurosciences and a broad range of functional considerations (e.g., Ârhem et al. 2002, and see section 6). Whatever the shortfalls of his specific proposals, Griffin played a crucial role in reintroducing explicit discussions of consciousness to the science of animal behavior and cognition, hence paving the way for modern investigations of the distribution and evolutionary origins of consciousness.

4. Epistemological and Metaphysical Issues
The topic of consciousness in nonhuman animals has been primarily of epistemological interest to philosophers of mind. Two central questions are:

Can we know which animals beside humans are conscious? (The Distribution Question)[5]
Can we know what, if anything, the experiences of animals are like? (The Phenomenological Question)
In his seminal paper “What is it like to be a bat?” Thomas Nagel (1974) simply assumes that there is something that it is like to be a bat, and focuses his attention on what he argues is the scientifically intractable problem of knowing what it is like. Nagel’s confidence in the existence of conscious bat experiences would generally be held to be the commonsense view and, as the preceding section illustrates, a view that is increasingly taken for granted by many scientists too. But, as we shall see, it is subject to challenge and there are those who would argue that the Distribution Question is just as intractable as the Phenomenological Question.

4.1 The Problem of Other Minds
The two questions might be seen as special cases — or, alternatively, as generalized versions — of the skeptical “problem of other minds” — how can one know that others have mental states that are anything like one’s own? Although there is no generally accepted solution to this problem, it is nevertheless generally ignored to good effect by psychologists, and indeed by most people, who in practice are willing to take for granted that others have mental states similar to theirs. However it is often thought that knowledge of animal minds presents special methodological difficulties. First of all, nonhuman animals cannot describe their mental states using language. Although there have been attempts to teach human-like languages to members of other species, none has reached a level of conversational ability that would solve this problem directly (see Anderson 2004 for a review). Furthermore, except for some language-related work with parrots and dolphins, such approaches are generally limited to those animals most like ourselves, particularly the great apes. But there is great interest in possible forms of consciousness in a much wider variety of species than are suitable for such research. More generally, the problem of other minds is more acute when applied to nonhuman animals because the similarities between our behavior and bodies, and those of others animals (which form the basis for ‘analogical’ solutions to the problem of other minds) are less exact. As well, the perceptual access to other minds that some have argued defuses the problem of other minds is arguably weaker regarding the minds of other animals. (Sober (2000) discusses of the problem of other minds within an evolutionary framework, and Farah 2008 provides a neuroscientist’s perspective.)

4.2 The Epistemic Status of Intuitions and Perception of Mental States
For many people it seems obvious that familiar animals such as dogs and cats have conscious mental lives that include perceptual states, motivational and hedonic states, basic emotions and social attachments. David Hume, known for championing skepticism generally, wrote that “no truth appears to me more evident, than that beasts are endow’d with thought and reason as well as men” (1888 p 176, reproduced in Jamieson 1998). Hume did not provide elaborate philosophical or empirical arguments to this effect — he thought it was clear from observation. As Searle (1998) puts it,

I do not infer that my dog is conscious, any more than, when I came into this room, I inferred that the people present are conscious. I simply respond to them as is appropriate to conscious beings. I just treat them as conscious beings and that is that.
What is the epistemic status of such pretheoretical intuitions (if that is indeed a fair way of describing them)?

Defenders of theories that deny consciousness to such animals must deny that such intuitions have any epistemic weight. For example Dennett (who argues that consciousness is unique to humans), claims that intuitive attributions of mental states are “untrustworthy”, and points out that “it is, in fact, ridiculously easy to induce powerful intuitions of not just sentience but full-blown consciousness (ripe with malevolence or curiosity) by exposing people to quite simple robots made to move in familiar mammalian ways at mammalian speeds (1995).” (Emphasis from the original.)

Carruthers (1989) acknowledges that intuitive attributions of consciousness to animals are widespread, and go hand in hand with sympathetic attitudes toward animals (e.g. wanting to prevent suffering). However, he argues that these attitudes are incorrect, and we have a moral imperative to purge or at least override them:

In the case of brutes: since their experiences, including their pains, are nonconscious ones, their pains are of no immediate moral concern... Neither the pain of the broken leg, itself, nor its further effects upon the life of the dog, have any rational claim upon our sympathy... Are we really capable of suppressing our sympathy when we see an animal (especially a cuddly one) in severe pain? Not only is it possible that this should occur — after all, the history of mankind is replete with examples of those who have eradicated all feelings of sympathy even for members of other races, by telling themselves that they are not ‘really human’ — but it is a moral imperative that it ought to. Much time and money is presently spent on alleviating the pains of brutes which ought properly to be directed toward human beings, and many are now campaigning to reduce the efficiency of modern farming methods because of the pain caused to the animals involved. If the arguments presented here have been sound, such activities are not only morally unsupportable but morally objectionable (Carruthers 1989, p. 268).
It should be noted that while Carruthers continues to argue that only humans have consciousness, he has more recently amended his ethical view, holding that animals may deserve some moral concern despite lacking consciousness (1999).

A crucial point here is how trustworthy these pretheoretic intuitions about the minds of animals are. Call Perceptualism the view that there is direct perception of (at least some) mental states of others. What this means is that, at least sometimes, when we observe another in a mental state (e.g. in joy, or in pain) their mental state is part of the content of our perception — we perceive the mental states of others. In contrast, call inferentialism the view that we perceive ‘mere behavior’ and must infer or reason to conclusions about mental states. An alternative way of framing the issues is in terms of whether or not behavior as we perceive it is laden with mental properties. According to perceptualism, we (at least sometimes) perceive states of mind in behavior — an action (e.g. walking across a room) can be perceivably angry or sad, purposeful or eager or hesitant, etc. Goals, desires, motivations, emotions, pain or pleasure, and many other mental states are manifested in modes of action — though they cannot be reduced to patterns of disposition to behave (this would amount to behaviorism), they are tightly linked to behavior by conceptual, constitutive or causal connections that ground perceptual access.

Jamieson (1998) argues for perceptualism, pointing out that our everyday practices of attributing mental states to nonhuman animals are deeply ingrained, automatic, conceptually unifying and empirically powerful. Strands of the same point of view can also be found in scientists writing about cognitive ethology and in Wittgensteinian attitudes towards questions of animal mind (e.g., Gaita 2003). Perceptualism as a theory of social cognition (e.g. empathy) in philosophy of psychology has recently been defended by Zahavi (2011) and Gallagher (2008).

The Perceptualism/Inferentialism question is critical for the deciding the epistemic value of common sense attributions of mental states to nonhuman animals. If inferentialism is true, then when I see, e.g., a dog bounding around in front of me with a toy in its mouth, wagging its tail and looking at me, then I may consider the possibility that the dog wants my attention, that it is feeling happy and playful — but this is only a hypothesis, for which I must provide a solid argument from justified premises if I am to justifiably believe it. On a perceptualist account, by contrast, I literally see (or at least, seem to see) that the dog wants my attention and feels happy and playful.

Perception is usually understood to ground defeasible epistemic warrant for belief — for example, if you look outside and it appears to be raining, you have some grounds to believe that it is raining. It is difficult to forgo this assumption without succumbing to radical global skepticism, since we base so many of our beliefs on perception. If seeming to perceive something to be the case provides defeasible epistemic warrant for believing it to be the case, than the fact the I seem to perceive a dog as being happy and playful warrants my belief that the dog is happy and playful, i.e. warrants my ascription of mental states to the dog. Given the prima facie epistemic support of seeming to perceive mental states in familiar animals like dogs, perceptualists would argue that only overwhelming evidence should overturn the common-sense, intuitive attribution of mental states to those animals. Whereas, as discussed above, Carruthers (1989) argues that because his theory denies consciousness to animals, we should strive to eradicate our intuitive attributions of consciousness, a perceptualist would respond that the evidence derived from our perceptual encounters with dogs is more convincing than his arguments (which hang on the plausibility of his higher order thought theory of consciousness; see section 6.1).

Nevertheless, even if we have perceptual access to the mental states of other humans and familiar animals like our pet dogs, there are sharp limitations to how far this will get us toward solving the general problem of animal consciousness. First of all, our perceptual access may be limited to animals that are familiar, comfortable interacting with humans, and biologically very similar to humans (i.e. mammals). It may be much harder to ‘see’ what (if anything) a spider or a squid is thinking and feeling as she goes about her business — both because these animals may express their mental states differently, and more radically because they may have a very different repertoire of mental states.

Second, as argued by Dennett, there are examples where our perceptions of mental states can be deceived — so Dennett seems to embrace perceptualism, but to hold that perceptions of mental states are particularly unreliable. However, Dennett’s favored example of the robot ‘Cog’, unlike nonhuman animals, was intentionally designed by human engineers to seem life-like, i.e., to mimic the dynamical properties of motion that trigger the perception of mindedness. Hence, there may be no more reason to fear that our seeming perceptions of mind in others are undermined by such examples than to fear that our perception of objects in space is undermined by the existence of photography — in both cases, human engineers can be characterized as having figured out ways of creating perceptual illusions. There are deep questions about how perception of bodies in motion might disclose the mental states of others — just as there are deep questions about how visual perception of objects in space is generally possible. But, pace Dennett, there is no clear reason why the existence of carefully crafted illusions undermines the general epistemic value of perception.

Third, even among scientists who are sympathetic to the idea of themselves as sensitive observers of animals with rich mental lives, there is the recognition that the scientific context requires them to provide a particular kind of empirical justification of mental state attributions. This demand requires those who would say that a tiger pacing in the zoo is “bored”, or that the hooked fish is in pain to define their terms, state empirical criteria for their application, and provide experimental or observational evidence for their claims. Even if perceptualism is a viable theory of folk practice with respect to attributing animal consciousness, it seems unlikely to make inroads against scientific epistemology.

4.3 Cognition and Consciousness
Many scientists and philosophers remain convinced that even if some questions about animal minds are empirically tractable, no amount of experimentation can provide access to phenomenal consciousness per se. This remains true even among those who are willing to invoke cognitive explanations of animal behavior that advert to internal representations. Opposition to dealing with consciousness can be understood in part as a legacy of behavioristic psychology first because of the behaviorists’ rejection of terms for unobservables unless they could be formally defined in terms of observables, or otherwise operationalized experimentally, and second because of the strong association in many behaviorists’ minds between the use of mentalistic terms and the twin bugaboos of Cartesian dualism and introspectionist psychology. In some cases these scientists are even dualists themselves, but they are strongly committed to denying the possibility of scientifically investigating consciousness, and remain skeptical of all attempts to bring it into the scientific mainstream.

Also important has been a line of argumentation by philosophers that the subjective nature of consciousness makes it inherently difficult to study. Block’s (1995) influential distinction between phenomenal and access consciousness was framed as part of a critique of treatments of consciousness in the psychological literature: by failing to properly distinguish between consciousness as experience (phenomenal consciousness) and consciousness as general availability of information (access consciousness), scientists were equivocating — drawing conclusions about consciousness in the phenomenal sense from premises about consciousness in the access sense. The conceptual distinction between access consciousness and phenomenal consciousness, and the difficulty of gaining empirical traction on the latter, has been seen as a major hurdle to empirical consciousness studies. Block himself has recently been more optimistic, even arguing that certain experiments can empirically tease apart phenomenal and access consciousness (Block 2011). But the distinction between access and phenomenal consciousness does raise special methodological hurdles for those who want to study the latter empirically.

Because consciousness is assumed to be private or subjective, it is often taken to be beyond the reach of objective scientific methods (e.g., Nagel 1974). This claim might be taken in either of two ways. On the one hand it might be taken to bear on the possibility of answering the Distribution Question, i.e., to reject the possibility of knowledge that a member of another taxonomic group (e.g., a bat) has conscious states. On the other hand it might be taken to bear on the possibility of answering the Phenomenological Question, i.e., to reject the possibility of knowledge of the phenomenological details of the mental states of a member of another taxonomic group. The difference between believing with justification that a bat is conscious and knowing what it is like to be a bat is important because, at best, the privacy of conscious experience supports a negative conclusion only about the latter. To support a negative conclusion about the former, one must also assume that consciousness has absolutely no measurable effects on behavior, i.e., one must accept epiphenomenalism. But if one rejects epiphenomenalism and maintains that consciousness does have effects on behavior then a strategy of inference to the best explanation may be used to support its attribution. Moreover, if particular conscious states have particular effects on behavior, then this strategy might be pursued to elucidate some specific features of the conscious experience of other animals, even if some aspects must remain out of reach because of our inability, as humans, to fully grasp what it would be like to experience them. More will be said about this in the next section.

If phenomenal consciousness is completely epiphenomenal, as some philosophers believe, then a search for the functions of consciousness is doomed to futility. In fact, if consciousness is completely epiphenomenal then it cannot have evolved by natural selection. On the assumption that phenomenal consciousness is an evolved characteristic of human minds, at least, and therefore that epiphenomenalism is false, then an attempt to understand the biological functions of consciousness may provide the best chance of identifying its occurrence in different species. (See Robinson 2007 for more discussion of this issue.)

4.4 Dualism and Physicalism
While epistemological and related methodological issues have been at the forefront of discussions about animal consciousness, philosophical attention to consciousness in the analytic tradition over the last several decades has focused on metaphysical questions about the nature of phenomenal consciousness and its fit (or lack thereof) within a naturalistic framework.

One might think that the question of what consciousness is (metaphysically) should be settled prior to tackling the Distribution Question — that ontology should drive the epistemology. However, the metaphysical questions that have occupied analytic philosophers over the last few decades are largely orthogonal to the distribution problem, which depends more on questions about the structure and function of consciousness, discussed below.

The traditional ‘Mind Body Problem’ concerns the metaphysical status of mind in relation to the physical world (see SEP article on dualism). Dualists argue that the mental and physical are fundamentally distinct, whereas physicalists hold that the mind is physical — and therefore not distinct, despite supposed appearances to the contrary. A third alternative is idealism, the view that the physical world is actually mental (and therefore that the two are not really distinct).

Dualistic theories of consciousness typically deny that it can be accounted for in the current terms of the natural sciences. Traditional dualists may argue that the reduction of consciousness to physically describable mechanisms is impossible on any concept of the physical. Others may hold that consciousness is an as-yet-undescribed fundamental constituent of the physical universe, not reducible to any known physical principles. Such accounts of consciousness (with the possible exception of those based in anthropocentric theology) provide no principled reasons, however, for doubting that animals are conscious.

Cartesian dualism is, of course, traditionally associated with the view that animals lack minds. Descartes’ argument for this view was not based, however, on any ontological principles, but upon what he took to be the failure of animals to use language rationally, or to reason generally. On this basis he claimed that nothing in animal behavior requires a non-mechanistic, mental explanation; hence he saw no reason to attribute possession of mind to animals. In a sense, therefore, the Cartesian argument for the human-uniqueness of consciousness rests on the premise that material processes are insufficient to account for human capacities for language, rationality, and self-awareness (i.e. the awareness of oneself as, putatively, an essentially thinking thing) — and hence a non-material soul was posited to account for these phenomena. Few today would hold that material processes are incapable of producing complex phenomena such as language and rationality, and indeed our understanding of ‘the material’ has changed dramatically since Descartes’ time. However, the subjective nature of consciousness continues to motivate some authors to argue that mental phenomena cannot be reduced to physical phenomena.

There is no conceptual reason why animal bodies are any less suitable vehicles for embodying a Cartesian soul, or any other of the putatively non-physical aspects of mind posited by proponents of dualism, than are human bodies. Hence, dualism does not preclude animal minds as a matter of conceptual necessity. The distribution of consciousness is a matter of empirical contingency on dualist theories as for physicalist theories. For some dualists, this may come down to whether or not the animals in question possess specific cognitive capacities, although others may argue that the non-physical nature of the mental makes it difficult or impossible to investigate empirically.

Early physicalist accounts of consciousness explored the philosophical consequences of identifying consciousness with unspecified physical or physiological properties of neurons. In this generic form, such theories do not provide any particular obstacles to attributing consciousness to animals, given that animals and humans are built upon the same biological, chemical, and physical principles. If it could be determined that phenomenal consciousness was identical to (or at least perfectly correlated with) some general property such as quantum coherence in the microtubules of neurons, or brain waves of a specific frequency, then settling the Distribution Question would be a straightforward matter of establishing whether or not members of other species possess the specified properties. Searle (1998) too, although he rejects the physicalist/dualist dialectic, also suggests that settling the Distribution Question for hard cases like insects will become trivial once neuroscientists have carried out the non-trivial task of determining the physiological basis of consciousness in animals for which no reasonable doubt of their consciousness can be entertained (i.e., mammals).

4.5 Neurofunctional Accounts
Some philosophers have sought more specific grounding in the neurosciences for their accounts of consciousness. Block (2005) pursues a strategy of using tentative functional characterizations of phenomenal and access consciousness to interpret evidence from the search by neuroscientists for neural correlates of consciousness. He argues, on the basis of evidence from both humans and monkeys, that recurrent feedback activity in sensory cortex is the most plausible candidate for being the neural correlate of phenomenal consciousness in these species. Prinz (2005) also pursues a neurofunctional account, but identifies phenomenal consciousness with a different functional role than Block. He argues for identifying phenomenal consciousness with brain processes that are involved in attention to intermediate-level perceptual representations which feed into working memory via higher level, perspective-invariant representations. Since the evidence for such processes is at least partially derived from animals, including other primates and rats, his view is supportive of the idea that phenomenal consciousness is found in some nonhuman species (presumably most mammals). Nevertheless, he maintains that it may be impossible ever to answer the Distribution Question for more distantly related species; he mentions octopus, pigeons, bees, and slugs in this context.

4.6 Representationalist Accounts
Representational theories of consciousness link phenomenal consciousness with the representational content of mental states, subject to some further functional criteria.

First-order representationalist accounts hold that if a particular state of the visual system of an organism represents some property of the world in a way that is functionally appropriate (e.g., not conceptually mediated, and operating as part of a sensory system), then the organism is phenomenally conscious of that property. First-order accounts are generally quite friendly to attributions of consciousness to animals, for it is relatively uncontroversial that animals have internal states that have the requisite functional and representational properties (insofar as mental representation itself is uncontroversial, that is). Such a view underlies Dretske’s (1995) claim that phenomenal consciousness is inseparable from a creature’s capacity to perceive and respond to features of its environment, i.e., one of the uncontroversial senses of consciousness identified above. On Dretske’s view, phenomenal consciousness is therefore very widespread in the animal kingdom. Likewise, Tye (2000) argues, based upon his first-order representational account of phenomenal consciousness, that it extends even to honeybees.

Driven by a variety of allegedly counter-intuitive consequences of first-order theories of consciousness, including skepticism about the range of organisms it spans, a number of philosophers have offered a variety of higher-order accounts of phenomenal consciousness. Such accounts invoke mental states directed towards other mental states to explain phenomenal consciousness. Carruthers’ “higher order thought” (HOT) theory is that a mental state is phenomenally conscious for a subject just in case it is available to be thought about directly by that subject (Carruthers 1998a,b, 2000). The term “available” here makes this a “dispositionalist” account. The contrast is an “actualist” account, which requires the actual occurrence of the 2nd order thought for subject to be conscious in the relevant sense. According to Carruthers, such higher-order thoughts are not possible unless a creature has a “theory of mind” to provide it with the concepts necessary for thought about mental states. Carruthers’ view is of particular interest in the current context because he has used it explicitly to deny phenomenal consciousness to (almost) all nonhuman animals.

Carruthers argues, there is little, if any, scientific support for theory of mind in nonhuman animals, even among the great apes — with the possible exception of chimpanzees — from which he concludes that there is little support either for the view that any animals possess phenomenological consciousness. Further evaluation of this argument will be taken up further below, but it is worth noting here that if (as experiments on the attribution of false beliefs suggest) young children before the age of four years typically lack a theory of mind, Carruthers’ view entails that they are not sentient either — fear of needles notwithstanding! This is a bullet Carruthers bites, although for many it constitutes a reductio of his view (a response Carruthers would certainly regard as question-begging).

In contrast to Carruthers’ higher-order thought account of sentience, other theorists such as Armstrong (1980), and Lycan (1996) have preferred a higher-order experience account, where consciousness is explained in terms of inner perception of mental states, a view that can be traced back to Aristotle, and also to John Locke. Because such models do not require the ability to conceptualize mental states, proponents of higher-order experience theories have been slightly more inclined than higher-order theorists to allow that such abilities may be found in other animals[6]. Gennaro (2004) argues, however, that a higher order thought theory is compatible with consciousness in nonhuman animals, arguing that Carruthers and others have overstated the requirements for the necessary mental concepts and that reentrant pathways in animal brains provide a structure in which higher- and lower-order representations could actually be combined into a unified conscious state.

4.7 Is Consciousness Binary?
One metaphysical question that is more directly relevant for the question of the phylogenetic distribution and evolution of consciousness is whether possessing it (i.e. being conscious) is binary (i.e. on/off, all-or-nothing), or admits of degrees. Several authors have, for quite different reasons, denied what they take to be a common but problematic assumption — that “Consciousness is an on/off switch; a system is either conscious or not,” as Searle — who endorses the thesis puts it (quoted by Lycan 1996, who denies the thesis).

Lycan argues that consciousness can come in a wide spectrum of degrees of richness or fullness of consciousness, and that there is a meaningful sense in which a system with a minimal degree of consciousness is not “really” conscious (1996, p. 8). Admittedly, this sounds a bit paradoxical, but the point seems to be that it is counter-intuitive for us to consider very low degrees of consciousness, as it is hard to imagine the contents of very simple mental states. One reading of this is that Lycan is arguing that the predicate ‘conscious’ is vague, without committing himself to the view that consciousness is distributed according to a linear scale.

Dennett (1995) also argues that consciousness is not binary. He does so in the context of advocating a radically deflationary anti-realism about consciousness overall, on which consciousness is essentially an illusion created by language (1991/1995). On his view, “the very idea of there being a dividing line between those creatures ‘it is like something to be’ and those that are ‘mere automata’ (is) an artifact of our traditional assumptions.” (1995, p. 706)

Velmans (2012) distinguishes between ‘discontinuity theories’, which claim that there was a particular point at which consciousness originated, before which there was no consciousness (this applies both the universe at large, and also to any particular consciousness individual), and ‘continuity theories’, which conceptualize the evolution of consciousness in terms of “a gradual transition in consciousness from unrecognizable to recognizable.” He argues that continuity theories are more elegant, as any discontinuity is based on arbitrary criteria, and that discontinuity theories face “the hard problem” in a way that continuity theories don’t. Velmans takes these arguments to weigh in favor of adopting, not just a continuity theory, but a form of panpsychism.

The three authors described just above deny that consciousness is binary for very different reasons, and each of their views is controversial. Further, none of them offers much in the way of tools or concepts for thinking about the putatively nonbinary nature of consciousness. Following up on Lycan’s suggestion of degrees of richness or fullness, one might ask what graded dimensions or qualitative thresholds might be available to distinguish different kinds of minds? Various authors have distinguished between ‘primary’ and ‘higher order’ consciousness (Seth et al. 2005); ‘primary’, ‘secondary’, and ‘tertiary’ consciousness (Panksepp 2005); and ‘core’ and ‘extended’ consciousness (Damasio 1999). However, most of these authors seem to correlate phenomenal consciousness, i.e. having any subjective experience at all, with primary or core consciousness. The terms “secondary” and “tertiary” are supposed to pick out elaborated forms of consciousness. Hence it is not clear that any of these taxonomies are at odds with the idea that phenomenal consciousness itself is binary — either wholly present or wholly absent for a given system. However, the issue deserves more scrutiny, as it bears on the problems of the distribution and evolutionary origins of consciousness. If consciousness is non-binary, then the distribution of consciousness will not be sharply bounded, but will include gradations — some animals may be partially or incompletely conscious.

4.8 Limits of Philosophical Theories
Phenomenal consciousness is just one feature (some would say the defining feature) of mental states or events. Any theory of animal consciousness must be understood, however, in the context of a larger investigation of animal cognition that (among philosophers) will also be concerned with issues such as intentionality (in the sense described by the 19th C. German psychologist Franz Brentano) and mental content (Dennett 1983, 1987; Allen 1992a,b).

Philosophical opinion divides over the relation of consciousness to intentionality with some philosophers maintaining that they are strictly independent, others (particularly proponents of the functionalist theories of consciousness described in this section) arguing that intentionality is necessary for consciousness, and still others arguing that consciousness is necessary for genuine intentionality. Many behavioral scientists accept cognitivist explanations of animal behavior that attribute representational states to their subjects. Yet they remain hesitant to attribute consciousness. If the representations invoked within cognitive science are intentional in Brentano’s sense, then these scientists seem committed to denying that consciousness is necessary for intentionality.

There remains great uncertainty about the metaphysics of phenomenal consciousness and its precise relations to intentionality, to the brain, to behavior, etc. It is beyond the scope of this article to survey the strong attacks that have been mounted against the various accounts of consciousness in these terms, but it is safe to say that none of them seems secure enough to hang a decisive endorsement or denial of animal consciousness upon it. Accounts of consciousness in terms of basic neurophysiological properties, the quantum-mechanical properties of neurons, or sui generis properties of the universe are just as insecure as the various functionalist accounts. And even those accounts that are compatible with animal in their general outline, are not specific enough to permit ready answers to the Distribution Question in its full generality. Hence no firm conclusions about the distribution of consciousness can be drawn on the basis of the philosophical theories of consciousness that have been discussed so far.

Where does this leave the epistemological questions about animal consciousness? While it may seem natural to think that we must have a theory of what consciousness is before we try to determine whether other animals have it, this may in fact be putting the conceptual cart before the empirical horse. In the early stages of the scientific investigation of any phenomenon, putative samples must be identified by rough rules of thumb (or working definitions) rather than complete theories. Early scientists identified gold by contingent characteristics rather than its atomic essence, knowledge of which had to await thorough investigation of many putative examples — some of which turned out to be gold and some not. Likewise, at this stage of the game, perhaps the study of animal consciousness would benefit from the identification of animal traits worthy of further investigation, with no firm commitment to idea that all these examples will involve conscious experience.

Recall the Cartesian argument that animals do not use language conversationally or reason generally. This argument, based on the alleged failure of animals to display certain intellectual capacities, is illustrative of a general pattern of using certain dissimilarities between animals and humans to argue that animals lack consciousness.

A common refrain in response to such arguments is that, in situations of partial information, “absence of evidence is not evidence of absence”. Descartes dismissed parrots vocalizing human words because he thought it was merely meaningless repetition. This judgment may have been appropriate for the few parrots he encountered, but it was not based on a systematic, scientific investigation of the capacities of parrots. Nowadays many would argue that Pepperberg’s study of the African Grey parrot “Alex” (Pepperberg 1999) should lay the Cartesian prejudice to rest. This study, along with several on the acquisition of a degree of communicative competence by chimpanzees and bonobos (e.g., Gardner et al. 1989; Savage-Rumbaugh 1996) would seem to undermine Descartes’ assertions about lack of meaningful communication and general reasoning abilities in animals. (See, also, contributions to Hurley & Nudds 2006.)

Cartesians respond by pointing out the limitations shown by animals in such studies (they can’t play a good game of chess, after all, let alone tell us what they are thinking about), and they join linguists in protesting that the subjects of animal-language studies have not fully mastered the recursive syntax of natural human languages.[7] But this kind of post hoc raising of the bar suggests to many scientists that the Cartesian position is not being held as a scientific hypothesis, but as a dogma to be defended by any means. Convinced by evidence of sophisticated cognitive abilities, most philosophers these days agree with Block that something like access consciousness is properly attributed to many animals. Nevertheless, when it comes to phenomenal consciousness, dissimilarity arguments are not entirely powerless to give some pause to defenders of animal sentience, for surely most would agree that, at some point, the dissimilarities between the capacities of humans and the members of another species (the common earthworm Lumbricus terrestris, for example) are so great that it is unlikely that such creatures are sentient. A grey area arises precisely because no one can say how much dissimilarity is enough to trigger the judgment that sentience is absent.

The aim of picking out, in a principled way, behavioral or neurophysiological characteristics that could serve as reliable indicators for consciousness motivates the structure and function oriented approach that many authors have pursued since the turn of the 21st century. Though sometimes pursued along with metaphysical questions about consciousness, this project promises empirical tractability even in the face of persistent uncertainty about the metaphysical questions of consciousness.

5. The Structure and Function of Consciousness
One strategy for bringing consciousness into the scientific fold is to try to articulate a theoretical basis for connecting the observable characteristics of animals (behavioral or neurological) to consciousness. What effects should consciousness have on behavior? What capacities and dispositions should we expect a conscious creature to have that might be absent in a nonconscious creature? What neurophysiological structures and processes might realize the dynamics or information processing required for consciousness?

Such an approach is nascent in Griffin’s attempts to force ethologists to pay attention to questions about animal consciousness, in all its senses — including phenomenal consciousness. In a series of books, Griffin (who made his scientific reputation by carefully detailing the physical and physiological characteristics of echolocation by bats) provides examples of communicative and problem-solving behavior by animals, particularly under natural conditions, and argues that these are prime places for ethologists to begin their investigations of animal consciousness (Griffin 1976, 1984, 1992).

Although he thinks that the intelligence displayed by these examples suggests conscious thought, many critics have been disappointed by the lack of systematic connection between Griffin’s examples and the attribution of consciousness (see, e.g., Alcock 1992). Griffin’s main positive proposal in this respect has been the rather implausible suggestion that consciousness might have the function of compensating for limited neural machinery. Thus Griffin is motivated to suggest that consciousness may be more important to honey bees than to humans.

If compensating for small sets of neurons is not a plausible function for consciousness, what might be? The commonsensical answer would be that consciousness “tells” the organism about events in the environment, or, in the case of pain and other proprioceptive sensations, about the state of the body. But this answer begs the question against opponents of attributing conscious states to animals for it fails to respect the distinction between phenomenal consciousness and mere awareness (in the uncontroversial sense of detection) of environmental or bodily events. Opponents of attributing phenomenal consciousness to animals are not committed to denying the more general kind of consciousness of various external and bodily events, so there is no logical entailment from awareness of things in the environment or the body to animal sentience.

Perhaps more sophisticated attempts to spell out the functions of consciousness are similarly doomed. But Allen & Bekoff (1997, ch. 8) suggest that progress might be made by investigating the capacities of animals to adjust to their own perceptual errors. Not all adjustments to error provide grounds for suspecting that consciousness is involved, but in cases where an organism can adjust to a perceptual error while retaining the capacity to exploit the content of the erroneous perception, then there may be a robust sense in which the animal internally distinguishes its own appearance states from other judgments about the world. (Humans, for instance, have conscious visual experiences that they know are misleading — i.e., visual illusions — yet they can exploit the erroneous content of these experiences for various purposes, such as deceiving others or answering questions about how things appear to them.) Given that there are theoretical grounds for identifying conscious experiences with “appearance states”, attempts to discover whether animals have such capacities might be a good place to start looking for animal consciousness. It is important, however, to emphasize that such capacities are not themselves intended to be definitive or in any way criterial for consciousness. Carruthers (2000) makes a similar suggestion about the function of consciousness, relating it to the general capacity for making an appearance-reality distinction; of course, he continues to maintain that this capacity depends upon having conceptual resources that are beyond the grasp of nonhuman animals.

The broad issue of function is closely related to questions about just what sort of mental process consciousness is. As we shall see in the next section, hypotheses in the modern literature on the distribution and evolution of consciousness are therefore generally advanced together with theories of its structure and function in the following senses:

Structure: what are the contents of consciousness (what information, representations, intentional contents, properties, processes, etc. does it include)? What (possibly unconscious or subconscious) information, representations, or other cognitive or intentional processes, entities and relations, are required for consciousness?

Function: how does consciousness relate to other (nonconscious) processes, in cognition, the body and the environment? How does possessing consciousness contribute to an animal’s ability to navigate and respond adaptively to its environment, to survive and thrive?

Different views about what consciousness is, qua cognitive process, and how it relates to other biological processes such as behavior, development and ecological interaction, largely determine biologically oriented views about which animals have consciousness and when, how, and why it evolved. To illustrate this, we can start with a crude distinction between views that see consciousness as fundamental to the basic perceptual and cognitive processes involved in controlling an animal body, or as something that can be added on or plugged in to a system that is already sufficient for basic control of perception-guided action. The more fundamental consciousness is to basic animal functioning, the more widely distributed and ancient consciousness must be; if, however, consciousness is relatively modular, functionally narrow, and conceptually high level, then it should be narrowly distributed among animals and relatively recently evolved. The views surveyed in the following section all exploit the connections between function, structure, distribution and evolutionary origin.

One further point worth noting is that structural models of consciousness are usually justified in terms of phenomenological or introspective observations — i.e. observations about the nature of consciousness as it is experienced by the subject. Though the use of such first person methods is now and has been controversial in psychology and philosophy throughout the 20th and 21st century, there seems to now be a broad acknowledgement that it has an indispensable role in the scientific study of consciousness, as many authors who have published recent scientific theories of consciousness include some appeal to phenomenological premises in justifying their views (e.g. Seth, Edelman and Baars 2005; Merker 2005; Tononi 2008; Cabanac et al. 2009).

6. Evolution and Distribution of Consciousness
A variety of hypotheses have been put forward by scientists and philosophers about which animals are conscious and which are not. These views span a huge range of possibilities, from the narrowest, which is that only humans are conscious, to some authors arguing that almost all animals, even simple invertebrates, have a basic capacity to experience the world. Some authors have even argued that single-celled organisms (Margulis 2001) or plants (A. Nagel 1997) are conscious, and some have given arguments for versions of pan-psychism, the view that consciousness is a property of fundamental physical entities, much in the same way that mass and charge are (Chalmers 2015). It is worth noting that neither the attribution of consciousness to single-celled organisms, nor to fundamental physical entities, implies that all animals are conscious. In the former case, it may be that the information processing complexity and integration of relatively complex single-celled organisms outstrips that of the simplest animals. In the latter case, while the version of panpsychism developed by Chalmers attributes ‘microexperience’ to ‘fundamental physical entities’, this does not imply that any particular macroscopic object (like an animal) has ‘macroexperience’ — i.e. “the sort of conscious experience had by human beings” (Chalmers 2015). This view is compatible with the possibility that a given animal has no conscious experience, although it is composed of microphysical entities which possess conscious microexperience. These issues will not be discussed further here, as they fall outside the scope of Animal Consciousness.

The question of which lineages (species, or more inclusive groupings such as class or phylum) of animals are conscious, inevitably goes hand-in-hand with considerations of the evolutionary origin of consciousness. This is a logical implication of the broadly Darwinian view of life, on which modern organisms have evolved through descent, with modification, from a small number (perhaps one) of very ancient ancestors. If a trait is characteristic of a given species, it either arose in that species, or is derived from an ancestor — in which case, it will be present in other species derived from that ancestor, unless it has been secondarily lost in those species. Did consciousness first arise in humans, or in an earlier, nonhuman ancestor? If the latter, then what was this ancestor? Another possibility is that consciousness may have arisen multiple times, like winged flight, which evolved independently in insects, birds, bats, and pterosaurs.

6.1 Humans
As described above, the view that consciousness is unique to humans has a long history. It coheres with a religious view of humanity as the pinnacle of creation, and it also may be appealing insofar as it absolves us of any guilt for our treatment of animals. Religion aside, it may derive considerable intuitive support because of the appeal of connecting consciousness to the problem of human uniquenesss. If consciousness can be tied together with language, abstract reasoning, or some other mental characteristic that potentially could explain our apparent seperateness from the natural world, this would solve two outstanding mysteries at once.

Dennett (1991, 1995) has been an outspoken advocate of the human-uniqueness of consciousness. Dennett argues for this position in connection with his anti-realist theory of consciousness, the upshot of which is that consciousness is a sort of “user illusion” (1995) or “fiction” (1991, p. 365, p. 429) constructed through people’s narrative descriptions:

What there is, really, is just various events of content-fixation occuring in various places at various times in the brain... Some of these content-fixations have further effects, which eventually lead to the utterance of sentences — in a natural language — either public or merely internal. And so a heterophenomenological text is created... What about the actual phenomenology? There is no such thing. (1991 p 365)
On Dennett’s view, because consciousness is a sort of story telling, which requires language, and only (adult, normally enculturated and language-capable) humans have language, only these humans have consciousness.

Carruthers has championed the view that only humans (with the possible exception of chimpanzees) are conscious, although for different reasons than Dennett. Carruthers (1998a,b, 2000) has argued to this effect based on his ‘higher-order thought’ theory, according to which, phenomenal consciousness requires the capacity to think about, and therefore conceptualize, one’s own thoughts.[8] Such conceptualization requires, according to Carruthers, a theory of mind. And, Carruthers maintains, there is little basis for thinking that any nonhuman animals have a theory of mind, with the possible exception of chimpanzees (see Lurz 2011 and Andrews 2012 for in depth discussion of theory of mind in nonhuman animals). This argument is, of course, no stronger than the higher-order thought account of consciousness upon which it is based. But setting that aside for the sake of argument, this challenge by Carruthers deserves further attention as perhaps the most empirically-detailed case against animal consciousness to have been made in the philosophical literature.

Carruthers neither endorses nor outright rejects the conclusion that chimpanzees are sentient. His suspicion that even chimpanzees might lack theory of mind, and therefore (on his view) phenomenal consciousness, is based on some ingenious laboratory studies by Povinelli (1996) showing that in interactions with human food providers, chimpanzees apparently fail to understand the role of eyes in providing visual information to the humans, despite their outwardly similar behavior to humans in attending to cues such as facial orientation. The interpretation of Povinelli’s work remains controversial. Hare et al. (2000) conducted experiments in which dominant and subordinate animals competed with each other for food, and concluded that “at least in some situations chimpanzees know what conspecifics do and do not see and, furthermore, that they use this knowledge to formulate their behavioral strategies in food competition situations.” They suggest that Povinelli’s negative results may be due to the fact that his experiments involve less natural chimp-human interactions. Given the uncertainty, Carruthers is therefore well-advised in the tentative manner in which he puts forward his claims about chimpanzee sentience.

A full discussion of the controversy over theory of mind (e.g., Heyes 1998; Lurz 2011; Andrews 2012) deserves an entry of its own, but it is worth remarking here that the theory of mind debate has origins in the hypothesis that primate intelligence in general, and human intelligence in particular, is specially adapted for social cognition (see Byrne & Whiten 1988, especially the first two chapters, by Jolly and Humphrey). Consequently, it has been argued that evidence for the ability to attribute mental states in a wide range of species might be better sought in natural activities such as social play, rather than in laboratory designed experiments which place the animals in artificial situations (Allen & Bekoff 1997; see esp. chapter 6; see also Hare et al. 2000, Hare et al. 2001, and Hare & Wrangham 2002). Alternative approaches that have attempted to provide strong evidence of theory of mind in nonhuman animals under natural conditions have generally failed to produce such evidence (see, e.g., the conclusions about theory of mind in vervet monkeys and baboons by Cheney & Seyfarth 1990, 2007), although anecdotal evidence tantalizingly suggests that researchers still have not managed to devise the right experiments. Furthermore, theory of mind — and social cognition more broadly — are active areas of research, and it is quite possible that new research will reveal evidence of theory of mind in nonhuman animals.

On views such as Carruthers’, consciousness is grounded in cognitive processes that are highly specific and modular — indeed, irrelevant for the perceptual, motivational and cognitive processes involved with all nonhuman animal behavior. Given that most of the cognitive processes (and corresponding brain-systems) involved with human activities are shared with nonhuman animals, this line of thinking implies that much of human activity is nonconscious as well. Thus, for example, Carruthers (1989, 1992) argued that all animal behavior can be assimilated to the non-conscious activities of humans, such as driving while distracted (“on autopilot”), or to the capacities of “blindsight” patients whose damage to visual cortex leaves them phenomenologically blind in a portion of their visual fields (a “scotoma”) but nonetheless able to identify things presented to the scotoma. (He refers to both of these as examples of “unconscious experiences”.)

This comparison of animal behavior to the unconscious capacities of humans can be criticized on the grounds that, like Descartes’ pronouncements on parrots, it is based only on unsystematic observation of animal behavior. There are grounds for thinking that careful investigation would reveal that there is not a very close analogy between animal behavior and human behaviors associated with these putative cases of unconscious experience. For instance, it is notable that the unconscious experiences of automatic driving are not remembered by their subjects, whereas there is no evidence that animals are similarly unable to recall their allegedly unconscious experiences. Likewise, blindsight subjects do not spontaneously respond to things presented to their scotomas, but must be trained to make responses using a forced-response paradigm. There is no evidence that such limitations are normal for animals, or that animals behave like blindsight victims with respect to their visual experiences (Jamieson & Bekoff 1992).

Nevertheless, there are empirical grounds for concern that behavior suggesting consciousness in animals may be the product of unconscious processes. Allen et al. (2009) describe work on learning in spinal cords of rats that shows phenomena analogous to latent inhibition and overshadowing. In intact animals, these learning and memory related phenomena have been argued to involve attention. But their similarity to mechanisms in the spinal cord, assumed by most not to involve consciousness, calls into question their status as evidence for consciousness. There are, of course, differences between the learning capacities of spinal cords and the learning capacities of intact organisms, and there are prima facie reasons for thinking that sophisticated forms of learning are related to consciousness (Clark & Squire 1998; Allen 2004; Ginsburg & Jablonka 2007b). But the current point is similar to that made about blindsight: a more fine-grained analysis of these similarities and differences is needed before conclusions about consciousness can be drawn.

6.2 Great Apes
Gallup (1970) developed an experimental test of mirror self-recognition that has become widely used as a test of self-awareness, although interpretation of the test remains controversial (see the section on self-consciousness and metacognition below). Gallup argues that the performance of chimpanzees in this test indicates that they are self-aware, and that animals that fail the test lack self-awareness. Further, foreshadowing Carruthers, Gallup argues that self-awareness — in the sense of being able to think about one’s own mental states — is required for having a mind, and therefore that animals that ‘fail’ the mirror test have no minds (1982, 1985). Though there has been controversy over just which animals ‘pass’ the validity of versions of the test modified for use with elephants, dolphins,and magpies has been challenged — as of 2002, Gallup maintained that there was evidence that humans, common chimpanzees, bonobos and orangutans consistently pass the test, and strong evidence that a wide range of other primates fail consistently fail. He took this to support the claim that self-awareness is unique to great apes (Gallup et al. 2002). Combined with his earlier arguments that consciousness requires the sort of self-awareness measured by the mirror test, this would imply that consciousness is unique to the great apes.

Gallup’s interpretation of the mirror results have not been uncontroversial (Mitchell 2002). Rochat and Zahavi (2010) challenge Gallup both on a) the interpretation of chimps’ mirror-oriented behavior as indicating a human-like experience of mirror self-recognition, and b) the claim that mirror self-recognition is implied by consciousness.

As a side note, there has been a debate, ongoing since the early 1990s (Cavalieri and Singer 1994) about whether great apes deserve special legal protection amounting to ‘human rights’. The crux of the debate is not whether the great apes have consciousness per se (this seems to be assumed by most participants of the debate, on both sides), but whether they have personhood. Personhood is a vexed notion, but is generally thought to be related to certain forms of agency and self awareness, and is often thought to be tightly coupled to moral status, as reflected in this debate (DeGrazia 1997; SEP article on Moral Status of Animals; Varner 2012). Though not essential to phenomenal consciousness, personhood is often thought to presuppose consciousness, and so perhaps is best thought of as a level of elaboration or complexity of consciousness.

6.3 Mammals
A variety of theoretical and empirical arguments have been put forward to the effect that consciousness is shared across all mammals. Seth, Baars and Edelman (2005) argue that the neural processes essential to human conscious — widespread reentrant activity in the thalamo-cortical complex — involve anatomical systems that are shared among all mammals (and perhaps more widely). Panksepp (reviewed in 2005) takes a similar approach, although focusing on the neurophysiological systems involved in the ‘core emotions’. Although in both of the above proposals, the authors acknowledge that consciousness may be more widespread than just mammals, they argue that in the case of mammals, the weight of evidence based on homology of relevant neurophysiological systems is overwhelming, whereas outside of mammals, the inference is more tenuous because of the biological differences in non-mammalian animals. Further, it should be kept in mind that all of the following proposals imply that consciousness is widely shared among mammals. Hence, the position that all mammals are conscious is widely agreed upon among scientists who express views on the distribution of consciousness.

6.4 Amniotes (including birds and reptiles)
Questions about whether reptiles are conscious (and if so what their mental lives might be like) are especially interesting because birds are more closely related to them than they are to mammals, yet birds display a variety of behaviors that tend to intuitively suggest intelligence and emotion to human observers much more obviously than the behavior of scaly, so-called ‘cold-blooded’ animals like snakes and turtles. Do birds and mammals share mental features (consciousness, intelligence, emotion, social attachment) that are absent in reptiles? If so this would represent independent, convergent evolution of these phenomena. Alternatively, are these features common to all of these animals, but less obvious in some than others?

Cabanac et al. (2009) argue that consciousness is unique to, and shared by all amniotes — the clade that includes all descendants of the common ancestor of living birds and mammals, including reptiles such as lizards, snakes, turtles and extinct animals such as dinosaurs, pterosaurs and pleseiosaurs (see http://tolweb.org/Amniota). On this hypothesis, only these animals, and not amphibians, fish, or any invertebrates, possess consciousness. Cabanac’s argument is based on an explicit structural and functional theory of consciousness as a unified representational space, “an abstract private model of reality with four dimensions: quality, intensity, hedonicity and duration” (2009, p.268). Possessing this ability to model reality allows animals to simulate possible courses of action, using hedonicity (pleasure or pain) as a ‘common currency’ to evaluate and choose between actions based on expected consequences (which are based on prior experience).

Cabanac identifies a set of behavioral markers of consciousness, based on this model structural and functional theory:

the ability to make motivational tradeoffs;
play;
navigational detouring (which requires an animal to pursue a series of nonrewarding intermediate goals in order to obtain an ultimate reward);
expression of emotion;
expression of sensory pleasure;
emotional fever (an increase in body temperature in response to a supposedly stressful situation — gentle handling, as operationalized in Cabanac’s experiments);
taste aversion.
Based on supposed evidence of these phenomena in amniotes but not in non-amniotes, Cabanac argues that consciousness originated in the common ancestor of amniotes, and hence is present in all living amniotes but in no other animals. Cabanac and Cabanac (2009) also argue that a qualitative difference in the role of dopamine in motivational processes in the brains of amniotes compared to non-amniotes supports this distribution/origin hypothesis.

Cabanac and colleagues have documented the presence of some of these phenomena in amniotes, in contrast with their absence in at least a small number of non-amniote species, such as emotional fever (Cabanac and Bernieri 2000; Cabanac and Cabanac 2000; Cabanac and Cabanac 2004) and taste aversion (Paradis and Cabanac 2004).

However, the assertion that these aspects of behavior and cognition do not exist outside amniota is largely based on absence of evidence (and hence, inherently limited). In particular, they do not offer direct support for their claims that non-amniotes are incapable of trading off punishments and rewards, play or detouring. Indeed, some of these claims appear to be contradicted by existing studies — for example, documentation of detouring in jumping spiders (Jackson and Wilcox 2003) and work by Elwood and Appel(2009) that shows motivational trade-off behavior in hermit crabs.

Cabanac’s structural and functional theory of consciousness can be evaluated independently of the evidence that he marshals in support of his view of the distribution and origins of consciousness. Indeed, one might challenge his views on distribution and origins precisely by accepting his structural and functional theory, and arguing that the list of proposed indicators can actually by identified with a wider distribution (i.e. if motivational trade-offs, play, and detouring are present outside of amniotes). As we shall see, his structural and functional views of consciousness have much in common with those of other authors who argue for wider distributions of consciousness among animals.

6.5 Vertebrates
‘Fish’ is a folk-biological term that does not correspond precisely to any monophyletic taxonomic group. This can be appreciated by noted that a coelacanth is more closely related to a human than to a tuna, or that a tuna is more closely related to a human than it is to a shark. I.e., some things that are intuitively fish are more closely related to non-fish than to other fish. Basically, the folk term ‘fish’ refers to all vertebrates other than tetrapods, although it is somewhat ambiguous in regards to animals such as sea-horses, eels, hagfish and sting-rays.

In any case, there has a lively debate over fish consciousness, mostly focusing on the issue of whether fish can experience pain, stress and suffering (see below, section 7.1; see also Rose (2002) and Sneddon et al. (2003) for contrasting views of conscious pain in fish; Allen 2013 and Brown 2015 for reviews of fish cognition and consciousness as it may relate to pain; and Braithwaite 2010 for a book-length treatment). This is of special relevance in the context of welfare regulation in commercial aquaculture and recreational angling; accordingly, the fish consciousness literature has focused experimentally on salmonids (especially salmon and trout), a group of high commercial and sport-fishing importance, but only a tiny phylogenetic corner of the animals that colloquially count as fish.

Merker (2005) has proposed that consciousness originated early in vertebrate evolution, and is therefore both ancient and widespread. On this proposal, not only mammals and birds, but amphibians and all marine vertebrates are conscious. Merker begins his argument with the phenomenological observation that the contents of conscious experience are object- and goal-oriented, but exclude the fine-grained sensory and motor details represented in peripheral and low-level neural processing. Merker argues that consciousness is an integrated representational platform — what he refers to a ‘synthesized reality space’ — that, for animals with complex bodies with many degrees of freedom of movement and multiple sensory modalities, solves a cluster of critical neural logistics problems. This includes:

maintaining the stability of perceptual contents against interference from self-generated motion;
integrating interoceptive information about the body’s movements and the body’s self-regulative needs (e.g. temperature, thirst, hunger);
affording high-level decision making that abstracts away from the irrelevant sensorimotor details of implementation.
The neuroanatomical details of Merker’s argument (2005) are beyond the scope of this article to review, but his conclusion is that the systems that solve the above problems — giving rise to consciousness — arose in an early vertebrate ancestor. Hence, consciousness is both ancient and widespread among living vertebrates.

6.6 Invertebrates
There are additional daunting challenges to addressing questions of consciousness outside the vertebrate lineage, given the radical differences between vertebrates and invertebrates with respect to anatomy and physiology. The strategy of identifying homologous and functionally analogous structures and processes, which underlies the confidence of researchers such as Cabanac (2009), Seth et al. (2005), Merker (2005), and Panksepp (2005) that consciousness is shared with other animals is much more difficult to apply (Seth et al. 2005).

The vertebrate lineage represents just one of approximately 34 known phyla — ancient lineages of animals characterized by differences in fundamental anatomical organization and the developmental processes that generate it. Each of these phyla is derived from a relatively simple state (i.e. few tissue types and a minimal central nervous system with limited sensory capacities). Hence, the invertebrates such as cephalopod mollusks (e.g., octopi and squids) and arthropods (e.g. crustaceans, insects and spiders), that are complex enough to attract the attention of those interested in animal consciousness, evolved their complexity independently from vertebrates, and in the case of cephalopods and arthropods, independently from each other.

Today, only three of the phyla (vertebrates, arthropods, and mollusks) include animals with complex active bodies (Trestman 2013a), characterized by:

articulated and differentiated appendages;
many degrees of freedom of controlled motion;
distal senses (e.g., ‘‘true’’ eyes);
anatomical capability for active, distal-sense-guided mobility (fins, legs, jet propulsion, etc.);
anatomical capability for active object manipulation (e.g., chelipeds, hands, tentacles, mouth-parts with fine-motor control).
Trestman (2013a) argues that the evolution of complex active bodies requires a capacity for integrated, embodied spatial cognition, and that this capacity evolved independently in each of the three phyla in which it is currently found (vertebrates, arthropods and mollusks). If Merker (2005) is right that consciousness represents a solution to the neural-logistics problems posed by controlling a complex body in space, it may be a good bet that these three lineages are likely suspects for possessing consciousness. This line of reasoning can be bolstered by considering the role of temporal integration of perceptual information in consciousness and in action-selection and object-oriented perception (Trestman 2013b). Perhaps each of these three lineages evolved consciousness independently during the transition from a relatively simple worm-like body morphology to having complex active bodies.

One group of invertebrate animals that has received attention in the context of questions about consciousness is the coleoid cephalopods — octopuses, squids and cuttlefish. These are large-brained, notoriously clever animals, well-known for their remarkable abilities to camouflage th emselves, and for their flexible hunting strategies. Mather (2008) argues that cephalopods exhibit many behavioral indicators of consciousness, including complex learning and spatial memory, as well as apparent play. Both Merker (2005) and Edelman et al. (2005, 2009) argue that a strong provisional case can be made for consciousness in cephalopods — although these authors emphasize the limitations on our understanding posed by the differences in anatomy and physiology between cephalopods and vertebrates.

The other phylum that has received particular attention is the arthropods, which includes insects, crustaceans, spiders, and many other less familiar animals. This is an ancient and tremendously diverse group of animals, so any generalizations should be made with caution. Arthropods were among the earliest animals to evolve complex active bodies — and correlatively to evolve brains capable of adaptively controlling complex adaptive bodies (Trestman 2013a), and so if the function of consciousness is to solve problems raised by the control of complex active bodies (cf. Merker 2005), it may have evolved early on in the arthropod lineage, in a common ancestor of all living arthropods.

Few studies have aimed directly at answering questions about consciousness in arthropods, but relevant empirical work includes:

Work by Elwood and Appel (2009) that seems to show that hermit crabs remember an aversive event (an electric shock), and can use that memory in later context-sensitive decision-making. This seems to satisfy Cabanac and Cabanac’s (2009) definition of ‘motivational trade-off’ behavior, which those authors argue is an indicator of consciousness.
Work by Jackson and colleagues (reviewed in Jackson and Wilcox 1998) documenting a variety of impressive behaviors in in jumping spiders, including:
detouring and other forms of apparent planning (noted as a potential indicator of consciousness by Cabanac et al., 2009)
flexible, context-sensitive adjustment of predatory behavior to prey behavior
deception and smokescreen tactics
Studies on bees, revealing pattern recognition, concepts of ‘same’ and ‘different’, navigation, communication, and visual working memory (reviewed in Srinivasan 2010), and on mood and cognitive bias (Mendl et al. 2011).
Another possibility is that consciousness evolved even earlier in animal history and is even more widely distributed among animals, and hence has a function that is even more fundamental to animal life. Ginsburg & Jablonka (2007a,b) attribute a primitive form of “overall sensation” as a by-product of even the simplest nerve nets in animals. They argue that as these states became harnessed to learning and motivation that they acquired the functional properties of “basic consciousness”. If this is right, than consciousness may have arisen not independently in arthropods, mollusks and vertebrates, but only once in the common ancestor of these ancient groups, very early in animal evolution.

7. Special Topics in the Study of Animal Consciousness
With the gradual loosening of behaviorist strictures in psychology and ethology, and independent advances in neuroscience, there has been a considerable increase in the number of animal studies that have some bearing on animal consciousness. Some of these studies focus on specific kinds of experience, such as pain, while others focus on cognitive abilities such as self-awareness that seem to be strongly correlated with human consciousness. This section contains brief reviews of some of the main areas of investigation. The aim is to provide some quick entry points into the scientific literature.

7.1 Animal pain and suffering
Given the centrality of pain to most accounts of our ethical obligations towards animals, as well as the importance of animal models of pain in clinical medical research (see Mogil 2009 for a review), it is hardly surprising that there is a substantial (albeit controversial) scientific literature bearing on animal pain. Reports by the Nuffield Council on Bioethics in the U.K. (Nuffield Council 2005; see esp. chapter 4) and the U.S. National Academy of the Sciences Institute for Animal Laboratory Research (ILAR 2009) have recently covered the definition of pain and the physiological, neurological, and behavioral evidence for pain in nonhuman animals. These reviews also distinguish pain from distress and suffering (see also Bermond 2001), and the ILAR has divided what used to be a single report on recognition and alleviation of pain and distress into two separate reports, although the scientific investigation of distress is relatively rudimentary (but see Dawkins 1985; Farah 2008).

A proper understanding of neurological studies of animal pain begins with the distinction between nociception and pain. Nociception — the capacity to sense noxious stimuli — is one of the most primitive sensory capacities. Neurons functionally specialized for nociception have been described in invertebrates such as the medical leech and the marine snail Aplysia californica (Walters 1996). Because nociceptors are found in a very wide range of species, and are functionally effective even in decerebrate or spinally transected animals, their presence and activity in a species provides little or no direct evidence for phenomenally conscious pain experiences. The gate control theory of Melzack and Wall (1965) describes a mechanism by which “top-down” signals from the brain modulate “bottom-up” nociception, providing space for the distinction between felt pain and nociception.

Smith & Boyd (1991) assess the evidence for the pain-sensing capabilities of animals in the categories of whether nociceptors are connected to the central nervous system, whether endogenous opioids are present, whether analgesics affect responses, and whether the ensuing behavioral responses are analogous to those of humans (see table 2.3 in Varner 1998, p. 53, which updates the one presented by Smith & Boyd). On the basis of these criteria, Varner follows Smith & Boyd in concluding tentatively that the most obvious place to draw a line between pain-conscious organisms and those not capable of feeling pain consciously is between vertebrates and invertebrates. However, Elwood & Appel (2009) conducted an experiment on hermit crabs which they interpret as providing evidence that pain is experienced and remembered by these crustaceans. Varner also expressed some hesitation about the evidence for conscious pain in “lower” vertebrates: fish, reptiles and amphibians. Allen (2004) argues, however, that subsequent research indicates that the direction of discovery seems uniformly towards identifying more similarities among diverse species belonging to different taxonomic classes, especially in the domains of anatomy and physiology of the nociceptive and pain systems.

It is generally accepted that the mammalian pain system has both a sensory and an affective pathway, and that these can be dissociated to some degree both pharmacologically (with morphine, e.g.) and surgical lesions. The anterior cingulate cortex (ACC) is a particularly important structure of the mammalian brain in this regard (Price 2000). Allen et al. (2005) and Shriver (2006) argue that this dissociability provides a route to empirical assessment of the affective component of animal consciousness, and Farah (2008) uses it to distinguish suffering from “mere pain”.

Detailed analysis of other taxonomic groups may, however, indicate important anatomical differences. Rose (2002) argues that because fish lack an ACC they may not be bothered by pain. This is in contrast to Sneddon et al. (2003) who argue that there is adequate behavioral and physiological evidence to support pain attributions to fish. (See, also, Chandroo et al. 2004 for a review.) While the ACC is important to mammals, there remains the possibility that other taxa may have functionally similar structures, such as the corticoidea dorsolateralis in birds (Atoji & Wild 2005; Dubbeldam 2009). Genetic knockout animals are also providing further clues about the affective aspects of pain (see Shriver 2009 for a review and application of these findings to animal welfare.)

Finally, it is worth noting that a major shift in veterinary practice in regards to animal pain has occurred in the past decade. Whereas surgery on animals was once routinely practiced without analgesics or anesthetics, the vast majority of veterinary practitioners now accept the basic premise that veterinarians can be trained to recognize animal pain reliably, and that veterinary patients benefit from the same kinds of pain alleviation treatments that are delivered to humans. It has even been argued that animals possess the neurobiological mechanisms responsible for phantom limb pain and neuropathic pain (pain in the presence of no obvious tissue damage or disease), and that these conditions may therefore be detectable and treatable in nonhuman animals (Mathews 2008).

7.2 Animal emotions
The idea of animal emotions is, of course, prominent in Darwin’s work with his 1872 book The Expression of the Emotions in Man and Animals. Willingness to see animals as emotional beings (and humans, by contrast, as endowed with rationality that can override the emotions) goes back at least to Ancient Greek philosophy. Konrad Lorenz seems to have held a similar view, echoing Oskar Heinroth’s statement that “animals are highly emotional people of very limited intelligence” (Lorenz 1971b, 334). These days it is more fashionable to regard emotions as an important component of intelligence. Regardless of the merits of that view, the scientific study of animal emotions has gained its own momentum. Early in the 20th century, although they are not arguing for or about animal consciousness, physiologists recognized that significance of emotion in animal behavior. Dror (1999) explains how the emotional state of animals was considered to be a source of noise in physiological experiments at that time, and researchers took steps to ensure that animals were calm before their experiments. According to Dror, although physiologists were forced to deal with the problem of emotional noise, attempts to treat emotion as a subject of study in its own right never crystallized to the extent of generating a journal or other institutional features (Dror 1999, 219).

More recently, Jaak Panksepp (2004, 2005) has been conducting a research program that he calls “affective neuroscience” and that encompasses direct study of animal emotions (2004), exemplified for example in the experimental investigation of rats “laughing” and seeking further contact in response to tickling by humans (Panksepp & Burgdorf 2003). Over several decades, his work (reviewed in Panksepp 2005) has elucidated the neuro- and molecular-physiological bases of several ‘core emotional systems’ including ‘seeking’, ‘fear’, ‘rage’, ‘lust’, ‘care’, ‘play’, and ‘panic’. Panksepp argues that these are shared by all mammals, and may be more widely shared among vertebrates.

Sufka et al. (2009) have proposed that animal models of neuropsychiatric disorders may also support the experimental investigation of animal emotions. Although depending on a more anecdotal, non-experimental approach, Smuts (2001) and Bekoff (2007) each defend the attribution of conscious emotions to animals from a scientist’s perspective. Bekoff has made much of play behavior as an indicator of animal emotions, an idea that is also taken up by Cabanac et al. (2009).

Empathy in animals is also a topic of current investigation (e.g., Preston & de Waal 2002). Langford et al. (2002) argue for empathy in mice based on experiments in mice who observe a cagemate given a noxious stimulus, or in pain, are more sensitive to painful stimuli than control mice who observe an unfamiliar mouse similarly treated. Byrne et al. (2008) argue for empathy in elephants as an inference to the best explanation of various capacities, such as diagnosing animacy and goal directedness, and assessing the physical abilities and emotional states of other elephants when these different from their own.

It is worth noting that almost all of the work, both theoretical and empirical, on animal emotions has limited its scope to mammals, or at least amniotes (For a notable recent exception, see Mendl et al. 2011). This work has exploited certain deep homologies of, e.g. brain structure and molecular neurophysiology (focusing especially on hormones and neurotransmitters) in making arguments that animals in these taxanomic groups share our emotions because they share the mechanisms of our own emotions (as well as behaviors that tend to indicate emotions in us, and bear the same relations to the underlying physiological mechanisms). This approach is not available to animals which are very distantly related to us, i.e. invertebrates. The ancestors of vertebrates split off from the rest of the animal phyla at a time when all animals were still relatively simple, in terms of structure, tissue types, number of neurons, bodily capacities for locomotion and other forms of behavior. The elaboration of complex physiological systems occurred independently in the various phyla. Therefore the physiological systems underlying emotions in other phyla — if these exist — may be very different, and hence difficult to identify, either in terms of direct physiological observations or in terms of observations of behavioral expressions of emotion. It is also possible that the repertoire of emotions in other phyla might be different, further problematizing the task of individuating non-vertebrate emotions. (Further discussion and additional scientific references for the topic of emotions and empathy in animals can be found in the section on emotions and empathy in the entry on animal cognition.)

7.3 Perceptual phenomenology
The idea that careful psychophysical work with could help us understand the nature of their subjective experiences of the world can be traced at least to Donald Griffin’s experimental tests of the limits of bat echolocation. It is also behind the idea that knowing that horses have near 360° vision, or that raptors have two fovea on each retina, may tell us something about the nature of their experiences — how the world appears to them — if it is granted that they have such experiences. Neural investigation adds a further layer of analysis to scientific understanding of the nature of perception. For instance, Leopold & Logothetis (1996) used neural data to support inferences about the percepts of monkeys under conditions of binocular rivalry (see also: Myserson et al. 1981; Rees et al. 2002). And Leopold et al. (2003) argue that neural recordings can be used to corroborate the non-verbal “reports” of monkeys shown ambiguous visual stimuli. (Think here of whether it is possible for the monkey to report that it is subject to Gestalt switches like those arising from ambiguous figures such as the duck-rabbit or figure-vase illusions.)

The phenomenon of blindsight, a form of unconscious visual perception that arises with damage to specific areas of primary visual cortex, has also been investigated in surgically lesioned monkeys (Stoerig & Cowey 1997), with a close correspondence between the monkeys’ deficits and those of the human patients vis-à-vis parts of the visual field that can be processed only unconsciously, and those for which the patients retain consciousness. The non-verbal approach to assessing visual awareness has been further validated by Stoerig et al. (2002). Blindsight subjects, both human and monkey, do not spontaneously respond to things presented to their scotomas (areas where they are visually unaware), but must be trained to make responses using a forced-response paradigm (Stoerig & Cowey 1997).

The emphasis on visual perception in most of these examples, no doubt reflects a primatocentric bias. We human primates are highly visual creatures, and, as Nagel (1974) argued, we face considerable hurdles in imagining (again, a visual metaphor) the subjective experiences of creatures in modalities in which humans are weak or completely unendowed. The examples of research also reflect an anthropocentric bias in that much of the animal experimentation is explicitly targeted at relieving human disorders. Although there is good work by neuroethologists on the psychophysics of echolocation by bats and dolphins, or on the sensory capacities of weakly electric fish, questions of subjective awareness are generally not broached in that literature.

As with the investigation of animal pain, fine-grained analysis of the neural correlates of consciousness may reveal subtle differences between different species. For instance, Rees et al. (2002) report that while the behavior of rhesus monkeys is rather similar to humans under conditions of binocular rivalry, “the firing of most cells in and around V1 primarily reflects stimulus properties rather than the conscious percept reported by the animal ... However, several neuroimaging studies in humans have presented evidence that argues for a stronger role of V1 in binocular rivalry and hence, by implication, visual awareness.” Nevertheless, it is noteworthy that they take the behavioral evidence to be unproblematically describable as report of a conscious percept by the monkey.

7.4 Mental Time Travel
A debate has unfolded in the literature over whether other animals, like humans, are capable of thinking about past and future events. Suddendorf and Corballis (1997, 2007) have argued that so-called ‘Mental Time Travel’ is unique to humans, and indeed plays a major role in explaining what is cognitively unique about humans, including capacities for language and culture. Many mammals, birds and fish exhibit behavior such as food caching, nest building, tool use, or migration that seems to suggest foresight. For example, tayras — a members of the weasel family found in Central and South America — hide bunches of bananas inside of bromeliads, recovering them only when the bananas are ripe (Soley et al. 2011). Skeptics are quick to point out that many of these examples may be either a) ‘instinctive’ fixed-action patterns shaped by natural selection or b) the result of classical or operant conditioning, rather than behavior that is mediated by ‘cognitive’ processes such as episodic memory, insight, or understanding. However, the novelty, flexibility and ability to make situation-specific adjustments often calls such dismissals into question. For example, tayras cache several species of bananas, and accurately judge for bananas of each species when the banana is mature enough to continue ripening once picked. This includes domestic bananas, to which tayras have not been exposed over evolutionary time-scales (Soley et al. 2011).

A variety of careful experimental work with animals shows impressive abilities for integrated what-where-when memory — the ability to recall details of an event together with its location and time. This work was pioneered by Clayton and colleagues with scrub jays, focusing on their caching behavior — wherein the birds bury food and later recover it (Clayton et al. 2003). For example, if scrub jays are prevented from recovering their caches for long enough, they will recover only nonperishable items (peanuts, in the study), ignoring their caches of otherwise preferred but perishable food (mealworms, in the study) (Clayton et al. 2003). Recent work has also documented what is referred to as ‘episodic-like memory’ in rats (Crystal 2009), and the apparent ability to plan for the future (including in novel ways that are not plausible ruled out as ‘mere instinct’) in several animals, including nonhuman primates, birds, rats and other mammals (Feeney et al. 2011 for an example of recent experimental work; see Roberts 2012 for a review and discussion).

This debate has been somewhat complicated by the fact that proponents of the human-uniqueness of mental time travel tend to rely on descriptions of the ability that are laden with researchers’ and subjects’ phenomenological, introspective or intuitive descriptions of the way their own minds work (e.g. Tulving 1985; Suddendorf and Corbalis 2007), whereas animal behavior researchers must rely on strict standards of behavioral evidence to support their claims. Animal behavior researchers are typically circumspect in their interpretations, limiting their claims to operationalizable terms such as ‘what-where-when’ memory, or ‘episodic-like’ memory, rather than making claims about the nature of the experience that may be involved in an animal’s performing a task. The situation may therefore represent a double standard in the interpretation of evidence about human and nonhuman animal subjects, with researchers uncritically making liberal assumptions about human cognition that would not be allowed for animal researchers — an example of what Buckner (2013) has called ‘anthropofabulation’. The question of to what extent, and in what ways, humans’ awareness of time differs from that of other animals remains an open one, and an active line of research.

7.5 Self-consciousness and metacognition
Systematic study of self-consciousness and theory of mind in nonhuman animals has roots in an approach to the study of self-consciousness pioneered by Gallup (1970). Gallup’s rationale for linking mirror-self recognition to self-awareness has already been discussed above. The idea for the experiment came from observations well-known to comparative psychologists that chimpanzees would, after a period of adjustment, use mirrors to inspect their own images. Gallup used these observations to develop a widely-replicated protocol that appears to allow a scientific determination of whether it is merely the mirror image per se that is the object of interest to the animal inspecting it, or whether it is the image qua proxy for the animal itself that is the object of interest. Taking chimpanzees who had extensive prior familiarity with mirrors, Gallup anesthetized his subjects and marked their foreheads with a distinctive dye, or, in a control group, anesthetized them only. Upon waking, marked animals who were allowed to see themselves in a mirror touched their own foreheads in the region of the mark significantly more frequently than controls who were either unmarked or not allowed to look into a mirror.

Although it is typically reported that chimpanzees consistently “pass” the mirror-mark test, a survey of the scientific literature by Shumaker & Swartz (2002) indicates that of 163 chimpanzees tested, only 73 showed mark-touching behavior (although there was considerable variation in the age and mirror experience among these animals). Shumaker & Swartz also report mark-touching behavior in 5 of 6 tested orang utans and 6 of 23 gorillas. They suggest that the lower incidence of mark touching by gorillas may be due to avoidance of socially-significant direct eye contact.

For non-human primates outside the great apes, the evidence for mirror self-recognition has been sparse. Gallup himself regards it as a phenomenon restricted to the great apes only, and he was among the first to challenge Hauser’s report that cotton top tamarins engaged in mirror-guided self-directed behaviors after their distinctive white tufts had been dyed neon colors, a stimulus that Hauser and coauthors argued was presumably more salient than the red dot used by Gallup (Hauser et al. 1995). Faced with Gallup’s challenge, Hauser himself was unable to replicate his initial results (Hauser et al. 2001). However, the idea that Gallup’s protocol uses a stimulus that is not particularly salient to monkeys continues to have some currency. For example, Rajala et al. (2010) have presented quantitative and videographic evidence that rhesus monkeys with surgical implants in their heads use mirrors to inspect the implants, as well as other parts of their bodies that they cannot usually see.

Modified versions of Gallup’s experiment have also been conducted with non-primate species. Notoriously, Epstein et al. (1981) trained pigeons to peck at a mark on their own bodies that was visible only in a mirror, and they used this to call into question the attribution of “self-awareness” on the basis of the mirror-mark test, preferring an associative learning explanation. Gallup et al. (2002) reject the claimed equivalence, pointing out that chimpanzees were not trained to touch marks before the test was administered. Reiss & Marino (2001) have offered evidence of mirror self-recognition in bottlenose dolphins. Using a modified version of Gallup’s procedure that involved no anesthesia, they inferred self-recognition from bodily contortions in front of the mirror (self-touching being anatomically impossible for dolphins). This evidence has been disputed (e.g. Wynne 2004). The mirror-mark test continues to be an area of active investigation in various species including elephants (Plotnik et al. 2006) and magpies (Prior et al. 2008). Various commentators have pointed out that the mirror test may not be entirely fair for species which depend more heavily on senses other than vision (Mitchell 2002; Bekoff and Burghardt 2002).

An intriguing line of research into animals’ knowledge of their own mental states considers the performance of animals in situations of cognitive uncertainty. When primates and dolphins are given a “bailout” response allowing them to avoid making difficult discriminations, they have been shown to choose the bailout option in ways that are very similar to humans (Smith et al. 2003). The fact that animals who have no bailout option and are thus forced to respond to the difficult comparisons do worse than those who have the bailout option but choose to respond to the test has been used to argue for some kind of higher-order self understanding. The original experiments have attracted both philosophical criticism of the second-order interpretation (e.g. Carruthers 2008) and methodological criticism by psychologists (reviewed by Crystal & Foote 2009), although alternative approaches to establishing metacognition in non-linguistic animals may be capable of avoiding these criticisms (Terrace & Son 2009).

In the literature on human cognition, awareness of what one knows is called “metacognition” and it is associated with a “feeling of knowing”. Smith and colleagues claim that investigating metacognition in animals could provide information about the relation of self-awareness to other-awareness (theory of mind), and that their results already show that “animals have functional features of or parallels to human conscious cognition” (Smith et al. 2003; Smith 2009). They also raise the question of what this might tell us about the phenomenal features of that cognition. Browne (2004) argues that the dolphin research cannot support the connection to theory of mind, but that it nevertheless is relevant to consciousness in dolphins, particularly within the theoretical framework provided by Lycan, described above. The notion of metacognition also seems relevant to questions about access consciousness. (For additional discussion of self awareness and metacognition, readers are referred to the section on theory of mind and metacognition in the entry on animal cognition.)

8. Summary
An article such as this perhaps raises more questions than it answers, but the topic would be of little philosophical interest if it were otherwise.

It is clear that for many philosophers, the topic of animal consciousness is no longer only of peripheral interest. There is increasing interest in animal cognition from a range of philosophical perspectives, including ethics, philosophy of mind, and the philosophy of science. Philosophers working in all of these areas are increasingly attentive to the particular details of scientific theory, methods, and results. Many scientists and philosophers believe that the groundwork has been laid for addressing at least some of the questions about animal consciousness in a philosophically sophisticated yet empirically tractable way. Yet there remain critics from both sides: on the one hand are those who still think that subjective phenomena are beyond the pale of scientific research, and on the other are those who think that science and philosophy have not moved far enough or fast enough to recognize animal consciousness. The arguments on both sides are by no means exhausted.

1. Frege and Russell: Existence is not a Property of Individuals
There are two sets of reasons for denying that existence is a property of individuals. The first is Hume and Kant’s puzzlement over what existence would add to an object. What is the difference between a red apple and a red existing apple? To be red (or even to be an apple) it must already exist, as only existing things instantiate properties. (This principle—that existence is conceptually prior to predication—is rejected by Meinongians.) Saying it is red and an apple and furthermore exists is to say one thing too many. The thought seems to be that instantiating any property whatsoever presupposes existence and so existence is not a further property over and above a thing’s genuine properties. The thought is not merely that everything that instantiates any property exists, as the same is true of being self-identical, being either human or not human—assuming the law of excluded middle—and being such that 2+2=4, all of which seem to be unproblematic properties of individuals even if that status is denied of existence. Instead the thought is that instantiating any property whatsoever conceptually presupposes the existence of a subject in a way that makes it incoherent to then think of existence as a further property of that thing. The thing’s existence is prior to any predication to it and so it is incoherent to think of existence as a property had by the thing. This thought is behind Aristotle’s thesis that existence is not a further feature of a thing beyond its essence.

The second consideration favoring the thesis that existence is not a property of individuals concerns the puzzle of negative singular existentials. Suppose that existence is a property of the designation of the subject term in a singular existential sentence. Then ‘Ronald McDonald does not exist’ predicates nonexistence of the designation of the subject term, in which case reality includes an entity—the designation of the singular term and subject of predication—that has the property of not existing. That, Russell complained, runs contrary to a robust sense of reality, according to which everything exists. (See [Russell 1905a].) So, we should reject the claim that existence is a property of the designation of subject terms in existential sentences.

To appreciate Russell’s alternative account, consider first general nonexistence claims. To say that foxes exist is to say that there are some things that are foxes; that is, the property of being a fox is instantiated. This is reflected in the standard regimentation of the sentences ‘Foxes exist’ and ‘There are foxes’ in first-order quantificational logic as ∃xFx, where Fx is the translation for the predicate ‘x is a fox’. General kind terms do not, then, designate individuals, which we then (redundantly) say exist when using the predicate ‘exists’ or (paradoxically) say are not when using the predicate ‘does not exist’. Instead, kind terms designate properties and simple seeming subject-predicate sentences like ‘Foxes are carnivores’ are claimed to possess a more complicated logical form, ∀x(Fx→ Cx), where Cx translates the predicate ‘x is a carnivore’. (This ignores the difficult question whether generics are really quantifiers at all, made more troubling by the fact that some generics seem to admit of exceptions—‘Birds fly’ is true, even though penguins are birds and don’t fly; ‘Cats have four legs’ is true, even though there is a three-legged cat wandering the planet. See the entry generics.) Given this analysis, general nonexistence claims are unproblematic. The sentence ‘Dragons do not exist’ says, on this analysis, that the property of being a dragon is not instantiated. Take the most inclusive class of what there is; nothing in that class has the property of being a dragon. That is what ¬∃xDx says, letting Dx translate the predicate ‘x is a dragon’. This is significant because it does not require identifying some entity to then predicate of that thing the property of nonexistence.

The Frege-Russell view that existence is a second-order property is based on the idea that seemingly singular existential and negative existential sentence like ‘Bill Gates exists’ and ‘Ronald McDonald does not exist’ are, in their deeper logical form, general existential and negative existential claims. Let us focus on Russell’s version of the view.

Russell claimed that ordinary proper names like ‘Bill Gates’ are disguised definite descriptions, something like ‘the richest man in the world’. And definite descriptions, given Russell’s view of definite descriptions, are not genuine referring terms but are instead quantificational expressions. The sentence ‘The richest man in the world lives in Washington’ has, as its logical form, a quantificational structure and not a subject-predicate structure, equivalent to something like the following: There is a unique richest person who lives in Washington. Individuals do not enter directly into the proposition expressed by the sentence and are not part of the sentence’s truth conditions.

These features of Russell’s account of definite descriptions are significant for the treatment of seemingly singular existential and negative existentials as they remove the need for entities to serve as the designation of the singular terms for the meaningfulness and truth of negative existentials. Seemingly singular existentials like ‘Bill Gates exists’ are assimilated to general existentials like ‘Foxes exist’. Assuming the proper name ‘Bill Gates’ is analyzed as the definite description ‘the richest person alive’, the sentence ‘Bill Gates exists’ has a logical form that can be more accurately expressed as There is someone that is uniquely richer than anyone else alive. This is neither redundant nor uninformative, as we can grasp in thought properties while coherently and rationally wondering whether or not they are instantiated. Russell’s account similarly dissolves the problems generated by seemingly singular negative existentials like ‘Ronald McDonald does not exist’. The truth of this sentence does not require a designation for the term of which nonexistence is then predicated. ‘Ronald McDonald’ is short for a definite description, say, ‘the happy hamburger clown’. The sentence ‘Ronald McDonald does not exist’ expresses a proposition of the form It is not the case that there is a unique happy hamburger clown. This proposition is true even if absolutely everything there is exists. The proposition concerns the property of being a happy hamburger clown and says of that property that it is not uniquely instantiated. As the property—the true subject of predication—exists, however, we are not forced to countenance the reality of entities that do not exist in order to recognize this sentence as saying something true.

Russell’s strategy depends on two claims. The first is that the negation in a negative existential takes wide scope, applying to the whole sub-sentence and not just the predicate. So, ‘Ronald McDonald does not exist’ does not involve ascribing the predicate ‘is nonexistent’ to the subject ‘Ronald McDonald’. Instead, it is more faithfully represented as ‘It is not the case that [Ronald McDonald exists]’. The second is that ‘Ronald McDonald’ is not a genuine referring expression and the predicate ‘exists’ really means something like is instantiated. Notice that the first in solitude is not sufficient to overcome the problems generated by seemingly true singular negative existentials. Even if the deep form of ‘Ronald McDonald does not exist’ is  ‘It is not the case that [Ronald McDonald exists]’, assuming that ‘Ronald McDonald’ is a genuine singular term, the problem remains of finding in reality some entity to serve as the designation of ‘Ronald McDonald’. That entity is then part of reality and so, assuming that Meinongianism is false, is existent. In that case, the sub-proposition Ronald McDonald exists is true and so its negation false. The problem of true singular negative existentials does not rest on the supposition that they involve ascribing the property of nonexistence. So, it is the second of the above claims that carries the weight of Russell’s solution to the problem of singular negative existentials.

The second component of the Russellian solution—the claim that ordinary proper names like ‘Bill Gates’ are disguised definite descriptions—faces a number of objections. One is the semantic argument. (See [Kripke 1972].) Suppose that the descriptive equivalent of the name ‘Bill Gates’ is ‘the richest living person in the world’. An adequate semantic understanding of the sentence ‘Bill Gates is richer than everyone else alive’ would then be sufficient for recognition of its truth. (More precisely, the sentence, ‘If anyone is richer than everyone else alive, then Bill Gates is richer than everyone else alive’ has this feature.) But that seems implausible. Surely we must collect empirical data to determine its truth. One who wonders whether someone, say, Warren Buffett, is wealthier than Bill Gates does not display irrationality or semantic ignorance, comparable to one who wonders whether a fortnight is longer than 14 nights.

Perhaps these considerations should motivate the descriptivist to abandon “great deeds” descriptions in favor of metalinguistic descriptions like ‘the person named ‘Bill Gates’’ or causal descriptions like ‘the person that stands at the origin of this chain of uses of the name ‘Bill Gates’’. (For discussion, see [Bach 1981, 2002], [Kroon 1987], and [Lewis 1984].) It is plausible that semantic competence suffices to know that the sentence ‘Bill Gates is named ‘Bill Gates’’ is true and, while perhaps importing extra-semantic facts about language use, it is plausible that any reflective speaker of English knows that any token of ‘Bill Gates is the person that stands at the origin of this chain of uses of the name ‘Bill Gates’’ is true. So these descriptions seem to survive the semantic argument presented in the previous paragraph. But they face another objection, also facing simpler versions of descriptivism: Namely, the modal objection ([Kripke 1972]). While it is absolutely impossible that Bill Gates is not Bill Gates, it is, it seems, metaphysically possible that Bill Gates is not the richest person alive, instead being a middle American, and it seems metaphysically possible that he is not named ‘Bill Gates’ and does not stand at the causal origin of any particular chain of uses of the name ‘Bill Gates’, unless the chain is individuated in part in terms of the actual individual that grounds it. This suggests that ordinary proper names and their alleged descriptive equivalents considered above are not, in fact, semantically equivalent, as they embed differently under modals like ‘it is necessary that’. [See the entry on names for further discussion of these problems.]

In response to the modal argument, the descriptivist might avail herself of individual essence descriptions like ‘the person identical to Bill Gates’, ‘the person that Bill-Gatizes’, or rigidifications of the above descriptions, ‘the person actually named ‘Bill Gates’’ and ‘the person that actually stands at the origin of this chain of uses of the name ‘Bill Gates’’, all of which designate the same person in every possible world in which they designate anything. It is plausible that semantic competence suffices for recognition of the truth of the sentence ‘Bill Gates is the person identical to Bill Gates’ and that that sentence expresses a necessary truth. So these versions of descriptivism seem to escape the problems discussed in the previous paragraphs. The first two candidates, however, do not hold much promise for solving the problem of apparently true singular negative existentials. We know what the property of being identical to Bill Gates is, but only because we know the result of plugging up one of the relata in the two-place relation is identical to with the individual Bill Gates. Insofar as we think that reality does not include any entity identical to Ronald McDonald, however, we are then left to wonder what the property of being identical to Ronald McDonald is. Because the contents of these properties are derivative from the individuals that serve as the referents of their names, they are poor candidate descriptive equivalences for a robust version of descriptivism and unlikely to shed light on the truth of seemingly singular negative existentials like ‘Ronald McDonald does not exist’. Similar considerations apply to the predicating view. 

The last candidates, rigidified metalinguistic and causal descriptions, are the most promising for a robust form of descriptivism. But some have claimed to discern important differences in the functioning of a name and its alleged semantically equivalent rigidified description, of any flavor. First, some have claimed that the name ‘Bill Gates’ designates Bill Gates with respect to every possible world, including worlds at which Bill Gates does not exist; otherwise the sentence ‘Bill Gates does not exist’ would not be true with respect to those worlds. But the rigidified description ‘the person actually named ‘Bill Gates’’, for example, does not designate anything with respect to such a world, as nothing in the domain of that world satisfies the condition being named ‘Bill Gates’ at the actual world. That is because it is only Bill Gates that satisfies that condition and he is not a member of the domain of the possible world in question. So, differences in how a name and a rigidified description embed under modal operators can still be discerned. (See [Salmon 1981] for further discussion.) This objection assumes that the domain of quantification varies from world to world and that individuals that serve as the designation of ordinary names are genuine contingent existents, theses that can be denied. The objection also assumes that the range of the description is the domain of the world with respect to which the description is being evaluated, the actuality operator rigidifying only the condition of the description, which may also be denied. The second objection to rigidified descriptivism concerns the differences some have claimed between how names and rigidified descriptions embed under propositional attitude verbs. Intuitively, Jones would have still believed that Bill Gates is wealthy even if things had been ever so slightly different than they actually are—say, I bought a poppy bagel instead of a sesame bagel this morning. But if the content of Jones’s belief concerns the actual world, as rigidified descriptivism dictates, then, to retain his actual belief in that counterfactual situation, he would have to believe something about another possible world—the actual world. But it is implausible that Jones would have a belief about another possible world. So, the content of Jones’s belief does not concern the actual world and so one can believe what is expressed by ‘Bill Gates is wealthy’ without believing what is expressed by ‘The person that actually stands at the origin of this chain of uses of the name ‘Bill Gates’ is wealthy’. (See [Soames 1998].) 

This section examined the thesis that seemingly singular existential and negative existential sentences are really general existentials, which are then treated as ascribing the property of being instantiated or not instantiated to some property. The need to grant being to entities that do not exist in order to account for the truth of sentences like ‘Ronald McDonald does not exist’ is then avoided, which is no small victory. The success of that proposal, however, was seen to rest on the claim that ordinary proper names have descriptive equivalences, which many philosophers of language reject. (For more on the question of whether or not ‘exists’ is a genuine first-order predicate in deep logical form, see, in addition to the earlier references in this section: [Crane 2012], [Dancy 1986], [Geach 1954.1986], [Haaparanta 1986], [Hintikka 1984,1986], [Kneale 1936], [Mackie 1976], [McGinn 2000], [Miller 1975,1986] [Moltmamnn 2013], [Moore 1936], [Owen 1965], [Pears 1967], [Quine 1948], [van Inwagen 2008], [Vilkko and Hintikka 2006], [Wiggins 1995], [Williams 1981], and [Williams 1995].

2. Meinongianism
In part on the basis of the above discussed problems, many philosophers reject descriptivism and accept that ordinary proper names are devices of direct reference, that there are true genuinely singular negative existentials, and so that there are nonexistent objects. ‘Ronald McDonald’ seems like a referring term, open to existential generalization, in the sense that a sentence like ‘Ronald McDonald does not exist’ entails ‘There is something that does not exist’, and ‘exists’ seems like a predicate that applies or fails to apply to the designation of subject-place terms, on a par with a predicate like ‘sits’. The Meinongian embraces these appearances and concludes that reality includes referents for empty names and those referents do not exist. The Meinongian trades logical and semantic simplicity for metaphysical abundance.

Meinongianism is the thesis that there are objects that do not exist and so included in the most unrestricted domain of quantification and discourse are nonexistent entities. One immediate challenge for the Meinongian is to offer individuating conditions for nonexistents. The most straightforward comprehension principle is the naive principle that, for any condition on objects, there is a unique object satisfying exactly that condition. For our purposes, we can conceive of a condition as determining a set of properties; crudely, the properties expressed by the predicates composing the condition. In that case, condition C is the same condition as C′ when they determine the same set of properties. It follows that corresponding to any set of properties, there is exactly one object with exactly those properties. The naive comprehension principle faces several problems. In what remains of this section, we shall present these problems and distinguish different versions of Meinongianism in terms of the devices employed to develop a restricted comprehension principle for objects that avoids those problems. (All of these problems are developed in Russell’s discussion of Meinong, see [Russell 1905a, 1907]. For a discussion of the debate between Russell and Meinong, see [Smith 1985].)

The first is the problem of incomplete objects. Conditions need not be total; that is, we do not require that the set of properties a condition determines is such that, for every property, either it or its complement is a member of that set. So, by the naive comprehension principle, the condition of being a singer defines an object with exactly that property—being a singer—and no other properties. A set with other properties as well is a distinct set of properties and so corresponds to a different condition and hence a different object. Some find incomplete objects problematic in themselves, as they are counterexamples to bivalence: Our singer, for example, has neither the property of wearing a dress nor the property of not wearing a dress. But they also lead to more general threats of paradox. Our singer is an object with exactly one property: That of being a singer. This is its sole defining characteristic. So having a exactly one property is also a property of our singer and that property is distinct from the property of being a singer, which our singer also has. So, the singer has two properties. Contradiction. One simple solution is to restrict the comprehension principle to total conditions. The resulting proposal, however, leads to a questionable application of Meinongian metaphysics to problems of fictional truth, as many want to claim that there is simply no fact of the matter as to whether or not Sherlock Holmes has a mole on his left shoulder, as that is left underdetermined by the Holmes stories and there are no deeper grounds for either predication. The promise of employing nonexistent objects in explaining apparent truths about fiction is one of the theory’s main virtues. Relatedly, this solution undermines a primary motivation for Meinongianism—namely, the idea that there is a subject of predication corresponding to any object of thought, as we certainly do not think only of complete objects. So, the simple solution is too simple and the Meinongian is better to find another, more complex solution to the problems of incompleteness.

The second is the problem of contradiction. A naive comprehension principle generates objects that violate the principle of noncontradiction. Consider the condition of being taller than everything. By the naive comprehension principle, this condition determines an object and so there is an object that has exactly the property of being taller than everything. But then it is taller than itself, which is a contradiction given the irreflexivity of the taller than relation. The irreflexivity of the taller than relation is nonlogical. But not so with the identity relation, as = is typically taken to be a logical predicate. It is a logical truth that everything is self-identical; i.e., the sentence ∀x x=x is true under every interpretation. But consider the property of being self-distinct. By the naive comprehension principle this condition determines an object and that object is self-distinct. But then that object does not satisfy the condition x=x. So our logically true sentence has a counterinstance. Contradiction.

A third problem, one of Russell’s objections to Meinongianism (see [Russell 1905a, 1907]), turns on the fact that existence is, on Meinongianism, a property and hence figures into the base of the naive comprehension principle. So, consider the condition of being winged, being a horse, and existing. By the naive comprehension principle, there is an object with exactly these features. But then this object exists, as existing is one of its characterizing features. Intuitively, however, there is no existent winged horse. An existent object cannot so easily be thought into being. Indeed, for every intuitively nonexistent object that motivates Meinongianism—Zeus, Pegasus, Santa Clause, and Ronald McDonald—there is, by the naive abstraction principle, an object just like it but with the additional property of existing. But then there is an existing Zeus, an existing Pegasus, etc.. This is overpopulation not of being but of existence as well.

The naive comprehension principle, then, must be rejected and a restricted principle connecting sets of properties with objects be put in its place. The principle should generate enough objects to serve the Meinongian purpose of ensuring a corresponding object for every thought while avoiding the problems discussed above. We can distinguish two strategies, both suggested by Meinong’s student Ernst Mally [Mally 1912]. The first distinguishes two kinds of properties, what, following Terence Parsons [Parsons 1978, 1980], we shall call nuclear and extra-nuclear properties. While the distinction remains ultimately unclear, the key idea is that nuclear properties are part of a thing’s nature, broadly construed, and extra-nuclear properties are external to a thing’s nature; more precisely, nuclear properties, but not extra-nuclear properties, are part of the characterization of what the object is. The comprehension principle is then restricted to conditions involving only nuclear predicates. Problematic properties, like existing, etc., are deemed extra-nuclear and beyond the scope of the comprehension principle, not determining the objects that there are. Nuclear, not extra-nuclear, properties individuate objects. The second Meinongian camp distinguishes two modes of predication: What Mally called determining and satisfying, Hector-Neri Castañeda [Castañeda 1974, 1975,1978, 1980, 1986, 1989, 1990] called internal and external predication, William Rapaport [Rapaport 1978] called constituency and exemplification, Kit Fine [Fine 1982] called implicit and explicit, and Edward Zalta [Zalta 1983, 1988] called encoding and exemplifying. There is, on this view, a single class of properties that the comprehension principle ranges over, but the principle determines the properties encoded not exemplified (to follow Zalta’s terminology) by the object characterized. For every condition, there is a unique object that encodes just those properties. An object may or may not exemplify the properties it encodes. Sherlock Holmes encodes the properties of being a detective and living at 221B Baker Street, etc., but he does not exemplify those properties. He exemplifies (but does not encode) the properties of being a fictional character and being the hero of Arthur Conan Doyle’s Holmes stories. The properties an object exemplify are not, on this view, a matter of mere stipulation.

How do these distinctions solve the problems raised above for the naive comprehension principle? Let us begin with Parsons’s view. Parsons focuses on the problems of contradiction and of the existent winged horse. Following Russell’s discussion of Meinong, in [Russell 1905a, 1907], Parsons considers the threat of contradiction generated by impossible objects like the round square. Meinong claimed that there is a round square, but that, complained Russell, leads to violations of the principle of noncontradiction, as that entity is then both round and not round, in light of the fact that it is square, which entails that it is not round. Parsons’s response (see [Parsons 1980], 38–42) seems to be to deny that being square entails not being round, in which case it is simply false that the round square is not round. He thinks that that implication holds only for “real” objects. He claims that there are counterexamples to the claim that all square objects are not round; after all, the round square is a square object that is round! This solution, however, does not seem to solve the more general threat of contradiction, as discussed above. Indeed, Parsons himself recognizes the limited success of his response (see [Parsons, 1980, 42n8]). He allows that being non-squared is a nuclear property. But then his comprehension principle entails that there is an object corresponding to the condition of being a non-squared square, where that object instantiates the incompatible properties of being a square and being a non-square. The threat of contradiction has not been silenced.

Let’s turn to Parsons’s response to the existence problem. The naive comprehension principle faced the problem of generating an existent winged horse. Because existence is an extra-nuclear property, however, Parsons’s version of the comprehension principle, which correlates sets of only nuclear properties to objects, avoids this problem. The condition of being an existent winged horse is not composed solely of nuclear properties and so Parsons’s principle does not correlate it to an object. Parsons’s distinction between nuclear and extra-nuclear properties similarly promises to solve the problem of incomplete objects. Recall our singer from above. That object does not have exactly one property; instead, it has exactly one nuclear property. As having exactly one nuclear property is itself an extra-nuclear property, much as being a complete object is on Parsons’s view, the threat of contradiction is avoided. 

The distinction between nuclear and extra-nuclear properties remains unclear. Parsons introduced the distinction with lists of nuclear predicates (‘is blue’, ‘is tall’, ‘kicked Socrates’, ‘is a mountain’) and extra-nuclear predicates (‘exists’, ‘is thought about by Meinong’, ‘is complete’). He then tells us that the extra-nuclear are those that do not stand for properties of individuals ([Parsons 1980, 24]). And, of course, it is nuclear and not extra-nuclear properties by which objects are individuated. Parsons’s individuation principle for objects is the following: “(1) No two objects (real or unreal) have exactly the same nuclear properties; and (2) For any set of nuclear properties, some object has all the properties in that set and no other nuclear properties” ([Parsons 1980, 19]). But it is not clear what status individual identity properties—properties like being identical to A, where A is an individual substance like, say, Parsons himself—have with respect to this distinction. He sometimes claims that they are extra-nuclear properties ([Parsons 1980, 28]). In that case, however, Parsons is committed to the problematic thesis of the identity of indiscernibles and so the impossibility of two primitively distinct but qualitatively identical objects. (For further discussion, see the entry on the identity of indiscernibles.) Many contemporary philosophers agree that objects are not individuated qualitatively, their identity and diversity being primitive. Max Black’s two qualitatively indiscernible spheres are primitively distinct, in virtue of which one has the property of being that very thing and the other lacking that property (see [Black 1953]). For Parsons to accept this, he needs to include individual identity properties among the nuclear properties. Furthermore, it is hard to see why identity properties are not properties of individuals. Suppose, then, that we count individual identity properties like being identical to A as nuclear properties, those properties entering the range of Parsons’s restricted comprehension principle. Then the nuclear negations of those properties are also nuclear. But then we can take the set of all objects, construct the individual identity property for each, construct the nuclear negation of each of those properties, and then construct a condition from those properties that, by Parsons’s comprehension principle, corresponds to an object. Then there is an object that is distinct from every object that there is, which is a contradiction. It is unclear, then, that the distinction between nuclear and extra-nuclear properties and the restriction of the comprehension principle to nuclear properties solves the problems facing the naive comprehension principle. (For further discussion of Parsons’s view, see [Fine 1982, 1984] and [Zalta 1992].)

Earlier we distinguished between two versions of sophisticated Meinongianism. The first, based on the distinction between nuclear and extra-nuclear properties, was found lacking. We turn now to the second, based on the distinction between encoding and exemplifying a property, focusing on Zalta’s version of the view, which is the most fully developed in the literature. Whereas Parsons distinguished different kinds of properties, restricting the comprehension principle to only nuclear properties in the hope of thereby avoiding the problems plaguing the naive comprehension principle, Zalta distinguishes two different modes of having a property for the same effect. Exemplifying a property is the familiar way in which an individual has a property; it is roughly what most metaphysicians have in mind when the speak of instantiating a property. Obama exemplifies humanity, my chair exemplifies being comfortable, and the fig tree in my backyard exemplifies needing water. What the comprehension principle does is say not what properties object exemplify, in this sense, but rather what properties they encode. So, for any condition C on properties, there is an object that encodes exactly those properties, which leaves open whether or not those objects also exemplify those properties.

How does this distinction solve the problems facing Meinongianism presented earlier in this section? By the comprehension principle, the condition of being a singer determines an object with exactly that property. But the comprehension principle does not imply that that object exemplifies the property of being a singer but rather that it encodes that property. Exemplifying the property of being a singer requires exemplifying other properties like having a spatial location, having a voice box, etc., all properties our singer neither encodes nor exemplifies. But the object can encode the property of being a singer without encoding these further properties. The singer does exemplify some properties, such as the property of being abstract. The singer encodes the property of being a singer, does not encode the property of being abstract, and exemplifies multiple properties, including the property of being abstract, being the topic of this paragraph, and not being a singer. This is not contradictory given the fundamental difference between encoding and exemplifying. More generally, Zalta’s comprehension principle correlates sets of properties with objects that encode, not (necessarily) exemplify, those properties. Insofar as the set of properties characterizing an object are not complete, the resulting object will be incomplete with respect to the properties it encodes. But it need not be incomplete with respect to the properties it exemplifies. While our singer encodes neither the property of wearing blue shoes nor the property of not wearing blue shoes, we can say that it exemplifies the property of not wearing blue shoes. Bi-valence is saved, at least with respect to exemplification.

Restricting the comprehension principle to the properties encoded and rejecting an easy transfer between properties encoded and properties exemplified also promises to avoid the other threats of contradiction presented above. Recall the logically impossible condition of being self-distinct. The principle of noncontradiction concerns the properties objects exemplify, not the properties objects encode (assuming our Meinongian is going to account for impossible objects). Because an object can encode inconsistent properties without exemplifying them, impossible objects do not violate the principle of noncontradiction. Finally, Russell’s worry that a Meinongian comprehension principle generates existent winged horses can be answered. There is an object correlated to the condition of being an existent winged horse, but that object encodes and does not exemplify the property of existing. Being existent can characterize an object without that object exemplifying existence. So we do not need to worry about an overpopulation of existent beings, as existent beings exemplify existence, which the existent winged horse does not. 

A view based on the distinction between encoding and exemplifying avoids the standard objections to Meinongianism while promising to deliver that view’s many benefits. The semantics and logic is straightforward and simple and surface forms of the natural language sentences of interest in this article match their deep logical forms. But the ontological costs are evident. There is semantic and logical simplicity at a metaphysical price. (For more on Meingianism, in addition to the references earlier in this section, see the following: [Barz 2016], [Berto 2012], [Berto and Priest 2014], [Findlay 1963], [Griffin 1985], [Jacquette 1989, 1996], [Lambert 1983], [Landini 1990], [Lewis 1990],[Priest 2005],[Rapaport 1976, 1978,,1981], [Routley 1966, 1979, 1980], [Voltolini 1995, 2006], [Zalta 1983, 1985,1988,1992].)

3. An Anti-Meinongian First-Order View
The previous two sections discussed views that deny that existence is a property of individuals and views that deny that existence is a universal property. This section considers views according to which existence is a universal property of individuals, in the hope of reaping the benefits of both the earlier views. It then explores the interaction between quantifiers, tense operators, modal operators, and a universal, first-order existence predicate in an attempt to expose some difficulties such a view faces.

For both the Meinongian and the proponent of the proposal under consideration, proper names are directly referential and simple sentences in which they occur express singular propositions. However, unlike the Meinongian, a proponent of the view to be developed in this section insists that absolutely everything exists. In that case, a sentence like ‘Ronald McDonald does not exist’ either expresses a fully articulate singular proposition and so is false, as in that case there is a referent of the subject-place singular term which exists, or does not express a truth evaluative proposition at all, as the singular term lacks a semantic content. In neither case is the sentence true. Avoiding that consequence was a primary motivation behind all of the alternative accounts discussed in the previous two sections. The first challenge facing a proponent of such a view, then, is to explain how sentences like ‘Ronald McDonald does not exist’ are both meaningful and sometimes apparently true without abandoning the theses that absolutely everything exists and that all names are devices of direct reference.

One important suggestion, adopted by Saul Kripke (1973 [2013]), Peter Inwagen (1977, 1983, 2000, 2003), Nathan Salmon (1998), David Braun (1993, 2005), and Amie Thomasson (1999, 2003, 2009), among others, is that seemingly empty names like ‘Ronald McDonald’ refer to existent, albeit abstract, fictional characters. Fictional characters have both being and existence. (For a powerful critique of this form of fictional realism, see Hofweber 2000.) As we don’t run into them on the street, see them on the bus, or feel them in our beds, given their lack of spatiotemporal location, it is plausible that what a speaker means when she utters the sentence ‘Ronald McDonald does not exist’ is not the false proposition that that sentence expresses but instead the true proposition that (the fictional character) Ronald McDonald is not a real person or is not concrete. Indeed, this is suggested by the natural amendment, ‘‘Ronald McDonald does not exist; he’s a creation of advertisement!’’ On this view, then, there are no genuinely true singular negative existentials. All meaningful singular existentials are true and their negations false. We mistakenly take some singular negative existentials to be true because we conflate or do not sharply distinguish existing from being concrete. The benefit of this account is the simple semantics of proper names and the sparse metaphysics. The cost is revisionism regarding what we mean when we use apparently true singular negative existentials.

We conclude this section by briefly discussing issues that arise with the interaction between quantifiers, tense and modal operators, and a universal, first-order existence predicate, as this interaction is the source of another important cost of the account of existence being outlined in this section. There are two sets of intuitions that seem to pull in opposite directions. The first concerns the transience and contingency of existence. Things seem to come in and go out of existence through time. While Plato and Descartes used to exist, they no longer do; when Plato existed, Descartes did not yet exist; and right now the first child to be born in 2150 does not exist, but that individual will. So, it seems, different things exist at different times. Likewise, of the things that in fact exist, it seems that some of them might not have existed at all and different things—things that in fact do not exist—might have existed instead or in addition. So, it seems, different things exist at different worlds. These intuitions are quite robust. The second set of intuitions concern the ontological status of nonactual and nonpresent objects. Many philosophers are drawn to the thesis of actualism: The thesis that absolutely everything is actual and how an object is simpliciter is how it actually is, unactualized possibilities for an object being in some sense hypothetical ways of being for that object. While less popular, many philosophers accept the temporal analog of actualism, the thesis of presentism, according to which absolutely everything is present and how an object is simpliciter is how it presently is, how an object was and will be are in some sense hypothetical ways of being for that object. These two sets of intuitions combined with the view of existence under consideration in this section lead to difficulties.

Let’s begin with the modal problem. There could have been an object distinct from all actually existing objects. For example, I could have had a brother and, given origin essentialism, if I had a brother, he would have been distinct from every actually existing objects, as no actually existing thing could have been my brother. Our intuitions concerning how things might have been lead us to accept this claim as true. But, by the thesis of actualism, absolutely everything is actual and, by our view of existence, exists and so actually exists. So, it seems that actualism and our view of existence are incompatible with the intuitive possibility of there being an object distinct from all existing objects and the intuition that I might have had a brother.

We can regiment the contingency of existence intuition as followings, letting A be the actuality operator, where Aφ is true with respect to a world w under an interpretation I just in case φ is true with respect to the distinguished world of I: ◊∃x¬A∃y(y=x). Call this sentence Alien. The worry is that the truth of Alien carries ontological commitment to merely possible individuals and so the falsity of the thesis of actualism. One way to substantiate this worry is to invoke the Barcan Formula, or one of the mixing axioms proposed for modal operators and quantifiers in Ruth Barcan Marcus’s groundbreaking work in quantified modal logic [Marcus 1946], according to which all instances of the sentence ◊∃xφ(x) →∃x◊φ(x) are logical true. (In the foregoing formulas, φ(x) stands for any formula in which the variable x may or may not be free.) We can then transpose the modal and quantifier in Alien to derive ∃x◊¬A∃y(y=x). The truth of this second sentence evidently requires that there is something that is not actual, contrary to the dictates of actualism. The Barcan Formula, and in part for this very reason, is controversial and rejected by those that subscribe to a varying domains possible worlds semantics for modal discourse. So this line of argument is not likely to convince everyone that our modal intuitions lead to problems.

The Barcan Formula is controversial. There is, however, a second line of argument that does not rest on the validity of the Barcan Formula, relying instead on combining standard truth definitions for quantified and modal sentences in the most straightforward way. Alien is true under an interpretation I just in case there is a world w accessible from the distinguished world of I with an object in its domain that is not in the domain of the distinguished world of I. This is because its truth requires that ∃x¬A∃y(y=x) is true with respect to w and so, it is tempting to conclude, that there is a witness that satisfies the condition ¬A∃y(y=x) at w. But that is the rub. If actualism is true, then there is no such witness, even if there could have been. If we are realistic about possible worlds semantics, the model theory for modal talk itself does not contain primitive modality, instead containing worlds as points of evaluation and the notion of truth at a world, in which case ‘there is’ in the above truth recursion does not occur inside the scope of a possibility operator. So, if Alien is true, there is some object o and accessible possible world w such that o satisfies ¬A∃y(y=x) at w, which seems to run contrary to the thesis of actualism, as that witness does not actually exist. (For further discussion of this problem and some of the solutions considered below, see the entry on the possibilism-actualism debate.)

One solution is to abandon actualism and accept that there are merely possible objects. According to this possibilist position, merely possible objects are among the most unrestricted domain of quantification, being constituents of fundamental reality. While this position deserves serious consideration, let us set it aside and explore only actualist solutions. (The position is structurally similar to the Meinongian position, as the most inclusive domain of quantification, where there is in the most inclusive and unrestricted of senses, includes entities that do not actually exist, even if they exist simplicter.) A second solution rests on the Meinongian distinction between being, in the sense of being a member of the most inclusive domain of quantification and discourse, and existing and the claim that there are objects that do not exist. Armed with a Meinongian metaphysics, we can reject Alien as capturing the intuition that existence is contingent, opting instead for the following sentence as doing that, where E!x is the Meinongian logically primitive existence predicate: ∃x(¬E!x ∧ ◊E!x). The Meinongian can then deny Alien and appeal to the truth of this sentence to explain our intuitions concerning the contingency of existence. Everything is actual, on this view, although some of those actual things do not exist but could have, even though they all have being and the domain of being is fixed across all possible worlds. This solution to our problems, however, is unavailable to a proponent of the view that existence is a universal property of individuals.

Bernard Linsky and Edward Zalta [Linsky and Zalta 1994] present a novel solution to this problem that promises to be consistent with the tenets of the view of existence under consideration in this section. (A similar account is defended by Timothy Williamson [Williamson 1998, 1999a [2000], 1999b, 2000, 2002, 2013]. For a very interesting discussion of Williamson, see [Goodman 2016].) Consider the intuitive possibility that I have a brother. An entity that encodes the property of being my brother actually exists, but as a nonconcrete object. That object is only contingently nonconcrete; it could have been concrete, and had it been concrete, it would have exemplified the property of being my brother (along with the other properties that it encodes and the necessary consequences thereof). On this view, my possible brother (as well as any alleged merely possible object) actually exists, but as a nonconcrete individual that could have been concrete. The view is both actualist, as absolutely everything is actual, and anti-Meinongian, as absolutely everything exists. Note, however, that Alien, the sentence two paragraphs above purported to capture our intuitions concerning the contingency of existence, is false on this view, as every individual is a necessary existent. Instead, our intuition that what there is is contingent is to be explained in terms of the contingency of what is concrete and nonconcrete. So, where C!x is a logically primitive predicate of concreteness, it is the truth of the following sentence, not Alien, that explains those intuitions: ∃x(¬C!x ∧ ◊C!x). While the explanation of the contingency of existence bears a structural similarity to the Meinongian explanation discussed in the previous paragraph, the metaphysics is importantly different and so the two views should not be collapsed. Linsky and Zalta describe a non-Meinongian, actualist view that treats existence as a universal property of individuals.

Linsky and Zalta’s view entails that concreteness is an accidental property, in the sense that the self-same individual that is in fact nonconcrete (my possible brother, for example) could have been concrete and the self-same individual that is in fact concrete (both you and me, for example) could have been nonconcrete. Many metaphysicians will reject this on the grounds that concreteness is categorical and an individual does not migrate through categorical properties across modal space. But now consider the temporal analog of the modal issues with existence and concreteness that we have been exploring: The problem of temporary existents. While one’s accounts of the two problems do not need to swing together (Linsky and Zalta, for example, do not offer the temporal analog of their account of contingent existents), as there are differences between alethic modality and temporality, it is useful to consider them as a pair for our purposes. Intuitively things come in and go out of existence; what exists at one time does not exist at another. The temporal analog of Linsky and Zalta’s view of contingent existents entails that everything always exists. What there is and what exists at one time is the same as what is and what exists at any other time; the domain of quantification is fixed across all times. What varies from time to time is instead which of those individuals are concrete. Socrates still exists now, although as a nonconcrete individual, who was concrete in 450 BCE, and similarly for the first child to be born in 2150. This view requires that a thing can survive the change from being nonconcrete to concrete, which is the explanation of what the ancients would call generation, and the change from being concrete to nonconcrete, which is the explanation of what the ancients would call destruction. On this view, then, seeming substantial changes are really forms of qualitative change: A change in the quality of concreteness. This runs contrary to the common conception that concreteness is necessary and eternal to any object that instantiates it, the divide between concrete and nonconcrete individuals marking a divide between categories of being. Many metaphysicians insist that, just as one and the same thing cannot go from being an individual to being a property, so too one and the same thing cannot go from being nonconcrete to being concrete.

What are the prospects of a theory according to which existence is a universal, genuinely contingent and transient property of individuals? Such a view requires that the domain of quantification varies from world to world and time to time, as everything that is exists but different individuals exist at different possible worlds and at different times, in which case the domain of quantification varies from world to world and time to time. In that case, Alien from above is true. So fault must be found with the earlier argument that the truth of Alien is inconsistent with the thesis of actualism. One response found in the literature rejects the last step, insisting that there are general claims that could have been true, and so are true at some accessible possible world, without there being specific instances of those claims that are true at those accessible worlds. In nonmodal environments, the quantified sentence ∃xφ(x) is true just in case there is some witness o that satisfies the condition φ(x). That condition fails, however, for quantified sentences true at a merely possible world. The model theory for a model language—with its space of possible worlds and individuals populating the domains of possible worlds—contains, like everything else if actualism is true, only actually existing entities. Still, sentences like Alien are true and so there are merely possible worlds at which ∃x¬A∃y(y=x) is true. There is no individual of which ¬A∃y(y=x) is true in virtue of which the quantified sentence is true, although there would have been had that merely possible world been actual. This is perhaps more clear when we turn from sentences being true with respect to merely possible worlds to propositions being true at merely possible worlds. There is a world w at which the existential proposition [there is something such that there is no actual thing identical to it] is true but there is no singular proposition [there is no actual thing identical to o] true at w as there is no such entity o. Had w been actual, however, then there would have been such an entity and it is this fact that grounds the truth of the existential proposition at w. (The classic source for this distinction is [Adams 1981]. See also [Fine 1985] and [Fitch 1996].) This suggestion, then, runs contrary to the standard semantics for quantificational sentences, which reduces the truth or falsity of existential and universal sentences to the truth or falsity of their instances, when extending that semantics to truth at a world. The suggestion also requires a distinction between truth at a world, in terms of which the model theory for modal operators is given, and truth in a world, which involves the notion of considering what would have been had a nonactual world been actual. (For more on this distinction and the problem of the contingency of existence more generally, see the entry on the on possibilism-actualism debate.)

4. Conclusion
This entry began by noting that existence raises a number of deep and important problems in metaphysics, philosophy of language, and philosophical logic. The entry has examined some of those problems and surveyed a number of different accounts of existence. None of the theories surveyed is wholly satisfying and without cost. The first view proposed by Frege and Russell treats existence as a second-order property and assimilates seemingly singular existentials to general existentials. The proposal requires descriptivism, the thesis that ordinary proper names have descriptive equivalences, which many find to be a problematic thesis. The second Meinongian view requires countenancing individuals that do not exist. We have seen the view face challenges in giving coherent and yet informative and compelling individuation principles for nonexistent individuals and all versions of the view suffer from the problem of metaphysical overpopulation. Finally, the naive view that existence is a universal property of individuals was presented. That view faced the problem of having to reject the truth of highly intuitively true singular negative existential sentences like ‘Ronald McDonald does not exist’. The view also faces difficulties in properly accounting for the interaction of quantifiers and modal and tense operators. Existence remains, then, itself a serious problem in philosophy of language, metaphysics, and logic and one connected to some of the deepest and most important problems in those areas.

1. History and Definitions of Social Networking Services
‘Social networking’ is an inherently ambiguous term requiring some clarification. Human beings have been socially ‘networked’ in one manner or another for as long as we have been on the planet, and we have historically availed ourselves of many successive techniques and instruments for facilitating and maintaining such networks. These include structured social affiliations and institutions such as private and public clubs, lodges and churches as well as communications technologies such as postal and courier systems, telegraphs and telephones. When philosophers speak today, however, of ‘Social Networking and Ethics’, they usually refer more narrowly to the ethical impact of an evolving and loosely defined group of information technologies, most based on or inspired by the ‘Web 2.0’ software standards that emerged in the first decade of the 21st century. While the most widely used social networking services are free, they operate on large platforms that offer a range of related products and services that underpin their business models, from targeted advertising and data licensing to cloud storage and enterprise software. Ethical impacts of social networking services are loosely clustered into three categories – direct impacts of social networking activity itself, indirect impacts associated with the underlying business models that are enabled by such activity, and structural implications of SNS as novel sociopolitical and cultural forces.

1.1 Online Social Networks and the Emergence of ‘Web 2.0’
Prior to the emergence of Web 2.0 standards, the computer had already served for decades as a medium for various forms of social networking, beginning in the 1970s with social uses of the U.S. military’s ARPANET and evolving to facilitate thousands of Internet newsgroups and electronic mailing lists, BBS (bulletin board systems), MUDs (multi-user dungeons) and chat rooms dedicated to an eclectic range of topics and social identities (Barnes 2001; Turkle 1995). These early computer social networks were systems that grew up organically, typically as ways of exploiting commercial, academic or other institutional software for more broadly social purposes. In contrast, Web 2.0 technologies evolved specifically to facilitate user-generated, collaborative and shared Internet content, and while the initial aims of Web 2.0 software developers were still largely commercial and institutional, the new standards were designed explicitly to harness the already-evident potential of the Internet for social networking. Most notably, Web 2.0 social interfaces redefined the social topography of the Internet by enabling users to build increasingly seamless connections between their online social presence and their existing social networks offline—a trend that shifted the Internet away from its earlier function as a haven for largely anonymous or pseudonymous identities forming sui generis social networks (Ess 2011).

Starting in the first decade of the 21st century, among the first websites to employ the new standards explicitly for general social networking purposes were Orkut, MySpace, LinkedIn, Friendster, Bebo, Habbo and Facebook. Subsequent trends in online social networking include the rise of sites dedicated to media and news sharing (YouTube, Reddit, Flickr, Instagram, Vine, Snapchat, TikTok), microblogging (Tumblr, Twitter, Weibo), location-based networking (Foursquare, Loopt, Yelp, YikYak), messaging and VoIP (WhatsApp, Messenger, WeChat), social gaming (Steam, Twitch) and interest-sharing (Pinterest).

1.2 Early Scholarly Engagement with Social Networking Services
Study of the ethical implications of SNS was initially seen as a subpart of Computer and Information Ethics (Bynum 2018). While Computer and Information Ethics certainly accommodates an interdisciplinary approach, its direction and problems were initially largely defined by philosophically-trained scholars such as James Moor (1985) and Deborah G. Johnson (1985). Yet this has not been the early pattern for the ethics of social networking. Partly due to the coincidence of the social networking phenomenon with the emerging interdisciplinary social science field of ‘Internet Studies’ (Consalvo and Ess, 2011), the ethical implications of social networking technologies were initially targeted for inquiry by a loose coalition of sociologists, social psychologists, anthropologists, ethnographers, law and media scholars and political scientists (see, for example, Giles 2006; Boyd 2007; Ellison et al. 2007; Ito 2009). Consequently, philosophers who have turned their attention to social networking and ethics have had to decide whether to pursue their inquiries independently, drawing primarily from traditional philosophical resources in applied computer ethics and the philosophy of technology, or to develop their views in consultation with the growing body of empirical data and conclusions already being generated by other disciplines. While this entry will primarily confine itself to reviewing existing philosophical research on social networking ethics, links between those researches and studies in other disciplinary contexts remain vital.

Indeed, recent academic and popular debates about the harms and benefits of large social media platforms have been driven far more visibly by scholars in sociology (Benjamin 2019), information studies (Roberts 2019), psychology (Zuboff 2019) and other social sciences than by philosophers, who remain comparatively disengaged. In turn, rather than engage with philosophical ethics, social science researchers in this field typically anchor normative dimensions of their analyses in broader political frameworks of justice and human rights, or psychological accounts of wellbeing. This has led to a growing debate about whether philosophical ‘ethics’ remains the right lens through which to subject social networking services or other emerging technologies to normative critique (Green 2021, Other Internet Resources). This debate is driven by several concerns. First is the growing professionalization of applied ethics (Stark and Hoffmann 2019) and its perceived detachment from social critique. A second concern is the trend of insincere corporate appropriation of the language of ethics for marketing, crisis management and public relations purposes, known as ‘ethicswashing’ (Bietti 2020). Finally, there is the question of whether philosophical theories of ethics, which have traditionally focused on individual actions, are sufficiently responsive to the structural conditions of social injustice that drive many SNS-associated harms.

2. Early Philosophical Concerns about Online Social Networks
Among the first philosophers to take an interest in the ethical significance of social uses of the Internet were phenomenological philosophers of technology Albert Borgmann and Hubert Dreyfus. These thinkers were heavily influenced by Heidegger’s (1954 [1977]) view of technology as a monolithic force with a distinctive vector of influence, one that tends to constrain or impoverish the human experience of reality in specific ways. While Borgmann and Dreyfus were primarily responding to the immediate precursors of Web 2.0 social networks (e.g., chat rooms, newsgroups, online gaming and email), their conclusions, which aim at online sociality broadly construed, are directly relevant to SNS.

2.1 Borgmann’s Critique of Social Hyperreality
Borgmann’s early critique (1984) of modern technology addressed what he called the device paradigm, a technologically-driven tendency to conform our interactions with the world to a model of easy consumption. By 1992’s Crossing the Postmodern Divide, however, Borgmann had become more narrowly focused on the ethical and social impact of information technologies, employing the concept of hyperreality to critique (among other aspects of information technology) the way in which online social networks may subvert or displace organic social realities by allowing people to “offer one another stylized versions of themselves for amorous or convivial entertainment” (1992, 92) rather than allowing the fullness and complexity of their real identities to be engaged. While Borgmann admits that in itself a social hyperreality seems “morally inert” (1992, 94), he insists that the ethical danger of hyperrealities lies in their tendency to leave us “resentful and defeated” when we are forced to return from their “insubstantial and disconnected glamour” to the organic reality which “with all its poverty inescapably asserts its claims on us” by providing “the tasks and blessings that call forth patience and vigor in people.” (1992, 96)

There might be an inherent ambiguity in Borgmann’s analysis, however. On the one hand he tells us that it is the competition with our organic and embodied social presence that makes online social environments designed for convenience, pleasure and ease ethically problematic, since the latter will inevitably be judged more satisfying than the ‘real’ social environment. But he goes on to claim that online social environments are themselves ethically deficient:

Those who become present via a communication link have a diminished presence, since we can always make them vanish if their presence becomes burdensome. Moreover, we can protect ourselves from unwelcome persons altogether by using screening devices….The extended network of hyperintelligence also disconnects us from the people we would meet incidentally at concerts, plays and political gatherings. As it is, we are always and already linked to the music and entertainment we desire and to sources of political information. This immobile attachment to the web of communication works a twofold deprivation in our lives. It cuts us off from the pleasure of seeing people in the round and from the instruction of being seen and judged by them. It robs us of the social resonance that invigorates our concentration and acumen when we listen to music or watch a play.…Again it seems that by having our hyperintelligent eyes and ears everywhere, we can attain world citizenship of unequaled scope and subtlety. But the world that is hyperintelligently spread out before us has lost its force and resistance. (1992, 105–6)
Critics of Borgmann saw him as adopting Heidegger’s (1954 [1977]) substantivist, monolithic model of technology as a singular, deterministic force in human affairs (Feenberg 1999; Verbeek 2005). This model, known as technological determinism, represents technology as an independent driver of social and cultural change, shaping human institutions, practices and values in a manner largely beyond our control. Whether or not this is ultimately Borgmann’s view (or Heidegger’s), his critics saw it in remarks of the following sort: “[Social hyperreality] has already begun to transform the social fabric…At length it will lead to a disconnected, disembodied, and disoriented sort of life…It is obviously growing and thickening, suffocating reality and rendering humanity less mindful and intelligent.” (Borgmann 1992, 108–9)

Critics asserted that Borgmann’s analysis suffered from his lack of attention to the substantive differences between particular social networking technologies and their varied contexts of use, as well as the different motivations and patterns of activity displayed by individual users in those contexts. For example, Borgmann neglected the fact that physical reality does not always enable or facilitate connection, nor does it do so equally for all persons. For example, those who live in remote rural areas, neurodivergent persons, disabled persons and members of socially marginalized groups are often not well served by the affordances of physical social spaces. As a consequence, Andrew Feenberg (1999) claims that Borgmann overlooked how online social networks can supply sites of democratic resistance for those who are physically or politically disempowered by many ‘real-world’ networks.

2.2 Hubert Dreyfus on Internet Sociality: Anonymity versus Commitment
Philosopher Hubert Dreyfus (2001) shared Borgmann’s early critical suspicion of the ethical possibilities of the Internet; like Borgmann, Dreyfus’s reflections on the ethical dimension of online sociality conveyed a view of such networks as an impoverished substitute for the real thing. Like Borgmann, Dreyfus’s suspicion was informed by his phenomenological roots, which led him to focus his critical attention on the Internet’s suspension of fully embodied presence. Yet rather than draw upon Heidegger’s metaphysical framework, Dreyfus (2004) reached back to Kierkegaard in forming his criticisms of life online. Dreyfus asserts that what online engagements intrinsically lack is exposure to risk, and without risk, Dreyfus tells us, there can be no true meaning or commitment found in the electronic domain. Instead, we are drawn to online social environments precisely because they allow us to play with notions of identity, commitment and meaning, without risking the irrevocable consequences that ground real identities and relationships. As Dreyfus put it:

…the Net frees people to develop new and exciting selves. The person living in the aesthetic sphere of existence would surely agree, but according to Kierkegaard, “As a result of knowing and being everything possible, one is in contradiction with oneself” (Present Age, 68). When he is speaking from the point of view of the next higher sphere of existence, Kierkegaard tells us that the self requires not “variableness and brilliancy,” but “firmness, balance, and steadiness” (Dreyfus 2004, 75)
While Dreyfus acknowledges that unconditional commitment and acceptance of risk are not excluded in principle by online sociality, he insists that “anyone using the Net who was led to risk his or her real identity in the real world would have to act against the grain of what attracted him or her to the Net in the first place” (2004, 78).

2.3 Contemporary Reassessment of Early Phenomenological Critiques of SNS
While Borgmann and Dreyfus’s views continue to inform the philosophical conversation about social networking and ethics, both of these early philosophical engagements with the phenomenon manifest certain predictive failures (as is perhaps unavoidable when reflecting on new and rapidly evolving technological systems). Dreyfus did not foresee the way in which popular SNS such as Facebook, LinkedIn and Twitter would shift away from the earlier online norms of anonymity and identity play, instead giving real-world identities an online presence which in some ways is less ephemeral than bodily presence (as those who have struggled to erase online traces of past tweets or to delete Facebook profiles of deceased loved ones can attest).

Likewise, Borgmann’s critiques of “immobile attachment” to the online datastream did not anticipate the rise of mobile social networking applications which not only encourage us to physically seek out and join our friends at those same concerts, plays and political events that he envisioned us passively digesting from an electronic feed, but also enable spontaneous physical gatherings in ways never before possible. That said, such short-term predictive failures may not, in the long view, turn out to be fatal to their legacies. After all, some of the most enthusiastic champions of the Internet’s liberating social possibilities to be challenged by Dreyfus (2004, 75), such as Sherry Turkle, have since articulated far more pessimistic views of the trajectory of new social technologies. Turkle’s concerns about social media in particular (2011, 2015), namely that they foster a peculiar alienation in connectedness that leaves us feeling “alone together,” resonate well with Borgmann’s earlier warnings about electronic networks.

2.3.1 Borgmann, Dreyfus and the ‘Cancel Culture’ Debates
The SNS phenomenon continues to be ambiguous with respect to confirming Borgmann and Dreyfus’ early predictions. One of their most unfounded worries was that online social media would lead to a culture in which personal beliefs and actions are stripped of enduring consequence, cut adrift from real-world identities as persons accountable to one another. Today, no regular user of Twitter or Reddit is cut off from “the instruction of being seen and judged” (Borgmann 1992). And contra Dreyfus, it is primarily through the power of social media that people’s identities in the real world are now exposed to greater risk than before – from doxing to loss of employment to being physically endangered by ‘swatting.’

If anything, contemporary debates about social media’s alleged propagation of a stifling ‘cancel culture,’ which bend back upon the philosophical community itself (Weinberg 2020, Other Internet Resources), reflect growing anxieties among many that social networking environments primarily lack affordances for forgiveness and mercy, not judgment and personal accountability. Yet others see the emergent phenomenon of online collective judgment as performing a vital function of moral and political levelling, one in which social media enable the natural ethical consequences of an agent’s speech and acts to at last be imposed upon the powerful, not merely the vulnerable and marginalized.

2.3.2. The Civic Harms of Social Hyperreality
One aspect of Borgmann’s (1992) account has recently rebounded in plausibility; namely, his prediction of a dire decline in civic virtues among those fully submerged in the distorted political reality created by the disembodied and disorienting ‘hyperintelligence’ of online social media. In the wake of the 2016 UK and US voter manipulation by foreign armies of social media bots, sock puppets, and astroturf accounts, the world has seen a rapid global expansion and acceleration of political disinformation and conspiracy theories through online social networks like Facebook, Twitter, YouTube and WhatsApp.

The profound harms of the ‘weaponization’ of social media disinformation go well beyond voter manipulation. In 2020, disinformation about the COVID-19 pandemic greatly impeded public health authorities by clouding the public’s perception of the severity and transmissibility of the virus as well as the utility of prophylactics such as mask-wearing. Meanwhile, the increasing global influence of ever-mutating conspiracy theories borne on social media platforms by the anonymous group QAnon suggests that Borgmann’s warning of the dangers of our rising culture of ‘hyperreality,’ long derided as technophobic ‘moral panic,’ was dismissed far too hastily. While the notorious ‘Pizzagate’ episode of 2016 (Miller 2021) was the first visible link between QAnon conspiracies and real-world violence, the alarming uptake in 2020 of QAnon conspiracies by violent right-wing militias in the United States led Facebook and Twitter to abandon their prior tolerance of the movement and ban or limit access to hundreds of thousands of QAnon-associated accounts.

Such moves came too late to stabilize the epistemic and political rift in a shared reality. By late 2020, QAnon had boosted a widely successful effort by supporters of outgoing President Donald Trump to create a (manifestly false) counter-narrative around the 2020 election purporting that he had actually won, leading to a failed insurrection at the U.S. Capitol on January 6, 2021. Borgmann’s warnings on ‘hyperreality’ seem less like moral panic and more like prescience when one considers the existence of a wide swath of American voters who remain convinced that Donald Trump remains legitimately in office, directing actions against his enemies. Such counter-narratives are not merely ‘underground’ belief systems; they compete directly with reality itself. On June 17, 2021, the mainstream national newspaper USA Today found it necessary to publish a piece titled “Fact Check: Hilary Clinton was not hanged at Guantanamo Bay” (Wagner 2021) in response to a video being widely shared on the social media platforms TikTok and Instagram, which describes in fine detail the (very much alive) Clinton’s last meal.

Borgmann’s long-neglected work on social hyperreality thus merits reevaluation in light of the growing fractures and incoherencies that now splinter and twist our digitally mediated experience of what remains, underneath it all, a common world. The COVID-19 pandemic and increasingly catastrophic impacts of climate change testify to humanity’s vital need to remain anchored in and intelligently responsive to a shared physical reality.

Yet both the spread of social media-driven disinformation and the rise of online moral policing reveal an unresolved philosophical tension that Borgmann’s own work did not explicitly confront. This is the Concept of Toleration and its Paradoxes, which continue to bedevil modern political thought. Social networking services have transformed this festering concern of political philosophy into something verging on an existential crisis. When malice and madness can be amplified on a global scale at lightspeed, in a manner affordable and accessible to anyone with a smartphone or wifi connection, what is too injurious and too irremediable, to be said, or shared (Marin 2021)?

Social media continue to drive a range of new philosophical investigations in the domains of social epistemology and ethics, including ‘vice epistemology’ (Kidd, Battaly, Cassam 2020). Such investigations raise urgent questions about the relationship between online disinformation/misinformation, individual moral and epistemic responsibility, and the responsibility of social media platforms themselves. On this point, Regina Rini (2017) has argued that the problem of online disinformation/misinformation is not properly conceived in terms of individual epistemic vice, but rather must be seen as a “tragedy of the epistemic commons” that will require institutional and structural solutions.

3. Contemporary Ethical Concerns about Social Networking Services
While early SNS scholarship in the social and natural sciences tended to focus on SNS impact on users’ psychosocial markers of happiness, well-being, psychosocial adjustment, social capital, or feelings of life satisfaction, philosophical concerns about social networking and ethics have generally centered on topics less amenable to empirical measurement (e.g., privacy, identity, friendship, the good life and democratic freedom). More so than ‘social capital’ or feelings of ‘life satisfaction,’ these topics are closely tied to traditional concerns of ethical theory (e.g., virtues, rights, duties, motivations and consequences). These topics are also tightly linked to the novel features and distinctive functionalities of SNS, more so than some other issues of interest in computer and information ethics that relate to more general Internet functionalities (for example, issues of copyright and intellectual property).

Despite the methodological challenges of applying philosophical theory to rapidly shifting empirical patterns of SNS influence, philosophical explorations of the ethics of SNS have continued in recent years to move away from Borgmann and Dreyfus’ transcendental-existential concerns about the Internet, to the empirically-driven space of applied technology ethics. Research in this space explores three interlinked and loosely overlapping kinds of ethical phenomena:

direct ethical impacts of social networking activity itself (just or unjust, harmful or beneficial) on participants as well as third parties and institutions;
indirect ethical impacts on society of social networking activity, caused by the aggregate behavior of users, platform providers and/or their agents in complex interactions between these and other social actors and forces;
structural impacts of SNS on the ethical shape of society, especially those driven by the dominant surveillant and extractivist value orientations that sustain social networking platforms and culture.
Most research in the field, however, remains topic- and domain-driven—exploring a given potential harm or domain-specific ethical dilemma that arises from direct, indirect, or structural effects of SNS, or more often, in combination. Sections 3.1–3.5 outline the most widely discussed of contemporary SNS’ ethical challenges.

3.1 Social Networking Services and Privacy
Fundamental practices of concern for direct ethical impacts on privacy include: the transfer of users’ data to third parties for intrusive purposes, especially marketing, data mining, and surveillance; the use of SNS data to train facial-recognition systems or other algorithmic tools that identify, track and profile people without their free consent; the ability of third-party applications to collect and publish user data without their permission or awareness; the dominant reliance by SNS on opaque or inadequate privacy settings; the use of ‘cookies’ to track online user activities after they have left a SNS; the abuse of social networking tools or data for stalking or harassment; widespread scraping of social media data by academic researchers for a variety of unconsented purposes; undisclosed sharing of user information or patterns of activity with government entities; and, last but not least, the tendency of SNS to foster imprudent, ill-informed or unethical information sharing practices by users, either with respect to their own personal data or data related to other persons and entities. Facebook has been a particular lightning-rod for criticism of its privacy practices (Spinello 2011, Vaidhyanathan 2018), but it is just the most visible member of a far broader and more complex network of SNS actors with access to unprecedented quantities of sensitive personal data.

Indirectly, the incentives of social media environments create particular problems with respect to privacy norms. For example, since it is the ability to access information freely shared by others that makes SNS uniquely attractive and useful, and since platforms are generally designed to reward disclosure, it turns out that contrary to traditional views of information privacy, giving users greater control over their information-sharing practices can actually lead to decreased privacy for themselves and others in their network. Indeed, advertisers, insurance companies and employers are increasingly less interested in knowing the private facts of individual users’ lives, and more interested in using their data to train algorithms that can predict the behavior of people very much like that user. Thus the real privacy risk of our social media practices is often not to ourselves but to other people; if a person is comfortable with the personal risk of their data sharing habits, it does not follow that these habits are ethically benign. Moreover, users are still caught in the tension between their personal motivations for using SNS and the profit-driven motivations of the corporations that possess their data (Baym 2011, Vaidhyanathan 2018). Jared Lanier frames the point cynically when he states that: “The only hope for social networking sites from a business point of view is for a magic formula to appear in which some method of violating privacy and dignity becomes acceptable” (Lanier 2010).

Scholars also note the way in which SNS architectures are often structurally insensitive to the granularity of human sociality (Hull, Lipford & Latulipe 2011). That is, such architectures tend to treat human relations as if they are all of a kind, ignoring the profound differences among types of social relation (familial, professional, collegial, commercial, civic, etc.). As a consequence, the privacy controls of such architectures often flatten the variability of privacy norms within different but overlapping social spheres. Among philosophical accounts of privacy, Nissenbaum’s (2010) view of contextual integrity has seemed to many to be particularly well suited to explaining the diversity and complexity of privacy expectations generated by new social media (see for example Grodzinsky and Tavani 2010; Capurro 2011). Contextual integrity demands that our information practices respect context-sensitive privacy norms, where ‘context’ refers not to the overly coarse distinction between ‘private’ and ‘public,’ but to a far richer array of social settings characterized by distinctive roles, norms and values. For example, the same piece of information made ‘public’ in the context of a status update to family and friends on Facebook may nevertheless be considered by the same discloser to be ‘private’ in other contexts; that is, she may not expect that same information to be provided to strangers Googling her name, or to bank employees examining her credit history.

On the design side, such complexity means that attempts to produce more ‘user-friendly’ privacy controls face an uphill challenge—they must balance the need for simplicity and ease of use with the need to better represent the rich and complex structures of our social universes. A key design question, then, is how SNS privacy interfaces can be made more accessible and more socially intuitive for users.

Hull et al. (2011) also take note of the apparent plasticity of user attitudes about privacy in SNS contexts, as evidenced by the pattern of widespread outrage over changed or newly disclosed privacy practices of SNS providers being followed by a period of accommodation to and acceptance of the new practices (Boyd and Hargittai 2010). In their 2018 book Re-Engineering Humanity, Brett Frischmann and Evan Selinger argue that SNS contribute to a slippery slope of “techno-social engineering creep” that produces a gradual normalization of increasingly pervasive and intrusive digital surveillance. A related concern is the “privacy paradox,” in which users’ voluntary sharing of data online belies their own stated values concerning privacy. However, recent data from Apple’s introduction in iOS 14.5 of opt-in for ad tracking, which the vast majority of iOS users have declined to allow, suggests that most people continue to value and act to protect their privacy, when given a straightforward choice that does not inhibit their access to services (Axon 2021). Working from the late writings of Foucault, Hull (2015) has explored the way in which the ‘self-management’ model of online privacy protection embodied in standard ‘notice and consent’ practices only reinforces a narrow neoliberal conception of privacy, and of ourselves, as commodities for sale and exchange. The debate continues about whether privacy violations can be usefully addressed by users making wiser privacy-preserving choices (Véliz 2021), or whether the responsibilization of individuals only obscures the urgent need for radical structural reforms of SNS business models (Vaidhyanathan 2018).

In an early study of online communities, Bakardjieva and Feenberg (2000) suggested that the rise of communities predicated on the open exchange of information may in fact require us to relocate our focus in information ethics from privacy concerns to concerns about alienation; that is, the exploitation of information for purposes not intended by the relevant community. Such considerations give rise to the possibility of users deploying “guerrilla tactics” of misinformation, for example, by providing SNS hosts with false names, addresses, birthdates, hometowns or employment information. Such tactics would aim to subvert the emergence of a new “digital totalitarianism” that uses the power of information rather than physical force as a political control (Capurro 2011).

Finally, privacy issues with SNS highlight a broader philosophical and structural problem involving the intercultural dimensions of information ethics and the challenges for ethical pluralism in global digital spaces (Ess 2021). Pak Hang Wong (2013) has argued for the need for privacy norms to be contextualized in ways that do not impose a culturally hegemonic Western understanding of why privacy matters; for example, in the Confucian context, it is familial privacy rather than individual privacy that is of greatest moral concern. Rafael Capurro (2005) has also noted the way in which narrowly Western conceptions of privacy occlude other legitimate ethical concerns regarding new media practices. For example, he notes that in addition to Western worries about protecting the private domain from public exposure, we must also take care to protect the public sphere from the excessive intrusion of the private. Though he illustrates the point with a comment about intrusive uses of cell phones in public spaces (2005, 47), the rise of mobile social networking has amplified this concern by several factors. When one must compete with Facebook or Twitter for the attention of not only one’s dinner companions and family members, but also one’s fellow drivers, pedestrians, students, moviegoers, patients and audience members, the integrity of the public sphere comes to look as fragile as that of the private.

3.2 The Ethics of Identity and Community on Social Networking Services
Social networking technologies open up a new type of ethical space in which personal identities and communities, both ‘real’ and virtual, are constructed, presented, negotiated, managed and performed. Accordingly, philosophers have analyzed SNS both in terms of their uses as Foucaultian “technologies of the self” (Bakardjieva and Gaden 2012) that facilitate the construction and performance of personal identity, and in terms of the distinctive kinds of communal norms and moral practices generated by SNS (Parsell 2008).

The ethical and metaphysical issues generated by the formation of virtual identities and communities have attracted much philosophical interest (see Introna 2011 and Rodogno 2012). Yet as noted by Patrick Stokes (2012), unlike earlier forms of online community in which anonymity and the construction of alter-egos were typical, SNS such as Facebook increasingly anchor member identities and connections to real, embodied selves and offline ‘real-world’ networks. Yet SNS still enable users to directly manage their self-presentation and their social networks in ways that offline social spaces at home, school or work often do not permit. The result, then, is an identity grounded in the person’s material reality and embodiment but more explicitly “reflective and aspirational” (Stokes 2012, 365) in its presentation, a phenomenon encapsulated in social media platforms such as Instagram. This raises a number of ethical questions: first, from what source of normative guidance or value does the aspirational content of an SNS user’s identity primarily derive? Do identity performances on SNS generally represent the same aspirations and reflect the same value profiles as users’ offline identity performances? Do they display any notable differences from the aspirational identities of non-SNS users? Are the values and aspirations made explicit in SNS contexts more or less heteronomous in origin than those expressed in non-SNS contexts? Do the more explicitly aspirational identity performances on SNS encourage users to take steps to actually embody those aspirations offline, or do they tend to weaken the motivation to do so?

A further SNS phenomenon of relevance here is the persistence and communal memorialization of Facebook profiles after the user’s death; not only does this reinvigorate a number of classical ethical questions about our ethical duties to honor and remember the dead, it also renews questions about whether our moral identities can persist after our embodied identities expire, and whether the dead have ongoing interests in their social presence or reputation (Stokes 2012).

Mitch Parsell (2008) raised early concerns about the unique temptations of ‘narrowcast’ social networking communities that are “composed of those just like yourself, whatever your opinion, personality or prejudices.” (41) Such worries about ‘echo chambers’ and ‘filter bubbles’ have only become more acute as political polarization continues to dominate online culture. Among the structural affordances of SNS is a tendency to constrict our identities to a closed set of communal norms that perpetuate increased polarization, prejudice and insularity. Parsells admitted that in theory the many-to-many or one-to-many relations enabled by SNS allow for exposure to a greater variety of opinions and attitudes, but in practice they often have the opposite effect. Building from de Laat (2006), who suggests that members of virtual communities embrace a distinctly hyperactive style of communication to compensate for diminished informational cues, Parsell claimed that in the absence of the full range of personal identifiers evident through face-to-face contact, SNS may also indirectly promote the deindividuation of personal identity by exaggerating and reinforcing the significance of singular shared traits (liberal, conservative, gay, Catholic, etc.) that lead us to see ourselves and our SNS contacts more as representatives of a group than as unique persons (2008, 46).

Parsell also noted the existence of inherently pernicious identities and communities that may be enabled or enhanced by SNS tools—he cites the example of apotemnophiliacs, or would-be amputees, who use such resources to create mutually supportive networks in which their self-destructive desires receive validation (2008, 48). Related concerns have been raised about “Pro-ANA” sites that provide mutually supportive networks for anorexics seeking information and tools to allow them to perpetuate disordered and self-harming identities (Giles 2006; Manders-Huits 2010).

Restraint of such affordances necessarily comes at some cost to user autonomy—a value that in other circumstances is critical to respecting the ethical demands of identity, as noted by Noemi Manders-Huits (2010). Manders-Huits explores the tension between the way in which SNS treat users as profiled and forensically reidentifiable “objects of (algorithmic) computation” (2010, 52) while at the same time offering those users an attractive space for ongoing identity construction. She argues that SNS developers have a duty to protect and promote the interests of their users in autonomously constructing and managing their own moral and practical identities. This autonomy exists in some tension with widespread but still crude practices of automated SNS content moderation that seek on the one hand, to preserve a ’safe’ space for expression, yet may disproportionately suppress marginalized identities (Gillespie 2020).

The ethical concern about SNS constraints on user autonomy is also voiced by Bakardjieva and Gaden (2012) who note that whether they wish their identities to be formed and used in this manner or not, the online selves of SNS users are constituted by the categories established by SNS developers, and ranked and evaluated according to the currency which primarily drives the narrow “moral economy” of SNS communities: popularity (2012, 410). They note, however, that users are not rendered wholly powerless by this schema; users retain, and many exercise, “the liberty to make informed choices and negotiate the terms of their self-constitution and interaction with others,” (2012, 411) whether by employing means to resist the “commercial imperatives” of SNS sites (ibid.) or by deliberately restricting the scope and extent of their personal SNS practices.

SNS can also enable authenticity in important ways. While a ‘Timeline’ feature that displays my entire online personal history for all my friends to see can prompt me to ‘edit’ my past, it can also prompt me to face up to and assimilate into my self-conception thoughts and actions that might otherwise be conveniently forgotten. The messy collision of my family, friends and coworkers on Facebook can be managed with various tools offered by the site, allowing me to direct posts only to specific sub-networks that I define. But the far simpler and less time-consuming strategy is to come to terms with the collision—allowing each network member to get a glimpse of who I am to others, while at the same time asking myself whether these expanded presentations project a person that is more multidimensional and interesting, or one that is manifestly insincere. As Tamara Wandel and Anthony Beavers put it:

I am thus no longer radically free to engage in creating a completely fictive self, I must become someone real, not who I really am pregiven from the start, but who I am allowed to be and what I am able to negotiate in the careful dynamic between who I want to be and who my friends from these multiple constituencies perceive me, allow me, and need me to be. (2011, 93)
Even so, Dean Cocking (2008) has argued that many online social environments, by amplifying active aspects of self-presentation under our direct control, compromise the important function of passive modes of embodied self-presentation beyond our conscious control, such as body language, facial expression, and spontaneous displays of emotion (130). He regards these as important indicators of character that play a critical role in how others see us, and by extension, how we come to understand ourselves through others’ perceptions and reactions. If Cocking’s view is correct, then SNS that privilege text-based and asynchronous communications may hamper our ability to cultivate and express authentic identities. The subsequent rise in popularity of video and livestream SNS services such as YouTube, TikTok, Stream and Twitch might therefore be seen as enabling of greater authenticity in self-presentation. Yet in reality, the algorithmic and profit incentives of these platforms have been seen to reward distorted patterns of expression: compulsive, ‘always performing’ norms that are reported to contribute to burnout and breakdown by content creators (Parkin 2018).

Ethical preoccupations with the impact of SNS on our authentic self-constitution and representation may be assuming a false dichotomy between online and offline identities; the informational theory of personal identity offered by Luciano Floridi (2011) problematizes this distinction. Soraj Hongladarom (2011) employs such an informational metaphysic to deny that any clear boundary can be drawn between our offline selves and our selves as cultivated through SNS. Instead, our personal identities online and off are taken as externally constituted by our informational relations to other selves, events and objects.

Likewise, Charles Ess makes a link between relational models of the self found in Aristotle, Confucius and many contemporary feminist thinkers and emerging notions of the networked individual as a “smeared-out self” (2010, 111) constituted by a shifting web of embodied and informational relations. Ess points out that by undermining the atomic and dualistic model of the self upon which Western liberal democracies are founded, this new conception of the self forces us to reassess traditional philosophical approaches to ethical concerns about privacy and autonomy—and may even promote the emergence of a much-needed “global information ethics” (2010, 112). Yet he worries that our ‘smeared-out selves’ may lose coherence as the relations that constitute us are increasingly multiplied and scattered among a vast and expanding web of networked channels. Can such selves retain the capacities of critical rationality required for the exercise of liberal democracy, or will our networked selves increasingly be characterized by political and intellectual passivity, hampered in self-governance by “shorter attention spans and less capacity to engage with critical argument” (2010, 114)? Ess suggests that we hope for, and work to enable the emergence of, ‘hybrid selves’ that cultivate the individual moral and practical virtues needed to flourish within our networked and embodied relations (2010, 116).

3.3 Friendship, Virtue and the Good Life on Social Networking Services
SNS can facilitate many types of relational connections: LinkedIn encourages social relations organized around our professional lives, Twitter is useful for creating lines of communication between ordinary individuals and figures of public interest, MySpace was for a time a popular way for musicians to promote themselves and communicate with their fans, and Facebook, which began as a way to link university cohorts and now connects people across the globe, also hosts business profiles aimed at establishing links to existing and future customers. Yet the overarching relational concept in the SNS universe has been, and continues to be, the ‘friend,’ as underscored by the now-common use of this term as a verb to refer to acts of instigating or confirming relationships on SNS.

This appropriation and expansion of the concept ‘friend’ by SNS has provoked a great deal of scholarly interest from philosophers and social scientists, more so than any other ethical concern except perhaps privacy. Early concerns about SNS friendship centered on the expectation that such sites would be used primarily to build ‘virtual’ friendships between physically separated individuals lacking a ‘real-world’ or ‘face-to-face’ connection. This perception was an understandable extrapolation from earlier patterns of Internet sociality, patterns that had prompted philosophical worries about whether online friendships could ever be ‘as good as the real thing’ or were doomed to be pale substitutes for embodied ‘face to face’ connections (Cocking and Matthews 2000). This view was robustly opposed by Adam Briggle (2008), who claimed that online friendships might enjoy certain unique advantages. For example, Briggle asserted that friendships formed online might be more candid than offline ones, thanks to the sense of security provided by physical distance (2008, 75). He also noted the way in which asynchronous written communications can promote more deliberate and thoughtful exchanges (2008, 77).

These sorts of questions about how online friendships measure up to offline ones, along with questions about whether or to what extent online friendships encroach upon users’ commitments to embodied, ‘real-world’ relations with friends, family members and communities, defined the ethical problem-space of online friendship as SNS began to emerge. But it did not take long for empirical studies of actual SNS usage trends to force a profound rethinking of this problem-space. Within five years of Facebook’s launch, it was evident that a significant majority of SNS users were relying on these sites primarily to maintain and enhance relationships with those with whom they also had a strong offline connection—including close family members, high-school and college friends and co-workers (Ellison, Steinfeld and Lampe 2007; Ito et al. 2009; Smith 2011). Nor are SNS used to facilitate purely online exchanges—many SNS users today rely on the sites’ functionalities to organize everything from cocktail parties to movie nights, outings to athletic or cultural events, family reunions and community meetings. Mobile SNS applications amplify this type of functionality further, by enabling friends to locate one another in their community in real-time, enabling spontaneous meetings at restaurants, bars and shops that would otherwise happen only by coincidence.

Yet lingering ethical concerns remain about the way in which SNS can distract users from the needs of those in their immediate physical surroundings (consider the widely lamented trend of users obsessively checking their social media feeds during family dinners, business meetings, romantic dates and symphony performances). Such phenomena, which scholars like Sherry Turkle (2011, 2015) continue to worry are indicative of a growing cultural tolerance for being ‘alone together,’ bring a new complexity to earlier philosophical concerns about the emergence of a zero-sum game between offline relationships and their virtual SNS competitors. They have also prompted a shift of ethical focus away from the question of whether online relationships are “real” friendships (Cocking and Matthews 2000), to how well the real friendships we bring to SNS are being served there (Vallor 2012). The debate over the value and quality of online friendships continues (Sharp 2012; Froding and Peterson 2012; Elder 2014; Turp 2020; Kristjánsson 2021); in large part because the typical pattern of those friendships, like most social networking phenomena, continues to evolve.

Such concerns intersect with broader philosophical questions about whether and how the classical ethical ideal of ‘the good life’ can be engaged in the 21st century. Pak-Hang Wong claims that this question requires us to broaden the standard approach to information ethics from a narrow focus on the “right/the just” (2010, 29) that defines ethical action negatively (e.g., in terms of violations of privacy, copyright, etc.) to a framework that conceives of a positive ethical trajectory for our technological choices; for example, the ethical opportunity to foster compassionate and caring communities, or to create an environmentally sustainable economic order. Edward Spence (2011) further suggests that to adequately address the significance of SNS and related information and communication technologies for the good life, we must also expand the scope of philosophical inquiry beyond its present concern with narrowly interpersonal ethics to the more universal ethical question of prudential wisdom. Do SNS and related technologies help us to cultivate the broader intellectual virtue of knowing what it is to live well, and how to best pursue it? Or do they tend to impede its development?

This concern about prudential wisdom and the good life is part of a growing philosophical interest in using the resources of classical and contemporary virtue ethics to evaluate the impact of SNS and related technologies (Vallor 2016, 2010; Wong 2012; Ess 2008). This program of research promotes inquiry into the impact of SNS not merely on the cultivation of prudential virtue, but on the development of a host of other moral and communicative virtues, such as honesty, patience, justice, loyalty, benevolence and empathy.

3.4 Democracy, Freedom and Social Networking Services in the Public Sphere
As is the case with privacy, identity, community and friendship on SNS, ethical debates about the impact of SNS on civil discourse, freedom and democracy in the public sphere must be seen as extensions of a broader discussion about the political implications of the Internet, one that predates Web 2.0 standards. Much of the literature on this subject focuses on the question of whether the Internet encourages or hampers the free exercise of deliberative public reason, in a manner informed by Jürgen Habermas’s (1992/1998) account of discourse ethics and deliberative democracy in the public sphere (Ess 1996 and 2005b; Dahlberg 2001; Bohman 2008). A related topic of concern is SNS fragmentation of the public sphere by encouraging the formation of ‘echo chambers’ and ‘filter bubbles’: informational silos for like-minded individuals who deliberately shield themselves from exposure to alternative views. Early worries that such insularity would promote extremism and the reinforcement of ill-founded opinions, while also preventing citizens of a democracy from recognizing their shared interests and experiences (Sunstein 2008), have unfortunately proven to be well-founded (as noted in section 2.3.2). Early optimism that SNS would facilitate popular revolutions resulting in the overthrow of authoritarian regimes (Marturano 2011; Frick and Oberprantacher 2011) have likewise given way to the darker reality that SNS are perhaps even more easily used as tools to popularize authoritarian and totalitarian movements, or foster genocidal impulses, as in the use of Facebook to drive violence against the Rohingya minority in Myanmar (BBC 2018).

When SNS in particular are considered in light of these questions, some distinctive considerations arise. First, sites like Facebook and Twitter (as opposed to narrower SNS utilities such as LinkedIn) facilitate the sharing of, and exposure to, an extremely diverse range of types of discourse. On any given day on Facebook a user may encounter in her NewsFeed a link to an article in a respected political magazine followed by a video of a cat in a silly costume, followed by a link to a new scientific study, followed by a lengthy status update someone has posted about their lunch, followed by a photo of a popular political figure overlaid with a clever and subversive caption. Vacation photos are mixed in with political rants, invitations to cultural events, birthday reminders and data-driven graphs created to undermine common political, moral or economic beliefs. Thus while a user has a tremendous amount of liberty to choose which forms of discourse to pay closer attention to, and tools with which to hide or prioritize the posts of certain members of her network, the sheer diversity of the private and public concerns of her fellows would seem to offer at least some measure of protection against the extreme insularity and fragmentation of discourse that is incompatible with the public sphere.

Yet in practice, the function of hidden platform algorithms can defeat this diversity. Trained on user behavior to optimize for engagement and other metrics that advertisers and platform companies associate with their profit, these algorithms can ensure that I experience only a pale shadow of the true diversity of my social network, seeing at the top of my feed only those posts that I am most likely to find subjectively rewarding to engage with. If, for example, I support the Black Lives Matter movement, and tend to close the app in frustration and disappointment whenever I see BLM denigrated by someone I consider a friend, the platform algorithm can easily learn this association and optimize my experience for one that is more conducive to retaining my presence. It is important to note, however, that in this case the effect is an interaction between the algorithm and my own behavior. How much responsibility for echo chambers and resulting polarization or insularity falls upon users, and how much on the designers of algorithms that track and amplify our expressed preferences?

Philosophers of technology often speak of the affordances or gradients of particular technologies in given contexts (Vallor 2010) insofar as they make certain patterns of use more attractive or convenient for users (while not rendering alternative patterns impossible). Thus while I can certainly seek out posts that will cause me discomfort or anxiety, the platform gradient will not be designed to facilitate such experiences. Yet it is not obvious if or when it should be designed to do so. As Alexis Elder notes (2020), civic discourse on social media can be furthered rather than inhibited by prudent use of tools enabling disconnection. Additionally, a platform affordance that makes a violent white supremacist feel accepted, valued, safe and respected in their social milieu (precisely for their expressed attitudes and beliefs in white supremacist violence) facilitates harm to others, in a way that a platform affordance that makes an autistic person or a transgender woman feel accepted, valued, safe and respected for who they are, does not. Fairness and equity in SNS platform design do not entail neutrality. Ethics explicitly demands non-neutrality between harm and nonharm, between justice and injustice. But ethics also requires epistemic anchoring in reality. Thus even if my own attitudes and beliefs harm no one, I may still have a normative epistemic duty to avoid the comfort of a filter bubble. Do SNS platforms have a duty to keep their algorithms from helping me into one? In truth, those whose identities are historically marginalized will rarely have the luxury of the filter bubble option; online and offline worlds consistently offer stark reminders of their marginalization. So how do SNS designers, users, and regulators mitigate the deleterious political and epistemic effects of filter bubble phenomena without making platforms more inhospitable to vulnerable groups than they already are?

One must also ask whether SNS can skirt the dangers of a plebiscite model of democratic discourse, in which minority voices are dispersed and drowned out by the many. Certainly, compared to the ‘one-to-many’ channels of communication favored by traditional media, SNS facilitate a ‘many-to-many’ model of communication that appears to lower the barriers to participation in civic discourse for everyone, including the marginalized. However, SNS lack the institutional structures necessary to ensure that minoritized voices enjoy not only free, but substantively equal access to the deliberative function of the public sphere.

We must also consider the quality of informational exchanges on SNS and the extent to which they promote a genuinely dialogical and deliberative public sphere marked by the exercise of critical rationality. SNS norms tend to privilege brevity and immediate impact over substance and depth in communication; Vallor (2012) suggests that this bodes poorly for the cultivation of those communicative virtues essential to a flourishing public sphere. This worry is only reinforced by empirical data suggesting that SNS perpetuate the ‘Spiral of Silence’ phenomenon that results in the passive suppression of divergent views on matters of important political or civic concern (Hampton et. al. 2014). In a related critique, Frick and Oberprantacher (2011) claim that the ability of SNS to facilitate public ‘sharing’ can obscure the deep ambiguity between sharing as “a promising, active participatory process” and “interpassive, disjointed acts of having trivia shared.” (2011, 22)

There remains a notable gap online between the prevalence of democratic discourse and debate—which require only the open voicing of opinions and reasons, respectively—and the relative absence of democratic deliberation, which requires the joint exercise of collective intentions, cooperation and compromise as well as a shared sense of reality on which to act. The greatest moral challenges of our time—responding to the climate change crisis, developing sustainable patterns of economic and social life, managing global threats to public health—aren’t going to be solved by ideological warfare but by deliberative, coordinated exercise of public wisdom. Today’s social media platforms are great for cultivating the former; for the latter, not so much.

Another vital issue for online democracy relates to the contentious debate emerging on social media platforms about the extent to which controversial or unpopular speech ought to be tolerated or punished by private actors, especially when the consequences manifest in traditional offline contexts and spaces such as the university. For example, the norms of academic freedom in the U.S. were greatly destabilized by the ‘Salaita Affair’ (in which a tenured job offer by the University of Illinois at Urbana-Champaign to Steven Salaita was withdrawn on the basis of his tweets criticizing Israel) and several other cases in which academics were censured or otherwise punished by their institutions as a result of their controversial social media posts (Protevi 2018). Yet how should we treat a post by a professor that expresses a desire to sleep with their students, or that expresses their doubts about the intelligence of women, or the integrity of students of a particular nationality? It remains to be seen what equilibrium can be found between moral accountability and free expression in communities increasingly mediated by SNS communications. A related debate concerns the ethical and social value of the kind of social media acts of moral policing frequently derided as insincere or performative ‘virtue signaling.’ To what extent are social media platforms a viable stage for moral performances, and are such performances merely performative? Are they inherently ‘grandstanding’ abuses of moral discourse (Tosi and Warmke 2020), or can they in fact be positive forces for social progress and reform (Levy 2020, Westra 2021)?

It also remains to be seen to what extent civic discourse and activism on SNS will continue to be manipulated or compromised by the commercial interests that currently own and manage the technical infrastructure. This concern is driven by the growing economic and political influence of companies in the technology sector, what Luciano Floridi (2015b) calls ‘grey power,’ and the potentially disenfranchising and disempowering effects of an economic model in which most users play a passive role (Floridi 2015a). Indeed, the relationship between social media users and service providers has become increasingly contentious, as users struggle to demand more privacy, better data security and more effective protections from online harassment in an economic context where they have little or no direct bargaining power (Zuboff 2019).

This imbalance was powerfully illustrated by the revelation in 2014 that Facebook researchers had quietly conducted psychological experiments on users without their knowledge, manipulating their moods by altering the balance of positive or negative items in their News Feeds (Goel 2014). The study added yet another dimension to existing concerns about the ethics and validity of social science research that relies on SNS-generated data (Buchanan and Zimmer 2012), concerns that drive an increasingly vital and contested area of research ethics (Woodfield 2018, franzke et al. 2020).

Ironically, in the power struggle between users and SNS providers, social networking platforms themselves have become the primary battlefield, where users vent their collective outrage in an attempt to force service providers into responding to their demands. The results are sometimes positive, as when Twitter users, after years of complaining, finally shamed the company in 2015 into providing better reporting tools for online harassment. Yet by its nature the process is chaotic and often controversial, as when later that year, Reddit users successfully demanded the ouster of CEO Ellen Pao, under whose leadership Reddit had banned some of its more repugnant ‘subreddit’ forums (such as “Fat People Hate”).

The only clear consensus emerging from the considerations outlined here is that if SNS are going to facilitate any enhancement of a Habermasian public sphere, or the civic virtues and praxes of reasoned discourse that any functioning public sphere must presuppose, then users will have to actively mobilize themselves to exploit such an opportunity (Frick and Oberprantacher 2011). Such mobilization may depend upon resisting the “false sense of activity and accomplishment” (Bar-Tura, 2010, 239) that may come from merely clicking ‘Like’ in response to acts of meaningful political speech, forwarding calls to sign petitions, or simply ‘following’ an outspoken social critic on Twitter whose ‘tweeted’ calls to action are drowned in a tide of corporate announcements, celebrity product endorsements and personal commentaries. Some argue that it will also require the cultivation of new norms and virtues of online civic-mindedness, without which online ‘democracies’ will continue to be subject to the self-destructive and irrational tyrannies of mob behavior (Ess 2010).

3.5 Social Networking Services and Cybercrime
SNS are hosts for a broad spectrum of ‘cybercrimes’ and related direct harms, including but not limited to: cyberbullying/cyberharassment, cyberstalking, child exploitation, cyberextortion, cyberfraud, illegal surveillance, identity theft, intellectual property/copyright violations, cyberespionage, cybersabotage and cyberterrorism. Each of these forms of criminal or antisocial behavior has a history that well pre-dates Web 2.0 standards, and philosophers have tended to leave the specific correlations between cybercrime and SNS as an empirical matter for social scientists, law enforcement and Internet security firms to investigate. Nevertheless, cybercrime is an enduring topic of philosophical interest for the broader field of computer ethics, and the migration to and evolution of such crime on SNS platforms raises new and distinctive ethical issues.

Among those of great ethical importance is the question of how SNS providers ought to respond to government demands for user data for investigative or counterterrorism purposes. SNS providers are caught between the public interest in crime prevention and their need to preserve the trust and loyalty of their users, many of whom view governments as overreaching in their attempts to secure records of online activity. Many companies have opted to favor user security by employing end-to-end encryption of SNS exchanges, much to the chagrin of government agencies who insist upon ‘backdoor’ access to user data in the interests of public safety and national security.

A related feature of SNS abuse and cybercrime is the associated skyrocketing need for content moderation at scale by these platforms. Because automated tools for content moderation remain crude and easily gamed, social media platforms rely on large human workforces working for low wages, who must manually screen countless images of horrific violence and abuse, often suffering grave and lasting psychological harm as a result (Roberts 2019). It is unclear how such harms to the content moderating workforce can be morally justified, even if they help to prevent the spread of such harm to others. The arrangement has uncomfortable echoes of Ursula LeGuin’s The Ones Who Walk Away From Omelas; so should platform users be the ones walking away? Or do platforms have an ethical duty to find a morally permissible solution, even if it endangers their business model?

Another emerging ethical concern is the increasingly political character of cyberharassment and cyberstalking. In the U.S., women who spoke out about the lack of diversity in the tech and videogame industries were early targets during online controversies such as 2014’s ‘Gamergate’ (Salter 2017), during which some victims were forced to cancel speaking appearances or leave their homes due to physical threats after their addresses and other personal info were posted on social media (a practice known as ‘doxing’ or ‘doxxing’). More recently, journalists have been doxed and subjected to violent threats, sometimes following accusations that their reporting itself constituted doxing (Wilson 2018).

Doxing presents complex ethical challenges (Douglas 2016). For victims of doxing and associated cyberthreats, traditional law enforcement bodies offer scant protection, as these agencies are often ill-equipped to police the blurry boundary between online and physical harms. But moreover, it’s not always clear what distinguishes immoral doxing from justified social opprobrium. If someone records a woman spitting racial epithets in a passerby’s face, or a man denying a disabled person service in a restaurant, and the victim or an observer posts the video online in a manner that allows the perpetrator to be identified by others in their social network, is that unethical shaming or just deserts? What’s the difference between posting someone’s home address, allowing them and their family to be terrorized by a mob, and posting someone’s workplace so that their employer can consider their conduct? Cases such as these get adjudicated by ad hoc social media juries weekly. Sometimes legal consequences do follow, as in the case of the notorious Amy Cooper, who in 2020 was charged with filing a false police report after being filmed by a Black man who she falsely accused of threatening her in Central Park. Are doxing and other modes of social media shaming legitimate tools of justice? Or are they indications of the dangers of unregulated moral policing? And if the answer is ‘both,’ or ‘it depends,’ then what are the key moral distinctions that allow us to respond appropriately to this new practice?

4. Social Networking Services and Metaethical Issues
A host of metaethical questions are raised by the rapid emergence of SNS. For example, SNS lend new data to an earlier philosophical debate (Tavani 2005; Moor 2008) about whether classical ethical traditions such as utilitarianism, Kantian ethics or virtue ethics possess sufficient resources for illuminating the implications of emerging information technology for moral values, or whether we require a new ethical framework to handle such phenomena. Charles Ess (2006, 2021) has suggested that a new, pluralistic “global information ethics” may be the appropriate context from which to view novel information technologies. Other scholars have suggested that technologies such as SNS invite renewed attention to existing ethical approaches such as pragmatism (van den Eede 2010), virtue ethics (Vallor 2016) feminist or care ethics (Hamington 2010; Puotinen 2011) that have often been neglected by applied ethicists in favor of conventional utilitarian and deontological resources.

A related metaethical project relevant to SNS is the development of an explicitly intercultural information ethics (Ess 2005a; Capurro 2008; Honglaradom and Britz 2010). SNS and other emerging information technologies do not reliably confine themselves to national or cultural boundaries, and this creates a particular challenge for applied ethicists. For example, SNS practices in different countries must be analyzed against a conceptual background that recognizes and accommodates complex differences in moral norms and practices (Capurro 2005; Hongladarom 2007, Wong 2013). SNS phenomena that one might expect to benefit from intercultural analysis include: varied cultural patterns and preference/tolerance for affective display, argument and debate, personal exposure, expressions of political, interfamilial or cultural criticism, religious expression and sharing of intellectual property. Alternatively, the very possibility of a coherent information ethics may come under challenge, for example, from a constructivist view that emerging socio-technological practices like SNS continually redefine ethical norms—such that our analyses of SNS and related technologies are not only doomed to operate from shifting ground, but from ground that is being shifted by the intended object of our ethical analysis.

Finally, there are pressing practical concerns about whether and how philosophers can actually have an impact on the ethical profile of emerging technologies such as SNS. If philosophers direct their ethical analyses only to other philosophers, then such analyses may function simply as ethical postmortems of human-technology relations, with no opportunity to actually pre-empt, reform or redirect unethical technological practices. But to whom else can, or should, these ethical concerns be directed: SNS users? Regulatory bodies and political institutions? SNS software developers? How can the theoretical content and practical import of these analyses be made accessible to these varied audiences? What motivating force are they likely to have?

These questions have become particularly acute of late with the controversy over alleged corporate capture by technology companies of the language of ethics, and associated charges of ‘ethics-washing’ (Green 2021 [Other Internet Resources], Bietti 2020). Some argue that ethics is the wrong tool to fight the harms of emerging technologies and large technology platforms (Hao 2021); yet alternative proposals to focus on justice, rights, harms, equity or the legitimate use of power unwittingly fall right back within the normative scope of ethics. Unless we resort to a cynical frame of ‘might makes right,’ there is no escaping the need to use ethics to distinguish the relationships with sociotechnical phenomena and powers that we regard as permissible, good, or right, from those that should be resisted and dismantled.

The profound urgency of this task becomes apparent once we recognize that unlike those ‘life or death’ ethical dilemmas with which many applied ethicists are understandably often preoccupied (e.g., abortion, euthanasia and capital punishment), emerging information technologies such as SNS have in a very short time worked themselves into the daily moral fabric of virtually all of our lives, transforming the social landscape and the moral habits and practices with which we navigate it. The ethical concerns illuminated here are, in a very real sense, anything but ‘academic,’ and neither philosophers nor the broader human community can afford the luxury of treating them as such.

1. Objectivity and Subjectivity
Perhaps the most familiar basic issue in the theory of beauty is whether beauty is subjective—located ‘in the eye of the beholder’—or rather an objective feature of beautiful things. A pure version of either of these positions seems implausible, for reasons we will examine, and many attempts have been made to split the difference or incorporate insights of both subjectivist and objectivist accounts. Ancient and medieval accounts for the most part located beauty outside of anyone’s particular experiences. Nevertheless, that beauty is subjective was also a commonplace from the time of the sophists. By the eighteenth century, Hume could write as follows, expressing one ‘species of philosophy’:

Beauty is no quality in things themselves: It exists merely in the mind which contemplates them; and each mind perceives a different beauty. One person may even perceive deformity, where another is sensible of beauty; and every individual ought to acquiesce in his own sentiment, without pretending to regulate those of others. (Hume 1757, 136)

And Kant launches his discussion of the matter in The Critique of Judgment (the Third Critique) at least as emphatically:

The judgment of taste is therefore not a judgment of cognition, and is consequently not logical but aesthetical, by which we understand that whose determining ground can be no other than subjective. Every reference of representations, even that of sensations, may be objective (and then it signifies the real [element] of an empirical representation), save only the reference to the feeling of pleasure and pain, by which nothing in the object is signified, but through which there is a feeling in the subject as it is affected by the representation. (Kant 1790, section 1)

However, if beauty is entirely subjective—that is, if anything that anyone holds to be or experiences as beautiful is beautiful (as James Kirwan, for example, asserts)—then it seems that the word has no meaning, or that we are not communicating anything when we call something beautiful except perhaps an approving personal attitude. In addition, though different persons can of course differ in particular judgments, it is also obvious that our judgments coincide to a remarkable extent: it would be odd or perverse for any person to deny that a perfect rose or a dramatic sunset was beautiful. And it is possible actually to disagree and argue about whether something is beautiful, or to try to show someone that something is beautiful, or learn from someone else why it is.

On the other hand, it seems senseless to say that beauty has no connection to subjective response or that it is entirely objective. That would seem to entail, for example, that a world with no perceivers could be beautiful or ugly, or perhaps that beauty could be detected by scientific instruments. Even if it could be, beauty would seem to be connected to subjective response, and though we may argue about whether something is beautiful, the idea that one’s experiences of beauty might be disqualified as simply inaccurate or false might arouse puzzlement as well as hostility. We often regard other people’s taste, even when it differs from our own, as provisionally entitled to some respect, as we may not, for example, in cases of moral, political, or factual opinions. All plausible accounts of beauty connect it to a pleasurable or profound or loving response, even if they do not locate beauty purely in the eye of the beholder.

Until the eighteenth century, most philosophical accounts of beauty treated it as an objective quality: they located it in the beautiful object itself or in the qualities of that object. In De Veritate Religione, Augustine asks explicitly whether things are beautiful because they give delight, or whether they give delight because they are beautiful; he emphatically opts for the second (Augustine, 247). Plato’s account in the Symposium and Plotinus’s in the Enneads connect beauty to a response of love and desire, but locate beauty itself in the realm of the Forms, and the beauty of particular objects in their participation in the Form. Indeed, Plotinus’s account in one of its moments makes beauty a matter of what we might term ‘formedness’: having the definite shape characteristic of the kind of thing the object is.

We hold that all the loveliness of this world comes by communion in Ideal-Form. All shapelessness whose kind admits of pattern and form, as long as it remains outside of Reason and Idea, is ugly from that very isolation from the Divine-Thought. And this is the Absolute Ugly: an ugly thing is something that has not been entirely mastered by pattern, that is by Reason, the Matter not yielding at all points and in all respects to Ideal-Form. But where the Ideal-Form has entered, it has grouped and coordinated what from a diversity of parts was to become a unity: it has rallied confusion into co-operation: it has made the sum one harmonious coherence: for the Idea is a unity and what it moulds must come into unity as far as multiplicity may. (Plotinus, 22 [Ennead I, 6])

In this account, beauty is at least as objective as any other concept, or indeed takes on a certain ontological priority as more real than particular Forms: it is a sort of Form of Forms.

Though Plato and Aristotle disagree on what beauty is, they both regard it as objective in the sense that it is not localized in the response of the beholder. The classical conception (see below) treats beauty as a matter of instantiating definite proportions or relations among parts, sometimes expressed in mathematical ratios, for example the ‘golden section.’ The sculpture known as ‘The Canon,’ by Polykleitos (fifth/fourth century BCE), was held up as a model of harmonious proportion to be emulated by students and masters alike: beauty could be reliably achieved by reproducing its objective proportions. Nevertheless, it is conventional in ancient treatments of the topic also to pay tribute to the pleasures of beauty, often described in quite ecstatic terms, as in Plotinus: “This is the spirit that Beauty must ever induce: wonderment and a delicious trouble, longing and love and a trembling that is all delight” (Plotinus 23, [Ennead I, 3]).

At latest by the eighteenth century, however, and particularly in the British Isles, beauty was associated with pleasure in a somewhat different way: pleasure was held to be not the effect but the origin of beauty. This was influenced, for example, by Locke’s distinction between primary and secondary qualities. Locke and the other empiricists treated color (which is certainly one source or locus of beauty), for example, as a ‘phantasm’ of the mind, as a set of qualities dependent on subjective response, located in the perceiving mind rather than of the world outside the mind. Without perceivers of a certain sort, there would be no colors. One argument for this was the variation in color experiences between people. For example, some people are color-blind, and to a person with jaundice much of the world allegedly takes on a yellow cast. In addition, the same object is perceived as having different colors by the same the person under different conditions: at noon and midnight, for example. Such variations are conspicuous in experiences of beauty as well.

Nevertheless, eighteenth-century philosophers such as Hume and Kant perceived that something important was lost when beauty was treated merely as a subjective state. They saw, for example, that controversies often arise about the beauty of particular things, such as works of art and literature, and that in such controversies, reasons can sometimes be given and will sometimes be found convincing. They saw, as well, that if beauty is completely relative to individual experiencers, it ceases to be a paramount value, or even recognizable as a value at all across persons or societies.

Hume’s “Of the Standard of Taste” and Kant’s Critique Of Judgment attempt to find ways through what has been termed ‘the antinomy of taste.’ Taste is proverbially subjective: de gustibus non est disputandum (about taste there is no disputing). On the other hand, we do frequently dispute about matters of taste, and some persons are held up as exemplars of good taste or of tastelessness. Some people’s tastes appear vulgar or ostentatious, for example. Some people’s taste is too exquisitely refined, while that of others is crude, naive, or non-existent. Taste, that is, appears to be both subjective and objective: that is the antinomy.

Both Hume and Kant, as we have seen, begin by acknowledging that taste or the ability to detect or experience beauty is fundamentally subjective, that there is no standard of taste in the sense that the Canon was held to be, that if people did not experience certain kinds of pleasure, there would be no beauty. Both acknowledge that reasons can count, however, and that some tastes are better than others. In different ways, they both treat judgments of beauty neither precisely as purely subjective nor precisely as objective but, as we might put it, as inter-subjective or as having a social and cultural aspect, or as conceptually entailing an inter-subjective claim to validity.

Hume’s account focuses on the history and condition of the observer as he or she makes the judgment of taste. Our practices with regard to assessing people’s taste entail that judgments of taste that reflect idiosyncratic bias, ignorance, or superficiality are not as good as judgments that reflect wide-ranging acquaintance with various objects of judgment and are unaffected by arbitrary prejudices. Hume moves from considering what makes a thing beautiful to what makes a critic credible. “Strong sense, united to delicate sentiment, improved by practice, perfected by comparison, and cleared of all prejudice, can alone entitle critics to this valuable character; and the joint verdict of such, wherever they are to be found, is the true standard of taste and beauty” (“Of the Standard of Taste” 1757, 144).

Hume argues further that the verdicts of critics who possess those qualities tend to coincide, and approach unanimity in the long run, which accounts, for example, for the enduring veneration of the works of Homer or Milton. So the test of time, as assessed by the verdicts of the best critics, functions as something analogous to an objective standard. Though judgments of taste remain fundamentally subjective, and though certain contemporary works or objects may appear irremediably controversial, the long-run consensus of people who are in a good position to judge functions analogously to an objective standard and renders such standards unnecessary even if they could be identified. Though we cannot directly find a standard of beauty that sets out the qualities that a thing must possess in order to be beautiful, we can describe the qualities of a good critic or a tasteful person. Then the long-run consensus of such persons is the practical standard of taste and the means of justifying judgments about beauty.

Kant similarly concedes that taste is fundamentally subjective, that every judgment of beauty is based on a personal experience, and that such judgments vary from person to person.

By a principle of taste I mean a principle under the condition of which we could subsume the concept of the object, and thus infer, by means of a syllogism, that the object is beautiful. But that is absolutely impossible. For I must immediately feel the pleasure in the representation of the object, and of that I can be persuaded by no grounds of proof whatever. Although, as Hume says, all critics can reason more plausibly than cooks, yet the same fate awaits them. They cannot expect the determining ground of their judgment [to be derived] from the force of the proofs, but only from the reflection of the subject upon its own proper state of pleasure or pain. (Kant 1790, section 34)

But the claim that something is beautiful has more content merely than that it gives me pleasure. Something might please me for reasons entirely eccentric to myself: I might enjoy a bittersweet experience before a portrait of my grandmother, for example, or the architecture of a house might remind me of where I grew up. “No one cares about that,” says Kant (1790, section 7): no one begrudges me such experiences, but they make no claim to guide or correspond to the experiences of others.

By contrast, the judgment that something is beautiful, Kant argues, is a disinterested judgment. It does not respond to my idiosyncrasies, or at any rate if I am aware that it does, I will no longer take myself to be experiencing the beauty per se of the thing in question. Somewhat as in Hume—whose treatment Kant evidently had in mind—one must be unprejudiced to come to a genuine judgment of taste, and Kant gives that idea a very elaborate interpretation: the judgment must be made independently of the normal range of human desires—economic and sexual desires, for instance, which are examples of our ‘interests’ in this sense. If one is walking through a museum and admiring the paintings because they would be extremely expensive were they to come up for auction, for example, or wondering whether one could steal and fence them, one is not having an experience of the beauty of the paintings at all. One must focus on the form of the mental representation of the object for its own sake, as it is in itself. Kant summarizes this as the thought that insofar as one is having an experience of the beauty of something, one is indifferent to its existence. One takes pleasure, rather, in its sheer representation in one’s experience:

Now, when the question is whether something is beautiful, we do not want to know whether anything depends or can depend on the existence of the thing, either for myself or anyone else, but how we judge it by mere observation (intuition or reflection). … We easily see that, in saying it is beautiful, and in showing that I have taste, I am concerned, not with that in which I depend on the existence of the object, but with that which I make out of this representation in myself. Everyone must admit that a judgement about beauty, in which the least interest mingles, is very partial and is not a pure judgement of taste. (Kant 1790, section 2)

One important source of the concept of aesthetic disinterestedness is the Third Earl of Shaftesbury’s dialogue The Moralists, where the argument is framed in terms of a natural landscape: if you are looking at a beautiful valley primarily as a valuable real estate opportunity, you are not seeing it for its own sake, and cannot fully experience its beauty. If you are looking at a lovely woman and considering her as a possible sexual conquest, you are not able to experience her beauty in the fullest or purest sense; you are distracted from the form as represented in your experience. And Shaftesbury, too, localizes beauty to the representational capacity of the mind. (Shaftesbury 1738, 222)

For Kant, some beauties are dependent—relative to the sort of thing the object is—and others are free or absolute. A beautiful ox would be an ugly horse, but abstract textile designs, for example, may be beautiful without a reference group or “concept,” and flowers please whether or not we connect them to their practical purposes or functions in plant reproduction (Kant 1790, section 16). The idea in particular that free beauty is completely separated from practical use and that the experiencer of it is not concerned with the actual existence of the object leads Kant to conclude that absolute or free beauty is found in the form or design of the object, or as Clive Bell (1914) put it, in the arrangement of lines and colors (in the case of painting). By the time Bell writes in the early twentieth century, however, beauty is out of fashion in the arts, and Bell frames his view not in terms of beauty but in terms of a general formalist conception of aesthetic value.

Since in reaching a genuine judgment of taste one is aware that one is not responding to anything idiosyncratic in oneself, Kant asserts (1790, section 8), one will reach the conclusion that anyone similarly situated should have the same experience: that is, one will presume that there ought to be nothing to distinguish one person’s judgment from another’s (though in fact there may be). Built conceptually into the judgment of taste is the assertion that anyone similarly situated ought to have the same experience and reach the same judgment. Thus, built into judgments of taste is a ‘universalization’ somewhat analogous to the universalization that Kant associates with ethical judgments. In ethical judgments, however, the universalization is objective: if the judgment is true, then it is objectively the case that everyone ought to act on the maxim according to which one acts. In the case of aesthetic judgments, however, the judgment remains subjective, but necessarily contains the ‘demand’ that everyone should reach the same judgment. The judgment conceptually entails a claim to inter-subjective validity. This accounts for the fact that we do very often argue about judgments of taste, and that we find tastes that are different than our own defective.

The influence of this series of thoughts on philosophical aesthetics has been immense. One might mention related approaches taken by such figures as Schopenhauer (1818), Hanslick (1891), Bullough (1912), and Croce (1928), for example. A somewhat similar though more adamantly subjectivist line is taken by Santayana, who defines beauty as ‘objectified pleasure.’ The judgment of something that it is beautiful responds to the fact that it induces a certain sort of pleasure; but this pleasure is attributed to the object, as though the object itself were having subjective states.

We have now reached our definition of beauty, which, in the terms of our successive analysis and narrowing of the conception, is value positive, intrinsic, and objectified. Or, in less technical language, Beauty is pleasure regarded as the quality of a thing. … Beauty is a value, that is, it is not a perception of a matter of fact or of a relation: it is an emotion, an affection of our volitional and appreciative nature. An object cannot be beautiful if it can give pleasure to nobody: a beauty to which all men were forever indifferent is a contradiction in terms. … Beauty is therefore a positive value that is intrinsic; it is a pleasure. (Santayana 1896, 50–51)

It is much as though one were attributing malice to a balky object or device. The object causes certain frustrations and is then ascribed an agency or a kind of subjective agenda that would account for its causing those effects. Now though Santayana thought the experience of beauty could be profound or could even be the meaning of life, this account appears to make beauty a sort of mistake: one attributes subjective states (indeed, one’s own) to a thing which in many instances is not capable of having subjective states.

It is worth saying that Santayana’s treatment of the topic in The Sense of Beauty (1896) was the last major account offered in English for some time, possibly because, once beauty has been admitted to be entirely subjective, much less when it is held to rest on a sort of mistake, there seems little more to be said. What stuck from Hume’s and Kant’s treatments was the subjectivity, not the heroic attempts to temper it. If beauty is a subjective pleasure, it would seem to have no higher status than anything that entertains, amuses, or distracts; it seems odd or ridiculous to regard it as being comparable in importance to truth or justice, for example. And the twentieth century also abandoned beauty as the dominant goal of the arts, again in part because its trivialization in theory led artists to believe that they ought to pursue more urgent and more serious projects. More significantly, as we will see below, the political and economic associations of beauty with power tended to discredit the whole concept for much of the twentieth century. This decline is explored eloquently in Arthur Danto’s book The Abuse of Beauty (2003).

However, there was a revival of interest in beauty in something like the classical philosophical sense in both art and philosophy beginning in the 1990s, to some extent centered on the work of art critic Dave Hickey, who declared that “the issue of the 90s will be beauty” (see Hickey 1993), as well as feminist-oriented reconstruals or reappropriations of the concept (see Brand 2000, Irigaray 1993). Several theorists made new attempts to address the antinomy of taste. To some extent, such approaches echo G.E. Moore’s: “To say that a thing is beautiful is to say, not indeed that it is itself good, but that it is a necessary element in something which is: to prove that a thing is truly beautiful is to prove that a whole, to which it bears a particular relation as a part, is truly good” (Moore 1903, 201). One interpretation of this would be that what is fundamentally valuable is the situation in which the object and the person experiencing are both embedded; the value of beauty might include both features of the beautiful object and the pleasures of the experiencer.

Similarly, Crispin Sartwell in his book Six Names of Beauty (2004), attributes beauty neither exclusively to the subject nor to the object, but to the relation between them, and even more widely also to the situation or environment in which they are both embedded. He points out that when we attribute beauty to the night sky, for instance, we do not take ourselves simply to be reporting a state of pleasure in ourselves; we are turned outward toward it; we are celebrating the real world. On the other hand, if there were no perceivers capable of experiencing such things, there would be no beauty. Beauty, rather, emerges in situations in which subject and object are juxtaposed and connected.

Alexander Nehamas, in Only a Promise of Happiness (2007), characterizes beauty as an invitation to further experiences, a way that things invite us in, while also possibly fending us off. The beautiful object invites us to explore and interpret, but it also requires us to explore and interpret: beauty is not to be regarded as an instantaneously apprehensible feature of surface. And Nehamas, like Hume and Kant, though in another register, considers beauty to have an irreducibly social dimension. Beauty is something we share, or something we want to share, and shared experiences of beauty are particularly intense forms of communication. Thus, the experience of beauty is not primarily within the skull of the experiencer, but connects observers and objects such as works of art and literature in communities of appreciation.

Aesthetic judgment, I believe, never commands universal agreement, and neither a beautiful object nor a work of art ever engages a catholic community. Beauty creates smaller societies, no less important or serious because they are partial, and, from the point of view of its members, each one is orthodox—orthodox, however, without thinking of all others as heresies. … What is involved is less a matter of understanding and more a matter of hope, of establishing a community that centers around it—a community, to be sure, whose boundaries are constantly shifting and whose edges are never stable. (Nehamas 2007, 80–81)

2. Philosophical Conceptions of Beauty
Each of the views sketched below has many expressions, some of which may be incompatible with one another. In many or perhaps most of the actual formulations, elements of more than one such account are present. For example, Kant’s treatment of beauty in terms of disinterested pleasure has obvious elements of hedonism, while the ecstatic neo-Platonism of Plotinus includes not only the unity of the object, but also the fact that beauty calls out love or adoration. However, it is also worth remarking how divergent or even incompatible with one another many of these views are: for example, some philosophers associate beauty exclusively with use, others precisely with uselessness.

2.1 The Classical Conception
The art historian Heinrich Wölfflin gives a fundamental description of the classical conception of beauty, as embodied in Italian Renaissance painting and architecture:

The central idea of the Italian Renaissance is that of perfect proportion. In the human figure as in the edifice, this epoch strove to achieve the image of perfection at rest within itself. Every form developed to self-existent being, the whole freely co-ordinated: nothing but independently living parts…. In the system of a classic composition, the single parts, however firmly they may be rooted in the whole, maintain a certain independence. It is not the anarchy of primitive art: the part is conditioned by the whole, and yet does not cease to have its own life. For the spectator, that presupposes an articulation, a progress from part to part, which is a very different operation from perception as a whole. (Wölfflin 1932, 9–10, 15)

The classical conception is that beauty consists of an arrangement of integral parts into a coherent whole, according to proportion, harmony, symmetry, and similar notions. This is a primordial Western conception of beauty, and is embodied in classical and neo-classical architecture, sculpture, literature, and music wherever they appear. Aristotle says in the Poetics that “to be beautiful, a living creature, and every whole made up of parts, must … present a certain order in its arrangement of parts” (Aristotle, volume 2, 2322 [1450b34]). And in the Metaphysics: “The chief forms of beauty are order and symmetry and definiteness, which the mathematical sciences demonstrate in a special degree” (Aristotle, volume 2, 1705 [1078a36]). This view, as Aristotle implies, is sometimes boiled down to a mathematical formula, such as the golden section, but it need not be thought of in such strict terms. The conception is exemplified above all in such texts as Euclid’s Elements and such works of architecture as the Parthenon, and, again, by the Canon of the sculptor Polykleitos (late fifth/early fourth century BCE).

The Canon was not only a statue deigned to display perfect proportion, but a now-lost treatise on beauty. The physician Galen characterizes the text as specifying, for example, the proportions of “the finger to the finger, and of all the fingers to the metacarpus, and the wrist, and of all these to the forearm, and of the forearm to the arm, in fact of everything to everything…. For having taught us in that treatise all the symmetriae of the body, Polyclitus supported his treatise with a work, having made the statue of a man according to his treatise, and having called the statue itself, like the treatise, the Canon” (quoted in Pollitt 1974, 15). It is important to note that the concept of ‘symmetry’ in classical texts is distinct from and richer than its current use to indicate bilateral mirroring. It also refers precisely to the sorts of harmonious and measurable proportions among the parts characteristic of objects that are beautiful in the classical sense, which carried also a moral weight. For example, in the Sophist (228c-e), Plato describes virtuous souls as symmetrical.

The ancient Roman architect Vitruvius epitomizes the classical conception in central, and extremely influential, formulations, both in its complexities and, appropriately enough, in its underlying unity:

Architecture consists of Order, which in Greek is called taxis, and arrangement, which the Greeks name diathesis, and of Proportion and Symmetry and Decor and Distribution which in the Greeks is called oeconomia.

Order is the balanced adjustment of the details of the work separately, and as to the whole, the arrangement of the proportion with a view to a symmetrical result.

Proportion implies a graceful semblance: the suitable display of details in their context. This is attained when the details of the work are of a height suitable to their breadth, of a breadth suitable to their length; in a word, when everything has a symmetrical correspondence.

Symmetry also is the appropriate harmony arising out of the details of the work itself: the correspondence of each given detail to the form of the design as a whole. As in the human body, from cubit, foot, palm, inch and other small parts come the symmetric quality of eurhythmy. (Vitruvius, 26–27)

Aquinas, in a typically Aristotelian pluralist formulation, says that “There are three requirements for beauty. Firstly, integrity or perfection—for if something is impaired it is ugly. Then there is due proportion or consonance. And also clarity: whence things that are brightly coloured are called beautiful” (Summa Theologica I, 39, 8).

Francis Hutcheson in the eighteenth century gives what may well be the clearest expression of the view: “What we call Beautiful in Objects, to speak in the Mathematical Style, seems to be in a compound Ratio of Uniformity and Variety; so that where the Uniformity of Bodys is equal, the Beauty is as the Variety; and where the Variety is equal, the Beauty is as the Uniformity” (Hutcheson 1725, 29). Indeed, proponents of the view often speak “in the Mathematical Style.” Hutcheson goes on to adduce mathematical formulae, and specifically the propositions of Euclid, as the most beautiful objects (in another echo of Aristotle), though he also rapturously praises nature, with its massive complexity underlain by universal physical laws as revealed, for example, by Newton. There is beauty, he says, “In the Knowledge of some great Principles, or universal Forces, from which innumerable Effects do flow. Such is Gravitation, in Sir Isaac Newton’s Scheme” (Hutcheson 1725, 38).

A very compelling series of refutations of and counter-examples to the idea that beauty can be a matter of any specific proportions between parts, and hence to the classical conception, is given by Edmund Burke in A Philosophical Enquiry into the Origin of our Ideas of the Beautiful and the Sublime:

Turning our eyes to the vegetable kingdom, we find nothing there so beautiful as flowers; but flowers are of every sort of shape, and every sort of disposition; they are turned and fashioned into an infinite variety of forms. … The rose is a large flower, yet it grows upon a small shrub; the flower of the apple is very small, and it grows upon a large tree; yet the rose and the apple blossom are both beautiful. … The swan, confessedly a beautiful bird, has a neck longer than the rest of its body, and but a very short tail; is this a beautiful proportion? we must allow that it is. But what shall we say of the peacock, who has comparatively but a short neck, with a tail longer than the neck and the rest of the body taken together? … There are some parts of the human body, that are observed to hold certain proportions to each other; but before it can be proved, that the efficient cause of beauty lies in these, it must be shewn, that wherever these are found exact, the person to whom they belong is beautiful. … For my part, I have at several times very carefully examined many of these proportions, and found them to hold very nearly, or altogether alike in many subjects, which were not only very different from one another, but where one has been very beautiful, and the other very remote from beauty. … You may assign any proportions you please to every part of the of the human body; and I undertake, that a painter shall observe them all, and notwithstanding produce, if he pleases, a very ugly figure. (Burke 1757, 84–89)

2.2 The Idealist Conception
There are many ways to interpret Plato’s relation to classical aesthetics. The political system sketched in the Republic characterizes justice in terms of the relation of part and whole. But Plato was also no doubt a dissident in classical culture, and the account of beauty that is expressed specifically in the Symposium—perhaps the key Socratic text for neo-Platonism and for the idealist conception of beauty—expresses an aspiration toward beauty as perfect unity.

In the midst of a drinking party, Socrates recounts the teachings of his instructress, one Diotima, on matters of love. She connects the experience of beauty to the erotic or the desire to reproduce (Plato, 558–59 [Symposium 206c–207e]). But the desire to reproduce is associated in turn with a desire for the immortal or eternal: “And why all this longing for propagation? Because this is the one deathless and eternal element in our mortality. And since we have agreed that the lover longs for the good to be his own forever, it follows that we are bound to long for immortality as well as for the good—which is to say that Love is a longing for immortality” (Plato, 559, [Symposium 206e–207a]). What follows is, if not classical, at any rate classic:

The candidate for this initiation cannot, if his efforts are to be rewarded, begin too early to devote himself to the beauties of the body. First of all, if his preceptor instructs him as he should, he will fall in love with the beauty of one individual body, so that his passion may give life to noble discourse. Next he must consider how nearly related the beauty of any one body is to the beauty of any other, and he will see that if he is to devote himself to loveliness of form it will be absurd to deny that the beauty of each and every body is the same. Having reached this point, he must set himself to be the lover of every lovely body, and bring his passion for the one into due proportion by deeming it of little or no importance.

Next he must grasp that the beauties of the body are as nothing to the beauties of the soul, so that wherever he meets with spiritual loveliness, even in the husk of an unlovely body, he will find it beautiful enough to fall in love with and cherish—and beautiful enough to quicken in his heart a longing for such discourse as tends toward the building of a noble nature. And from this he will be led to contemplate the beauty of laws and institutions. And when he discovers how every kind of beauty is akin to every other he will conclude that the beauty of the body is not, after all, of so great moment. …

And so, when his prescribed devotion to boyish beauties has carried our candidate so far that the universal beauty dawns upon his inward sight, he is almost within reach of the final revelation. … Starting from individual beauties, the quest for universal beauty must find him mounting the heavenly ladder, stepping from rung to rung—that is, from one to two, and from two to every lovely body, and from bodily beauty to the beauty of institutions, from institutions to learning, and from learning in general to the special lore that pertains to nothing but the beautiful itself—until at last he comes to know what beauty is.

And if, my dear Socrates, Diotima went on, man’s life is ever worth living, it is when he has attained this vision of the very soul of beauty. (Plato, 561–63 [Symposium 210a–211d])

Beauty here is conceived—perhaps explicitly in contrast to the classical aesthetics of integral parts and coherent whole—as perfect unity, or indeed as the principle of unity itself.

Plotinus, as we have already seen, comes close to equating beauty with formedness per se: it is the source of unity among disparate things, and it is itself perfect unity. Plotinus specifically attacks what we have called the classical conception of beauty:

Almost everyone declares that the symmetry of parts towards each other and towards a whole, with, besides, a certain charm of colour, constitutes the beauty recognized by the eye, that in visible things, as indeed in all else, universally, the beautiful thing is essentially symmetrical, patterned.

But think what this means.

Only a compound can be beautiful, never anything devoid of parts; and only a whole; the several parts will have beauty, not in themselves, but only as working together to give a comely total. Yet beauty in an aggregate demands beauty in details; it cannot be constructed out of ugliness; its law must run throughout.

All the loveliness of colour and even the light of the sun, being devoid of parts and so not beautiful by symmetry, must be ruled out of the realm of beauty. And how comes gold to be a beautiful thing? And lightning by night, and the stars, why are these so fair?

In sounds also the simple must be proscribed, though often in a whole noble composition each several tone is delicious in itself. (Plotinus, 21 [Ennead I,6])

Plotinus declares that fire is the most beautiful physical thing, “making ever upwards, the subtlest and sprightliest of all bodies, as very near to the unembodied. … Hence the splendour of its light, the splendour that belongs to the Idea” (Plotinus, 22 [Ennead I,3]). For Plotinus as for Plato, all multiplicity must be immolated finally into unity, and all roads of inquiry and experience lead toward the Good/Beautiful/True/Divine.

This gave rise to a basically mystical vision of the beauty of God that, as Umberto Eco has argued, persisted alongside an anti-aesthetic asceticism throughout the Middle Ages: a delight in profusion that finally merges into a single spiritual unity. In the sixth century, Pseudo-Dionysius the Areopagite characterized the whole of creation as yearning toward God; the universe is called into being by love of God as beauty (Pseudo-Dionysius, 4.7; see Kirwan 1999, 29). Sensual/aesthetic pleasures could be considered the expressions of the immense, beautiful profusion of God and our ravishment thereby. Eco quotes Suger, Abbot of St Denis in the twelfth century, describing a richly-appointed church:

Thus, when—out of my delight in the beauty of the house of God—the loveliness of the many-colored gems has called me away from external cares, and worthy meditation has induced me to reflect, transferring that which is material to that which is immaterial, on the diversity of the sacred virtues: then it seems to me that I see myself dwelling, as it were, in some strange region of the universe which neither exists entirely in the slime of the earth nor entirely in the purity of Heaven; and that, by the grace of God, I can be transported from this inferior to that higher world in an anagogical manner. (Eco 1959, 14)

This conception has had many expressions in the modern era, including in such figures as Shaftesbury, Schiller, and Hegel, according to whom the aesthetic or the experience of art and beauty is a primary bridge (or to use the Platonic image, stairway or ladder) between the material and the spiritual. For Shaftesbury, there are three levels of beauty: what God makes (nature); what human beings make from nature or what is transformed by human intelligence (art, for example); and finally, the intelligence that makes even these artists (that is, God). Shaftesbury’s character Theocles describes “the third order of beauty,”

which forms not only such as we call mere forms but even the forms which form. For we ourselves are notable architects in matter, and can show lifeless bodies brought into form, and fashioned by our own hands, but that which fashions even minds themselves, contains in itself all the beauties fashioned by those minds, and is consequently the principle, source, and fountain of all beauty. … Whatever appears in our second order of forms, or whatever is derived or produced from thence, all this is eminently, principally, and originally in this last order of supreme and sovereign beauty. … Thus architecture, music, and all which is of human invention, resolves itself into this last order. (Shaftesbury 1738, 228–29)

Schiller’s expression of a similar series of thoughts was fundamentally influential on the conceptions of beauty developed within German Idealism:

The pre-rational concept of Beauty, if such a thing be adduced, can be drawn from no actual case—rather does itself correct and guide our judgement concerning every actual case; it must therefore be sought along the path of abstraction, and it can be inferred simply from the possibility of a nature that is both sensuous and rational; in a word, Beauty must be exhibited as a necessary condition of humanity. Beauty … makes of man a whole, complete in himself. (1795, 59–60, 86)

For Schiller, beauty or play or art (he uses the words, rather cavalierly, almost interchangeably) performs the process of integrating or rendering compatible the natural and the spiritual, or the sensuous and the rational: only in such a state of integration are we—who exist simultaneously on both these levels—free. This is quite similar to Plato’s ‘ladder’: beauty as a way to ascend to the abstract or spiritual. But Schiller—though this is at times unclear—is more concerned with integrating the realms of nature and spirit than with transcending the level of physical reality entirely, a la Plato. It is beauty and art that performs this integration.

In this and in other ways—including in the tripartite dialectical structure of his account—Schiller strikingly anticipates Hegel, who writes as follows.

The philosophical Concept of the beautiful, to indicate its true nature at least in a preliminary way, must contain, reconciled within itself, both the extremes which have been mentioned [the ideal and the empirical] because it unites metaphysical universality with real particularity. (Hegel 1835, 22)

Beauty, we might say, or artistic beauty at any rate, is a route from the sensuous and particular to the Absolute and to freedom, from finitude to the infinite, formulations that—while they are influenced by Schiller—strikingly recall Shaftesbury, Plotinus, and Plato.

Hegel, who associates beauty and art with mind and spirit, holds with Shaftesbury that the beauty of art is higher than the beauty of nature, on the grounds that, as Hegel puts it, “the beauty of art is born of the spirit and born again” (Hegel 1835, 2). That is, the natural world is born of God, but the beauty of art transforms that material again by the spirit of the artist. This idea reaches is apogee in Benedetto Croce, who very nearly denies that nature can ever be beautiful, or at any rate asserts that the beauty of nature is a reflection of the beauty of art. “The real meaning of ‘natural beauty’ is that certain persons, things, places are, by the effect which they exert upon one, comparable with poetry, painting, sculpture, and the other arts” (Croce 1928, 230).

2.3 Love and Longing
Edmund Burke, expressing an ancient tradition, writes that, “by beauty I mean, that quality or those qualities in bodies, by which they cause love, or some passion similar to it” (Burke 1757, 83). As we have seen, in almost all treatments of beauty, even the most apparently object or objectively-oriented, there is a moment in which the subjective qualities of the experience of beauty are emphasized: rhapsodically, perhaps, or in terms of pleasure or ataraxia, as in Schopenhauer. For example, we have already seen Plotinus, for whom beauty is certainly not subjective, describe the experience of beauty ecstatically. In the idealist tradition, the human soul, as it were, recognizes in beauty its true origin and destiny. Among the Greeks, the connection of beauty with love is proverbial from early myth, and Aphrodite the goddess of love won the Judgment of Paris by promising Paris the most beautiful woman in the world.

There is an historical connection between idealist accounts of beauty and those that connect it to love and longing, though there would seem to be no entailment either way. We have Sappho’s famous fragment 16: “Some say thronging cavalry, some say foot soldiers, others call a fleet the most beautiful sights the dark world offers, but I say it’s whatever you love best” (Sappho, 16). (Indeed, at Phaedrus 236c, Socrates appears to defer to “the fair Sappho” as having had greater insight than himself on love [Plato, 483].)

Plato’s discussions of beauty in the Symposium and the Phaedrus occur in the context of the theme of erotic love. In the former, love is portrayed as the ‘child’ of poverty and plenty. “Nor is he delicate and lovely as most of us believe, but harsh and arid, barefoot and homeless” (Plato, 556 [Symposium 203b–d]). Love is portrayed as a lack or absence that seeks its own fulfillment in beauty: a picture of mortality as an infinite longing. Love is always in a state of lack and hence of desire: the desire to possess the beautiful. Then if this state of infinite longing could be trained on the truth, we would have a path to wisdom. The basic idea has been recovered many times, for example by the Romantics. It fueled the cult of idealized or courtly love through the Middle Ages, in which the beloved became a symbol of the infinite.

Recent work on the theory of beauty has revived this idea, and turning away from pleasure has turned toward love or longing (which are not necessarily entirely pleasurable experiences) as the experiential correlate of beauty. Both Sartwell and Nehamas use Sappho’s fragment 16 as an epigraph. Sartwell defines beauty as “the object of longing” and characterizes longing as intense and unfulfilled desire. He calls it a fundamental condition of a finite being in time, where we are always in the process of losing whatever we have, and are thus irremediably in a state of longing. And Nehamas writes that “I think of beauty as the emblem of what we lack, the mark of an art that speaks to our desire. … Beautiful things don’t stand aloof, but direct our attention and our desire to everything else we must learn or acquire in order to understand and possess, and they quicken the sense of life, giving it new shape and direction” (Nehamas 2007, 77).

2.4 Hedonist Conceptions
Thinkers of the 18th century—many of them oriented toward empiricism—accounted for beauty in terms of pleasure. The Italian historian Ludovico Antonio Muratori, for example, in quite a typical formulation, says that “By beautiful we generally understand whatever, when seen, heard, or understood, delights, pleases, and ravishes us by causing within us agreeable sensations” (see Carritt 1931, 60). In Hutcheson it is not clear whether we ought to conceive beauty primarily in terms of classical formal elements or in terms of the viewer’s pleasurable response. He begins the Inquiry Into the Original of Our Ideas of Beauty and Virtue with a discussion of pleasure. And he appears to assert that objects which instantiate his ‘compound ratio of uniformity and variety’ are peculiarly or necessarily capable of producing pleasure:

The only Pleasure of sense, which our Philosophers seem to consider, is that which accompanys the simple Ideas of Sensation; But there are vastly greater Pleasures in those complex Ideas of objects, which obtain the Names of Beautiful, Regular, Harmonious. Thus every one acknowledges he is more delighted with a fine Face, a just Picture, than with the View of any one Colour, were it as strong and lively as possible; and more pleased with a Prospect of the Sun arising among settled Clouds, and colouring their Edges, with a starry Hemisphere, a fine Landskip, a regular Building, than with a clear blue Sky, a smooth Sea, or a large open Plain, not diversify’d by Woods, Hills, Waters, Buildings: And yet even these latter Appearances are not quite simple. So in Musick, the Pleasure of fine Composition is incomparably greater than that of any one Note, how sweet, full, or swelling soever. (Hutcheson 1725, 22)

When Hutcheson then goes on to describe ‘original or absolute beauty,’ he does it, as we have seen, in terms of the qualities of the beautiful thing (a “compound ratio” of uniformity and variety), and yet throughout, he insists that beauty is centered in the human experience of pleasure. But of course the idea of pleasure could come apart from Hutcheson’s particular aesthetic preferences, which are poised precisely opposite Plotinus’s, for example. That we find pleasure in a symmetrical rather than an asymmetrical building (if we do) is contingent. But that beauty is connected to pleasure appears, according to Hutcheson, to be necessary, and the pleasure which is the locus of beauty itself has ideas rather than things as its objects.

Hume writes in a similar vein in the Treatise of Human Nature:

Beauty is such an order and construction of parts as, either by the primary constitution of our nature, by custom, or by caprice, is fitted to give a pleasure and satisfaction to the soul. … Pleasure and pain, therefore, are not only necessary attendants of beauty and deformity, but constitute their very essence. (Hume 1740, 299)

Though this appears ambiguous as between locating the beauty in the pleasure or in the impression or idea that causes it, Hume is soon talking about the ‘sentiment of beauty,’ where sentiment is, roughly, a pleasurable or painful response to impressions or ideas, though the experience of beauty is a matter of cultivated or delicate pleasures. Indeed, by the time of Kant’s Third Critique and after that for perhaps two centuries, the direct connection of beauty to pleasure is taken as a commonplace, to the point where thinkers are frequently identifying beauty as a certain sort of pleasure. Santayana, for example, as we have seen, while still gesturing in the direction of the object or experience that causes pleasure, emphatically identifies beauty as a certain sort of pleasure.

One result of this approach to beauty—or perhaps an extreme expression of this orientation—is the assertion of the positivists that words such as ‘beauty’ are meaningless or without cognitive content, or are mere expressions of subjective approval. Hume and Kant were no sooner declaring beauty to be a matter of sentiment or pleasure and therefore to be subjective than they were trying to ameliorate the sting, largely by emphasizing critical consensus. But once this fundamental admission is made, any consensus seems contingent. Another way to formulate this is that it appears to certain thinkers after Hume and Kant that there can be no reasons to prefer the consensus to a counter-consensus assessment. A.J. Ayer writes:

Such aesthetic words as ‘beautiful’ and ‘hideous’ are employed … not to make statements of fact, but simply to express certain feelings and evoke a certain response. It follows…that there is no sense attributing objective validity to aesthetic judgments, and no possibility of arguing about questions of value in aesthetics. (Ayer 1952, 113)

All meaningful claims either concern the meaning of terms or are empirical, in which case they are meaningful because observations could confirm or disconfirm them. ‘That song is beautiful’ has neither status, and hence has no empirical or conceptual content. It merely expresses a positive attitude of a particular viewer; it is an expression of pleasure, like a satisfied sigh. The question of beauty is not a genuine question, and we can safely leave it behind or alone. Most twentieth-century philosophers did just that.

2.5 Use and Uselessness
Philosophers in the Kantian tradition identify the experience of beauty with disinterested pleasure, psychical distance, and the like, and contrast the aesthetic with the practical. “Taste is the faculty of judging an object or mode of representing it by an entirely disinterested satisfaction or dissatisfaction. The object of such satisfaction is called beautiful” (Kant 1790, 45). Edward Bullough distinguishes the beautiful from the merely agreeable on the grounds that the former requires a distance from practical concerns: “Distance is produced in the first instance by putting the phenomenon, so to speak, out of gear with our practical, actual self; by allowing it to stand outside the context of our personal needs and ends” (Bullough 1912, 244).

On the other hand, many philosophers have gone in the opposite direction and have identified beauty with suitedness to use. ‘Beauty’ is perhaps one of the few terms that could plausibly sustain such entirely opposed interpretations.

According to Diogenes Laertius, the ancient hedonist Theodorus the Atheist took a rather direct approach.

Is not then, also, a beautiful woman useful in proportion as she is beautiful; and a boy and a youth useful in proportion to their beauty? Well then, a handsome boy and a handsome youth must be useful exactly in proportion as they are handsome. Now the use of beauty is, to be embraced. If then a man embraces a woman just as it is useful that he should, he does not do wrong; nor, again, will he be doing wrong in employing beauty for the purposes for which it is useful. (Diogenes Laertius, 94)

In some ways, Aristippus is portrayed parodically: as the very worst of the sophists, though supposedly a follower of Socrates. And yet the idea of beauty as suitedness to use finds expression in a number of thinkers. Xenophon’s Memorabilia puts the view in the mouth of Socrates, with Aristippus as interlocutor:

Socrates: In short everything which we use is considered both good and beautiful from the same point of view, namely its use.

Aristippus: Why then, is a dung-basket a beautiful thing?

Socrates: Of course it is, and a golden shield is ugly, if the one be beautifully fitted to its purpose and the other ill. (Xenophon, Book III, viii)

Berkeley expresses a similar view in his dialogue Alciphron, though he begins with the hedonist conception: “Every one knows that beauty is what pleases” (Berkeley 1732, 174; see Carritt 1931, 75). But it pleases for reasons of usefulness. Thus, as Xenophon suggests, on this view, things are beautiful only in relation to the uses for which they are intended or to which they are properly applied. The proper proportions of an object depend on what kind of object it is and, again, a beautiful car might make an ugly tractor. “The parts, therefore, in true proportions, must be so related, and adjusted to one another, as they may best conspire to the use and operation of the whole” (Berkeley 1732, 174–75; see Carritt 1931, 76). One result of this is that, though beauty remains tied to pleasure, it is not an immediate sensible experience. It essentially requires intellection and practical activity: one has to know the use of a thing and assess its suitedness to that use.

This treatment of beauty is often used, for example, to criticize the distinction between fine art and craft, and it avoids sheer philistinism by enriching the concept of ‘use,’ so that it might encompass not only performing a practical task, but performing it especially well or with an especial satisfaction. Ananda Coomaraswamy, the Ceylonese-British scholar of Indian and European medieval arts, adds that a beautiful work of art or craft expresses as well as serves its purpose.

A cathedral is not as such more beautiful than an airplane, … a hymn than a mathematical equation. … A well-made sword is not less beautiful than a well-made scalpel, though one is used to slay, the other to heal. Works of art are only good or bad, beautiful or ugly in themselves, to the extent that they are or are not well and truly made, that is, do or do not express, or do or do not serve their purpose. (Coomaraswamy 1977, 75)

Roger Scruton, in his book Beauty (2009) returns to a modified Kantianism with regard to both beauty and sublimity, enriched by many and varied examples. “We call something beautiful,” writes Scruton, “when we gain pleasure from contemplating it as an individual object, for its own sake, and in its presented form” (Scruton 2009, 26). Despite the Kantian framework, Scruton, like Sartwell and Nehamas, throws the subjective/objective distinction into question. He compares experiencing a beautiful thing to a kiss. To kiss someone that one loves is not merely to place one body part on another, “but to touch the other person in his very self. Hence the kiss is compromising – it is a move from one self toward another, and a summoning of the other into the surface of his being” (Scruton 2009, 48). This, Scruton says, is a profound pleasure.

3. The Politics of Beauty
Kissing sounds nice, but some kisses are coerced, some pleasures obtained at a cost to other people. The political associations of beauty over the last few centuries have been remarkably various and remarkably problematic, particularly in connection with race and gender, but in other aspects as well. This perhaps helps account for the neglect of the issue in early-to-mid twentieth-century philosophy as well as its growth late in the century as an issue in social justice movements, and subsequently in social-justice oriented philosophy.

3.1 Aristocracy and Capital
The French revolutionaries of 1789 associated beauty with the French aristocracy and with the Rococo style of the French royal family, as in the paintings of Fragonard: hedonist expressions of wealth and decadence, every inch filled with decorative motifs. Beauty itself became subject to a moral and political critique, or even to direct destruction, with political motivations (see Levey 1985). And by the early 20th century, beauty was particularly associated with capitalism (ironically enough, considering the ugliness of the poverty and environmental destruction it often induced). At times even great art appeared to be dedicated mainly to furnishing the homes of rich people, with the effect of concealing the suffering they were inflicting. In response, many anti-capitalists, including many Marxists, appeared to repudiate beauty entirely. And in the aesthetic politics of Nazism, reflected for example in the films of Leni Riefenstahl, the association of beauty and right wing politics was sealed to devastating effect (see Spotts 2003).

Early on in his authorship, Karl Marx could hint that the experience of beauty distinguishes human beings from all other animals. An animal “produces only under the dominion of immediate physical need, whilst man produces even when he is free from physical need and only truly produces in freedom therefrom. Man therefore also forms objects in accordance with the laws of beauty” (Marx 1844, 76). But later Marx appeared to conceive beauty as “superstructure” or “ideology” disguising the material conditions of production. Perhaps, however, he also anticipated the emergence of new beauties, available to all both as makers and appreciators, in socialism.

Capitalism, of course, uses beauty – at times with complete self-consciousness – to manipulate people into buying things. Many Marxists believed that the arts must be turned from providing fripperies to the privileged or advertising that helps make them wealthier to showing the dark realities of capitalism (as in the American Ashcan school, for example), and articulating an inspiring Communist future. Stalinist socialist realism consciously repudiates the aestheticized beauties of post-impressionist and abstract painting, for example. It has urgent social tasks to perform (see Bown and Lanfranconi 2012). But the critique tended at times to generalize to all sorts of beauty: as luxury, as seduction, as disguise and oppression. The artist Max Ernst (1891–1976), having survived the First World War, wrote this about the radical artists of the early century: “To us, Dada was above all a moral reaction. Our rage aimed at total subversion. A horrible futile war had robbed us of five years of our existence. We had experienced the collapse into ridicule and shame of everything represented to us as just, true, and beautiful. My works of that period were not meant to attract, but to make people scream” (quoted in Danto 2003, 49).

Theodor Adorno, in his book Aesthetic Theory, wrote that one symptom of oppression is that oppressed groups and cultures are regarded as uncouth, dirty, ragged; in short, that poverty is ugly. It is art’s obligation, he wrote, to show this ugliness, imposed on people by an unjust system, clearly and without flinching, rather to distract people by beauty from the brutal realities of capitalism. “Art must take up the cause of what is proscribed as ugly, though no longer to integrate or mitigate it or reconcile it with its own existence,” Adorno wrote. “Rather, in the ugly, art must denounce the world that creates and reproduces the ugly in its own image” (Adorno 1970, 48–9).

The political entanglements of beauty tend to throw into question various of the traditional theories. For example, the purity and transcendence associated with the essence of beauty in the realm of the Forms seems irrelevant, as beauty shows its centrality to politics and commerce, to concrete dimensions of oppression. The austere formalism of the classical conception, for example, seems neither here nor there when the building process is brutally exploitative.

3.2 The Feminist Critique
As we have seen, the association of beauty with the erotic is proverbial from Sappho and is emphasized relentlessly by figures such as Burke and Nehamas. But the erotic is not a neutral or universal site, and we need to ask whose sexuality is in play in the history of beauty, with what effects. This history, particularly in the West and as many feminist theorists and historians have emphasized, is associated with the objectification and exploitation of women. Feminists beginning in the 19th century gave fundamental critiques of the use of beauty as a set of norms to control women’s bodies or to constrain their self-presentation and even their self-image in profound and disabling ways (see Wollstonecraft 1792, Grimké 1837).

In patriarchal society, as Catherine MacKinnon puts it, the content of sexuality “is the gaze that constructs women as objects for male pleasure. I draw on pornography for its form and content,” she continues, describing her treatment of the subject, “for the gaze that eroticizes the despised, the demeaned, the accessible, the there-to-be-used, the servile, the child-like, the passive, and the animal. That is the content of sexuality that defines gender female in this culture, and visual thingification is its method” (MacKinnon 1987, 53–4). Laura Mulvey, in “Visual Pleasure and Narrative Cinema,” reaches one variety of radical critique and conclusion: “It is said that analyzing pleasure, or beauty, destroys it. That is the intention of this article” (Mulvey 1975, 60).

Mulvey’s psychoanalytic treatment was focused on the scopophilia (a Freudian term denoting neurotic sexual pleasure configured around looking) of Hollywood films, in which men appeared as protagonists, and women as decorative or sexual objects for the pleasure of the male characters and male audience-members. She locates beauty “at the heart of our oppression.” And she appears to have a hedonist conception of it: beauty engenders pleasure. But some pleasures, like some kisses, are sadistic or exploitative at the individual and at the societal level. Art historians such as Linda Nochlin (1988) and Griselda Pollock (1987) brought such insights to bear on the history of painting, for example, where the scopophilia is all too evident in famous nudes such as Titian’s Venus of Urbino or Velazquez’s Rokeby Venus, which a feminist slashed with knife in 1914 because “she didn’t like the way men gawked at it”.

Feminists such as Naomi Wolf in her book The Beauty Myth, generalized such insights into a critique of the ways women are represented throughout Western popular culture: in advertising, for example, or music videos. Such practices have the effect of constraining women to certain acceptable ways of presenting themselves publicly, which in turn greatly constrains how seriously they are taken, or how much of themselves they can express in public space. As have many other commentators, Wolf connects the representation of the “beautiful” female body, in Western high art but especially in popular culture, to eating disorders and many other self-destructive behaviors, and indicates that a real overturning of gender hierarchy will require deeply re-construing the concept of beauty.

The demand on women to create a beautiful self-presentation by male standards, Wolf argues, fundamentally compromises women’s action and self-understanding, and makes fully human relationships between men and women difficult or impossible. In this Wolf follows, among others, the French thinker Luce Irigaray, who wrote that “Female beauty is always considered as finery ultimately designed to attract the other into the self. It is almost never perceived as a manifestation of, an appearance of, a phenomenon expressive of interiority – whether of love, of thought, of flesh. We look at ourselves in the mirror to please someone, rarely to interrogate the state of our body or our spirit, rarely for ourselves and in search of our becoming” (quoted in Robinson 2000, 230).

“Sex is held hostage by beauty,” Wolf remarks, “and its ransom terms are engraved in girls’ minds early and deeply with instruments more beautiful that those which advertisers or pornographers know how to use: literature, poetry, painting, and film” (Wolf 1991f, 157).

3.3 Colonialism and Race
Early in the 20th century, black nationalist leader Marcus Garvey (1887–1940) described European or white standards of beauty as a deep dimension of oppression, quite similarly to the way Naomi Wolf describes beauty standards for women. These standards are relentlessly reinforced in authoritative images, but they are incompatible with black skin, black bodies, and also traditional African ways of understanding human beauty. White standards of beauty, Garvey argued, devalue black bodies. The truly oppressive aspects of such norms can be seen in the way they induce self-alienation, as Wolf argues with regard to sexualized images of women. “Some of us in America, the West Indies, and Africa believe that the nearer we approach the white man in color, the greater our social standing and privilege,” he wrote (Garvey 1925 [1986], 56). He condemns skin bleaching and hair straightening as ways that black people are taught to devalue themselves by white standards of beauty. And he connects such standards to ‘colorism’ or prejudice in the African-American community toward darker-skinned black people.

Such observations suggest some of the strengths of cultural relativism as opposed to subjectivism or universalism: standards of beauty appear in this picture not to be idiosyncratic to individuals, nor to be universal among all people, but to be tied to group identities and to oppression and resistance.

In his autobiography, Malcolm X (1925–1965), whose parents were activists in the Garvey movement, describes ‘conking’ or straightening his hair with lye products as a young man. “This was my first really big step toward self-degradation,” he writes, “when I endured all of that pain, literally burning my flesh to have it look like a white man’s hair. I had joined that multitude of Negro men and women in America who are brainwashed into believing that black people are ‘inferior’ – and white people ‘superior’ – that they will even violate and mutilate their God-created bodies to try to look ‘pretty’ by white standards” (X 1964, 56–7). For both Marcus Garvey and Malcolm X, a key moment in the transformation of racial oppression would be the affirmation of standards of black beauty that are not parasitic on white standards, and hence not directly involved in racial oppression. This was systematically developed after Malcolm’s death in the “natural” hairstyles and African fabrics in the Black Power movement. Certainly, people have many motivations for straightening or coloring their hair, for example. But the critical examination of the racial content of beauty norms was a key moment in black liberation movements, many of which, around 1970, coalesced around the slogan Black is beautiful. These are critiques of specific standards of beauty; they are also tributes to beauty’s power.

Imposing standards of beauty on non-Western cultures, and, in particular, misappropriating standards of beauty and beautiful objects from them, formed one of the most complex strategies of colonialism. Edward Said famously termed this dynamic “orientalism.” Novelists such as Nerval and Kipling and painters such as Delacroix and Picasso, he argued, used motifs drawn from Asian and African cultures, treating them as “exotic” insertions into Western arts. Such writers and artists might even have understood themselves to be celebrating the cultures they depicted in pictures of Arabian warriors or African masks. But they used this imagery precisely in relation to Western art history. They distorted what they appropriated.

“Being a White Man, in short,” writes Said, “was a very concrete manner of being-in-the-world, a way of taking hold of reality, language, and thought. It made a specific style possible” (Said 1978, 227). This style might be encapsulated in the outfits of colonial governors, and their mansions. But it was also typified by an appropriative “appreciation” of “savage” arts and “exotic” beauties, which were of course not savage or exotic in their own context. Even in cases where the beauty of such objects was celebrated, the appreciation was mixed with condescension and misapprehension, and also associated with stripping colonial possessions of their most beautiful objects (as Europeans understood beauty)—shipping them back to the British Museum, for example. Now some beautiful objects, looted in colonialism, are being returned to their points of origin (see Matthes 2017), but many others remain in dispute.

3.4 Beauty and Resistance
However, if beauty has been an element in various forms of oppression, it has also been an element in various forms of resistance, as the slogan “Black is beautiful” suggests. The most compelling responses to oppressive standards and uses of beauty have given rise to what might be termed counter-beauties. When fighting discrimination against people with disabilities, for example, one may decry the oppressive norms that regard disabled bodies as ugly and leave it at that. Or one might try to discover what new standards of beauty and subversive pleasures might arise in the attempt to regard disabled bodies as beautiful (Siebers 2005). For that matter, one might uncover the ways that non-normative bodies and subversive pleasures actually do fulfill various traditional criteria of beauty. Indeed, for some decades there has been a disability arts movement, often associated with artists such as Christine Sun Kim and Riva Lehrer, which tries to do just that (see Siebers 2005).

The exploration of beauty, in some ways flipping it over into an instrument of feminist resistance, or showing directly how women’s beauty could be experienced outside of patriarchy, has been a theme of much art by women of the 20th and 21st centuries. Georgia O’Keeffe’s flowers and Judy Chicago’s “Dinner Party” place settings undertake to absorb and reverse the objectifying gaze. The exploration of the meaning of the female body in the work of performance artists such as Hannah Wilke, Karen Finley, and Orlan, tries both to explore the objectification of the female body and to affirm women’s experience in its concrete realities from the inside: to make of it emphatically a subject rather than an object (see Striff 1997).

“Beauty seems in need of rehabilitation today as an impulse that can be as liberating as it has been deemed enslaving,” wrote philosopher Peg Zeglin Brand in 2000. “Confident young women today pack their closets with mini-skirts and sensible suits. Young female artists toy with feminine stereotypes in ways that make their feminist elders uncomfortable. They recognize that … beauty can be a double-edged sword – as capable of destabilizing rigid conventions and restrictive behavioral models as it is of reinforcing them” (Brand 2000, xv). Indeed, vernacular norms of beauty as expressed in media and advertising have shifted in virtue of the feminist and anti-racist attacks on dominant body norms, as the concept’s long journey continues.

1. Introduction
Ambiguity is generally taken to be a property enjoyed by signs that bear multiple (legitimate) interpretations in a language or, more generally, some system of signs. ’legitimate’ is a cover term I’m using to nod to the fact that many signs can, in principle, bear just about any interpretation. The relativization is to prevent ambiguity in terms like like ‘leaped’ which means leaped in English but loved in German. In common parlance, the word ‘ambiguity’ is used loosely: often simple underspecificity will suffice for a charge of ambiguity. The U.S.’s policy towards the unification of China and Taiwan has been described as a policy of ‘strategic ambiguity’, one that allows the U.S. to be non-specific with respect to the status of Taiwan. ‘Jane’s sister will come to visit’ is sometimes thought to be ambiguous when Jane has multiple sisters. A movie with a character that heads to surgery at the end, leaving it open whether he lives or dies, is said to have an ambiguous ending. There is a medical condition known as ‘ambiguous genitalia’ in which the genitals don’t categorize clearly, or exclusively, into male or female genitalia.

In many domains, however, theorists have found it useful to divide the phenomenon of ambiguity from other phenomena (e.g., underspecification, vagueness, context sensitivity). Ambiguity is of interest to philosophers for a variety of reasons, some of which we will look at below. First, ambiguity makes vivid some of the differences between formal languages and natural languages and presents demands on the usage of the former to provide representations of the latter. Second, ambiguity can have a deleterious effect on our ability to determine the validity of arguments in natural language on account of possible equivocation. Third, ambiguity in art can intentionally (or unintentionally) increase the interest in a work of art by refusing to allow easy categorization and interpretation. Fourth, ambiguity in the statement of the law can undermine their applicability and our ability to obey them. Finally, ambiguity resolution is an important feature of our cognitive understanding and interpretative abilities. Studying ambiguity and how we resolve it in practice can give us insight into both thought and interpretation.

Ambiguity has excited philosophers for a very, very long time. It was studied in the context of the study of fallacies in Aristotle’s Sophistical Refutations. Aristotle identifies various fallacies associated with ambiguity and amphiboly[1] writing:

There are three varieties of these ambiguities and amphibolies: (1) When either the expression or the name has strictly more than one meaning… (2) when by custom we use them so; (3) when words that have a simple sense taken alone have more than one meaning in combination; e.g. ‘knowing letters’. For each word, both ‘knowing’ and ‘letters’, possibly has a single meaning: but both together have more than one-either that the letters themselves have knowledge or that someone else has it of them. (Sophistical Refutations bk. 4)

The stoics were also intrigued by ambiguity (see Atherton 1993). Chrysippus claimed at one point that every word is ambiguous – though by this he meant that the same person may understand a word spoken to him in many distinct ways. Philosophers concerned with the relation between language and thought, particularly those who argue for a language of thought, concerned themselves with whether the language in which we think could contain ambiguous phrases. Ockham, for example, was willing to countenance ambiguities in mental sentences of a language of thought but not mental terms in that language (see Spade p. 101). Frege contemplated non-overlap of sense in natural language in a famous footnote, writing:

…So long as the reference remains the same, such variations of sense may be tolerated, although they are to be avoided in the theoretical structure of a demonstrative science and ought not to occur in a perfect language. (Frege 1948 [1892], p. 210 fn. 2)

Frege’s hostility to ambiguity remains with us today. Frequently we use formal languages precisely so that we can disambiguate otherwise ambiguous sentences (brackets being a paradigm example of a disambiguating device).

Giving an account of ambiguity (and disambiguation) requires one to discern the bearer(s) of ambiguity. Propositions, for example, are presumably unambiguous (since they are meanings they can’t be subject to further considerations of meaning). This leaves a range of potential objects: utterances, utterances relative to a context, sentences, sentences relative to a context, discourses, inscriptions…. The differences aren’t trivial: a written down sentence corresponds to many possible ways of being uttered in which features such as prosody can prevent certain meanings that the written down sentence seems capable of enjoying. Two written utterances may sound the same (if they contain words that sound alike) without being spelt alike (if the words aren’t co-spelled) thus resulting in phonological ambiguity without corresponding orthographic ambiguity. I’m going to (somewhat perversely) simply use ‘sentence’ and ‘phrase’ ambiguously, and I will attempt to disambiguate when necessary. We will also look briefly at the application of ambiguity to discourse transitions.

One important question regarding ambiguity is how we ought to represent ambiguities. With structural ambiguities there is no independent issue but with lexical ambiguities there is a real issue. It’s tempting to see this as a question we could answer in any number of equally good ways. For example, we may choose to represent the meaning of ‘bank’ disjunctively or we may choose to individuate ‘bank’ as multiple lexical items that simply sound and look alike, perhaps using subscripts. Both are potentially problematic if taken as analyses: disjunctive meanings are not unique to ambiguity (I can introduce any term I like with a single disjunctive meaning), and representation using subscripts simply masks the question of what the subscripts represent. This suggests that the issue is more like a problem than a nuisance or a trivial choice and actually has serious ramifications for how to pursue truth conditional semantics. (See Davidson 1967, Gillon 1990, and Saka 2007 (Ch. 6) for an interesting account of the problem regarding representing ambiguity.) I’ll proceed as though lexical ambiguities are properly represented as two separate words/lexical items that overlap with respect to some significant feature (phonologically, graphemically, pictorially…).

A brief terminological point: ‘polysemy’ refers to a phenomenon that is closely related to ambiguity, but often is characterized as a term with multiple meanings that are, in some hard to specify sense, interestingly related. For example, ‘in’ is often thought to be a paradigm of polysemy: to be in a car, in my thoughts and in trouble seem to play on notions of containment but there is clearly a difference in how we interpret ‘in’ in each case. It is sometimes characterized as a phenomenon subsumable under ambiguity (basically, an ambiguity with the meanings that are tightly related meanings) but sometimes it is taken to be a different phenomenon altogether. One traditional carving is that ambiguity in words is a matter of two or more lexical entries that correspond to the same word and polysemy a single lexeme that has multiple meanings.[2] For the rest of this article, I will assume that polysemy is simply ambiguity with tightly corresponding meanings and I will not try to distinguish polysemy from ambiguity very carefully. Many cognitive linguists contend that there there is no principled way to divide these in any case. It’s worth noticing that terms could be both ambiguous and polysemous if it had three meanings, two of which were suitably related and one which was quite far apart from the other two. See Vicente and Falkum (2017) for a detailed look at polysemy.

2. What (Linguistic) Ambiguity Isn’t
‘Ambiguity’, as used by philosophers of language and linguists, refers to a more specific phenomenon than that of multiple permissible interpretations. Distinguishing ambiguity from these related phenomenon can be a difficult and tendentious (and sometimes tedious!) affair. We will discuss testing for ambiguity below: for now, we will try to isolate ambiguity by separating it from other typical cases with which ambiguity is easily conflated.

2.1 Vagueness
Characterizing vagueness is notoriously (and ironically) difficult, but it seems to stem from lack of precision in the meaning or reference of a term or phrase. There are clearly words that are ambiguous but not (obviously) vague: ‘bat’ is not vague but it is ambiguous. ‘Is bald’ looks to be vague but not ambiguous.

A general hallmark of vagueness is that it involves borderline cases: possible cases that are neither clearly in the extension of the vague term nor clearly not in its extension. An alternative characterization involves fuzzy boundaries rather than borderline cases (see Fara 2000, 47–48). Cases of ambiguity can be like this: one can imagine a sorites series involving something that is clearly a baseball bat at t1 that is changed particle by particle into a chiropteran with borderline cases of each mid-series, thus being a vague case of ‘bat’ in both senses. However, ambiguity need not be characterized by borderline cases nor by sorites-series susceptibility.

Interestingly, there are views regarding vague language that treat vagueness as at least akin to ambiguity. Braun and Sider (2007) treat sentences with vague terms as expressing multiple distinct propositions and supervaluationism treats vague terms as expressing multiple distinct semantic values. But the relevant notion of multiple expression seem different from paradigmatic ambiguity, where two meanings are definitely meanings of a term or phrase, not where a bunch of meanings are acceptable ways of making a term more precise. If anything, one might think that these views treat vagueness as a sort of polysemy.

2.2 Context Sensitivity
Context sensitivity is (potential) variability in content due purely to changes in the context of utterance without a change in the convention of word usage. Thus, ‘I am hungry’ varies in content speaker to speaker because ‘I’ is context sensitive and shifts reference depending on who utters it. ‘I’, however, is not massively ambiguous – if anything, the mystery of context sensitive terms has been how they could have a single meaning with multiple reference. ‘Bank’ is ambiguous, not (at least, not obviously) context sensitive. Of course, knowledge of context may well help disambiguate an ambiguous utterance. Nonetheless, ambiguity is not characterized by interaction with (extra- linguistic) context but is a property of the meanings of the terms.

2.3 Under-specification and Generality
I have a sister in New York, a sister in Kingston and one in Toronto. If I tell you that I am going to visit one of my sisters, what I say underspecifies which sister I am going to see. This can be frustrating if you are trying to figure out where I am going. But this isn’t due to ‘one of my sisters’ being ambiguous ambiguous. Its meaning is clear. The sentence is ‘sense-general’; it doesn’t specify some detail without thereby being ambiguous with respect to that detail. In general, under- determination and generality may leave open many possibilities without being ambiguous between those possibilities. One more terminological note: in the cognitive linguistics literature (e.g. Dunbar 2001) it is common to treat what we call ‘sense generality’ as vagueness: a single lexeme with a unified meaning that is unspecified with respect to certain features.

Similarly, if I tell you that I am going to visit my aunt, I underspecify whether it is my mother’s sister or my father’s sister whom I am going to go visit. Nothing follows about the univocality or ambiguity of ‘aunt’. It simply means ‘aunt’ is true of things that are female siblings of your parent. By the same token, ‘human’ doesn’t make any demand on an person’s mass in order to be part of its extension.

It is easy to mistake sense generality for ambiguity, as often the extension of a univocal term can break up into two or more distinct salient categories. The sentence ‘I ordered filet mignon’ doesn’t specify whether or not the filet was to be given to me cooked or raw. You will surely be annoyed and say ‘that’s not what I meant’ at a restaurant if the waiter brings the filet raw, but not so at the butcher shop. Often it is difficult to tell when the distinction in extension corresponds to an ambiguity in the meaning of the term. But difficulty in telling these apart in some cases should not lead us to abjure the distinction.

2.4 Sense and Reference Transfer
One difficult phenomenon to classify is transference of sense or reference (see Nunberg, Ward). When you say ‘I am parked on G St.’, you presumably manage to refer to the car rather than yourself. Similarly, ‘I am traditionally allowed a final supper’ said by a prisoner is not about himself (there are no traditions regarding him). The mechanics of reference transfer are mysterious, and the interaction of transferred terms with the syntax is a matter of some dispute.

Of course, sentences can have many of these properties at once. ‘My uncle wonders if I am parked where the bank begins’ is sense-general, ambiguous, context-sensitive, vague and it involves reference-transfer. Nonetheless, it is important to keep these properties apart as the semantic treatment we give each may vary wildly, the ways of testing for them may require highly specialized considerations and their source may well differ radically from phenomenon to phenomenon.

3. Types of Ambiguity
There are different sources and types of ambiguities. To explore these, however, we will need to adopt some terminology to make clear what sorts of phenomena we are looking at. Those familiar with some of the issues in current syntactic theory can skip until the next section.

Modern linguistic theory involves, in part, the study of syntax. The dominant strain of current syntactic theory takes the lexicon as primitive and studies the rule-governed derivation of syntactic forms, which are structures known as LFs (or, more misleadingly, Logical Forms). The relationship of sentences in natural language to LFs can be one to many: the phonological/orthographic forms of a sentence can be associated with more than one LF. Thus, ‘every man loves a woman’ has been argued (e.g., May 1977) to involve two distinct logical forms. It has also been argued (see May 1985) to involve one that is multiply interpretable with constrained but not determined quantifier scopes.

A standard, but controversial, assumption is that LFs are the input to semantic theory, not the phonological/orthographic objects we hear and see. (see May 1985). Thus, while LFs may not be ambiguous, the sentences we actually use and assert often are. If this assumption turns out to be false, then it will be a great deal more difficult to locate the source of some ambiguities.

LFs can be represented as trees, and the terminal nodes of the branches are taken from the lexicon. A lexicon is a repository of lexical items, which need not look like words and they certainly need not correspond to our intuitions about words. Thus, intuitions about a word’s modal profile suggest that it can undergo massive shifts in its orthographic and phonetic properties. It is far less clear that the lexemes retain their identity over shifts of phonological properties. We should be a bit careful, then, about the relationship between words and lexemes: a word may retain its identity while the lexeme it is derived from may not constitute it over time. Fortunately, issues of concerning the diachronic identity of words won’t concern us much here.

The LF driven picture of semantic interpretation is controversial for many reasons: some people don’t think that LFs are properly thought of as inputs to anything, never mind semantic interpretation. Culicover and Jackendoff (2005) argue for much less extensive syntactic structures coupled with very messy mappings to semantic (or ‘conceptual’) structures. Others think that most of the work done by LFs could be done by taking a notion of surface syntax seriously, trading in syntactic structure for very complicated semantic theories to account for the data. (Bittner 2007, Jacobson 1999). Thus, the description of some of the ambiguities as syntactic or structural rather than semantic can be somewhat controversial. However, everyone in the game needs something to serve as the input to semantic interpretation and everyone needs some way to describe those structures (if you don’t, call me and let’s talk about it…) so hopefully similar points will hold in your preferred syntactic framework. We will highlight some of these controversies where necessary.

One more clarification: ambiguity is a property of either sentences or perhaps the speech acts in which the sentences are used. But ambiguity of a sentence or sentences uttered does not necessarily result in any unclarity regarding what was expressed or meant by the speaker. There is no guarantee that unambiguous utterances will result in full univocal clear understanding either. In some syntactic contexts, the ambiguity won’t show up at all: ‘I want to see you duck’ is a case in which the NP interpretation of ‘duck’ is simply unavailable (especially with no comma after ‘you’). In many cases our best theory predicts an ambiguity in the sentence used, without predicting confusion over how the utterance ought to be interpreted.

3.1 Lexical Ambiguity
The lexicon contains entries that are homophonous, or even co-spelled, but differ in meanings and even syntactic categories. ‘Duck’ is both a verb and a noun as is ‘cover’. ‘Bat’ is a noun with two different meanings and a verb with at least one meaning. ‘Kick the bucket’ is arguably ambiguous between one meaning involving dying and one meaning involving application of foot to bucket.

This sort of ambiguity is often very easy to detect by simple linguistic reflection, especially when the meanings are wildly distinct such as in the case of ‘bat’. It can be more difficult, however, when the meanings are closely related. A classic case is the short word ‘in’. The meaning(s) of ‘in’, if it is ambiguous, seem to crucially involve a general notion of containment, but at a more fine-grained level, the types of containment can seem wildly distinct. One can be in therapy, in Florida, in the Mafia, in the yearbook…but it seems like a joke to say that one is in therapy and the Mafia.

The considerations suggest that ‘in’ is ambiguous, but perhaps it is univocal with a very sense general meaning that involves containment of an appropriate sort and different objects require different sorts of appropriate containment. Telling between these two possibilities is difficult. An even harder case of lexical ambiguity involves the putative ambiguity in ‘any’ between the reading as a universal quantifier and a ‘free choice’ item. (see Dayal 2004)

A few points about lexical ambiguity should be kept in mind, so I’ll repeat them. First, a bookkeeping issue: should we relegate lexical ambiguity to the lexicon (two non-identical entries for ambiguous terms) or to semantic interpretation (one lexical entry, two or more meanings)? We’ll go with the first option (so the two meanings of ‘bank’ correspond to two separate lexical items) but nothing I know of forces this choice. Second, the word/lexical item distinction may cause us some trouble. While ‘holey’ and ‘holy’ are homophonous, they are not co-spelled. Thus an utterance of ‘the temple is holey’ is ambiguous between two sentences, while an inscription in English is not. Sometimes co-spelled words are distinct sounding, such as ‘refuse’ which is distinct sounding (in my dialect at least) between ‘ree-fuze’ and ‘reh-fuse’. Fortunately, we have the relevant categories to describe these differences and we can talk about ambiguity in sound or in notation (or in sign).

3.2 Syntactic Ambiguity
Syntactic ambiguity occurs when there are many LFs that correspond to the same sentence – assuming we don’t think of sentences as distinct if their LFs are distinct. This may be the result of scope, movement or binding, and the level at which the ambiguity is localized can involve full sentences or phrases. Here are some examples of purportedly syntactic ambiguities.

3.2.1 Phrasal
A phrase can be ambiguous by corresponding to distinct syntactic structures. The classic example:

superfluous hair remover
can mean the same as ‘hair remover that is superfluous’ or ‘remover of hair that is superfluous’. The ambiguity results from the lack of representation of constituent structure in the English sentence, since it is unclear if the noun ‘hair remover’ is modified by ‘superfluous’ in its specifier or if the ‘superfluous hair’ is the specifier of the noun ‘remover’. In current syntax, the phrase would be associated with two different NPs.

Similarly, a phrase can be ambiguous between an adjunct and an argument:

John floated the boat between the rocks.
‘between the rocks’ can modify the event of floating, saying where it happened and thus acts as an adjunct. It can also act as an argument of ‘float’, specifying where the resulting location of the boat on account of the floating. It can also act as an adjunct modifying ‘the boat’, helping to specify which boat it is. All of these are readings of (1) and in each case we find ‘between the rocks’ playing very different roles. Assuming these roles are dictated by their relations in the relevant LF, we get three very different LFs that correspond to (1).

Thematic assignments can be similarly ambiguous at the level of LF with deleted phrases:

The chicken is ready to eat.
(2) can mean that the chicken is ready to be fed or to be fed to someone depending on the thematic assignment. In a popular semantic framework, this is because ‘the chicken’ is assigned agent on one reading and patient on another. Arguably, these assignments is corresponds syntactic phenomenon assuming principles that align thematic role and syntactic position (see Baker 1988, 1997; Williams 1994; and Grimshaw 1990) but the semantic point stands either way. They result in a clear ambiguity that we may term ‘thematic ambiguity’ for present purposes.

Multiple connectives present similar ambiguities. The following ambiguity, for example, is borne directly out of failure to tell which connective has widest scope:

He got drunk and fired or divorced.
We teach our students in propositional logic to disambiguate these with brackets but we are not so lucky when it comes to the orthographic and phonetic groupings in natural language.

An interesting case is the semantics of modals. At least some modal auxiliaries and adverbs seem to allow for distinct senses such as metaphysical, deontic, doxastic and perhaps practical. Consider

John ought to be at home by now.
(4) can mean that John’s presence at home is, given everything we know, guaranteed. It might mean that, though we have no idea where he is, he is under the obligation to be at home. Similarly:

The coin might come up heads.
(5) means that there is an open metaphysical possibility in which the coin comes up heads. It also means that everything we know doesn’t tell us that the coin won’t come up heads. On the latter reading, for example, we can utter (5) truly even if we know that the coin is weighted, but we aren’t sure in which way.

Similarly:

You must eat a piece of cake.
(6) can express a moral imperative: you are obliged morally to eat a piece of cake. It can express a practical obligation: given your tastes you’d be remiss if you didn’t eat a piece. Though this would rarely make sense, (6) can suggest a doxastic certainty: everything we know entails that you won’t fail to eat the cake.

The multiplicity of interpretation in these modals is pretty clear. One particularly controversial case involves imperative vs epistemic interpretations of ‘must’ as in ‘He must be here’. However, whether or not it is a lexical or structural ambiguity (or best treated as a case of univocality with indexicality) is a source of some controversy (see Drubig 2001). In the semantics literature, views on which modalities are treated indexically rather than as cases of ambiguity pretty much dominate all contemporary thinking, as we shall see in section 6.3.

3.2.1 Quantifier and Operator Scope
Finally, and of much interest to philosophers and logicians, there are scopal ambiguities involving operators and quantifiers. For example:

Every woman squeezed a man.
(7) can express

[∀x:Wx][∃y:My](x squeezed y)
(In regimented English: For every womani there is at least one man that shei squeezed.)

Or

[∃y:My][∀x:Wx](x squeezed y)
(In regimented English: There is at least one mani who is such that every womanj squeezed himi.)

These ambiguities can be very difficult to hear in some cases. For example:

Someone is in a car accident every 10 seconds.
No one is tempted to hear the reading of (10) that involves an unlucky driver who is constantly in car accidents. Thus, our best theory may determine an ambiguity that is never the intended meaning of an utterance of the ambiguous sentence. If we were able to revive people frequently and very quickly and immediately get them into cars , we would presumably start to consider the currently pragmatically unavailable reading of (10) more seriously.

Operators have scopal interactions with quantifiers as well. The semantics of modal auxiliaries, adverbs, temporal modifiers and tense are the subject of much concern but one thing is clear: they have interactive effects.

Modal and temporal fallacies abound if we aren’t careful about scope:

(P1)
John is a bachelor.
(P2)
All bachelors are necessarily unmarried.
(C)
Therefore John is necessarily unmarried.
If we allow ‘necessarily’ to have ‘bachelors’ etc. within its scope, P2 is true but the conclusion is not entailed. If the modal is interpreted narrowly, the conclusion follows but P2 is false and so is the conclusion.

There is a great deal of controversy over how scope is to be handled. Orthodoxy suggests movement of quantifiers at LF where quantifier scope is made explicit and unambiguous. May (1985) is often cited as the canonical source for this – but it is worth noting that in that work May treats some LFs as underdetermining some semantic scopal relations. The situation is less clear with temporal and modal (and other) operators: many semantic theories treat tense and temporal adverbs as quantifiers, while some treat modal expression in this manner. Other treat them as the operators or adverbs they appear to be. One respectable semantic tradition sees (P2) as ambiguous, for example, between:

[∀w][∀x:Bachelor(w,x)](Unmarried(x,w))
(In regimented English: Every world is such that every bachelor at that world is unmarried at that world.)

And

[∀x:Bachelor(w,x)][∀w′](Unmarried (x,w′))
(In regimented English: Every bachelor at a world is such that at every world he is a bachelor.)

On the first reading, the world-quantifier takes wide scope. On the second, the bachelor-quantifier takes wide scope and the world variable is unbound. On the operator treatment, we dispose of quantification over worlds and let the predicates be interpreted relative to the operators, perhaps as a matter of movement, perhaps by other semantic means.

Negation has similarly been argued to present interesting scope ambiguities (see Russell (1905) for an early example of a philosophical use of this type of ambiguity). The following, according to Russell, is ambiguous:

The present king of France is not bald.
As is:

All that glitters is not gold.
Russell claims that (13) and (14) are ambiguous between a reading on which negation that scopes over the sentence as a whole and one reading on which it scopes under the determiner phrase and over the predicate (though see Strawson (1950) See also Neale (1990)).

Long story short, of great interest to philosophers are these sorts of scope worries as many an argument has been accused of looking convincing because of a scope ambiguity (the causal argument for God’s existence, the ontological argument). The development of logics capable of handling multiple quantification was an achievement in part because they could sort out just this sort of linguistic phenomenon.

One final note: even in the domain of scopal ambiguities, there are controversies about whether to treat (some of) these apparent ambiguities as ambiguities. Pietroski and Hornstein (2002) argue that many of these cases aren’t ambiguities at all and prefer a pragmatic explanation of the multiple readings.

3.2.2 Pronouns
Bound and unbound readings of pronouns give rise to similar problems, though whether this is a semantic, syntactic or pragmatic ambiguity has been the source of heated debate. If I tell you ‘everyone loves his mother’, the sentence may be interpreted with ‘his’ being co-indexed with ‘everyone’ and yielding different mothers (potentially) for different values of ‘everyone’ or it could be interpreted deictically saying that everyone loves that [appropriate demonstration] guy’s mother. Static semantics usually treats the distinction between bound and free pronouns as a fundamental ambiguity; dynamic semantics relegates the distinction to an ambiguity in variable choice (see Heim 1982, 1983, and Kamp 1981).

The phenomenon is subject to syntactic constraints. We have a good idea of the conditions under which we can fail to get bound readings, as characterized by binding theory. Thus, we know that binding is impossible in cross-over cases and cases where pronouns are ‘too close’ to their binder ((15) is a case of ‘weak crossover’, (16) is a case of ‘strong crossover’ and (17) is a violation of principle B of binding theory):

?His1 mother loves John1.
*He1 loves John1.
*John1 loves him1.
However, the impossibility of these readings demonstrates constraints on interpretation. It doesn’t resolve the ambiguity in sentences where violations of binding theory do not occur.

3.3 Pragmatic Ambiguity
Pragmatics has been claimed to be the study of many different things; but for our purposes we can focus on two: speech acts and truth conditional pragmatics.

3.3.1 Speech Acts
Speech act theory is complicated and it is not easy to offer a neutral account of the typology or interpretation of speech acts. But, intuitively, an utterance (locutionary act) of the sentence ‘The cops are coming’ can be an assertion, a warning, or an expression of relief. ‘I’m sorry you were raised so badly’ can be an assertion or an apology. ‘You want to cook dinner’ can function as a request or as an assertion. ‘Can you pick me up later?’ can function as a request or a question or both. And these are just examples of speech acts that are conventionally tied to these sentence forms. Many, if not all, sentences can be used in multiple ways.

Interestingly, these ambiguities are not always signaled by the content of the sentence. For example the following differ in their potential for use in speech acts though they seem to express similar content:

Can you pass the salt?
Are you able to pass the salt?
Some creativity may allow (19) to function as a request but it is very difficult compared to (18). As such, some theorists have been interested in trying to determine whether sentence types constrain the speech act potential of utterances of them (see Murray and Starr (2018) for an overview).

3.3.2 Pragmatic Ambiguity
An interesting case of ubiquitous potential ambiguity is the notion, suggested by Donnellan (1966), that the apparent referential use of some sentences with definite descriptions. Donnellan writes:

It does not seem possible to say categorically of a definite description in a particular sentence that it is a referring expression (of course, one could say this if he meant that it might be used to refer). In general, whether or not a definite description is used referentially or attributively is a function of the speaker’s intentions in a particular case. … Nor does it seem at all attractive to suppose an ambiguity in the meaning of the words; it does not appear to be semantically ambiguous. (Perhaps we could say that the sentence is pragmatically ambiguous ….) (Donnellan, p. 297)
Philosophers puzzled a great deal over the import of a ‘pragmatic’ ambiguity that wasn’t a speech act ambiguity or perhaps an ambiguity in what a speaker implies by uttering a sentence. Kripke (1977) and Searle (1979: p. 150 fn. 3) claim that pragmatic ambiguity is conceptually confused – either the sentence bears two interpretations and there is a vanilla ambiguity or the sentence used in univocal but the speaker is using it to get across a different or additional piece of information. But the intuition that perhaps pragmatics has a great role to play in interpretation than merely an account of inferences licensed by the needs of conversational coherence has led philosophers to consider what ambiguity that resides in the interface of semantics and pragmatics might look like (see Recanati (2010).

3.3.3 Presuppositional Ambiguity
Ambiguity can be found at the level of presupposition, terms of identifying the presupposition triggered by a sentence/utterance, as well. The case of ‘too’ is instructive. It has long been observed that the word ‘too’ triggers presuppositions, as in:

Maria solved the problem too.
It’s natural on first read to think that (20) carries the presupposition that someone else solved the problem. But that need not be the case: it may presuppose that Maria solved the problem as well as having done something else, as in:

Maria came up with the problem. Maria solved the problem too.
Kent Bach (1982) explores the intriguing case of:

I love you too.
This can mean (at least) one of four distinct things:

I love you (just like you love me)
I love you (just like someone else does)
I love you (and I love someone else)
I love you (as well as bearing some other relationship (i.e. admiring) to you)
If none of these are true, ‘I love you too’ is clearly infelicitous.

3.4 Other Interesting Cases
3.4.1 Pros Hen Ambiguity
Aristotle noticed in Metaphysics Γ2 that some words are related in meaning but subtly distinct in what they imply. He thought that ‘being’ was like this and he illustrates his point with examples such as ‘health’:

There are many senses in which a thing may be said to ‘be’, but all that ‘is’ is related to one central point, one definite kind of thing, and is not said to ‘be’ by a mere ambiguity. Everything which is healthy is related to health, one thing in the sense that it preserves health, another in the sense that it produces it, another in the sense that it is a symptom of health, another because it is capable of it. (Metaphysics Γ2)

The idea here is that there are words like ‘health’ (and, if Aristotle is right, ‘being’) that are ambiguous between a ‘primary’ sense of ‘healthy’ is that which applies to things that can enjoy health, such as people, dogs, plants, and perhaps corporations but also a ‘secondary’ sense that involves promoting or signaling the presence of health in the primary sense. For example, your diet may be healthy not because it is failing to suffer from a disease but because it promotes your health. Your doctor may tell you that you have healthy urine on account of it being a positive indication of your health. This ambiguity is special in that the derivative senses of ‘health’ are all defined in terms of the more primary sense of ‘health’. The linguistic context doesn’t always settle which sense of is at play: ‘dogs are healthy pets’ can both mean that dogs tend to be themselves healthy and that dogs tend to promote health in their owners.

3.4.2 Collective-Distributive Ambiguity
Another interesting ambiguity is the collective-distributive ambiguity that occurs in the case of some predicates with certain quantificational or conjunctive antecedents. Consider:

The politicians lifted the piano.
Sam and Jess brokered deals.
(27) enjoys a collective reading on which the piano lifting is true of the politicians collectively but not true of any particular politician and a similar ambiguity is present in (28). They also have distributive readings involving as many liftings of the piano as there were politicians and at least two different deal brokerings respectively. See section (4.1) for relevant considerations.

3.4.3 Ellipsis and Complement Ambiguity
An interesting case of ambiguity comes from ellipsis. The following is clearly ambiguous:

John loves his mother and Bill does too.
We’ve already discussed the bound/unbound ambiguity inherent in ‘John loves his mother’. Consider the bound reading of the first sentence. Now, on that reading, there are still two interpretations of the second sentence to deal with: one on which Bill loves John’s mother and one on which Bill loves his own. This ambiguity has been given the regrettable name ‘strict-sloppy identity’ and seems to be the result of what ‘does too’ is short form for. There is a long-standing debate over whether the mechanism is primarily one of copying over at LF (Fiengo and May 1994), the result of expressing a lambda-abstracted predicate (Sag, 1976; Williams, 1977) or the result of centering on a discourse referent (see Hardt and Stone 1997). Ambiguities can arise from words that aren’t written or said as well as from ones that are.

Similar ambiguities come up in cases such as:

Sam loves Jess more than Jason.
(30) can mean either that Sam loves Jess more than he loves Jason or that Sam loves Jess more than Jason loves Jess. This ambiguity arises from phrasal and clausal comparatives: the phrasal comparative of ‘more than’ takes a noun phrase and relates Jess and Jason (effectively saying that the degree to which Sam loves Jess exceeds the degree to which he loves Jason). On the other hand, one can read (30) as involving ellipsis in which ‘loves Jess’ is stripped from the complement of Jason and left sotto voce.

3.4.4 Flexible Types
Montague (Montague 1973) held to a policy of holding fixed the semantic type of lexical items by their category, so that names, falling in the same category as quantifier phrases, were assigned the same type as quantifier phrases. Otherwise, he reasoned, there would be a type mismatch when we conjoined names and quantifier phrases. Others, however, have been content to posit ambiguities in type for one and the same expression. Thus, we may posit that ‘John’, when the word occurs alone, is of type ⟨e⟩ (entity referring) but when conjoined with ‘every man’, it is of type ⟨⟨e,t⟩,t⟩ (a function from functions to truth values) just like quantifier phrases. The semantics is carefully rigged so as not to make a truth-conditional difference; but there is ambiguity nonetheless in what names literally express.

There are alternatives. We could retain the univocality of names and treat ‘and’ as flexible in type depending on its arguments. We could also treat ‘and’ as a type-shifter. Similar considerations hold for verb phrases. Whether or not there is an ambiguity present in such cases is likely to be determined by very high level considerations, not by competent speakers ability to detect a difference in intuitive meaning.

3.4.5 Generic vs. Non-Generic Readings
Some terms are ambiguous between a generic and non-generic reading, and the sentences they play into are similarly ambiguous between the two readings. For example:

Dinosaurs ate kelp. (Carlson 1982: p. 163)
(31) is clearly ambiguous between a generic reading (equivalent roughly to ‘dinosaurs were kelp-eaters’) and a non-generic, episodic reading (equivalent to ‘there were some dinosaurs that ate some kelp’). The ambiguity can be located with certain predicates as well:

John ate breakfast with a gold fork.
The habitual reading (describing how John favored utensil for eating breakfast) vs. the episodic reading (describing a particular breakfast John ate) is evident in (32).

3.4.6 Inchoative Alternations
The following sentences are obviously related:

I broke the vase.
The vase broke.
‘Broke’ and other words like it (e.g., ‘boiled’) have double lives as transitive and intransitive verbs. This could encourage one to posit an ambiguity (or a polysemy) since the putative lexical entries are closely related. However, that would be awfully quick: another approach is to take words like ‘broke’ as playing two distinct syntactic roles univocally, where the root ‘broke’ is a monadic predicate of events. Another is to take ‘broke’ to be univocal and allow the object to move into subject position. Whether or not the term is ambiguous lexically depends a great deal on which theory of the inchoative turns out to be right.

3.4.7 Granularity
Yet another systematic (seeming) ambiguity corresponds roughly to the type-token distinction that philosophers cherish, though it is more general. Philosophers have noticed that (35) is ambiguous between a type and a token reading:

I paid for the same car.
(35) can express a complaint that a car was paid for twice or the claim that I now own a car that is like yours. How closely they have to correspond in similarity is an open question. But interestingly, the two senses cannot always be accessed felicitously:

?I skidded on ice and hit the same car.
One cannot read (36) as saying, say, that my Honda hit another Honda. It’s tempting to think that ‘same’ is the culprit, allowing for sameness across different levels of grain from the very fine to the very coarse. The phenomenon is quite wide-spread, however (See Hobbs 1985).

3.4.8 Count/Mass Nouns
Another ambiguity, though perhaps best thought of as polysemy due to the similarity of the meanings, concerns count nouns like ‘(one) chicken’ and mass nouns like, say, ‘(a lot of) chicken’. David Lewis used the idea of a universal grinder (reported by Pelletier in his (1975)) to suggest that we can make sense of mass uses of substantive count nouns – apply the imaginary grinder to, say, three guitars and you can then make sense of:

There was guitar all over the floor.
The possibility of grinding out mass nouns with the universal grinder is limited to predicates that refer to things we can imagine being grindable in their extensions – it’s hard to see how one gets a mass interpretation of ‘melody’ by grinding. The applicability of the universal grinder, moreover, is not linguistically universal in its ability to imbue one and the same noun with a mass interpretation. The count/mass distinction concerns, in part, whether nouns supply a criterion for counting (explaining why count nouns play well with numerical determiners). Thus, continuing our example of ground guitars, notice that (38) doesn’t entail and isn’t entailed by (39):

John picked up more guitars than Sarah.
John picked up more guitar than Sarah.
This doesn’t hold for, say ‘footwear’ and ‘shoes’ where owing more shoes entails owning more footwear and vice versa. See Doetjes (2011) for discussion.

3.4.9 Discourse Relations
Much recent work has gone into trying to give informative explanations of the oddity of discourses such as:

?Raskolnikov killed Alyona. The tacos at Lalos are delicious.
A standard Gricean response to this oddity is that (40) is odd because the second sentence fails to be relevant to the first, and thus uncooperative (unless the speaker wants to signal a hidden connection between the tacos and the murder). This seems like a promising start but the injunction to be relevant fails to provide enough theoretical options to explain other transitions between sentences. For example (due to Hobbs 1979):
Peter picked the lock. He learned how from Jason.
Peter picked the lock and he learned how from Jason.
An utterance (41) strongly conveys the information that Jason’s teaching Peter is what explains the lock picking. No such inference seems available in (42), in which the learning to lock pick seems (strangely) to temporally follow the lock picking. It’s difficult to see how the period vs. ‘and’ distinction could be responsible for this. Moreover, much empirical work has been done to show that the manner in which we interpret sentences as connected in a discourse effects how we resolve the reference of anaphora. For example (Smyth (1994)):
Phil tickled Stanley, and Liz poked him.
Clearly, the ‘him’ in (43) can be interpreted as Phil or Stanley. But, crucially, how you interpret ‘him’ will depend on how you connect the two sentences. On the one hand, the interpretation of ‘him’ as referring to Phil goes hand in hand with a causal relation – its was the tickling that caused the poking (known as a result relation. Interpreting ‘him’ as referring to Stanley suggests goes hand in hand with a parallel relation. Of course the inference is defeasible – one can always break the connection between discourse relation and pronoun resolution in a manner that looks much like cancellation for Griceans (‘…Liz poked him, I mean, Phil, for unrelated reasons’). But the point is that the search for discourse relations that help settle pronominal reference is good evidence that the discourse relations are part of your linguistic knowledge, not just a reflect of cooperative conversation and maxim following or flaunting. The study of discourse relations has flourished into a large literature in the last 20 years but the relevant point for us is that it looks like (43) is ambiguous as a discourse. This type of ambiguity is fairly novel and much work is still needed to get clear on the number and nature of possible relations that provide the possible resolutions of ambiguities like (41).

4. Detecting Ambiguity
Now that we have separated types of ambiguity, we may reasonably ask how we tell when a term or phrase contains an ambiguity. The answer may be disappointing – there are tests and considerations but no firm answers and probably a lot depends on what the ‘best theories’ in linguistics etc. end up looking like. Nevertheless, we can make some progress. The canonical source for these tests is Zwicky and Sadock’s ‘Ambiguity Tests and How to Fail Them’ (1975).

These tests generally depend on the presence or lack of interpretations and on judgments regarding the ridiculousness of interpretation (the absurdity of the meaning is known as zeugma – though it should probably be known as syllepsis). These judgments can be difficult to make, especially in tricky philosophical cases, so we must treat the results of the tests with care.

4.1 Conjunction Reduction
A standard test for ambiguity is to take two sentences that contain the purportedly ambiguous term and conjoin them by using the term only once in contexts where both meanings are encouraged. For example, ‘light’ is a predicate that can enjoy the same meaning as either ‘not dark’ or ‘not heavy’.

The colours are light.
The feathers are light.
The following, however, seems to be zeugmatic:

?The colours and the feathers are light.
The reduced sentence is zeugmatic for obvious reasons. This is evidence for ambiguity (or polysemy) in ‘light’. On the other hand, ‘exist’, which has been claimed to be ambiguous, seems not to display such zeugmatic effects:

Toronto exists.
Numbers exist.
Triadic relations exist.
Toronto and numbers and triadic relations exist.
The test is limited in one way. If a term can be ambiguous but in a way so subtle that competent speakers may miss it, then the zeugma might not be noticeable. Given that these tests try to draw on linguistic judgments to detect ambiguity, it’s not clear how to proceed when there is a case of disagreement over the presence of zeugma.

We can use the test in cases in which one wouldn’t necessarily expect zeugma, but merely lack of multiple interpretations. For example:

Han and Chewbacca used superfluous hair removers.
(51) doesn’t allow a reading on which Han used a hair remover that was superfluous and Chewbacca used a remover of superfluous hair. If multiple interpretations are impossible, there is evidence of ambiguity. This is to be expected since the point of conjunction reduction is to ‘freeze’ the syntactic structure and in ambiguous cases, the effect is achieved.

As mentioned above, conjunction reduction has been used to argue that collective-distributive ambiguities are due to an ambiguity in the subject phrase. Consider:

John and Jane moved a piano.
One might think that the readings are generated by an ambiguity in ‘and’: sometimes it acts as a sentential operator and sometimes as a term-forming operator that makes two names into a single term for predication. However, notice that there are some predicates that can only be (sensibly) interpreted collectively, such as ‘met’:

John and Jane met for lunch.
In this case, there is no sense to be made of ‘John met for lunch and Jane met for lunch’ and so the sentential conjunction reading is not available. Using conjunction reduction on (52) and (53) we get:

John and Jane moved a piano and met for lunch.
(54) has a reading on which ‘moved the piano’ is interpreted distributively (two liftings) and ‘met’ is read collectively. The felicity of the conjunction reduced (54) suggests that the ambiguity isn’t the result of an ambiguity in conjunction. (see Schein (2006), McKay (2006)). We can try to use the test in an extended manner on full sentences if we embed them under ‘says that’ or perhaps ‘believes that’: ‘John and Adam believe that Sarah bought a superfluous hair remover’ is infelicitous if the unconjoined sentences involve different interpretations of ‘superfluous hair remover’.

The test has certain weaknesses. In actual utterances, intonation can be used to indicate an assertion or an each question (‘Ben wanted to eat that?) conjoined with ‘Ben wanted to eat that’ yields an infelicity even if the demonstrative has the same value on both occasions – though we may try to fix things up by demanding that the test be run using common intonation (at least in spoken uses of the test!). On that note, the test will judge demonstrative and indexicals to be ambiguous since they are famously not generally conjunction reducible. Similar worries concern polysemy and ambiguity, which conjunction reduction may be overly sensitive to (See Viebahn (2016) for relevant considerations).

4.2 Ellipsis
Ellipsis tests work in a manner similar to conjunction reduction tests. For example:

I saw his duck and swallow under the table and I saw hers too. (Zwicky and Sadock 1975)
(55) can mean that I saw their birds under the table or that I saw their activities of ducking and swallowing but it can’t mean that I saw one’s birds and the other’s activities. Similar features hold for structural ambiguities:

I’m happy that every man met two women and Jim is too.
It isn’t possible to interpret (56) as having ‘every man’ with wide scope in one but narrow in the other. This suggests a real ambiguity in the scope of the two quantifiers. This test has led people some philosophers to surprising results. For example, Atlas (1989) argues that the acceptability of the following suggest that negation does not interact scopally with descriptions in the ways we have come to expect:

John thinks that the King of France is not bald and Bob thinks so too.
The purported availability of both readings suggests that sentences with negation(s) and descriptions are sense-general rather than ambiguous, contradicting many standard assumptions about the available truth conditions these structures should make available. Alternatively, it may lead us to think that there weren’t as many readings as we initially thought there were (or that we have the wrong theory of descriptions).

4.3 Contradiction Tests
Another way to test for ambiguity is to test for lack of contradiction in sentences that look to be contradictory. For example, say someone argued that ‘aunt’ was ambiguous on account of not specifying maternal from paternal aunt. If that was the case, we would expect that we can access the two distinct senses of ‘aunt’ just as we can for ‘bank’. However, compare:

That bank isn’t a bank.
*She is an aunt but she isn’t an aunt.
Both sentences are rather awkward but only one is doomed to life as a contradiction. This is good evidence that ‘aunt’ is unspecified with respect to which side of the family she comes from, but not ambiguous. The tests can be used for most of the other types of ambiguity:

My superfluous hair remover is not a superfluous hair remover; (I need it!)
The goose is ready to eat but it’s not ready to eat; (we need to cook it first.)
(It helps to provide a paraphrase afterwards to bring out the distinct senses). The tests can be used to detect lexical, structural and thematic ambiguity.

4.4 Definitional Tests
Aristotle offers a test for ambiguity: try to construct a definition that encompasses both meanings and posit an ambiguity only if you fail. The notion of definition here has to be taken as a heavy-weight notion: ‘bank’ is ambiguous even though you can ‘define’ it as ‘financial institution or river side’. However, we can get a reasonable grip on what Aristotle had in mind. ‘Uncle’ is not ambiguous because it has a single definition that covers both: x is an uncle iff x is the brother of y and y has a child.

The test depends partly on how strict we are about what counts as a definition. And on the assumption that there are interesting definitions to be had (see Fodor 1998).

4.5 Checking the Lexicon of Other Languages
Kripke, in his famous attack on Donnellan, suggests a few tests for ambiguity that are more conceptual in nature. In particular, he makes the following intriguing suggestion:

“Bank” is ambiguous; we would expect the ambiguity to be disambiguated by separate and unrelated words in some other languages. Why should the two separate senses be reproduced in languages unrelated to English? First, then, we can consult our linguistic intuitions, independently of any empirical investigation. Would we be surprised to find languages that used two separate words for the two alleged senses of a given word? If so, then, to that extent our linguistic intuitions are really intuitions of a unitary concept, rather than of a word that expresses two distinct and unrelated senses. Second, we can ask empirically whether languages are in fact found that contain distinct words expressing the allegedly distinct senses. If no such language is found, once again this is evidence that a unitary account of the word or phrase in question should be sought. (Kripke 1977: p. 268)

In other words, since lexical ambiguity should involve something like accidental homophony, one would expect that other languages would lexicalize these meanings differently. Thus, it would not surprise one to find out that the two meanings of ‘bat’ were expressed by two different words in other languages. It may well surprise one to find out that every action verb was lexicalized as two different verbs, one for a reading on which the action was done intentionally, one on which it wasn’t in some other language.

One may worry about this test, especially with respect to its ability to differentiating sense generality from ambiguity. It would not be surprising to find out that other languages lexicalize ‘uncle’ in two different words (in Croatian, there is no one word translation of ‘uncle’: ‘stric’ means brother of one’s father and ‘ujak’ means an uncle from the mother’s side). Nonetheless, there is no reason to think that ‘uncle’ is ambiguous in English. Why wouldn’t language users create words to designate the specific meanings that are left sense-general in a different language?

4.6 Problems for the Tests
4.6.1 Privative Opposites
Zwicky and Sadock (1975) argue that sometimes the two (or more) putative meanings of a word are related by overlapping except with respect to one or more features. The Random House Dictionary, for example, gives (amongst many others) the following two definitions for ‘dog’:

any carnivore of the dog family Canidae, having prominent canine teeth and, in the wild state, a long and slender muzzle, a deep-chested muscular body, a bushy tail, and large, erect ears. Compare canid.
the male of such an animal.
Ignoring for now whether or not dictionaries manage to report analyticities (is having a bushy tail really an analytic necessary condition for being a dog?), it looks like sense (ii) and (iii) differ merely by specification of gender, and so if this makes for ambiguity, it may well be hard to test for. Similarly for verbs that allow a factive and non-factive reading such as ‘report’ where the factive reading entails the non-factive. If I say ‘the police reported that the criminal was apprehended but the police didn’t report that the criminal was apprehended’ there is at least one reading that is anomalous, but largely out of contradiction engendered by entailment rather than univocality: it takes subtle intuitions to train one’s ear to hear ambiguities when the meanings are largely overlapping. As mentioned above, Pietroski and Hornstein (2002) make a similar point regarding syntactic ambiguities. Noting that the two putative readings of ‘every man loves a woman’ are such that the wide scope ‘a woman’ reading entails the narrow, they ask whether or not we should be countenancing a structural ambiguity or chalking up the two ‘readings’ to confusion over the specific and general case. If these sorts of factors can interfere, we will indeed have to apply our tests gingerly.

4.6.2 The Inconsistency of Zeugma
A problem for the conjunction reduction test involves the context-sensitivity of zeugma. As noted by Lewandowska-Tomaszczyk (following Cruse 1986), the following two are different in terms of zeugma:

?Judy’s dissertation is thought provoking and yellowed with age.
Judy’s dissertation is still thought provoking although yellowed with age.
Similarly, from the literature on generics:

Bees thrive in warm environments and hence are swarming my porch.
These cases looks like a problem for the conjunction reduction test, depending on how one thinks we should treat the ambiguity in generics. One might think that this provides evidence against ambiguity in bare plurals.

4.7 Contextual Resolution and Degree of Zeugma
As we suggested above, context-sensitivity, vagueness and indexicality are frequently thought to be different phenomena than ambiguity, requiring a different treatment than lexical proliferation or differences in structure. However, in context, it can be pretty easy to make them pass some of the tests for ambiguity. For example, consider James, who wants to meet a man who is is tall for a philosopher, and Jane who wants to meet a man who is tall for a horse jockey (who tend to be a fair bit shorter on average). Let’s conjunction reduce and see what happens:

?James and Jane want to meet a tall man.
Admittedly, (65) strikes me as meriting a ‘?’ rather than a ‘#’, but I am unwilling to let it escape unmarked. Let’s try another case. Consider, James speaking to Jill and disagreeing over the relevant height required to be tall:

?That mani is tall but hei’s not tall.
It’s possible, I think, to get a non-contradictory reading of (66). But it requires, to my ear, adding a good helping of focal stress on the second ‘tall’. Of course, putting focal stress on a word has semantic effects of its own. So we don’t have clear counter-examples to the tests here. But we do have some evidence that running the tests requires controlling for variables.

Similarly, speaker’s reference and semantic reference distinctions mentioned above can interfere with the proper operation of the tests. Let’s consider a variant on Kripke’s famous case. We see someone who looks like Smith (but is Jones) raking the leaves and someone else sees Smith (the actual Smith) raking leaves. Can we hear the following as non-zeugmatic?

We saw Smith raking the leaves and he did too.
In context, this sounds awfully bad to me. It doesn’t seem, however, that the word ‘Smith’ is ambiguous in sometimes referring to Jones, sometimes Smith. The utterance of the word ‘Smith’ however, may well be used with referential intentions that lead to utterance ambiguity.

The bottom line is that in clear cases, the tests work great. In controversial cases, one must be very careful and run many of them and hope for the best; it will sometimes involve sifting through degrees of zeugma rather than triumphantly producing an indisputable result.

4.8 Metaphor and Non-Literal Usage
Metaphor and non-literal usage can also confound the tests. For example:

#We saw Zoe down in the dumps and her therapist did too.
#Life and the 401 are highways.
The metaphors aren’t very good and (68) and (69) are clearly zeugmatic. Given how many parts of speech can be used metaphorically, slavish obedience to the test would postulate massive and unconstrained ambiguity in natural language. (See Camp 2006) The natural answer is to restrict the use of the test to cases in which the words are used literally; but of course the tests are supposed to help us decide when we have literal, semantic difference and when we don’t. To add to the complication, metaphors that are used in similar manners over time tend to become ‘dead’ metaphors – literally ambiguities that took a causal path through metaphor. ‘Deadline’ is a pretty clear case of a metaphor that has died. Since the passing of the non-literal into the standardized literal is not exactly a transition whose time of occurrence is obvious, it will be difficult in some cases to tell what has been lexicalized as a different meaning and what has not (think, again, of ‘deadline’ as a case, which once meant a line the crossing of which would result in your death. Think of that next time you are late with a paper…)

5. Philosophical Issues
There are a few main philosophical issues involved in ambiguity.

5.1 Validity
Many arguments look persuasive but fail on closer inspection on account of structural and/or lexical ambiguity. For example, consider:

Babe Ruth owned a bat.
Bats have wings.
Babe Ruth owned something with wings.
The argument looks valid and the premises seem true, on at least one reading, but the conclusion doesn’t follow.

If logic is to be free of issues that would complicate telling valid from non-valid arguments by form, detecting ambiguity is essential to logical representation of natural language arguments. Frege noted this to be the main defect of natural language and a real obstacle to trying to formalize it (as opposed to just using the formal language without translation from natural language). We typically are more optimistic on this point than Frege; but the long history of dispute over such issues as the pragmatic-semantics distinction and skepticism over the viability of semantic theory in general stand as challenges.

5.2 Basic Semantic Methodology
Ambiguity has been used methodologically as a way to shield a theory from counter-example. Kripke laments this tendency explicitly:

It is very much the lazy man’s approach in philosophy to posit ambiguities when in trouble. If we face a putative counterexample to our favorite philosophical thesis, it is always open to us to protest that some key term is being used in a special sense, different from its use in the thesis. We may be right, but the ease of the move should counsel a policy of caution: Do not posit an ambiguity unless you are really forced to, unless there are really compelling theoretical or intuitive grounds to suppose that an ambiguity really is present.(Kripke 1977, p.268)

Grice (1975) counsels a methodological principle: ‘Senses are not to be multiplied beyond necessity’.

This general moral seems right. It is worryingly easy to deflect a counter-example or to explain an intuition by claiming differences in meaning. On the other hand, in philosophical discourse, distinctions that are quite fine can be made that may well be missed by normal users of the language who are inclined to miss differences in meaning that are slight. One thus often will be tempted to posit ambiguity as a way to reconcile differences between two plausible hypotheses about the meanings of words and phrases (‘evidence’ has both an internal sense and an external sense, ‘right action’ has both a utilitarian sense and a deontic sense…) A neat case of this is Gilbert Ryle’s contention that ‘exists’ is ambiguous mentioned above:

…two different senses of ‘exist’, somewhat as ‘rising’ has different senses in ‘the tide is rising’, ‘hopes are rising’, and ‘the average age of death is rising’. A man would be thought to be making a poor joke who said that three things are now rising, namely the tide, hopes and the average age of death. It would be just as good or bad a joke to say that there exist prime numbers and Wednesdays and public opinions and navies; or that there exist both minds and bodies. (Ryle 1949, p. 23)

Ryle here makes use of the conjunction reduction test mentioned above and has been the target of much scorn for his intuitions on this matter. This may just go to show how hard it is to (dis)prove a claim to ambiguity using the tests.

5.3 The Analytic-Synthetic Distinction
One long-standing issue about ambiguity is that it assumes a difference between something like sense and reference. While some words can clearly be used to refer to things that are wildly different in ontic category, that has not been taken to be sufficient for a claim to ambiguity. In theory, a phrase could be ambiguous and yet differ not at all in reference: imagine a term t that was ambiguous between two meanings, but it turned out as highly surprising essential condition that things that were t in the first sense were also t in the second sense – while this seems unlikely to happen, it is by no means conceptually impossible.

However, the 20th century saw a vicious and sometimes relentless attack on the distinction between facts about meaning and facts about reference (see the entry on the analytic/synthetic distinction). If the line between these two is blurry, there will very likely be cases in which the line between ambiguity and sense-generality is blurry as well (and not just epistemologically). Let’s indulge in some possible-world anthropology on a group that uses a term, ‘gavagai’ (Quine 1960). Furthermore, I stipulate (perhaps counter-possibly) that the world is a four-dimensional world with respect to the referent of ‘gavagai’ so if they refer at all with ‘gavagai’, they refer to something made up of stages. Now we sit down to write the lexicon of the world’s inhabitants and we come to ‘gavagai’. We write:

‘Gavagai’ (ga-vuh-guy): (N, sing.):

It’s not easy to know what to write down for this entry as it’s not obvious what counts as semantic content for the word and what counts as information about the referent of the word. For example, say they clearly think that the referent of ‘gavagai’ is something that does not have temporal parts. Does this mean that they fail to refer to rabbits with ‘gavagai’ or that they are mistaken about their nature? If this question is hard to answer, we can generalize to harder cases: say that some of the ‘rabbits’ in this world are three-dimensional and some four- dimensional. Should we countenance an ambiguity in ‘gavagai’ given that the people use it indiscriminately to refer to both? Should we posit a lexical ambiguity with two different definitions for ‘gavagai’?

This case may be far-fetched; but we have a real live cases of it. Field (1973) discusses the case of the term ‘mass’, which seems to have been thought to pick out one property of objects but in fact picks out two that are really very different in character. Deciding whether this is a surprising case of disjunctive reference, or an indeterminacy in reference is no easy task, but the decision has ramifications for whether or not we categorize ‘mass’ as ambiguous or highly sense-general (and if sense-general, what is the general sense?)

5.4 The Flexibility of the Lexicon
The lexicon is highly productive and easily extended. Most people, including myself, upon hearing:

She bought a rabbit.
will think that it’s safe to infer that she bought a fuzzy little pet that hops around and likes carrots. However, upon learning that there is a car by the same name made by Volkswagen, it will be much less clear to me that I know what she bought.

Similar phenomena include dead metaphors and idioms. The former include such items as ‘branch’ which now applies to distinct sections of the government, the latter to phrases ‘kick the bucket.’ (As an aside, I puzzled over several candidates for both and realized it was hard to tell in most cases which were which!) These clearly pass the ambiguity tests above by exhibiting zeugma, i.e.,

?The government and the trees have branches.
?He kicked the bucket last week and she did too, twice.
It’s controversial whether metaphors ever actually die and whether or not, assuming they do die, they are metaphors. So it is controversial whether or not ‘branch’ is lexically ambiguous. It clearly has two readings but whether or not these are to be reflected as lexical meanings is a difficult and vague matter – not that it clearly matters all that much in most cases.

5.5 Legal Interpretations
On the other hand, the facts about ambiguity can matter a great deal when it comes to determining policy, extension of law etc. The law is sensitive to this and makes certain division between ambiguities. For example, the law divides between patent and latent ambiguity, where the former roughly corresponds to a case where the meaning of a law is unclear, the latter to cases where the meaning is clear but applies equally well to highly disparate things. In effect, this is the difference between ambiguity in sense and ambiguity in reference.

U.S. Constitution scholars sometimes claim that the Constitution is ‘ambiguous’ at key points. A famous example of such an ambiguity is the succession of the vice president, where the framers stipulate that:

In Case of the Removal of the President from Office, or of his Death, Resignation, or Inability to discharge the Powers and Duties of the said Office, the same shall devolve on the Vice President, (Article 2, section 1)

The clause is not clear as to what ‘devolve’ means.

Of course, given what has been discussed, this looks to be more like a case of under-specificity, or simply ignorance of a word’s meaning (in 1787), not ambiguity. As the distinction has no real legal relevance in this case, it is ignored as it generally is in common parlance.

6. Ambiguity and Indexicality: Are They Easily Told Apart?
In section 2 we looked at phenomena that were not the same as ambiguity; in this section, we look at a few cases in which we might have been wrong to tear them apart.

6.1 Deictic vs. Bound Anaphora
It is often claimed that:

John loves his mother.
is ambiguous between a deictic reading and a bound reading. Syntactic orthodoxy holds that either ‘his’ is co-indexed with John or it bears a different referential index. Various theories of anaphora, however, have claimed that we can dispense with the fundamental ambiguity between free and bound anaphora and unify the treatment of the two. Dynamic Semantics aspires to offer just such a unified account, taking all anaphora to always refer to discourse referents, or functions from information states to information states. This provides a unified treatment of the function of anaphora in natural language and dispenses with the need to think of anaphoric interpretation as ambiguous as opposed to merely context-sensitive. (See Heim 1982, 1983, and Kamp 1981).

6.2 The Scope of Indefinites
Consider:

Every man who read a book by Chomsky is happy.
(77) is ambiguous between one where ‘a book by Chomsky’ takes wide scope over ‘every man who reads’ and one where it takes narrow scope. Maybe so; but most quantifiers in fact cannot escape from relative clauses. Relative clauses are known as ‘scope islands’, or contexts in which quantifiers can’t be interpreted as raised. In fact, it has been noted that indefinites seem to escape from nearly any normal scope island whatsoever. This suggests that treating the various readings as an ambiguity akin to other scopal ambiguities is mistaken. Another treatment of (77)’s multiplicity of readings involves domain restriction: if we restrict the domain of ‘a book’ to only one particular book, we can emulate the reading one would get from treating ‘a book’ as having wide-scope. Domain restriction traditionally is treated as a matter of context sensitivity rather than ambiguity. We thus have some reason to doubt that the right treatment of (77) has much to do with the phenomenon of scope. (see Schwarzchild (2002) for further discussion).

6.3 Modals
As noted above, modals seem to come in various flavours (doxastic, metaphysical, logical, deontic, practical…). It is tempting to treat these as ambiguities involving the modal term. However, it is worth noting that other treatments abound. Kratzer (1983) treats modals as univocal but indexical: they get their differing interpretations by taking in different input sets of worlds and orderings induced on the relevant sets. If this is right, it may well be that what looks like an ambiguity should actually be treated as a matter of straightforward indexicality (much like ‘I’ is not ambiguous but indexical).

6.4 Focal Stress
A really interesting case that may be loosely described as ambiguity at the level of a sentence concerns focal stress and its myriad of interesting effects. Generally focal stress is well known to co-ordinate assertions with questions under discuss and to introduce sets of alternatives into a discourse. In particular, these alternative sets can have truth conditional effects, for example:

Putin only poisons his opponents.
Putin only poisons his opponents
(78) is falsified by Putin shooting an opponent, (79) is not. (78) introduces a presupposition that Putin does something to his opponents while (79) introduces a presupposition that Putin poisons someone. The sentence, thought of in terms of orthography, ‘Putin only poisons his opponents’ is thus ambiguous. Assuming that focal stress is syntactically marked, the LF disambiguates. See (Rooth (1993) and Herburger (2000) for semantic theories of focal stress).
6.5 Cancellation vs. Disambiguation
Griceans have long used cancellation as a method to detect conversational implicatures, or information communicated by an utterer of a sentence that isn’t part of what’s said by S. Cancellation is a procedure by which an explicit denial of putatively conveyed information is conjoined to the original utterance to see if the result is a contradiction. For example, consider an utterance of:

I got drunk and I drove home (but not in that order).
The non-bracketed sentence, absent an utterance of the bracketed content, will typically convey the order events as being mirrored in the order of the conjuncts. But, as Grice famously argued, this isn’t due to an embedded ordering in the meaning of ‘and’ as shown by the addition of the bracketed content not producing a contradiction. The Gricean stories about how we come about this extra information in non-cancellation cases is fairly well known. But given the preceding, it’s not hard to see that an option has been overlooked: why shouldn’t we think of ‘but’ as playing the role of a disambiguator? If ‘and’ were ambiguous, for example, wouldn’t one way of avoiding an contradictory utterance involve adding a phrase that ruled out one possible meaning? We saw Grice’s claims about Modified Occam’s razor and so perhaps attributing an ambiguity to ‘and’ is not so attractive. But perhaps an ambiguity in the assignment of times to the present tense markers is, and the putative cancellation serves to indicate the intended resolution of the those variables? Or perhaps ‘and’ signals two or more possible discourse relations and the putative cancellation services to disambiguate between those? Lepore and Stone (2016) put disambiguation to work in an attempt to show that ambiguities in interpretation are more rife and wide spread than we might have previously assumed. If they are right, ambiguity plays a more central role than perhaps might have been thought in sentence, utterance and discourse interpretation. It remains to see if they are. The point of these examples is that it is often difficult to tell which theoretical treatment best explains a case of multiple interpretability. One must be cautious in one’s approach to these issues. It is all too easy to notice an apparent ambiguity, but often all too difficult to explain its nature.

1. The Nature of Imagination
A variety of roles have been attributed to imagination across various domains of human understanding and activity (section 3). Not surprisingly, it is doubtful that there is one component of the mind that can satisfy all the various roles attributed to imagination (Kind 2013). Nevertheless, perhaps guided by these roles, philosophers have attempted to clarify the nature of imagination in three ways. First, philosophers have tried to disambiguate different senses of the term “imagination” and, in some cases, point to some core commonalities amongst the different disambiguations (section 1.1). Second, philosophers have given partial taxonomies to distinguish different types of imaginings (section 1.2). Third, philosophers have located norms that govern paradigmatic imaginative episodes (section 1.3).

1.1 Varieties of Imagination
There is a general consensus among those who work on the topic that the term “imagination” is used too broadly to permit simple taxonomy. Indeed, it is common for overviews to begin with an invocation of P.F. Strawson’s remarks in “Imagination and Perception”, where he writes:

The uses, and applications, of the terms “image”, “imagine”, “imagination”, and so forth make up a very diverse and scattered family. Even this image of a family seems too definite. It would be a matter of more than difficulty to identify and list the family’s members, let alone their relations of parenthood and cousinhood. (Strawson 1970: 31)

These taxonomic challenges carry over into attempts at characterization. In the opening chapter of Mimesis as Make-Believe—perhaps the most influential contemporary monograph on imagination—Kendall Walton throws up his hands at the prospect of delineating the notion precisely. After enumerating and distinguishing a number of paradigmatic instances of imagining, he asks:

What is it to imagine? We have examined a number of dimensions along which imaginings can vary; shouldn’t we now spell out what they have in common?—Yes, if we can. But I can’t. (Walton 1990: 19)

Leslie Stevenson (2003: 238) makes arguably the only recent attempt at a somewhat comprehensive inventory of the term’s uses, covering twelve of “the most influential conceptions of imagination” that can be found in recent discussions in “philosophy of mind, aesthetics, ethics, poetry and … religion”.

1.2 Taxonomies of Imagination
To describe the varieties of imaginings, philosophers have given partial and overlapping taxonomies.

Some taxonomies are merely descriptive, and they tend to be less controversial. For example, Kendall Walton (1990) distinguishes between spontaneous and deliberate imagining (acts of imagination that occur with or without the one’s conscious direction); between occurrent and nonoccurrent imaginings (acts of imagination that do or do not occupy the one’s explicit attention); and between social and solitary imaginings (episodes of imagining that occur with or without the joint participation of several persons).

One notable descriptive taxonomy concerns imagining from the inside versus from the outside (Williams 1973; Wollheim 1973; see Ninan 2016 for an overview). To imagine from the outside that one is Napoleon involves imagining a scenario in which one is Napoleon. To imagine from the inside that one is Napoleon involves that plus something else: namely, that one is occupying the perspective of Napoleon. Imagining from the inside is essentially first-personal, imagining from the outside is not. This distinction between two modes of imagining is especially notable for its implications for thought experiments about the metaphysics of personal identity (Nichols 2008; Ninan 2009; Williams 1973).

Some taxonomies aim to be more systematic—to carve imaginings at their joints, so to speak—and they, as one might expect, tend to be more controversial.

Gregory Currie and Ian Ravenscroft (2002) distinguishes creative imagination (combining ideas in unexpected and unconventional ways); sensory imagination (perception-like experiences in the absence of appropriate stimuli); and what they call recreative imagination (an ability to experience or think about the world from a perspective different from the one that experience presents). Neil Van Leeuwen (2013, 2014) takes a similar approach to delineate three common uses of “imagination” and cognate terms. First, these terms can be used to refer to constructive imagining, which concerns the process of generating mental representations. Second, these terms can be used to refer to attitude imagining, which concerns the propositional attitude one takes toward mental representations. Third, these terms can be used to refer to imagistic imagining, which concerns the perception-like format of mental representations.

Amy Kind and Peter Kung (2016b) pose the puzzle of imaginative use—on the seeming irreconcilability between the transcendent uses of imagination, which enables one to escape from or look beyond the world as it is, and the instructive uses of imagination, which enables one to learn about the world as it is. Kind and Kung ultimately resolve the puzzle by arguing that the same attitude can be put to these seemingly disparate uses because the two uses differ not in kind, but in degree—specifically, the degree of constraint on imaginings.

Finally, varieties of imagination might be classified in terms of their structure and content. Consider the following three types of imaginings, each illustrated with an example. When one imagines propositionally, one represents to oneself that something is the case. So, for example, Juliet might imagine that Romeo is by her side. To imagine in this sense is to stand in some mental relation to a particular proposition (see the entry on propositional attitude reports). When one imagines objectually, one represents to oneself a real or make-believe entity or situation (Yablo 1993; see also Martin 2002; Noordhof 2002; O’Shaughnessy 2000). So, for example, Prospero might imagine an acorn or a nymph or the city of Naples or a wedding feast. To imagine in this sense is to stand in some mental relation to a representation of an (imaginary or real) entity or state of affairs. When one imagines X-ing, one simulatively represents to oneself some sort of activity or experience (Walton 1990). So, for example, Ophelia might imagine seeing Hamlet or getting herself to a nunnery. To imagine in this sense is to stand in a first-personal mental relation to some (imaginary or real) behavior or perception.

1.3 Norms of Imagination
There are general norms that govern operations of imagination (Gendler 2003).

Mirroring is manifest to the extent that features of the imaginary situation that have not been explicitly stipulated are derivable via features of their real-world analogues, or, more generally, to the extent that imaginative content is taken to be governed by the same sorts of restrictions that govern believed content. For example, in a widely-discussed experiment conducted by Alan Leslie (1994), children are asked to engage in an imaginary tea party. When an experimenter tips and “spills” one of the (empty) teacups, children consider the non-tipped cup to be “full” (in the context of the pretense) and the tipped cup to be “empty” (both within and outside of the context of the pretense). In fact, both make-believe games and more complicated engagements with the arts are governed by principles of generation, according to which prompts or props prescribe particular imaginings (Walton 1990).

Quarantining is manifest to the extent that events within the imagined or pretended episode are taken to have effects only within a relevantly circumscribed domain. So, for example, the child engaging in the make-believe tea party does not expect that “spilling” (imaginary) “tea” will result in the table really being wet, nor does a person who imagines winning the lottery expect that when she visits the ATM, her bank account will contain a million dollars. More generally, quarantining is manifest to the extent that proto-beliefs and proto-attitudes concerning the imagined state of affairs are not treated as beliefs and attitudes relevant to guiding action in the actual world.

Although imaginative episodes are generally governed by mirroring and quarantining, both may be violated in systematic ways.

Mirroring gives way to disparity as a result of the ways in which (the treatment of) imaginary content may differ from (that of) believed content. Imagined content may be incomplete (for example, there may be no fact of the matter (in the pretense) just how much tea has spilled on the table) or incoherent (for example, it might be that the toaster serves (in the pretense) as a logical-truth inverter). And content that is imagined may give rise to discrepant responses, most strikingly in cases of discrepant affect—where, for example, the imminent destruction of all human life is treated as amusing rather than terrifying.

Quarantining gives way to contagion when imagined content ends up playing a direct role in actual attitudes and behavior (see also Gendler 2008a, 2008b). This is common in cases of affective transmission, where an emotional response generated by an imagined situation may constrain subsequent behavior. For example, imagining something fearful (such as a tiger in the kitchen) may give rise to actual hesitation (such as reluctance to enter the room). And it also occurs in cases of cognitive transmission, where imagined content is thereby “primed” and rendered more accessible in ways that go on to shape subsequent perception and experience. For example, imagining some object (such as a sheep) may make one more likely to “perceive” such objects in one’s environment (such as mistaking a rock for a ram).

2. Imagination in Cognitive Architecture
One way to make sense of the nature of imagination is by drawing distinctions, giving taxonomies, and elucidating governing norms (section 1). Another, arguably more prominent, way to make sense of the nature is by figuring out, in a broadly functionalist framework, how it fits in with more well-understood mental entities from folk psychology and scientific psychology (see the entry on functionalism).

There are two related tasks involved. First, philosophers have used other mental entities to define imagination by contradistinction (but see Wiltsher forthcoming for a critique of this approach). To give an oversimplified example, many philosophers hold that imagining is like believing except that it does not directly motivate actions. Second, philosophers have used other mental entities to understand the inputs and outputs of imagination. To give an oversimplified example, many philosophers hold that imagination does not output to action-generating systems.

Amongst the most widely-discussed mental entities in contemporary discussions of imagination are belief (section 2.1), desire (section 2.2), mental imagery (section 2.3), memory (section 2.4), and supposition (section 2.5). The resolution of these debates ultimately rest on the extent to which the imaginative attitude(s) posited can fulfill the roles ascribed to imagination from various domains of human understanding and activity (section 3).

2.1 Imagination and Belief
To believe is to take something to be the case or regard it as true (see the entry on belief). When one says something like “the liar believes that his pants are on fire”, one attributes to the subject (the liar) an attitude (belief) towards a proposition (his pants are on fire). Likewise, when one says something like “the liar imagines that his pants are on fire”, one attributes to the subject (the liar) an attitude (imagination) towards a proposition (his pants are on fire). The similarities and differences between the belief attribution and the imagination attribution point to similarities and differences between imagining and believing.

Imagining and believing are both cognitive attitudes that are representational. They take on the same kind of content: representations that stand in inferential relationship with one another. On the single code hypothesis, it is the sameness of the representational format that grounds functional similarities between imagining and believing (Nichols & Stich 2000, 2003; Nichols 2004a). As for their differences, there are two main options for distinguishing imagining and believing (Sinhababu 2016).

The first option characterizes their difference in normative terms. While belief aims at truth, imagination does not (Humberstone 1992; Shah & Velleman 2005). If the liar did not regard it as true that his pants are on fire, then it seems that he cannot really believe that his pants are on fire. By contrast, even if the liar did not regard it as true that his pants are on fire, he can still imagine that his pants are on fire. While the norm of truth is constitutive of the attitude of belief, it is not constitutive of the attitude of imagination. In dissent, Neil Sinhababu (2013) argues that the norm of truth is neither sufficient nor necessary for distinguishing imagining and believing.

The second option characterizes their difference in functional terms. One purported functional difference between imagination and belief concerns their characteristic connection to actions. If the liar truly believes that his pants are on fire, he will typically attempt to put out the fire by, say, pouring water on himself. By contrast, if the liar merely imagines that his pants are on fire, he will typically do no such thing. While belief outputs to action-generation system, imagination does not (Nichols & Stich 2000, 2003). David Velleman (2000) and Tyler Doggett and Andy Egan (2007) point to particular pretense behaviors to challenge this way of distinguishing imagining and believing. Velleman argues that a belief-desire explanation of children’s pretense behaviors makes children “depressingly unchildlike”. Doggett and Egan argue that during immersive episodes, pretense behaviors can be directly motivated by imagination. In response to these challenges, philosophers typically accept that imagination can have a guidance or stage-setting role in motivating behaviors, but reject that it directly outputs to action-generation system (Van Leeuwen 2009; O’Brien 2005; Funkhouser & Spaulding 2009; Everson 2007; Kind 2011; Currie & Ravenscroft 2002).

Another purported functional difference between imagination and belief concerns their characteristic connection to emotions. If the liar truly believes that his pants are on fire, then he will be genuinely afraid of the fire; but not if he merely imagines so. While belief evokes genuine emotions toward real entities, imagination does not (Walton 1978, 1990, 1997; see also related discussion of the paradox of fictional emotions in Supplement on Puzzles and Paradoxes of Imagination and the Arts). This debate is entangled with the controversy concerning the nature of emotions (see the entry on emotion). In rejecting this purported functional difference, philosophers also typically reject narrow cognitivism about emotions (Nichols 2004a; Meskin & Weinberg 2003; Weinberg & Meskin 2005, 2006; Kind 2011; Spaulding 2015; Carruthers 2003, 2006).

Currently, the consensus is that there exists some important difference between imagining and believing. Yet, there are two distinct departures from this consensus. On the one hand, some philosophers have pointed to novel psychological phenomena in which it is unclear whether imagination or belief is at work—such as delusions (Egan 2008a) and immersed pretense (Schellenberg 2013)—and argued that the best explanation for these phenomena says that imagination and belief exists on a continuum. In responding to the argument from immersed pretense, Shen-yi Liao and Tyler Doggett (2014) argue that a cognitive architecture that collapses distinctive attitudes on the basis of borderline cases is unlikely to be fruitful in explaining psychological phenomena. On the other hand, some philosophers have pointed to familiar psychological phenomena and argued that the best explanation for these phenomena says that imagination is ultimately reducible to belief. Peter Langland-Hassan (2012, 2014) argues that pretense can be explained with only reference to beliefs—specifically, beliefs about counterfactuals. Derek Matravers (2014) argues that engagements with fictions can be explained without references to imaginings.

2.2 Imagination and Desire
To desire is to want something to be the case (see the entry on desire). Standardly, the conative attitude of desire is contrasted with the cognitive attitude of belief in terms of direction of fit: while belief aims to make one’s mental representations match the way the world is, desire aims to make the way the world is match one’s mental representations. Recall that on the single code hypothesis, there exists a cognitive imaginative attitude that is structurally similar to belief. Is there a conative imaginative attitude—call it desire-like imagination (Currie 1997, 2002a, 2002b, 2010; Currie & Ravenscroft 2002), make-desire (Currie 1990; Goldman 2006), or i-desire (Doggett & Egan 2007, 2012)—that is structurally similar to desire?

The debates on the relationship between imagination and desire is, not surprisingly, thoroughly entangled with the debates on the relationship between imagination and belief. One impetus for positing a conative imaginative attitude comes from behavior motivation in imaginative contexts. Tyler Doggett and Andy Egan (2007) argue that cognitive and conative imagination jointly output to action-generation system, in the same way that belief and desire jointly do. Another impetus for positing a conative imaginative attitude comes from emotions in imaginative contexts (see related discussions of the paradox of fictional emotions and the paradoxes of tragedy and horror in Supplement on Puzzles and Paradoxes of Imagination and the Arts). Gregory Currie and Ian Ravenscroft (2002) and Doggett and Egan (2012) argue the best explanation for people’s emotional responses toward non-existent fictional characters call for positing conative imagination. Currie and Ravenscroft (2002), Currie (2010), and Doggett and Egan (2007) argue that the best explanation for people’s apparently conflicting emotional responses toward tragedy and horror too call for positing conative imagination.

Given the entanglement between the debates, competing explanations of the same phenomena also function as arguments against conative imagination (Nichols 2004a, 2006b; Meskin & Weinberg 2003; Weinberg & Meskin 2005, 2006; Spaulding 2015; Kind 2011; Carruthers 2003, 2006; Funkhouser & Spaulding 2009; Van Leeuwen 2011). In addition, another argument against conative imagination is that its different impetuses call for conflicting functional properties. Amy Kind (2016b) notes a tension between the argument from behavior motivation and the argument from fictional emotions: conative imagination must be connected to action-generation in order for it to explain pretense behaviors, but it must be disconnected from action-generation in order for it to explain fictional emotions. Similarly, Shaun Nichols (2004b) notes a tension between Currie and Ravenscroft’s (2002) argument from paradox of fictional emotions and argument from paradoxes of tragedy and horror.

2.3 Imagination, Imagery, and Perception
To have a (merely) mental image is to have a perception-like experience triggered by something other than the appropriate external stimulus; so, for example, one might have “a picture in the mind’s eye or … a tune running through one’s head” (Strawson 1970: 31) in the absence of any corresponding visual or auditory object or event (see the entry on mental imagery). While it is propositional imagination that gets compared to belief and desire, it is sensory or imagistic imagination that get compared to perception (Currie & Ravenscroft 2002). Although it is possible to form mental images in any of the sensory modalities, the bulk of discussion in both philosophical and psychological contexts has focused on visual imagery.

Broadly, there is agreement on the similarity between mental imagery and perception in phenomenology, which can be explicated as a similarity in content (Nanay 2016b; see, for example, Kind 2001; Nanay 2015; Noordhof 2002). Potential candidates for distinguishing mental imagery and perception include intensity (Hume’s Treatise of Human Nature; but see Kind 2017), voluntariness (McGinn 2004; Ichikawa 2009), causal relationship with the relevant object (Noordhof 2002); however, no consensus exists on features that clearly distinguish the two, in part because of ongoing debates about perception (see the entries on contents of perception and epistemological problems of perception).

What is the relationship between imaginings and mental imagery?

Historically, mental imagery is thought to be an essential component of imaginings. Aristotle’s phantasia, which is sometimes translated as imagination, is a faculty that produces images (De Anima; see entry on Aristotle’s conception of imagination; but see Caston 1996). René Descartes (Meditations on First Philosophy) and David Hume (Treatise of Human Nature) both thought that to imagine just is to hold a mental image, or an impression of perception, in one’s mind. However, George Berkeley’s puzzle of visualizing the unseen (Three Dialogues between Hylas and Philonous) arguably suggests the existence of a non-imagistic hypothetical attitude.

Against the historical orthodoxy, the contemporary tendency is to recognize that there is at least one species of imagination—propositional imagination—that does not require mental imagery. For example, Kendall Walton simply states, “imagining can occur without imagery” (1990: 13). In turn, against this contemporary tendency, Amy Kind (2001) argues that an image-based account can explain three crucial features of imagination—directedness, active nature, and phenomenological character—better than its imageless counterpart. As a partial reconciliation of the two, Peter Langland-Hassan (2015) develops a pluralist position on which there exists a variety of imaginative attitudes, including ones that can take on hybrid contents that are partly propositional and partly sensorily imagistic. (For a nuanced overview of this debate, see Gregory 2016: 103–106.)

Finally, the relationship between mental imagery and perception has potential implications for the connection between imagination and action. The orthodoxy on propositional belief-like imagination holds that imagination does not directly output to action-generation system; rather, the connection between the two is mediated by belief and desire. In contrast, the enactivist program in the philosophy of perception holds that perception can directly output to action-generation system (see, for example, Nanay 2013). Working from the starting point that imagistic imagination is similar to perception in its inclusion of mental imagery, some philosophers have argued for a similar direct connection between imagistic imagination and action-generation system (Langland-Hassan 2015; Nanay 2016a; Van Leeuwen 2011, 2016b). That is, there exist imagery-oriented actions that are analogous to perception-oriented actions. For example, Neil Van Leeuwen (2011) argues that an account of imagination that is imagistically-rich can better explain pretense behaviors than its propositional-imagination-only rivals. Furthermore, Robert Eamon Briscoe (2008, 2018) argues that representations that blend inputs from perception and mental imagery, which he calls “make-perceive”, guide many everyday actions. For example, a sculptor might use a blend of the visual perception of a stone and the mental imagery of different parts of the stone being subtracted to guide their physical manipulation of the stone.

2.4 Imagination and Memory
To remember, roughly, is to represent something that is no longer the case. On the standard taxonomy, there are three types of memory. Nondeclarative memory involves mental content that is not consciously accessible, such as one’s memory of how to ride a bike. Semantic declarative memory involves mental content that are propositional and not first-personal, such as one’s memory that Taipei is the capital of Taiwan. Episodic declarative memory involves mental content about one’s own past, such as one’s memory of the birth of one’s child. (See the entry on memory for a detailed discussion of this taxonomy, and especially the criterion of episodicity.) In situating imagination in cognitive architecture, philosophers have typically focused on similarities and differences between imagination and episodic declarative memory.

There are obvious similarities between imagination and memory: both typically involve imagery, both typically concern what is not presently the case, and both frequently involve perspectival representations. Thomas Hobbes (Leviathan: 2.3) claims that “imagination and memory are but one thing, which for diverse consideration has diverse names”. In making this bold statement, Hobbes represents an extreme version of continuism, a view on which imagination and memory refer to the same psychological mechanisms.

The orthodoxy on imagination and memory in the history of philosophy, however, is discontinuism, a view on which there are significant differences between imagination and memory, even if there are overlaps in their psychological mechanisms. Some philosophers find the distinction in internalist factors, such as the phenomenological difference between imagining and remembering. Most famously, David Hume sought to distinguish the two in terms of vivacity—“the ideas of the memory are much more lively and strong than those of the imagination” (Treatise of Human Nature: 1.3; but see Kind 2017). Others who have adopted a phenomenological criterion include René Descartes, Bertrand Russell, and William James (De Brigard 2017). Other philosophers find the distinction in externalist factors, such as the causal connection that exists between memories and the past that is absent with imagination. Aristotle uses the causal connection criterion to distinguish between imagination and memory (De Anima 451a2; 451a8–12; see De Brigard 2017). Indeed, nowadays the idea that a causal connection is essential to remembering is accepted as “philosophical common sense” (see the entry on memory; but see also De Brigard 2014 on memory traces). As such, it is unsurprising that discontinuism remains the orthodoxy. As J. O. Urmson (1967: 83) boldly claims, “One of these universally admitted distinctions is that between memory and imagination”.

In recent years, two sets of findings from cognitive science has given philosophers reasons to push back against discontinuism.

The first set of findings concern distortions and confabulations. The traditional conception of memory is that it functions as an archive: past experiences are encapsulated and stored in the archive, and remembering is just passively retrieving the encapsulated mental content from the archive (Robins 2016). Behavioral psychology has found numerous effects that challenge the empirical adequacy of the archival conception of memory. Perhaps the most well-known is the misinformation effect, which occurs when a subject incorporates inaccurate information into their memory of an event—even inaccurate information that they received after the event (Loftus 1979 [1996]).

The second set of findings concern the psychological underpinnings of “mental time travel”, or the similarities between remembering the past and imagining the future, which is also known as mental time travel (see Schacter et al. 2012 for a review). Using fMRI, neuroscientists have found a striking overlap in the brain activities for remembering the past and imagining the future, which suggest that the two psychological processes utilize the same neural network (see, for example, Addis et al. 2007; Buckner & Carroll 2007; Gilbert & Wilson 2007; Schacter et al. 2007; Suddendorf & Corballis 1997, 2007). The neuroscientific research is preceded by and corroborated by works from developmental psychology (Atance & O’Neill 2011) and on neurodivergent individuals: for example, the severely amnesic patient KC exhibits deficits with remembering the past and imagining the future (Tulving 1985), and also exhibits deficits with the generation of non-personal fictional narratives (Rosenbaum et al. 2009). Note that, despite the evocative contrast between “remembering the past” and “imagining the future”, it is questionable whether temporality is the central contrast. Indeed, some philosophers and psychologists contend that temporality is orthogonal to the comparison between imagination and memory (De Brigard & Gessell 2016; Schacter et al. 2012).

These two set of findings have given rise to an alternative conception that sees memory as essentially constructive, in which remembering is actively generating mental content that more or less represent the past. The constructive conception of memory is in a better position to explain why memories can contain distortions and confabulations (but see Robins 2016 for complications), and why remembering makes use of the same neural networks as imagining.

In turn, this constructive turn in the psychology and philosophy of memory has revived philosophers’ interest in continuism concerning imagination and memory. Kourken Michaelian (2016) explicitly rejects the causal connection criterion and defends a theory on which remembering, like imagining, centrally involves simulation. Karen Shanton and Alvin Goldman (2010) characterizes remembering as mindreading one’s past self. Felipe De Brigard (2014) characterizes remembering as a special instance of hypothetical thinking. Robert Hopkins (2018) characterizes remembering as a kind of imagining that is controlled by the past. However, the philosophical interpretation of empirical research remain contested; in dissent, Dorothea Debus (2014, 2016) considers the same sets of findings but ultimately concludes that remembering and imagining remain distinct mental kinds.

2.5 Imagination and Supposition
To suppose is to form a hypothetical mental representation. There exists a highly contentious debate on whether supposition is continuous with imagination, which is also a hypothetical attitude, or whether there are enough differences to make them discontinuous. There are two main options for distinguishing imagination and supposition, by phenomenology and by function.

The phenomenological distinction standardly turns on the notion of vivacity: whereas imaginings are vivid, suppositions are not. Indeed, one often finds in this literature the contrast between “merely supposing” and “vividly imagining”. Although vivacity has been frequently invoked in discussions of imagination, Amy Kind (2017) draws on empirical and theoretical considerations to argue that it is ultimately philosophically untenable. If that is correct, then the attempt to demarcate imagination and supposition by their vivacity is untenable too. More rarely, other phenomenological differences are invoked; for example, Brian Weatherson (2004) contends that “supposing can be coarse in a way that imagining cannot”.

Imagination	Supposition
Affect	Variable	Atypical
Monitoring	Typical	Typical
Inference	Typical	Typical
Updater	Typical	Atypical
Domain-Specific Systems	Typical	Variable
Script Elaborator	Variable	Atypical
Inputter (punctuate)	Typical	Typical
Inputter (streaming)	Typical	Atypical
Table 1. Architectural similarities and differences between imagination and supposition (Weinberg & Meskin 2006).

There have been diverse functional distinctions attributed to the discontinuity between imagination and supposition, but none has gained universal acceptance. Richard Moran (1994) contends that imagination tends to give rise to a wide range of further mental states, including affective responses, whereas supposition does not (see also Arcangeli 2014, 2017). Tamar Szabó Gendler (2000a) contends that while attempting to imagine something like that female infanticide is morally right seems to generate imaginative resistance, supposing it does not (see the discussion on imaginative resistance in Supplement on Puzzles and Paradoxes of Imagination and the Arts). Gregory Currie and Ian Ravenscroft (2002) contend that supposition involves only cognitive imagination, but imagination involves both cognitive and conative imagination. Alvin Goldman contends that suppositional imagination involves supposing that particular content obtains (for example, supposing that I am elated) but enactment imagination involves “enacting, or trying to enact, elation itself.” (2006: 47–48, italics omitted). Tyler Doggett and Andy Egan (2007) contend that imagination tends to motivate pretense actions, but supposition tends not to. On Jonathan Weinberg and Aaron Meskin (2006)’s synthesis, while there are a few functional similarities, there are many more functional differences between imagination and supposition (Table 1).

There remain ongoing debates about specific alleged functional distinctions, and about whether the functional distinctions are numerous or fundamental enough to warrant discontinuism or not. Indeed, it remains contentious which philosophers count as continuists and which philosophers count as discontinuists (for a few sample taxonomies, see Arcangeli 2017; Balcerak Jackson 2016; Kind 2013).

3. Roles of Imagination
Much of the contemporary discussion of imagination has centered around particular roles that imagination is purported to play in various domains of human understanding and activity. Amongst the most widely-discussed are the role of imagination in understanding other minds (section 3.1), in performing and recognizing pretense (section 3.2), in characterizing psychopathology (section 3.3), in engaging with the arts (section 3.4), in thinking creatively (section 3.5), in acquiring knowledge about possibilities (section 3.6), and in interpreting figurative language (section 3.7).

The variety of roles ascribed to imagination, in turn, provides a guide for discussions on the nature of imagination (section 1) and its place in cognitive architecture (section 2).

3.1 Mindreading
Mindreading is the activity of attributing mental states to oneself and to others, and of predicting and explaining behavior on the basis of those attributions. Discussions of mindreading in the 1990s were often framed as debates between “theory theory”—which holds that the attribution of mental states to others is guided by the application of some (tacit) folk psychological theory—and “simulation theory”—which holds that the attribution of mental states is guided by a process of replicating or emulating the target’s (apparent) mental states, perhaps through mechanisms involving the imagination. (Influential collections of papers on this debate include Carruthers & Smith (eds.) 1996; Davies & Stone (eds.) 1995a, 1995b.) In recent years, proponents of both sides have increasingly converged on common ground, allowing that both theory and simulation play some role in the attribution of mental states to others (see Carruthers 2003; Goldman 2006; Nichols & Stich 2003). Many such hybrid accounts include a role for imagination.

On theory theory views, mindreading involves the application of some (tacit) folk psychological theory that allows the subject to make predictions and offer explanations of the target’s beliefs and behaviors. On pure versions of such accounts, imagination plays no special role in the attribution of mental states to others. (For an overview of theory theory, see entry on folk psychology as a theory).

On simulation theory views, mindreading involves simulating the target’s mental states so as to exploit similarities between the subject’s and target’s processing capacities. It is this simulation that allows the subject to make predictions and offer explanations of the target’s beliefs and behaviors. (For early papers, see Goldman 1989; Gordon 1986; Heal 1986; for recent dissent, see, for example, Carruthers 2009; Gallagher 2007; Saxe 2005, 2009; for an overview of simulation theory, see entry on folk psychology as mental simulation).

Traditional versions of simulation theory typically describe simulation using expressions such as “imaginatively putting oneself in the other’s place”. How this metaphor is understood depends on the specific account. (A collection of papers exploring various versions of simulation theory can be found in Dokic & Proust (eds.) 2002.) On many accounts, the projection is assumed to involve the subject’s imaginatively running mental processes “off-line” that are directly analogous to those being run “on-line” by the target (for example Goldman 1989). Whereas the “on-line” mental processes are genuine, the “off-line” mental processes are merely imagined. For example, a target that is deciding whether to eat sushi for lunch is running their decision-making processes “on-line”; and a subject that is simulating the target’s decision-making is running the analogous processes “off-line”—in part, by imagining the relevant mental states of the target. Recent empirical work in psychology has explored the accuracy of such projections (Markman, Klein, & Suhr (eds.) 2009, section V; Saxe 2005, 2006, 2009.)

Though classic simulationist accounts have tended to assume that the simulation process is at least in-principle accessible to consciousness, a number of recent simulation-style accounts appeal to neuroscientific evidence suggesting that at least some simulative processes take place completely unconsciously. On such accounts of mindreading, no special role is played by conscious imagination (see Goldman 2009; Saxe 2009.)

Many contemporary views of mindreading are hybrid theory views according to which both theorizing and simulation play a role in the understanding of others’ mental states. Alvin Goldman (2006), for example, argues that while mindreading is primarily the product of simulation, theorizing plays a role in certain cases as well. Many recent discussions have endorsed hybrid views of this sort, with more or less weight given to each of the components in particular cases (see Carruthers 2003; Nichols & Stich 2003.)

A number of philosophers have suggested that the mechanisms underlying subjects’ capacity to engage in mindreading are those that enable engagement in pretense behavior (Currie & Ravenscroft 2002; Goldman 2006; Nichols & Stich 2003; for an overview of recent discussions, see Carruthers 2009.) According to such accounts, engaging in pretense involves imaginatively taking up perspectives other than one’s own, and the ability to do so skillfully may rely on—and contribute to—one’s ability to understand those alternate perspectives (see the entry on empathy). Partly in light of these considerations, the relative lack of spontaneous pretense in children with autistic spectrum disorders is taken as evidence for a link between the skills of pretense and empathy.

3.2 Pretense
Pretending is an activity that occurs during diverse circumstances, such as when children make-believe, when criminals deceive, and when thespians act (Langland-Hassan 2014). Although “imagination” and “pretense” have been used interchangeably (Ryle 1949), in this section we will use “imagination” to refer to one’s state of mind, and “pretense” to refer to the one’s actions in the world.

Different theories of pretense disagree fundamentally about what it is to pretend (see Liao & Gendler 2011 for an overview). Consequently, they also disagree about the mental states that enable one to pretend. Metarepresentational theories hold that engaging in pretend play requires the innate mental-state concept pretend (Baron-Cohen, Leslie, & Frith 1985; Friedman 2013; Friedman & Leslie 2007; Leslie 1987, 1994). To pretend is to represent one’s own representations under the concept pretend. Behaviorist theories hold that engaging in pretend play requires a process of behaving-as-if (Harris 1994, 2000; Harris & Kavanaugh 1993; Jarrold et al. 1994; Lillard & Flavell 1992; Nichols & Stich 2003; Perner 1991; Rakoczy, Tomasello, & Striano 2004; Stich & Tarzia 2015). Different behaviorist theories explicate behaving-as-if in different ways, but all aim to provide an account of pretense without recourse to the innate mental-state concept pretend.

Philosophical and psychological theories have sought to explain both the performance of pretense and the recognition of pretense, especially concerning evidence from developmental psychology (see Lillard 2001 for an early overview). On the performance side, children on a standard developmental trajectory exhibit early indicators of pretend play around 15 months; engage in explicit prop-oriented play by 24 months; and engage in sophisticated joint pretend play with props by 36 months (Harris 2000; Perner, Baker, & Hutton 1994; Piaget 1945 [1951]). On the recognition side, children on a standard developmental trajectory distinguish pretense and reality via instinctual behavioral cues around 15–18 months; and start to do so via conventional behavioral cues from 36 months on (Friedman et al. 2010; Lillard & Witherington 2004; Onishi & Baillargeon 2005; Onishi, Baillargeon, & Leslie 2007; Richert and Lillard 2004).

Not surprisingly, the debate between theories of pretense often rest on interpretations of such empirical evidence. For example, Ori Friedman and Alan Leslie (2007) argue that behavioral theories cannot account for the fact that children as young as 15 months old can recognize pretend play and its normativity (Baillargeon, Scott, & He 2010). Specifically, they argue that behavioral theories do not offer straightforward explanations of this early development of pretense recognition, and incorrectly predicts that children systematically mistake other acts of behaving-as-if—such as those that stem from false beliefs—for pretense activities. In response, Stephen Stich and Joshua Tarzia (2015) has acknowledged these problems for earlier behaviorist theories, and developed a new behaviorist theory that purportedly explains the totality of empirical evidence better than metarepresentational rivals. Importantly, Stich and Tarzia argue that their account can better explain Angeline Lillard (1993)’s empirical finding that young children need not attribute a mental concept such as pretend to someone else in order to understand them as pretending.

The debate concerning theories of pretense has implications for the role of imagination in pretense. Behaviorist theories tend to take imagination as essential to explaining pretense performance; metarepresentational theories do not. (However, arguably the innate mental-state concept pretend posited by metarepresentational theories serve similar functions. See Nichols and Stich’s (2000) discussion of the decoupler mechanism, which explicitly draws from Leslie 1987. Currie and Ravenscroft (2002) give a broadly behaviorist theory of pretense that does not require imagination.) Specifically, on most behaviorist theories, imagination is essential for guiding elaborations of pretense episodes, especially via behaviors (Picciuto & Carruthers 2016; Stich & Tarzia 2015).

Most recently, Peter Langland-Hassan (2012, 2014) has developed a theory that aims to explain pretense behavior and pretense recognition without appeal to either metarepresentation or imagination. Langland-Hassan argues that pretense behaviors can be adequately explained by beliefs, desires, and intentions—including beliefs in counterfactuals; and that the difference between pretense and sincerity more generally can be adequately characterized in terms of a person’s beliefs, intentions, and desires. While Langland-Hassan does not deny that pretense is in some sense an imaginative activity, he argues that we do not need to posit a sui generis component of the mind to account for it.

3.3 Psychopathology
Autism and delusions have been—with much controversy—characterized as disorders of imagination. That is, the atypical patterns of cognition and behavior associated with each psychopathology have been argued to result from atypical functions of imagination.

Autism can be characterized in terms of a trio of atypicalities often referred to as “Wing’s triad”: problems in typical social competence, communication, and imagination (Happé 1994; Wing & Gould 1979). The imaginative aspect of autism interacts with other prominent roles of imagination, namely mindreading, pretense, and engagement with the arts (Carruthers 2009). Children with autism do not engage in spontaneous pretend play in the ways that typically-developing children do, engaging instead in repetitive and sometimes obsessional activities; and adults with autism often show little interest in fiction (Carpenter, Tomasello, & Striano 2005; Happé 1994; Rogers, Cook, & Meryl 2005; Wing & Gould 1979). The degree to which an imaginative deficit is implicated in autism remains a matter of considerable debate. Most radically, Gregory Currie and Ian Ravenscroft (2002) have argued that, with respect to Wing’s triad, problems in typical social competence and communication are rooted in an inability to engage in imaginative activities.

Delusions can be characterized as belief-like mental representations that manifest an unusual degree of disconnectedness from reality (Bortolotti & Miyazono 2015). Particularly striking examples would include Capgras and Cotard delusions. In the former, the sufferer takes her friends and family to have been replaced by imposters; in the latter, the sufferer takes himself to be dead. More mundane examples might include ordinary cases of self-deception.

One approach to delusions characterize them as beliefs that are dysfunctional in their content or formation. (For a representative collection of papers that present and criticize this perspective, see Coltheart & Davies (eds.) 2000). However, another approach to delusions characterize them as dysfunctions of imaginings. Currie and Ravenscroft (2002: 170–175) argue that delusions are imaginings that are misidentified by the subject as the result of an inability to keep track of the sources of one’s thoughts. That is, a delusion is an imagined representation that is misidentified by the subject as a belief. Tamar Szabó Gendler (2007) argues that in cases of delusions and self-deceptions, imaginings come to play a role in one’s cognitive architecture similar to that typically played by beliefs. Andy Egan (2008a) likewise argues that the mental states involved in delusions are both belief-like (in their connection to behaviors and inferences) and imagination-like (in their circumscription); however, he argues that these functional similarities suggest the need to posit an in-between attitude called “bimagination”.

3.4 Engagement with the Arts
There is an entrenched historical connection between imagination and the arts. David Hume and Immanuel Kant both invoke imagination centrally in their exploration of aesthetic phenomena (albeit in radically different ways; see entries on Hume’s aesthetics and Kant’s aesthetics). R.G. Collingwood (1938) defines art as the imaginative expression of feeling (Wiltsher 2018; see entry on Collingwood’s aesthetics). Roger Scruton (1974) develops a Wittgensteinian account of imagination and accords it a central role in aesthetic experience and aesthetic judgment.

In contemporary philosophy, the most prominent theory of imagination’s role in engagement with the arts is presented in Kendall Walton’s Mimesis as Make-Believe (1990). (Although Walton uses “fictions” as a technical term to refer to artworks, his conception of the arts is broad enough to include both high-brow and low-brow; popular and obscure; a variety of specific arts such as poetry and videogames; and—as Stacie Friend (2008) clarifies—both fictive and non-fictive works.) Walton’s core insight is that engagement with the arts is fundamentally similar to children’s games of make-believe. When one engages with an artwork, one uses it as a prop in a make-believe game. As props, artworks generate prescriptions for imaginings. These prescriptions also determine the representational contents of artworks (that is, “fictionality”, or what is true in a fictional world). When one correctly engages with an artwork, then, one imagines the representational contents as prescribed.

Out of all the arts, it is the engagement with narratives that philosophers have explored most closely in conjunction with imagination (see Stock 2013 for an overview). Gregory Currie (1990) offers an influential account of imagination and fiction, and Peter Lamarque and Stein Haugom Olsen (1996) discuss literature specifically. Indeed, this research program—despite many criticisms of Walton’s specific theory—remains lively today (see, for example, papers in Nichols (ed.) 2006b). For example, Kathleen Stock (2017) argues that a specific kind of propositional imagination is essential for engagement with fictions. In dissent, Derek Matravers (2014) argues that, contra Walton, imagination is not essential for engagement with fictions.

Philosophers have also done much to articulate the connection between imagination and engagement with music (see the entry on philosophy of music; see also Trivedi 2011). Some philosophers focus on commonalities between engagement with narratives and engagement with music. For example, even though Walton (1990, 1994a, 1999) acknowledges that fictional worlds of music are much more indeterminate than fictional worlds of narratives, he maintains that the same kind of imagining used in experiencing narratives is also used in experiencing various elements of music, such as imagining continuity between movements and imagining feeling musical tension. Similarly, Andrew Kania (2015) argues that experiencing musical space and movement is imaginative like our experience of fictional narratives. Other philosophers draw parallels between engagement with music and other imaginative activities, namely as understanding other minds (section 3.1) and interpreting metaphor (section 3.7). As an example of the former, Jerrold Levinson (1996) argues that the best explanation of musical expressiveness requires listeners to experience music imaginatively—specifically, imagining a persona expressing emotions through the music. As an example of the latter, Scruton (1997) argues that musical experience is informed by spatial concepts applied metaphorically, and so imaginative perception is necessary for musical understanding (but see Budd 2003 for a criticism; see also De Clercq 2007 and Kania 2015). Stephen Davies (2005, 2011) and Peter Kivy (2002) notably criticize the imaginative accounts of engagement with music on empirical and theoretical grounds.

Other imaginative accounts of engagement with the arts can be found in entries on philosophy of film and philosophy of dance. Indeed, imagination’s aesthetic significance extends beyond the arts; philosophical aestheticians have recognized the role of imagination in appreciating nature (Brady 1998) and in appreciating mundane objects, events, and activities (see the entry on aesthetics of the everyday).

Philosophers have sought to clarify the role of imagination in engagement with the arts by focusing on a number of puzzles and paradoxes in the vicinity. The puzzle of imaginative resistance explores apparent limitations on what can be imagined during engagements with the arts and, relatedly, what can be made fictional in artworks. The paradox of emotional response to fictions (widely known as “paradox of fiction”) examines psychological and normative similarities between affective responses prompted by imaginings versus affective responses by reality-directed attitudes. The paradox of tragedy and the paradox of horror examine psychological and normative differences between affective responses prompted by imaginings versus affective responses by reality-directed attitudes. Finally, the puzzle of moral persuasion is concerned with real-world outputs of imaginative engagements with artworks; specifically, whether and how artworks can morally educate or corrupt. For more detail on each of these artistic phenomena, see the Supplement on Puzzles and Paradoxes of Imagination and the Arts.

3.5 Creativity
The idea that imagination plays a central role in creative processes can be traced back to Immanuel Kant (Critique of Pure Reason), who takes artistic geniuses as paradigmatic examples of creativity. On Kant’s account, when imagination aims at the aesthetic, it is allowed to engage in free play beyond the understanding available to oneself. The unconstrained imagination can thereby take raw materials and produce outputs that transcend concepts that one possesses.

While the precise characterization of creativity remains controversial (see Gaut & Kieran (eds.) 2018; Paul & Kaufman (eds.) 2014), contemporary philosophers typically conceive of it more broadly than Kant did. In addition to creative processes in the aesthetic realm, they also consider creative processes in, for example, “science, craft, business, technology, organizational life and everyday activities” (Gaut 2010: 1034; see also Stokes 2011). As an example, Michael Polanyi (1966) gives imagination a central role in the creative endeavor of scientific discovery, by refining and narrowing the solution space to open-ended scientific problems (see Stokes 2016: 252–256). And, in addition to creative processes of geniuses, contemporary philosophers also consider creative processes of ordinary people.

With this broadened scope, contemporary philosophers have followed Kant’s lead in exploring the role of imagination in creativity (see Stokes 2016 for an overview). Berys Gaut (2003) and Dustin Stokes (2014) argue that two characteristic features of imagination—its lack of aim at truth and its dissociation from action—make it especially suitable for creative processes. Peter Carruthers (2002) argues that the same cognitive resources, including imagination, underlie children’s pretend play and adults’ creative thinking. Specifically, Carruthers hypothesizes that children’s play evolutionarily developed as precursors to and practices for adults’ creative thinking.

There are two points of disagreement regarding the role of imagination in creative processes. First, philosophers disagree about the nature and the strength of the connection between imagination and creativity. Kant takes imagination to be constitutive of creativity: what makes a creative process creative is the involvement of imagination aiming at the aesthetic (see also A. Hills & Bird forthcoming). Gaut and Stokes, by contrast, thinks there is only an imperfect causal connection between imagination and creativity: while imagination is useful for creative processes, there are creative processes that do not involve imagination and there are imaginings that are uncreative (see also Beaney 2005). Second, philosophers disagree about the type of imagination involved in creative processes. By hypothesizing a common evolutionary cause, Carruthers suggests that the same imaginative capacity is involved in pretense and in creativity. By contrast, perhaps echoing Kant’s distinction of productive versus reproductive imagination, Currie and Ravenscroft (2002) sharply distinguish recreative imagination, which is involved in pretense and mindreading, from creative imagination.

3.6 Knowledge
Imagination plays a role in the acquisition of knowledge. Many philosophical arguments call on imagination when they appeal to metaphysical modal knowledge (see the entry on epistemology of modality; the papers collected in Gendler & Hawthorne (eds.) 2002; and Kung 2016 and Strohminger & Yli-Vakkuri 2017 for overviews). The kind of thought experiments that are regularly used in scientific theorizing is also plausibly premised on imaginative capacities (see the entry on thought experiments). As already discussed, people use imagination to understand the perspectives of others (section 3.1). Moreover, people often make decisions via thinking about counterfactuals, or what would happen if things had been different from how they in fact are (see the entries on causation and counterfactual conditionals). However, the phenomenon of transformative experience has recently called into question which kind of imaginary scenarios are truly epistemically accessible. (For a representative collection of papers that explore different epistemic roles of imagination, see Kind & Kung (eds.) 2016a.)

Broadly speaking, thought experiments use imaginary scenarios to elicit responses that (ideally) grant people knowledge of possibilities. A special, but prominent, type of thought experiment in philosophy concerns the link between imagination, conceivability, and metaphysical possibility. René Descartes famously offered a modal argument in the Sixth Meditation, reasoning from the fact that he could clearly and distinctly conceive of his mind and body as distinct to the real distinctness between them. The current prevalence of similar modal arguments can be verified by entries on zombies and dualism. These modal arguments all rely, in some way, on the idea that what one can imagine functions as a fallible and defeasible guide to what is really possible in the broadest sense.

Pessimists, notably Peter Van Inwagen (1998: 70), doubt that imagination can give us an accurate understanding of scenarios that are “remote from the practical business of everyday life”, such as those called upon in philosophical modal arguments. Optimists typically take it as a given that there is some connection between imagination and metaphysical modal knowledge, but focus on understanding where the connection is imperfect, such as when one (apparently) imagines the impossible. To just give a few examples, Saul Kripke (1972 [1980]), Stephen Yablo (1993), David Chalmers (2002), Dominic Gregory (2004), Timothy Williamson (2007, 2016), Peter Kung (2010), and Magdalena Balcerak Jackson (2018) have each developed a distinctive approach to this task. For example, Kripke adopts a redescription approach to modeling (some) modal errors: in some cases where one is apparently imagining the impossible, one is in fact imagining a possible scenario but misconstruing it as an impossible one. On this diagnosis, in such cases, the error resides not with imaginative capacities, but with the capacity to describe one’s own imaginings.

Other thought experiments are scoped more narrowly; for example, scientific thought experiments are intended to allow people to explore nomic possibilities. Galileo (On Motion) famously offered a thought experiment that disproved Aristotle’s theory of motion, which predicts that heavier objects fall more quickly. In this thought experiment, Galileo asked people to imagine the falling of a composite of a light and heavy object versus the falling of the heavy object alone. When one runs the thought experiment—that is, when one elaborates on the starting point of this imaginary scenario—one notices an incoherence in Aristotle’s theory: on the one hand, it should predict that the composite would fall more slowly because the light object would slow down the heavy object; on the other hand, it should also predict that the composite would fall more quickly because the composite is heavier than the heavy object alone. While it is incontrovertible that imagination is central to thought experiments, debates remain on whether imagination can be invoked in the context of justification (Gendler 2000b; Williamson 2016) or only in the context of discovery (Norton 1991, 1996; Spaulding 2016).

The role of imagination in counterfactual reasoning—and, in particular, the question of what tends to be held constant when one contemplates counterfactual scenarios—has been explored in detail in recent philosophical and psychological works (Byrne 2005; Williamson 2005, 2007, 2016). Williamson suggests that

When we work out what would have happened if such-and-such had been the case, we frequently cannot do it without imagining such-and-such to be the case and letting things run. (2005: 19)

It is imagination that lets one move from counterfactuals’ antecedents to their consequents. Williamson (2016) argues that our imaginings have evolved to be suitably constrained, such that such counterfactual reasoning can confer knowledge. Indeed, he argues that if one were to be skeptical about gaining knowledge from such a hypothetical reasoning process, then one would be forced to be (implausibly) skeptical about much of ordinary reasoning about actuality. Developing an idea anticipated by Williamson (2007), Margot Strohminger and Juhani Yli-Vakkuri (forthcoming) argue that the same imaginative mechanisms that capable of producing metaphysical modal knowledge are also capable of producing knowledge of other restricted modalities, such as nomic and practical modality. In parallel, Amy Kind (2016c, 2018) argues that imaginings can confer knowledge when they are guided by reality-sensitive constraints, in a manner akin to computer simulations.

Thinking about counterfactuals is just one way that imagination can factor into mundane decision-making. Neil Van Leeuwen (2011, 2016a, 2016b) and Bence Nanay (2016a) have recently started to elaborate on the connection between imagination and actions via decision-making. Although neither authors focus on the epistemic status of imagination, their accounts of decision-making seem to suggest that imagination is used to gain practical knowledge about the probability and value of actions’ possible outcomes.

At the same time, the recently prominent discussion of transformative experiences calls into question the extent to which imagination can be epistemically useful for making life-altering decisions. L.A. Paul (2014, 2015, 2018; see also Jackson 1982, 1986; D. Lewis 1988) argues that some types of knowledge—especially de se knowledge concerning one’s values—are inaccessible by imaginings; only actual experiences can confer these types of knowledge. For example, one cannot really know whether one wants to become a parent without experiencing being a parent because parenthood itself can transform one’s values. If one cannot reasonably imagine oneself with radically different values, then plausibly one cannot appropriately imagine the values associated with the outcomes of one’s actions. As such, despite their epistemic worth in ordinary contexts, imaginings might not help in making life-altering decisions.

3.7 Figurative Language
Finally, imagination might play a role in interpreting figurative language. The exact role ascribed to imagination varies greatly from theory to theory. In part, this variation arose from a longstanding debate in philosophy of language concerning the divide between literal and figurative language: while some imaginative theories of figurative language (such as Walton 1990) accept a strong divide, others (such as Lepore & Stone 2015) reject it. Although this controversy cannot be avoided entirely, it is worth reiterating that the present aim is only to highlight the possible role(s) that imagination might play in the psychology of irony, metaphor, and nearby linguistic phenomena.

Despite immense differences between them, numerous theories of irony have converged on the idea that interpreting irony involves imagination. Kendall Walton (1990) treats ironic and metaphoric speech as props in momentary games of make-believe. On Walton’s theory, imagination is central to understanding and interpreting such figurative speech. Herbert Clark and Richard Gerrig (1984) and Gregory Currie (2006) connect irony to pretense, but without further linking all cases of pretense to imaginative capacities. Elisabeth Camp (2012) similarly endorses a role for pretense in the interpretation of irony and the related case of sarcasm. Finally, this idea that interpreting irony involves imagination is corroborated by psychological research: irony recognition is difficult for neurodivergent individuals who lack imaginative capacities (Happé 1991)—specifically, in individuals with Asperger’s syndrome, who have deficits with meta-representation—and in individuals with schizophrenia, who have deficits with theory-of-mind (Langdon et al. 2002).

Again, despite immense differences between them, numerous theories of metaphor have also converged on the idea that interpreting metaphor involves imagination (see the entry on metaphor). The first family of theories focus on imagination’s role in pretense. As mentioned earlier, Walton (1990) takes metaphors to be props in momentary games of make-believe. Walton (1993, 2000) and David Hills (1997) further develop this idea. (Importantly, Walton (1993) notes that interpretation of a metaphor may not involve actual imaginings, but only the recognition of the type of imaginings prescribed.) Andy Egan (2008b) extends the idea to account for idioms. These theories remain controversial: in particular, Camp (2009) and Catherine Wearing (2011) have offered forceful criticisms. The second family of theories focus on imagination’s role in providing novel perspectives. While Camp (2009) criticizes the first family of theories, she also acknowledges a role for imagination. On her account, pretense and metaphor typically involve distinct types of imaginings: pretense-imaginings allow one to access counterfactual content, but metaphor-imaginings allow one to re-interpret actual content from a novel perspective. Indeed Camp (2007) argues that the kind of imagination involved in interpreting metaphors is also used to interpret similes and juxtapositions. The third family of theories focus on imagination’s role in providing mental images. Paul Ricoeur (1978), Richard Moran (1989), and Robyn Carston (2010) all propose theories on which mental imagery plays an important role in processing metaphors. Outside of philosophy of language, James Grant (2011) argues that metaphors are prevalent in art criticism because they prompt readers’ imaginings.

1. The True: Science, Epistemology and Metaphysics in the Enlightenment
In this era dedicated to human progress, the advancement of the natural sciences is regarded as the main exemplification of, and fuel for, such progress. Isaac Newton’s epochal accomplishment in his Principia Mathematica (1687), which, very briefly described, consists in the comprehension of a diversity of physical phenomena – in particular the motions of heavenly bodies, together with the motions of sublunary bodies – in few relatively simple, universally applicable, mathematical laws, was a great stimulus to the intellectual activity of the eighteenth century and served as a model and inspiration for the researches of a number of Enlightenment thinkers. Newton’s system strongly encourages the Enlightenment conception of nature as an orderly domain governed by strict mathematical-dynamical laws and the conception of ourselves as capable of knowing those laws and of plumbing the secrets of nature through the exercise of our unaided faculties. – The conception of nature, and of how we know it, changes significantly with the rise of modern science. It belongs centrally to the agenda of Enlightenment philosophy to contribute to the new knowledge of nature, and to provide a metaphysical framework within which to place and interpret this new knowledge.

1.1 Rationalism and the Enlightenment
René Descartes’ rationalist system of philosophy is one of the pillars on which Enlightenment thought rests. Descartes (1596–1650) undertakes to establish the sciences upon a secure metaphysical foundation. The famous method of doubt Descartes employs for this purpose exemplifies (in part through exaggerating) an attitude characteristic of the Enlightenment. According to Descartes, the investigator in foundational philosophical research ought to doubt all propositions that can be doubted. The investigator determines whether a proposition is dubitable by attempting to construct a possible scenario under which it is false. In the domain of fundamental scientific (philosophical) research, no other authority but one’s own conviction is to be trusted, and not one’s own conviction either, until it is subjected to rigorous skeptical questioning. With his method, Descartes casts doubt upon the senses as authoritative source of knowledge. He finds that God and the immaterial soul are both better known, on the basis of innate ideas, than objects of the senses. Through his famous doctrine of the dualism of mind and body, that mind and body are two distinct substances, each with its own essence, the material world (allegedly) known through the senses becomes denominated as an “external” world, insofar as it is external to the ideas with which one immediately communes in one’s consciousness. Descartes’ investigation thus establishes one of the central epistemological problems, not only of the Enlightenment, but also of modernity: the problem of objectivity in our empirical knowledge. If our evidence for the truth of propositions about extra-mental material reality is always restricted to mental content, content before the mind, how can we ever be certain that the extra-mental reality is not other than we represent it as being? Descartes’ solution depends on our having secured prior and certain knowledge of God. In fact, Descartes argues that all human knowledge (not only knowledge of the material world through the senses) depends on metaphysical knowledge of God.

Despite Descartes’ grounding of all scientific knowledge in metaphysical knowledge of God, his system contributes significantly to the advance of natural science in the period. He attacks the long-standing assumptions of the scholastic-aristotelians whose intellectual dominance stood in the way of the development of the new science; he developed a conception of matter that enabled mechanical explanation of physical phenomena; and he developed some of the fundamental mathematical resources – in particular, a way to employ algebraic equations to solve geometrical problems – that enabled the physical domain to be explained with precise, simple mathematical formulae. Furthermore, his grounding of physics, and all knowledge, in a relatively simple and elegant rationalist metaphysics provides a model of a rigorous and complete secular system of knowledge. Though major Enlightenment thinkers (for example Voltaire in his Letters on the English Nation, 1734) embrace Newton’s physical system in preference to Descartes’, Newton’s system itself depends on Descartes’ earlier work, a dependence to which Newton himself attests.

Cartesian philosophy also ignites various controversies in the latter decades of the seventeenth century that provide the context of intellectual tumult out of which the Enlightenment springs. Among these controversies are the following: Are mind and body really two distinct sorts of substances, and if so, what is the nature of each, and how are they related to each other, both in the human being (which presumably “has” both a mind and a body) and in a unified world system? If matter is inert (as Descartes claims), what can be the source of motion and the nature of causality in the physical world? And of course the various epistemological problems: the problem of objectivity, the role of God in securing our knowledge, the doctrine of innate ideas, and others.

Baruch Spinoza’s systematic rationalist metaphysics, which he develops in his Ethics (1677) in part in response to problems in the Cartesian system, is also an important basis for Enlightenment thought. Spinoza develops, in contrast to Cartesian dualism, an ontological monism according to which there is only one substance, God or nature, with two attributes, corresponding to mind and body. Spinoza’s denial, on the basis of strict philosophical reasoning, of the existence of a transcendent supreme being, his identification of God with nature, gives strong impetus to the strands of atheism and naturalism that thread through Enlightenment philosophy. Spinoza’s rationalist principles also lead him to assert a strict determinism and to deny any role to final causes or teleology in explanation. (See Israel 2001.)

The rationalist metaphysics of Leibniz (1646–1716) is also foundational for the Enlightenment, particularly the German Enlightenment (die Aufklärung), one prominent expression of which is the Leibnizian rationalist system of Christian Wolff (1679–1754). Leibniz articulates, and places at the head of metaphysics, the great rationalist principle, the principle of sufficient reason, which states that everything that exists has a sufficient reason for its existence. This principle exemplifies the characteristic conviction of the Enlightenment that the universe is thoroughly rationally intelligible. The question arises of how this principle itself can be known or grounded. Wolff attempts to derive it from the logical principle of non-contradiction (in his First Philosophy or Ontology, 1730). Criticism of this alleged derivation gives rise to the general question of how formal principles of logic can possibly serve to ground substantive knowledge of reality. Whereas Leibniz exerts his influence through scattered writings on various topics, some of which elaborate plans for a systematic metaphysics which are never executed by Leibniz himself, Wolff exerts his influence on the German Enlightenment through his development of a rationalist system of knowledge in which he attempts to demonstrate all the propositions of science from first principles, known a priori.

Wolff’s rationalist metaphysics is characteristic of the Enlightenment by virtue of the pretensions of human reason within it, not by reason’s success in establishing its claims. Much the same could be said of the great rationalist philosophers of the seventeenth century. Through their articulation of the ideal of scientia, of a complete science of reality, composed of propositions derived demonstratively from a priori first principles, these philosophers exert great influence on the Enlightenment. But they fail, rather spectacularly, to realize this ideal. To the contrary, what they bequeath to the eighteenth century is metaphysics, in the words of Kant, as “a battlefield of endless controversies.” However, the controversies themselves – regarding the nature of God, mind, matter, substance, cause, et cetera, and the relations of each of these to the others – provide tremendous fuel to Enlightenment thought.

1.2 Empiricism and the Enlightenment
Despite the confidence in and enthusiasm for human reason in the Enlightenment – it is sometimes called “the Age of Reason” – the rise of empiricism, both in the practice of science and in the theory of knowledge, is characteristic of the period. The enthusiasm for reason in the Enlightenment is primarily not for the faculty of reason as an independent source of knowledge, which is embattled in the period, but rather for the human cognitive faculties generally; the Age of Reason contrasts with an age of religious faith, not with an age of sense experience. Though the great seventeenth century rationalist metaphysical systems of Descartes, Spinoza and Leibniz exert tremendous influence on philosophy in the Enlightenment; moreover, and though the eighteenth-century Enlightenment has a rationalist strain (perhaps best exemplified by the system of Christian Wolff), nevertheless, that the Encyclopedia of Diderot and D’Alembert is dedicated to three empiricists (Francis Bacon, John Locke and Isaac Newton), signals the ascendency of empiricism in the period.

If the founder of the rationalist strain of the Enlightenment is Descartes, then the founder of the empiricist strain is Francis Bacon (1561–1626). Though Bacon’s work belongs to the Renaissance, the revolution he undertook to effect in the sciences inspires and influences Enlightenment thinkers. The Enlightenment, as the age in which experimental natural science matures and comes into its own, admires Bacon as “the father of experimental philosophy.” Bacon’s revolution (enacted in, among other works, The New Organon, 1620) involves conceiving the new science as (1) founded on empirical observation and experimentation; (2) arrived at through the method of induction; and (3) as ultimately aiming at, and as confirmed by, enhanced practical capacities (hence the Baconian motto, “knowledge is power”).

Of these elements of Bacon’s revolution, the point about method deserves special emphasis. Isaac Newton’s work, which stands as the great exemplar of the accomplishments of natural science for the eighteenth century, is, like Bacon’s, based on the inductive method. Whereas rationalist of the seventeenth century tend to conceive of scientific knowledge of nature as consisting in a system in which statements expressing the observable phenomena of nature are deduced from first principles, known a priori, Newton’s method begins with the observed phenomena of nature and reduces its multiplicity to unity by induction, that is, by finding mathematical laws or principles from which the observed phenomena can be derived or explained. The evident success of Newton’s “bottom-up” procedure contrasts sharply with the seemingly endless and fruitless conflicts among philosophers regarding the meaning and validity of first principles of reason, and this contrast naturally favors the rise of the Newtonian (or Baconian) method of acquiring knowledge of nature in the eighteenth century.

The tendency of natural science toward progressive independence from metaphysics in the eighteenth century is correlated with this point about method. The rise of modern science in the sixteenth and seventeenth centuries proceeds through its separation from the presuppositions, doctrines and methodology of theology; natural science in the eighteenth century proceeds to separate itself from metaphysics as well. Newton proves the capacity of natural science to succeed independently of a priori, clear and certain first principles. The characteristic Enlightenment suspicion of all allegedly authoritative claims the validity of which is obscure, which is directed first of all against religious dogmas, extends to the claims of metaphysics as well. While there are significant Enlightenment thinkers who are metaphysicians – again, one thinks of Christian Wolff – the general thrust of Enlightenment thought is anti-metaphysical.

John Locke’s Essay Concerning Human Understanding (1690) is another foundational text of the Enlightenment. A main source of its influence is the epistemological rigor that it displays, which is at least implicitly anti-metaphysical. Locke undertakes in this work to examine the human understanding in order to determine the limits of human knowledge; he thereby institutes a prominent pattern of Enlightenment epistemology. Locke finds the source of all our ideas, the ideas out of which human knowledge is constructed, in the senses and argues influentially against the rationalists’ doctrine of innate ideas. Locke’s sensationalism exerts great influence in the French Enlightenment, primarily through being taken up and radicalized by the philosophe, Abbé de Condillac. In the Treatise on Sensations (1754), Condillac attempts to explain how all human knowledge arises out of sense experience. Locke’s epistemology, as developed by Condillac and others, contributes greatly to the emerging science of psychology in the period.

Locke and Descartes both pursue a method in epistemology that brings with it the epistemological problem of objectivity. Both examine our knowledge by way of examining the ideas we encounter directly in our consciousness. This method comes to be called “the way of ideas”. Though neither for Locke nor for Descartes do all of our ideas represent their objects by way of resembling them (e.g., our idea of God does not represent God by virtue of resembling God), our alleged knowledge of our environment through the senses does depend largely on ideas that allegedly resemble external material objects. The way of ideas implies the epistemological problem of how we can know that these ideas do in fact resemble their objects. How can we be sure that these objects do not appear one way before the mind and exist in another way (or not at all) in reality outside the mind? George Berkeley, an empiricist philosopher influenced by John Locke, avoids the problem by asserting the metaphysics of idealism: the (apparently material) objects of perception are nothing but ideas before the mind. However, Berkeley’s idealism is less influential in, and characteristic of, the Enlightenment, than the opposing positions of materialism and Cartesian dualism. Thomas Reid, a prominent member of the Scottish Enlightenment, attacks the way of ideas and argues that the immediate objects of our (sense) perception are the common (material) objects in our environment, not ideas in our mind. Reid mounts his defense of naïve realism as a defense of common sense over against the doctrines of the philosophers. The defense of common sense, and the related idea that the results of philosophy ought to be of use to common people, are characteristic ideas of the Enlightenment, particularly pronounced in the Scottish Enlightenment.

1.3 Skepticism in the Enlightenment
Skepticism enjoys a remarkably strong place in Enlightenment philosophy, given that confidence in our intellectual capacities to achieve systematic knowledge of nature is a leading characteristic of the age. This oddity is at least softened by the point that much skepticism in the Enlightenment is merely methodological, a tool meant to serve science, rather than a position embraced on its own account. The instrumental role for skepticism is exemplified prominently in Descartes’ Meditations on First Philosophy (1641), in which Descartes employs radical skeptical doubt to attack prejudices derived from learning and from sense experience and to search out principles known with certainty which may serve as a secure foundation for a new system of knowledge. Given the negative, critical, suspicious attitude of the Enlightenment towards doctrines traditionally regarded as well founded, it is not surprising that Enlightenment thinkers employ skeptical tropes (drawn from the ancient skeptical tradition) to attack traditional dogmas in science, metaphysics and religion.

However, skepticism is not merely a methodological tool in the hands of Enlightenment thinkers. The skeptical cast of mind is one prominent manifestation of the Enlightenment spirit. The influence of Pierre Bayle, another founding figure of the Enlightenment, testifies to this. Bayle was a French Protestant, who, like many European philosophers of his time, was forced to live and work in politically liberal and tolerant Holland in order to avoid censorship and prison. Bayle’s Historical and Critical Dictionary (1697), a strange and wonderful book, exerts great influence on the age. The form of the book is intimidating: a biographical dictionary, with long scholarly entries on obscure figures in the history of culture, interrupted by long scholarly footnotes, which are in turn interrupted by further footnotes. Rarely has a work with such intimidating scholarly pretentions exerted such radical and liberating influence in the culture. It exerts this influence through its skeptical questioning of religious, metaphysical, and scientific dogmas. Bayle’s eclecticism and his tendency to follow arguments without pre-arranging their conclusions make it difficult to categorize his thought. It is the attitude of inquiry that Bayle displays, rather than any doctrine he espouses, that mark his as distinctively Enlightenment thought. He is fearless and presumptuous in questioning all manner of dogma. His attitude of inquiry resembles both that of Descartes’ meditator and that of the person undergoing enlightenment as Kant defines it, the attitude of coming to think for oneself, of daring to know. This epistemological attitude, as manifest in distrust of authority and reliance on one’s own capacity to judge, expresses the Enlightenment values of individualism and self-determination.

This skeptical/critical attitude underlies a significant tension in the age. While it is common to conceive of the Enlightenment as supplanting the authority of tradition and religious dogma with the authority of reason, in fact the Enlightenment is characterized by a crisis of authority regarding any belief. This is perhaps best illustrated with reference to David Hume’s skepticism, as developed in Book One of A Treatise of Human Nature (1739–40) and in his later Enquiries Concerning Human Understanding (1748). While one might take Hume’s skepticism to imply that he is an outlier with respect to the Enlightenment, it is more convincing to see Hume’s skepticism as a flowering of a crisis regarding authority in belief that is internal to the Enlightenment. Hume articulates a variety of skepticisms. His “skepticism with regard to the senses” is structured by the epistemological problem bound up with the way of ideas, described above. Hume also articulates skepticism with regard to reason in an argument that is anticipated by Bayle. Hume begins this argument by noting that, though rules or principles in demonstrative sciences are certain or infallible, given the fallibility of our faculties, our applications of such rules or principles in demonstrative inferences yield conclusions that cannot be regarded as certain or infallible. On reflection, our conviction in the conclusions of demonstrative reasoning must be qualified by an assessment of the likelihood that we made a mistake in our reasoning. Thus, Hume writes, “all knowledge degenerates into probability” (Treatise, I.iv.i). Hume argues further that, given this degeneration, for any judgment, our assessment of the likelihood that we made a mistake, and the corresponding diminution of certainty in the conclusion, is another judgment about which we ought make a further assessment, which leads to a further diminution of certainty in our original conclusion, leading “at last [to] a total extinction of belief and evidence”. Hume also famously questions the justification of inductive reasoning and causal reasoning. According to Hume’s argument, since in causal reasoning we take our past observations to serve as evidence for judgments regarding what will happen in relevantly similar circumstances in the future, causal reasoning depends on the assumption that the future course of nature will resemble the past; and there is no non-circular justification of this essential assumption. Hume concludes that we have no rational justification for our causal or inductive judgments. Hume’s skeptical arguments regarding causal reasoning are more radical than his skeptical questioning of reason as such, insofar as they call into question even experience itself as a ground for knowledge and implicitly challenge the credentials of Newtonian science itself, the very pride of the Enlightenment. The question implicitly raised by Hume’s powerful skeptical arguments is whether any epistemological authority at all can withstand critical scrutiny. The Enlightenment begins by unleashing skepticism in attacking limited, circumscribed targets, but once the skeptical genie is out of the bottle, it becomes difficult to maintain conviction in any authority. Thus, the despairing attitude that Hume famously expresses in the conclusion to Book One of the Treatise, as the consequence of his epistemological inquiry, while it clashes with the self-confident and optimistic attitude we associate with the Enlightenment, in fact reflects an essential possibility in a distinctive Enlightenment problematic regarding authority in belief.

1.4 Science of Man and Subjectivism in the Enlightenment
Though Hume finds himself struggling with skepticism in the conclusion of Book One of the Treatise, the project of the work as he outlines it is not to advance a skeptical viewpoint, but to establish a science of the mind. Hume is one of many Enlightenment thinkers who aspire to be the “Newton of the mind”; he aspires to establish the basic laws that govern the elements of the human mind in its operations. Alexander Pope’s famous couplet in An Essay on Man (1733) (“Know then thyself, presume not God to scan/ The proper study of mankind is man”) expresses well the intense interest humanity gains in itself within the context of the Enlightenment, as a partial substitute for its traditional interest in God and the transcendent domain. Just as the sun replaces the earth as the center of our cosmos in Copernicus’ cosmological system, so humanity itself replaces God at the center of humanity’s consciousness in the Enlightenment. Given the Enlightenment’s passion for science, the self-directed attention naturally takes the form of the rise of the scientific study of humanity in the period.

The enthusiasm for the scientific study of humanity in the period incorporates a tension or paradox concerning the place of humanity in the cosmos, as the cosmos is re-conceived in the context of Enlightenment philosophy and science. Newton’s success early in the Enlightenment of subsuming the phenomena of nature under universal laws of motion, expressed in simple mathematical formulae, encourages the conception of nature as a very complicated machine, whose parts are material and whose motions and properties are fully accounted for by deterministic causal laws. But if our conception of nature is of an exclusively material domain governed by deterministic, mechanical laws, and if we at the same time deny the place of the supernatural in the cosmos, then how does humanity itself fit into the cosmos? On the one hand, the achievements of the natural sciences in general are the great pride of the Enlightenment, manifesting the excellence of distinctively human capacities. The pride and self-assertiveness of humanity in the Enlightenment expresses itself, among other ways, in humanity’s making the study of itself its central concern. On the other hand, the study of humanity in the Enlightenment typically yields a portrait of us that is the opposite of flattering or elevating. Instead of being represented as occupying a privileged place in nature, as made in the image of God, humanity is represented typically in the Enlightenment as a fully natural creature, devoid of free will, of an immortal soul, and of a non-natural faculty of intelligence or reason. The very title of J.O. de La Mettrie’s Man a Machine (1748), for example, seems designed to deflate humanity’s self-conception, and in this respect it is characteristic of the Enlightenment “science of man”. It is true of a number of works of the Enlightenment, perhaps especially works in the more radical French Enlightenment – notable here are Helvétius’s Of the Spirit (1758) and Baron d’Holbach’s System of Nature (1770) – that they at once express the remarkable self-assertiveness of humanity characteristic of the Enlightenment in their scientific aspirations while at the same time painting a portrait of humanity that dramatically deflates its traditional self-image as occupying a privileged position in nature.

The methodology of epistemology in the period reflects a similar tension. Given the epistemological role of Descartes’ famous “cogito, ergo sum” in his system of knowledge, one might see Descartes’ epistemology as already marking the transition from an epistemology privileging knowledge of God to one that privileges self-knowledge instead. However, in Descartes’ epistemology, it remains true that knowledge of God serves as the necessary foundation for all human knowledge. Hume’s Treatise displays such a re-orientation less ambiguously. As noted, Hume means his work to comprise a science of the mind or of man. In the Introduction, Hume describes the science of man as effectively a foundation for all the sciences since all sciences “lie under the cognizance of men, and are judged of by their powers and faculties.” In other words, since all science is human knowledge, scientific knowledge of humanity is the foundation of the sciences. Hume’s placing the science of man at the foundation of all the sciences both exemplifies the privilege afforded to “mankind’s study of man” within the Enlightenment and provides an interpretation of it. But Hume’s methodological privileging of humanity in the system of sciences contrasts sharply with what he says in the body of his science about humanity. In Hume’s science of man, reason as a faculty of knowledge is skeptically attacked and marginalized; reason is attributed to other animals as well; belief is shown to be grounded in custom and habit; and free will is denied. So, even as knowledge of humanity supplants knowledge of God as the keystone of the system of knowledge, the scientific perspective on humanity starkly challenges humankind’s self-conception as occupying a privileged position in the order of nature.

Immanuel Kant explicitly enacts a revolution in epistemology modeled on the Copernican in astronomy. As characteristic of Enlightenment epistemology, Kant, in his Critique of Pure Reason (1781, second edition 1787) undertakes both to determine the limits of our knowledge, and at the same time to provide a foundation of scientific knowledge of nature, and he attempts to do this by examining our human faculties of knowledge critically. Even as he draws strict limits to rational knowledge, he attempts to defend reason as a faculty of knowledge, as playing a necessary role in natural science, in the face of skeptical challenges that reason faces in the period. According to Kant, scientific knowledge of nature is not merely knowledge of what in fact happens in nature, but knowledge of the causal laws of nature according to which what in fact happens must happen. But how is knowledge of necessary causal connection in nature possible? Hume’s investigation of the idea of cause had made clear that we cannot know causal necessity through experience; experience teaches us at most what in fact happens, not what must happen. In addition, Kant’s own earlier critique of principles of rationalism had convinced him that the principles of (“general”) logic also cannot justify knowledge of real necessary connections (in nature); the formal principle of non-contradiction can ground at best the deduction of one proposition from another, but not the claim that one property or event must follow from another in the course of nature. The generalized epistemological problem Kant addresses in the Critique of Pure Reason is: how is science possible (including natural science, mathematics, metaphysics), given that all such knowledge must be (or include) knowledge of real, substantive (not merely logical or formal) necessities. Put in the terms Kant defines, the problem is: how is synthetic, a priori knowledge possible?

According to Kant’s Copernican Revolution in epistemology addressed to this problem, objects must conform themselves to human knowledge rather than knowledge to objects. Certain cognitive forms lie ready in the human mind – prominent examples are the pure concepts of substance and cause and the forms of intuition, space and time; given sensible representations must conform themselves to these forms in order for human experience (as empirical knowledge of nature) to be possible at all. We can acquire scientific knowledge of nature because we constitute it a priori according to certain cognitive forms; for example, we can know nature as a causally ordered domain because we originally synthesize a priori the given manifold of sensibility according to the category of causality, which has its source in the human mind.

Kant saves rational knowledge of nature by limiting rational knowledge to nature. According to Kant’s argument, we can have rational knowledge only of the domain of possible experience, not of supersensible objects such as God and the soul. Moreover Kant’s solution brings with it a kind of idealism: given the mind’s role in constituting objects of experience, we know objects only as appearances, only as they appear according to our faculties, not as they are in themselves. This is the subjectivism of Kant’s epistemology. Kant’s epistemology exemplifies Enlightenment thought by replacing the theocentric conception of knowledge of the rationalist tradition with an anthropocentric conception.

However, Kant means his system to make room for humanity’s practical and religious aspirations toward the transcendent as well. According to Kant’s idealism, the realm of nature is limited to a realm of appearances, and we can intelligibly think supersensible objects such as God, freedom and the soul, though we cannot know them. Through the postulation of a realm of unknowable noumena (things in themselves) over against the realm of nature as a realm of appearances, Kant manages to make place for practical concepts that are central to our understanding of ourselves even while grounding our scientific knowledge of nature as a domain governed by deterministic causal laws. Though Kant’s idealism is highly controversial from its initial publication, a main point in its favor, according to Kant himself, is that it reconciles, in a single coherent tension, the main tension between the Enlightenment’s conception of nature, as ordered according to deterministic causal laws, and the Enlightenment’s conception of ourselves, as morally free, as having dignity, and as perfectible.

1.5 Emerging Sciences and the Encyclopedia
The commitment to careful observation and description of phenomena as the starting point of science, and then the success at explaining and accounting for observed phenomena through the method of induction, naturally leads to the development of new sciences for new domains in the Enlightenment. Many of the human and social sciences have their origins in the eighteenth century (e.g., history, anthropology, aesthetics, psychology, economics, even sociology), though most are only formally established as autonomous disciplines later. The emergence of new sciences is aided by the development of new scientific tools, such as models for probabilistic reasoning, a kind of reasoning that gains new respect and application in the period. Despite the multiplication of sciences in the period, the ideal remains to comprehend the diversity of our scientific knowledge as a unified system of science; however, this ideal of unity is generally taken as regulative, as an ideal to emerge in the ever-receding end-state of science, rather than as enforced from the beginning by regimenting science under a priori principles.

As exemplifying these and other tendencies of the Enlightenment, one work deserves special mention: the Encyclopedia, edited by Denis Diderot and Jean La Rond d’Alembert. The Encyclopedia (subtitled: “systematic dictionary of the sciences, arts and crafts”) was published in 28 volumes (17 of text, 11 of plates) over 21 years (1751–1772), and consists of over 70,000 articles, contributed by over 140 contributors, among them many of the luminaries of the French Enlightenment. The work aims to provide a compendium of existing human knowledge to be transmitted to subsequent generations, a transmission intended to contribute to the progress and dissemination of human knowledge and to a positive transformation of human society. The orientation of the Encyclopedia is decidedly secular and implicitly anti-authoritarian. Accordingly, the French state of the ancien régime censors the project, and it is completed only through the persistence of Diderot. The collaborative nature of the project, especially in the context of state opposition, contributes significantly to the formation of a shared sense of purpose among the wide variety of intellectuals who belong to the French Enlightenment. The knowledge contained in the Encyclopedia is self-consciously social both in its production – insofar as it is immediately the product of what the title page calls “a society of men of letters” – and in its address – insofar as it is primarily meant as an instrument for the education and improvement of society. It is a striking feature of the Encyclopedia, and one by virtue of which it exemplifies the Baconian conception of science characteristic of the period, that its entries cover the whole range and scope of knowledge, from the most abstract theoretical to the most practical, mechanical and technical.

2. The Good: Political Theory, Ethical Theory and Religion in the Enlightenment
2.1 Political Theory
The Enlightenment is most identified with its political accomplishments. The era is marked by three political revolutions, which together lay the basis for modern, republican, constitutional democracies: The English Revolution (1688), the American Revolution (1775–83), and the French Revolution (1789–99). The success at explaining and understanding the natural world encourages the Enlightenment project of re-making the social/political world, in accord with the models we allegedly find in our reason. Enlightenment philosophers find that the existing social and political orders do not withstand critical scrutiny. Existing political and social authority is shrouded in religious myth and mystery and founded on obscure traditions. The criticism of existing institutions is supplemented with the positive work of constructing in theory the model of institutions as they ought to be. We owe to this period the basic model of government founded upon the consent of the governed; the articulation of the political ideals of freedom and equality and the theory of their institutional realization; the articulation of a list of basic individual human rights to be respected and realized by any legitimate political system; the articulation and promotion of toleration of religious diversity as a virtue to be respected in a well ordered society; the conception of the basic political powers as organized in a system of checks and balances; and other now-familiar features of western democracies. However, for all the enduring accomplishments of Enlightenment political philosophy, it is not clear that human reason proves powerful enough to put a concrete, positive authoritative ideal in place of the objects of its criticism. As in the epistemological domain, reason shows its power more convincingly in criticizing authorities than in establishing them. Here too the question of the limits of reason is one of the main philosophical legacies of the period. These limits are arguably vividly illustrated by the course of the French Revolution. The explicit ideals of the French Revolution are the Enlightenment ideals of individual freedom and equality; but, as the revolutionaries attempt to devise rational, secular institutions to put in place of those they have violently overthrown, eventually they have recourse to violence and terror in order to control and govern the people. The devolution of the French Revolution into the Reign of Terror is perceived by many as proving the emptiness and hypocrisy of Enlightenment reason, and is one of the main factors which account for the end of the Enlightenment as an historical period.

The political revolutions of the Enlightenment, especially the French and the American, were informed and guided to a significant extent by prior political philosophy in the period. Though Thomas Hobbes, in his Leviathan (1651), defends the absolute power of the political sovereign, and is to that extent opposed to the revolutionaries and reformers in England, this work is a founding work of Enlightenment political theory. Hobbes’ work originates the modern social contract theory, which incorporates Enlightenment conceptions of the relation of the individual to the state. According to the general social contract model, political authority is grounded in an agreement (often understood as ideal, rather than real) among individuals, each of whom aims in this agreement to advance his rational self-interest by establishing a common political authority over all. Thus, according to the general contract model (though this is more clear in later contract theorists such as Locke and Rousseau than in Hobbes himself), political authority is grounded not in conquest, natural or divinely instituted hierarchy, or in obscure myths and traditions, but rather in the rational consent of the governed. In initiating this model, Hobbes takes a naturalistic, scientific approach to the question of how political society ought to be organized (against the background of a clear-eyed, unsentimental conception of human nature), and thus decisively influences the Enlightenment process of secularization and rationalization in political and social philosophy.

Baruch Spinoza also greatly contributes to the development of Enlightenment political philosophy in its early years. The metaphysical doctrines of the Ethics (1677) lay the groundwork for his influence on the age. Spinoza’s arguments against Cartesian dualism and in favor of substance monism, the claim in particular that there can only be one substance, God or nature, was taken to have radical implications in the domains of politics, ethics and religion throughout the period. Spinoza’s employment of philosophical reason leads to the denial of the existence of a transcendent, creator, providential, law-giving God; this establishes the opposition between the teachings of philosophy, on the one hand, and the traditional orienting practical beliefs (moral, religious, political) of the people, on the other hand, an opposition that is one important aspect of the culture of the Enlightenment. In his main political work, Tractatus Theologico-Politicus (1677), Spinoza, building on his rationalist naturalism, opposes superstition, argues for toleration and the subordination of religion to the state, and pronounces in favor of qualified democracy. Liberalism is perhaps the most characteristic political philosophy of the Enlightenment, and Spinoza, in this text primarily, is one of its originators.

However, John Locke’s Second Treatise of Government (1690) is the classical source of modern liberal political theory. In his First Treatise of Government, Locke attacks Robert Filmer’s Patriarcha (1680), which epitomizes the sort of political theory the Enlightenment opposes. Filmer defends the right of kings to exercise absolute authority over their subjects on the basis of the claim that they inherit the authority God vested in Adam at creation. Though Locke’s assertion of the natural freedom and equality of human beings in the Second Treatise is starkly and explicitly opposed to Filmer’s view, it is striking that the cosmology underlying Locke’s assertions is closer to Filmer’s than to Spinoza’s. According to Locke, in order to understand the nature and source of legitimate political authority, we have to understand our relations in the state of nature. Drawing upon the natural law tradition, Locke argues that it is evident to our natural reason that we are all absolutely subject to our Lord and Creator, but that, in relation to each other, we exist naturally in a state of equality “wherein all the power and jurisdiction is reciprocal, no one having more than another” (Second Treatise, §4). We also exist naturally in a condition of freedom, insofar as we may do with ourselves and our possessions as we please, within the constraints of the fundamental law of nature. The law of nature “teaches all mankind … that, being all equal and independent, no one ought to harm another in his life, health, liberty, or possessions” (§6). That we are governed in our natural condition by such a substantive moral law, legislated by God and known to us through our natural reason, implies that the state of nature is not Hobbes’ war of all against all. However, since there is lacking any human authority over all to judge of disputes and enforce the law, it is a condition marred by “inconveniencies”, in which possession of natural freedom, equality and possessions is insecure. According to Locke, we rationally quit this natural condition by contracting together to set over ourselves a political authority, charged with promulgating and enforcing a single, clear set of laws, for the sake of guaranteeing our natural rights, liberties and possessions. The civil, political law, founded ultimately upon the consent of the governed, does not cancel the natural law, according to Locke, but merely serves to draw that law closer. “[T]he law of nature stands as an eternal rule to all men” (§135). Consequently, when established political power violates that law, the people are justified in overthrowing it. Locke’s argument for the right to revolt against a government that opposes the purposes for which legitimate government is taken by some to justify the political revolution in the context of which he writes (the English revolution) and, almost a hundred years later, by others to justify the American revolution as well.

Though Locke’s liberalism has been tremendously influential, his political theory is founded on doctrines of natural law and religion that are not nearly as evident as Locke assumes. Locke’s reliance on the natural law tradition is typical of Enlightenment political and moral theory. According to the natural law tradition, as the Enlightenment makes use of it, we can know through the use of our unaided reason that we all – all human beings, universally – stand in particular moral relations to each other. The claim that we can apprehend through our unaided reason a universal moral order exactly because moral qualities and relations (in particular human freedom and equality) belong to the nature of things, is attractive in the Enlightenment for obvious reasons. However, as noted above, the scientific apprehension of nature in the period does not support, and in fact opposes, the claim that the alleged moral qualities and relations (or, indeed, that any moral qualities and relations) are natural. According to a common Enlightenment assumption, as humankind clarifies the laws of nature through the advance of natural science and philosophy, the true moral and political order will be revealed with it. This view is expressed explicitly by the philosophe Marquis de Condorcet, in his Sketch for a Historical Picture of the Progress of the Human Mind (published posthumously in 1795 and which, perhaps better than any other work, lays out the paradigmatically Enlightenment view of history of the human race as a continual progress to perfection). But, in fact, advance in knowledge of the laws of nature in the science of the period does not help with discernment of a natural political or moral order. This asserted relationship between natural scientific knowledge and the political and moral order is under great stress already in the Enlightenment. With respect to Lockean liberalism, though his assertion of the moral and political claims (natural freedom, equality, et cetera) continues to have considerable force for us, the grounding of these claims in a religious cosmology does not. The question of how to ground our claims to natural freedom and equality is one of the main philosophical legacies of the Enlightenment.

The rise and development of liberalism in Enlightenment political thought has many relations with the rise of the mercantile class (the bourgeoisie) and the development of what comes to be called “civil society”, the society characterized by work and trade in pursuit of private property. Locke’s Second Treatise contributes greatly to the project of articulating a political philosophy to serve the interests and values of this ascending class. Locke claims that the end or purpose of political society is the preservation and protection of property (though he defines property broadly to include not only external property but life and liberties as well). According to Locke’s famous account, persons acquire rightful ownership in external things that are originally given to us all by God as a common inheritance, independently of the state and prior to its involvement, insofar as we “mix our labor with them”. The civil freedom that Locke defines, as something protected by the force of political laws, comes increasingly to be interpreted as the freedom to trade, to exchange without the interference of governmental regulation. Within the context of the Enlightenment, economic freedom is a salient interpretation of the individual freedom highly valued in the period. Adam Smith, a prominent member of the Scottish Enlightenment, describes in his An Inquiry into the Nature and Causes of the Wealth of Nations (1776) some of the laws of civil society, as a sphere distinct from political society as such, and thus contributes significantly to the founding of political economy (later called merely “economics”). His is one of many voices in the Enlightenment advocating for free trade and for minimal government regulation of markets. The trading house floor, in which people of various nationalities, languages, cultures, religions come together and trade, each in pursuit of his own self-interest, but, through this pursuit, supplying the wants of their respective nations and increasing its wealth, represents for some Enlightenment thinkers the benign, peaceful, universal rational order that they wish to see replace the violent, confessional strife that characterized the then-recent past of Europe.

However, the liberal conception of the government as properly protecting economic freedom of citizens and private property comes into conflict in the Enlightenment with the value of democracy. James Madison confronts this tension in the context of arguing for the adoption of the U.S. Constitution (in his Federalist #10). Madison argues that popular government (pure democracy) is subject to the evil of factions; in a pure democracy, a majority bound together by a private interest, relative to the whole, has the capacity to impose its particular will on the whole. The example most on Madison’s mind is that those without property (the many) may seek to bring about governmental re-distribution of the property of the propertied class (the few), perhaps in the name of that other Enlightenment ideal, equality. If, as in Locke’s theory, the government’s protection of an individual’s freedom is encompassed within the general end of protecting a person’s property, then, as Madison argues, the proper form of the government cannot be pure democracy, and the will of the people must be officially determined in some other way than by directly polling the people.

Jean-Jacques Rousseau’s political theory, as presented in his On the Social Contract (1762), presents a contrast to the Lockean liberal model. Though commitment to the political ideals of freedom and equality constitutes a common ground for Enlightenment political philosophy, it is not clear not only how these values have a home in nature as Enlightenment science re-conceives it, but also how concretely to interpret each of these ideals and how properly to balance them against each other. Contrary to Madison, Rousseau argues that direct (pure) democracy is the only form of government in which human freedom can be realized. Human freedom, according to Rousseau’s interpretation, is possible only through governance according to what he calls “the general will,” which is the will of the body politic, formed through the original contract, concretely determined in an assembly in which all citizens participate. Rousseau’s account intends to avert the evils of factions by structural elements of the original contract. The contract consists in the self-alienation by each associate of all rights and possessions to the body politic. Because each alienates all, each is an equal member of the body politic, and the terms and conditions are the same for all. The emergence of factions is avoided insofar as the good of each citizen is, and is understood to be, equally (because wholly) dependent on the general will. Legislation supports this identification with the general will by preserving the original equality established in the contract, prominently through maintaining a measure of economic equality. Rousseau’s account of the ideal relation of the individual citizen to the state differs from Locke’s; in Rousseau’s account, the individual must be actively engaged in political life in order to maintain the identification of his supremely authoritative will with the general will, whereas in Locke the emphasis is on the limits of governmental authority with respect to the expressions of the individual will. Though Locke’s liberal model is more representative of the Enlightenment in general, Rousseau’s political theory, which in some respects presents a revived classical model modified within the context of Enlightenment values, in effect poses many of the enduring questions regarding the meaning and interpretation of political freedom and equality within the modern state.

Both Madison and Rousseau, like most political thinkers of the period, are influenced by Baron de Montesquieu’s The Spirit of the Laws (1748), which is one of the founding texts of modern political theory. Though Montesquieu’s treatise belongs to the tradition of liberalism in political theory, given his scientific approach to social, legal and political systems, his influence extends beyond this tradition. Montesquieu argues that the system of legislation for a people varies appropriately with the particular circumstances of the people. He provides specific analysis of how climate, fertility of the soil, population size, et cetera, affect legislation. He famously distinguishes three main forms of governments: republics (which can either be democratic or aristocratic), monarchies and despotisms. He describes leading characteristics of each. His argument that functional democracies require the population to possess civic virtue in high measure, a virtue that consists in valuing public good above private interest, influences later Enlightenment theorists, including both Rousseau and Madison. He describes the threat of factions to which Madison and Rousseau respond in different (indeed opposite) ways. He provides the basic structure and justification for the balance of political powers that Madison later incorporates into the U.S. Constitution.

It is striking how unenlightened many of the Enlightenment’s celebrated thinkers are concerning issues of race and of gender (regarding race, see Race and Enlightenment: A Reader, edited by Emmanuel Chukwudi Eze). For all the public concern with the allegedly universal “rights of man” in the Enlightenment, the rights of women and of non-white people are generally overlooked in the period. (Mary Wollstonecraft’s Vindication of the Rights of Woman (1792) is a noteworthy exception.) When Enlightenment thinkers do turn their attention to the social standing of women or of non-white people, they tend to spout unreasoned prejudice. Moreover, while the philosophies of the Enlightenment generally aspire or pretend to universal truth, unattached to particular time, place or culture, Enlightenment writings are rife with rank ethno- and Eurocentrism, often explicit.

In the face of such tensions within the Enlightenment, one response is to affirm the power of the Enlightenment to improve humanity and society long beyond the end of the eighteenth century, indeed, down to the present day and into the future. This response embraces the Enlightenment and interprets more recent emancipation movements and achievement of recognition of the rights and dignity of traditionally oppressed and marginalized groups as expressions of Enlightenment ideals and aspirations. Critics of the Enlightenment respond differently to such tensions. Critics see them as symptoms of disorder, ideology, perversity, futility or falsehood that afflict the very core of the Enlightenment itself. (See James Schmidt’s “What Enlightenment Project?” for discussion of critics of the Enlightenment.) Famously, Adorno and Horkheimer interpret Nazi death camps as the result of “the dialectic of the Enlightenment”, as what historically becomes of the supremacy of instrumental reason asserted in the Enlightenment. As another example, we may point to some post-modern feminists, who argue, in opposition to the liberal feminists who embrace broadly Enlightenment ideals and conceptions, that the essentialism and universalism associated with Enlightenment ideals are both false and intrinsically hostile to the aspirations to self-realization of women and of other traditionally oppressed groups. (See Strickland and the essays in Akkerman and Stuurman.) This entry is not the place to delineate strains of opposition to the Enlightenment, but it is worth noting that post-Enlightenment social and political struggles to achieve equality or recognition for traditionally marginalized or oppressed groups are sometimes self-consciously grounded in the Enlightenment and sometimes marked by explicit opposition to the Enlightenment’s conceptions or presuppositions.

2.2 Ethical Theory
Many of the leading issues and positions of contemporary philosophical ethics take shape within the Enlightenment. Prior to the Enlightenment in the West, ethical reflection begins from and orients itself around religious doctrines concerning God and the afterlife. The highest good of humanity, and, accordingly, the content and grounding of moral duties, are conceived in immediately religious terms. During the Enlightenment, this changes, certainly within philosophy, but to some significant degree, within the population of western society at large. As the processes of industrialization, urbanization, and dissemination of education advance in this period, happiness in this life, rather than union with God in the next, becomes the highest end for more and more people. Also, the violent religious wars that bloody Europe in the early modern period motivate the development of secular, this-worldly ethics, insofar as they indicate the failure of religious doctrines concerning God and the afterlife to establish a stable foundation for ethics. In the Enlightenment, philosophical thinkers confront the problem of developing ethical systems on a secular, broadly naturalistic basis for the first time since the rise of Christianity eclipsed the great classical ethical systems. However, the changes in our understanding of nature and cosmology, effected by modern natural science, make recourse to the systems of Plato and Aristotle problematic. The Platonic identification of the good with the real and the Aristotelian teleological understanding of natural things are both difficult to square with the Enlightenment conception of nature. The general philosophical problem emerges in the Enlightenment of how to understand the source and grounding of ethical duties, and how to conceive the highest good for human beings, within a secular, broadly naturalistic context, and within the context of a transformed understanding of the natural world.

In ethical thought, as in political theory, Hobbes’ thought is an important provocation in the Enlightenment. Hobbes understands what is good, as the end of human action, to be “whatsoever is the object of any man’s appetite or desire,” and evil to be “the object of his hate, and aversion,” “there being nothing simply and absolutely so; nor any common rule of good and evil, to be taken from the nature of the objects themselves” (Leviathan, chapter 6). Hobbes’ conception of human beings as fundamentally motivated by their perception of what is in their own best interest implies the challenge, important for Enlightenment moral philosophy, to construct moral duties of justice and benevolence out of such limited materials. The basis of human action that Hobbes posits is immediately intelligible and even shared with other animals to some extent; a set of moral duties constructed on this basis would also be intelligible, de-mystified, and fit within the larger scheme of nature. Bernard Mandeville is sometimes grouped with Hobbes in the Enlightenment, especially by critics of them both, because he too, in his popular Fable of the Bees; or, Private Vices, Public Benefits (1714), sees people as fundamentally motivated by their perceived self-interest, and then undertakes to tell a story about how moral virtue, which involves conquering one’s own appetite and serving the interests of others, can be understood to arise on this basis.

Samuel Clarke, an influential rationalist British thinker early in the Enlightenment, undertakes to show in his Discourse concerning the Unchangeable Obligations of Natural Religion (1706), against Hobbes, that the absolute difference between moral good and moral evil lies in the immediately discernible nature of things, independently of any compacts or positive legislation by God or human beings. Clarke writes that “in men’s dealing … one with another, it is undeniably more fit, absolutely and in the nature of the thing itself, that all men should endeavor to promote the universal good and welfare of all; than that all men should be continually contriving the ruin and destruction of all”. Likewise for the rest of what morality enjoins upon us. According to Clarke, that some actions (those we call morally good or required) are “fit to be done” and others not fit is grounded upon the immediately evident relations in which things stand to each other in nature, just as “the proportions of lines or numbers” are evident to the rational perception of a reasonable being. Similarly, Christian Wolff’s rationalist practical philosophy also grounds moral duties in an objective rational order. However, the objective quality on which moral requirements are grounded for Wolff is not the “fitness” of things to be done but rather their perfection. Wolff counts as a founder of the Aufklärung in part because of his attempted derivation of ethical duties from an order of perfection in things, discernable through reason, independently of divine commands.

Rationalist ethics so conceived faces the following obstacles in the Enlightenment. First, as implied above, it becomes increasingly implausible that the objective, mind-independent order is really as rationalist ethicists claim it to be. Second, even if the objective realm were ordered as the rationalist claims, it remains unclear how this order gives rise (on its own, as it were) to obligations binding on our wills. David Hume famously exposes the fallacy of deriving a prescriptive statement (that one ought to perform some action) from a description of how things stand in relation to each other in nature. Prima facie, there is a gap between the rationalist’s objective order and a set of prescriptions binding on our wills; if a supreme legislator must be re-introduced in order to make the conformity of our actions to that objective order binding on our wills, then the alleged existence of the objective moral order does not do the work the account asks of it in the first place.

Alongside the rationalist strand of ethical philosophy in the Enlightenment, there is also a very significant empiricist strand. Empirical accounts of moral virtue in the period are distinguished, both by grounding moral virtue on an empirical study of human nature, and by grounding cognition of moral duties and moral motivation in human sensibility, rather than in reason. The Third Earl of Shaftesbury, author of the influential work Characteristics of Men, Manners, Opinions, Times (1711), is a founding figure of the empiricist strand. Shaftesbury, like Clarke, is provoked by Hobbes’ egoism to provide a non-egoistic account of moral virtue. Shaftesbury conceives the core notion of the goodness of things teleologically: something is good if it contributes to the well-being or furtherance of the system of which it is a part. Individual animals are members of species, and therefore they are good as such insofar as they contribute to the well-being of the species of which they are a part. Thus, the good of things, including human beings, for Shaftesbury as for Clarke, is an objective quality that is knowable through reason. However, though we can know what is good through reason, Shaftesbury maintains that reason alone is not sufficient to motivate human action. Shaftesbury articulates the structure of a distinctively human moral sensibility. Moral sensibility depends on the faculty of reflection. When we reflect on first-order passions such as gratitude, kindness and pity, we find ourselves approving or liking them and disapproving or disliking their opposites. By virtue of our receptivity to such feelings, we are capable of virtue and have a sense of right and wrong. In this way, Shaftesbury defines the moral sense that plays a significant role in the theories of subsequent Enlightenment thinkers such as Francis Hutcheson and David Hume.

In the rationalist tradition, the conflict within the breast of the person between the requirements of morality and self-interest is canonically a conflict between the person’s reason and her passions. Shaftesbury’s identification of a moral sentiment in the nature of humanity renders this a conflict within sensibility itself, a conflict between different sentiments, between a self-interested sentiment and an unegoistic sentiment. Though both Shaftesbury and Hutcheson, no less than Clarke, oppose Hobbes’s egoism, it is nonetheless true that the doctrine of moral sensibility softens moral demands, so to speak. Doing what is morally right or morally good is intrinsically bound up with a distinctive kind of pleasure on their accounts. It is significant that both Shaftesbury and Hutcheson, the two founders of modern moral sense theory, articulate their ethical theory in conjunction with an aesthetic theory. Arguably the pleasure we feel in the apprehension of something beautiful is disinterested pleasure. Our susceptibility to aesthetic pleasure can be taken to reveal that we apprehend and respond to objective (or, anyway, universal) values, not only or necessarily on the basis of reason, but through our natural sensibility instead. Thus, aesthetics, as Shaftesbury and Hutcheson independently develop an account of it, gives encouragement to their doctrines of moral sensibility. But an account of moral virtue, unlike aesthetics, requires an account of moral motivation. As noted above, both Shaftesbury and Hutcheson want to do justice to the idea that proper moral motivation is not the pursuit of pleasure, even disinterested pleasure, but rather an immediate response to the perception of moral value. The problem of giving a satisfying account of moral motivation is a difficult one for empiricist moral philosophers in the Enlightenment.

While for Shaftesbury, at the beginning of the moral sense tradition, moral sense tracks a mind-independent order of value, David Hume, motivated in part by a more radical empiricism, is happy to let the objective order go. We have no access through reason to an independent order of value which moral sense would track. For Hume, morality is founded completely on our sentiments. Hume is often regarded as the main originator of so-called “ethical subjectivism”, according to which moral judgments or evaluations (regarding actions or character) do not make claims about independent facts but merely express the subject’s feelings or attitudes with respect to actions or character. Such subjectivism is relieved of the difficult task of explaining how the objective order of values belongs to the natural world as it is being reconceived by natural science in the period; however, it faces the challenge of explaining how error and disagreement in moral judgments and evaluations are possible. Hume’s account of the standards of moral judgment follows that of Hutcheson in relying centrally on the “natural” responses of an ideal observer or spectator.

Hume’s ethics is exemplary of philosophical ethics in the Enlightenment by virtue of its belonging to the attempt to provide a new, empirically grounded science of human nature, free of theological presuppositions. As noted above, the attempts by the members of the French Enlightenment to present a new understanding of human nature are strongly influenced by Locke’s “sensationalism”, which, radicalized by Condillac, amounts to the attempt to base all contents and faculties of the human mind on the senses. Typically, the French philosophes draw more radical or iconoclastic implications from the new “science of man” than English or Scottish Enlightenment figures. Claude-Adrien Helvétius (1715–1771) is typical here. In De l’ésprit (1758), Helvétius follows the Lockean sensationalism of Condillac and pairs it with the claim that human beings are motivated in their actions only by the natural desire to maximize their own pleasure and minimize their pain. De l’ésprit, though widely read, gives rise to strong negative reactions in the time, both by political and religious authorities (the Sorbonne, the Pope and the Parlement of Paris all condemn the book) and by prominent fellow philosophes, in great part because Helvétius’s psychology seems to critics to render moral imperatives and values without basis, despite his best attempts to derive them. Helvétius attempts to ground the moral equality of all human beings by portraying all human beings, whatever their standing in the social hierarchy, whatever their special talents and gifts, as equally products of the nature we share plus the variable influences of education and social environment. But, to critics, Helvétius’s account portrays all human beings as equal only by virtue of portraying all as equally worthless (insofar as the claim to equality is grounded on all being equally determined by external factors). However, Helvétius’s ideas, in De l’ésprit as well as in its posthumously published sequel De l’homme (1772), exert a great deal of influence, especially his case for the role of pleasure and pain in human motivation and the role of education and social incentives in shaping individuals into contributors to the social good. Helvétius is sometimes regarded as the father of modern utilitarianism through his articulation of the greatest happiness principle and through his influence on Bentham.

Helvétius is typical in the respect that he is radical in the revisions he proposes, not in common moral judgments or customs of the time, but rather regarding the philosophical grounding of those judgments and customs. But there are some philosophers in the Enlightenment who are radical in the revisions they propose regarding the content of ethical judgments themselves. The Marquis de Sade is merely the most notorious example, among a set of Enlightenment figures (including also the Marquis de Argens and Diderot himself in some of his writings) who, within the context of the new naturalism and its emphasis on the pursuit of pleasure, celebrate the avid pursuit of sexual pleasure and explicitly challenge the sexual mores, as well as the wider morality, of their time. The more or less fictionalized, philosophically self-conscious “libertine” is one significant expression of Enlightenment ethical thought.

If the French Enlightenment tends to advance this-worldly happiness as the highest good for human beings more insistently than the Enlightenment elsewhere, then Rousseau’s voice is, in this as in other respects, a discordant voice in that context. Rousseau advances the cultivation and realization of human freedom as the highest end for human beings and thereby gives expression to another side of Enlightenment ethics. As Rousseau describes it, the capacity for individual self-determination puts us in a problematic relation to our natural desires and inclinations and to the realm of nature generally, insofar as that realm is constituted by mechanistic causation. Though Rousseau places a great deal of emphasis on human freedom, and makes significant contributions to our understanding of ourselves as free, he does not address very seriously the problem of the place of human freedom in the cosmos as it is conceived within the context of Enlightenment naturalism.

However, Rousseau’s writings help Kant to the articulation of a practical philosophy that addresses many of the tensions in the Enlightenment. Kant follows Rousseau, and disagrees with empiricism in ethics in the period, in emphasizing human freedom, rather than human happiness, as the central orienting concept of practical philosophy. Though Kant presents the moral principle as a principle of practical reason, his ethics also disagrees significantly with rationalist ethics in the period. According to Kant, rationalists such as Wolff, insofar as they take moral prescriptions to follow from an end given to the will (in Wolff’s case, the end of perfection), do not understand us as autonomous in our moral activity. Through interpreting the faculty of the will itself as practical reason, Kant understands the moral principle as internally legislated, thus as not only compatible with freedom, but as equivalent to the principle of a free will, as a principle of autonomy. As noted above, rationalists in ethics in the period are challenged to explain how the objective moral order which reason in us allegedly discerns gives rise to valid prescriptions binding on our wills (the gap between is and ought). For Kant, the moral order is not independent of our will, but rather represents the formal constraints of willing as such. Kant’s account thus both avoids the is-ought gap and interprets moral willing as expressive of our freedom.

Moreover, by virtue of his interpretation of the moral principle as the principle of pure practical reason, Kant is able to redeem the ordinary sense of moral requirements as over-riding, as potentially opposed to the claims of one’s happiness, and thus as different in kind from the deliverances of prudential reasoning. This ordinary sense of moral requirements is not easily accommodated within the context of Enlightenment empiricism and naturalism. Kant’s stark dichotomy between a person’s practical reason and her sensible nature is strongly criticized, both by the subsequent Romantic generation and in the contemporary context; but this dichotomy is bound up with an important benefit of Kant’s view – much promoted by Kant himself – within the context of the Enlightenment. Elaborated in the context of Kant’s idealism as a contrast between the “realm of freedom” and the “realm of nature”, the dichotomy enables Kant’s proposed solution to the conflict between freedom and nature that besets Enlightenment thought. As noted above, Kant argues that the application of the causal principle is restricted to the realm of nature, thus making room for freedom, compatibly with the causal determination of natural events required by scientific knowledge. Additionally, Kant attempts to show that morality “leads ineluctably to” religious belief (in the supersensible objects of God and of the immortal soul) while being essentially not founded on religious belief, thus again vindicating the ordinary understanding of morality while still furthering Enlightenment values and commitments.

2.3 Religion and the Enlightenment
Though the Enlightenment is sometimes represented as the enemy of religion, it is more accurate to see it as critically directed against various (arguably contingent) features of religion, such as superstition, enthusiasm, fanaticism and supernaturalism. Indeed the effort to discern and advocate for a religion purified of such features – a “rational” or “natural” religion – is more typical of the Enlightenment than opposition to religion as such. Even Voltaire, who is perhaps the most persistent, powerful, vocal Enlightenment critic of religion, directs his polemic mostly against the Catholic Church in France – “l’infâme” in his famous sign-off in his letters, “Écrasez l’infâme” (“Crush the infamous”) refers to the Church, not to religion as such. However, controversy regarding the truth-value or reasonableness of religious belief in general, Christian belief in particular, and controversy regarding the proper place of religion in society, occupies a particularly central place in the Enlightenment. It’s as if the terrible, violent confessional strife in the early modern period in Europe, the bloody drawn-out wars between the Christian sects, was removed to the intellectual arena in the Enlightenment and became a set of more general philosophical controversies.

Alongside the rise of the new science, the rise of Protestantism in western Christianity also plays an important role in generating the Enlightenment. The original Protestants assert a sort of individual liberty with respect to questions of faith against the paternalistic authority of the Church. The “liberty of conscience”, so important to Enlightenment thinkers in general, and asserted against all manner of paternalistic authorities (including Protestant), descends from this Protestant assertion. The original Protestant assertion initiates a crisis of authority regarding religious belief, a crisis of authority that, expanded and generalized and even, to some extent, secularized, becomes a central characteristic of the Enlightenment spirit. The original Protestant assertion against the Catholic Church bases itself upon the authority of scripture. However, in the Enlightenment, the authority of scripture is strongly challenged, especially when taken literally. Developing natural science renders acceptance of a literal version of the Bible increasingly untenable. But authors such as Spinoza (in his Tractatus Theologico-Politicus) present ways of interpreting scripture according to its spirit, rather than its letter, in order to preserve its authority and truth, thus contributing to the Enlightenment controversy of whether some rationally purified version of the religion handed down in the culture belongs to the true philosophical representation of the world or not; and, if so, what its content is.

It is convenient to discuss religion in the Enlightenment by presenting four characteristic forms of Enlightenment religion in turn: deism, religion of the heart, fideism and atheism.

Deism. Deism is the form of religion most associated with the Enlightenment. According to deism, we can know by the natural light of reason that the universe is created and governed by a supreme intelligence; however, although this supreme being has a plan for creation from the beginning, the being does not interfere with creation; the deist typically rejects miracles and reliance on special revelation as a source of religious doctrine and belief, in favor of the natural light of reason. Thus, a deist typically rejects the divinity of Christ, as repugnant to reason; the deist typically demotes the figure of Jesus from agent of miraculous redemption to extraordinary moral teacher. Deism is the form of religion fitted to the new discoveries in natural science, according to which the cosmos displays an intricate machine-like order; the deists suppose that the supposition of God is necessary as the source or author of this order. Though not a deist himself, Isaac Newton provides fuel for deism with his argument in his Opticks (1704) that we must infer from the order and beauty in the world to the existence of an intelligent supreme being as the cause of this order and beauty. Samuel Clarke, perhaps the most important proponent and popularizer of Newtonian philosophy in the early eighteenth century, supplies some of the more developed arguments for the position that the correct exercise of unaided human reason leads inevitably to the well-grounded belief in God. He argues that the Newtonian physical system implies the existence of a transcendent cause, the creator God. In his first set of Boyle lectures, A Demonstration of the Being and Attributes of God (1705), Clarke presents the metaphysical or “argument a priori” for God’s existence. This argument concludes from the rationalist principle that whatever exists must have a sufficient reason or cause of its existence to the existence of a transcendent, necessary being who stands as the cause of the chain of natural causes and effects. Clarke also supports the empirical argument from design, the argument that concludes from the evidence of order in nature to the existence of an intelligent author of that order. In his second set of Boyle lectures, A Discourse Concerning the Unchangeable Obligations of Natural Religion (1706), Clarke argues as well that the moral order revealed to us by our natural reason requires the existence of a divine legislator and an afterlife, in which the supreme being rewards virtue and punishes vice. In his Boyle lectures, Clarke argues directly against the deist philosophy and maintains that what he regards as the one true religion, Christianity, is known as such on the basis of miracles and special revelation; still, Clarke’s arguments on the topic of natural religion are some of the best and most widely-known arguments in the period for the general deist position that natural philosophy in a broad sense grounds central doctrines of a universal religion.

Enlightenment deism first arises in England. In On the Reasonableness of Christianity (1695), Locke aims to establish the compatibility of reason and the teachings of Christianity. Though Locke himself is (like Newton, like Clarke) not a deist, the major English deists who follow (John Toland, Christianity Not Mysterious [1696]); Anthony Collins, A Discourse of Freethinking [1713]; Matthew Tindal, Christianity as Old as Creation [1730]) are influenced by Locke’s work. Voltaire carries deism across the channel to France and advocates for it there over his long literary career. Toward the end-stage, the farcical stage, of the French Revolution, Robespierre institutes a form of deism, the so-called “Cult of the Supreme Being”, as the official religion of the French state. Deism plays a role in the founding of the American republic as well. Many of the founding fathers (Jefferson, Franklin, Madison, Paine) author statements or tracts that are sympathetic to deism; and their deistic sympathies influence the place given (or not given) to religion in the new American state that they found.

Religion of the Heart. Opposition to deism derives sometimes from the perception of it as coldly rationalistic. The God of the deists, arrived at through a priori or empirical argument and referred to as the Prime Mover or Original Architect, is often perceived as distant and unconcerned with the daily struggles of human existence, and thus as not answering the human needs from which religion springs in the first place. Some important thinkers of the Enlightenment – notably Shaftesbury and Rousseau – present religion as founded on natural human sentiments, rather than on the operations of the intellect. Rousseau has his Savoyard Vicar declare, in his Profession of Faith in Emile (1762), that the idea of worshiping a beneficent deity arose in him initially as he reflected on his own situation in nature and his “heart began to glow with a sense of gratitude towards the author of our being”. The Savoyard Vicar continues: “I adore the supreme power, and melt into tenderness at his goodness. I have no need to be taught artificial forms of worship; the dictates of nature are sufficient. Is it not a natural consequence of self-love to honor those who protect us, and to love such as do us good?” This “natural” religion – opposed to the “artificial” religions enforced in the institutions – is often classed as a form of deism. But it deserves separate mention, because of its grounding in natural human sentiments, rather than in reason or in metaphysical or natural scientific problems of cosmology.

Fideism. Deism or natural religion of various sorts tends to rely on the claim that reason or human experience supports the hypothesis that there is a supreme being who created or authored the world. In one of the most important philosophical texts on natural religion to appear during the Enlightenment, David Hume’s Dialogues Concerning Natural Religion (published posthumously in 1779), this supposition is criticized relentlessly, incisively and in detail. Naturally, the critical, questioning attitude characteristic of the Enlightenment in general is directed against the arguments on which natural religion is based. In Part Nine of the Dialogues, Samuel Clarke’s “argument a priori” (as defended by the character Demea) is dispatched fairly quickly, but with a battery of arguments. But Hume is mainly concerned in the Dialogues with the other major pillar of natural religion in the Enlightenment, the “empirical” argument, the teleological argument or the argument from design. Cleanthes, the character who advances the design argument in the dialogue, proceeds from the rule for empirical reasoning that like effects prove like causes. He reasons that, given the resemblance between nature, which displays in many respects a “curious adaptation of means to ends”, and a man-made machine, we must infer the cause of nature to be an intelligence like ours, though greater in proportion as nature surpasses in perfection the products of human intelligence. Philo, the skeptical voice in the Dialogues, presses Cleanthes’ argument on many fronts. He points out that the argument is only as strong as the similarity between nature or parts of nature and man-made machines, and further, that a close scrutiny reveals that analogy to be weak. Moreover, according to the principle of the argument, the stronger the evidence for an author (or authors) of nature, the more like us that author (or authors) should be taken to be. Consequently, according to Philo, the argument does not support the conclusion that God exists, taking God to be unitary, infinite, perfect, et cetera. Also, although the existence of evil and disorder in nature may serve actually to strengthen the case for the argument, given the disorder in human creations as well, the notion that God authors evil and disorder is disturbing. If one denies that there is disorder and evil in nature, however implausibly, the effect is to emphasize again the dissimilarity between nature and human products and thus weaken the central basis of the argument. With these and other considerations, Philo puts the proponent of the empirical argument in a difficult dialectical position. But Cleanthes is not moved. He holds the inference from the phenomenon of the curious adaptation of means to ends in nature to the existence of an intelligent and beneficent author to be so natural as to be impervious to the philosophical cavils raised by Philo. And, in the ambiguous conclusion of the work, Philo seems to agree. Though Hume himself seems to have been an atheist, one natural way to take the upshot of his Dialogues is that religious belief is so “natural” to us that rational criticism cannot unseat it. The ambiguous upshot of the work can be taken to be the impotence of rational criticism in the face of religious belief, rather than the illegitimacy of religious belief in the face of rational criticism. This tends toward fideism, the view according to which religious faith maintains its truth over against philosophical reasoning, which opposes but cannot defeat it. Fideism is most often associated with thinkers whose beliefs run contrary to the trends of the Enlightenment (Blaise Pascal, Johann-Georg Hamann, Søren Kierkegaard), but the skeptical strain in the Enlightenment, from Pierre Bayle through David Hume, expresses itself not only in atheism, but also in fideism.

Atheism. Atheism is more present in the French Enlightenment than elsewhere. In the writings of Denis Diderot, atheism is partly supported by an expansive, dynamic conception of nature. According to the viewpoint developed by Diderot, we ought to search for the principles of natural order within natural processes themselves, not in a supernatural being. Even if we don’t yet know the internal principles for the ordering and development of natural forms, the appeal to a transcendent author of such things is reminiscent, to Diderot’s ear, of the appeal to Aristotelian “substantial forms” that was expressly rejected at the beginning of modern science as explaining nothing. The appeal to a transcendent author does not extend our understanding, but merely marks and fixes the limits of it. Atheism (combined with materialism) in the French Enlightenment is perhaps most identified with the Baron d’Holbach, whose System of Nature (1770) generated a great deal of controversy at the time for urging the case for atheism explicitly and emphatically. D’Holbach’s system of nature is strongly influenced by Diderot’s writings, though it displays less subtlety and dialectical sophistication. Though most Enlightenment thinkers hold that morality requires religion, in the sense that morality requires belief in a transcendent law-giver and in an after-life, d’Holbach (influenced in this respect by Spinoza, among others) makes the case for an ethical naturalism, an ethics that is free of any reference to a supernatural grounding or aspiration. Like Helvétius before him, d’Holbach presents an ethics in which virtue consists in enlightened self-interest. The metaphysical background of the ethics he presents is deterministic materialism. The Prussian enlightened despot, Frederick the Great, famously criticizes d’Holbach’s book for exemplifying the incoherence that troubles the Enlightenment generally: while d’Holbach provides passionate moral critiques of existing religious and social and political institutions and practices, his own materialist, determinist conception of nature allows no place for moral “oughts” and prescriptions and values.

3. The Beautiful: Aesthetics in the Enlightenment
Modern systematic philosophical aesthetics not only first emerges in the context of the Enlightenment, but also flowers brilliantly there. As Ernst Cassirer notes, the eighteenth century not only thinks of itself as the “century of philosophy”, but also as “the age of criticism,” where criticism is centrally (though not only) art and literary criticism (Cassirer 1932, 255). Philosophical aesthetics flourishes in the period because of its strong affinities with the tendencies of the age. Alexander Baumgarten, the German philosopher in the school of Christian Wolff, founds systematic aesthetics in the period, in part through giving it its name. “Aesthetics” is derived from the Greek word for “senses”, because for Baumgarten a science of the beautiful would be a science of the sensible, a science of sensible cognition. The Enlightenment in general re-discovers the value of the senses, not only in cognition, but in human lives in general, and so, given the intimate connection between beauty and human sensibility, the Enlightenment is naturally particularly interested in aesthetics. Also, the Enlightenment includes a general recovery and affirmation of the value of pleasure in human lives, against the tradition of Christian asceticism, and the flourishing of the arts, of the criticism of the arts and of the philosophical theorizing about beauty, promotes and is promoted by this recovery and affirmation. The Enlightenment also enthusiastically embraces the discovery and disclosure of rational order in nature, as manifest most clearly in the development of the new science. It seems to many theorists in the Enlightenment that the faculty of taste, the faculty by which we discern beauty, reveals to us some part of this order, a distinctive harmony, unities amidst variety. Thus, in the phenomenon of aesthetic pleasure, human sensibility discloses to us rational order, thus binding together two enthusiasms of the Enlightenment.

3.1 French Classicism and German Rationalism
In the early Enlightenment, especially in France, the emphasis is upon the discernment of an objective rational order, rather than upon the subject’s sensual aesthetic pleasure. Though Descartes’ philosophical system does not include a theory of taste or of beauty, his mathematical model of the physical universe inspires the aesthetics of French classicism. French classicism begins from the classical maxim that the beautiful is the true. Nicolas Boileau writes in his influential didactic poem, The Art of Poetry (1674), in which he lays down rules for good versification within different genres, that “Nothing is beautiful but the true, the true alone is lovable.” In the period the true is conceived of as an objective rational order. According to the classical conception of art that dominates in the period, art imitates nature, though not nature as given in disordered experience, but the ideal nature, the ideal in which we can discern and enjoy “unity in multiplicity.” In French classicism, aesthetics is very much under the influence of, and indeed modeled on, systematic, rigorous theoretical science of nature. Just as in Descartes’ model of science, where knowledge of all particulars depends on prior knowledge of the principle from which the particulars are deduced, so also in the aesthetics of French classicism, the demand is for systematization under a single, universal principle. The subjection of artistic phenomena to universal rules and principles is expressed, for example, in the title of Charles Batteaux’s main work, The Fine Arts Reduced to a Single Principle (1746), as well as in Boileau’s rules for good versification.

In Germany in the eighteenth century, Christian Wolff’s systematic rationalist metaphysics forms the basis for much of the reflection on aesthetics, though sometimes as a set of doctrines to be argued against. Wolff affirms the classical dictum that beauty is truth; beauty is truth perceived through the feeling of pleasure. Wolff understands beauty to consist in the perfection in things, which he understands in turn to consist in a harmony or order of a manifold. We judge something beautiful through a feeling of pleasure when we sense in it this harmony or perfection. Beauty is, for Wolff, the sensitive cognition of perfection. Thus, for Wolff, beauty corresponds to objective features of the world, but judgments of beauty are relative to us also, insofar as they are based on the human faculty of sensibility.

3.2 Empiricism and Subjectivism
Though philosophical rationalism forms the basis of aesthetics in the early Enlightenment in France and Germany, thinkers in the empiricist tradition in England and Scotland introduce many of the salient themes of Enlightenment aesthetics. In particular, with the rise of empiricism and subjectivism in this domain, attention shifts to the ground and nature of the subject’s experience of beauty, the subject’s aesthetic response. Lord Shaftesbury, though not himself an empiricist or subjectivist in aesthetics, makes significant contributions to this development. Shaftesbury re-iterates the classical equation, “all beauty is truth,” but the truth that beauty is for Shaftesbury is not an objective rational order that could also be known conceptually. Though beauty is, for Shaftesbury, a kind of harmony that is independent of the human mind, under the influence of Plotinus, he understands the human being’s immediate intuition of the beautiful as a kind of participation in the original harmony. Shaftesbury focuses attention on the nature of the subject’s response to beauty, as elevating the person, also morally. He maintains that aesthetic response consists in a disinterested unegoistic pleasure; the discovery of this capacity for disinterested pleasure in harmony shows the way for the development of his ethics that has a similar grounding. And, in fact, in seeing aesthetic response as elevating oneself above self-interested pursuits, through cultivating one’s receptivity to disinterested pleasure, Shaftesbury ties tightly together aesthetics and ethics, morality and beauty, and in that respect also contributes to a trend of the period. Also, in placing the emphasis on the subject’s response to beauty, rather than on the objective characteristics of the beautiful, Shaftesbury makes aesthetics belong to the general Enlightenment interest in human nature. Thinkers of the period find in our receptivity to beauty a key both to understanding both distinctively human nature and its perfection.

Francis Hutcheson follows Shaftesbury in his emphasis on the subject’s aesthetic response, on the distinctive sort of pleasure that the beautiful elicits in us. Partly because the Neo-Platonic influence, so pronounced in Shaftesbury’s aesthetics, is washed out of Hutcheson’s, to be replaced by a more thorough-going empiricism, Hutcheson understands this distinctive aesthetic pleasure as more akin to a secondary quality. Thus, Hutcheson’s aesthetic work raises the prominent question whether “beauty” refers to something objective at all or whether beauty is “nothing more” than a human idea or experience. As in the domain of Enlightenment ethics, so with Enlightenment aesthetics too, the step from Shaftesbury to Hutcheson marks a step toward subjectivism. Hutcheson writes in one of his Two Treatises, his Inquiry Concerning Beauty, Order, Harmony, Design (1725) that “the word ‘beauty’ is taken for the idea raised in us, and a sense of beauty for our power of receiving this idea” (Section I, Article IX). However, though Hutcheson understands beauty to be an idea in us, he takes this idea to be “excited” or “occasioned” in us by distinctive objective qualities, in particular by objects that display “uniformity amidst variety” (ibid., Section II, Article III). In the very title of Hutcheson’s work above, we see the importance of the classical ideas of (rational) order and harmony in Hutcheson’s aesthetic theory, even as he sets the tenor for much Enlightenment discussion of aesthetics through placing the emphasis on the subjective idea and aesthetic response.

David Hume’s famous essay on “the standard of taste” raises and addresses the epistemological problem raised by subjectivism in aesthetics. If beauty is an idea in us, rather than a feature of objects independent of us, then how do we understand the possibility of correctness and incorrectness – how do we understand the possibility of standards of judgment – in this domain? The problem is posed more clearly for Hume because he intensifies Hutcheson’s subjectivism. He writes in the Treatise that “pleasure and pain….are not only necessary attendants of beauty and deformity, but constitute their very essence” (Treatise, Book II, part I, section viii). But if a judgment of taste is based on, or expresses, subjective sentiments, how can it be incorrect? In his response to this question, Hume accounts for the expectation of agreement in judgments of taste by appealing to the fact that we share a common human nature, and he accounts for ‘objectivity’ or expertise in judgments of taste, within the context of his subjectivism, by appealing to the normative responses of well-placed observers. Both of these points (the commonality of human nature and the securing of ‘objectivity’ in judgments based on sentiments by appeal to the normative responses of appropriately placed observers) are typical of the period more generally, and especially of the strong empiricist strain in the Enlightenment. Hume develops the empiricist line in aesthetics to the point where little remains of the classical emphasis on the order or harmony or truth that is, according to the French classicists, apprehended and appreciated in our aesthetic responses to the beautiful, and thus, according to the classicists, the ground of aesthetic responses.

3.3 Late Enlightenment Aesthetics
Immanuel Kant faces squarely the problem of the normativity of judgments of taste. Influenced by Hutcheson and the British empiricist tradition in general, Kant understands judgments of taste to be founded on a distinctive sort of feeling, a disinterested pleasure. In taking judgments of taste to be subjective (they are founded on the subject’s feeling of pleasure) and non-cognitive (such judgments do not subsume representations under concepts and thus do not ascribe properties to objects), Kant breaks with the German rationalist school. However Kant continues to maintain that judgments of beauty are like cognitive judgments in making a legitimate claim to universal agreement – in contrast to judgments of the agreeable. The question is how to vindicate the legitimacy of this demand. Kant argues that the distinctive pleasure underlying judgments of taste is the experience of the harmony of the faculties of the imagination and the understanding, a harmony that arises through their “free play” in the process of cognizing objects on the basis of given sensible intuition. The harmony is “free” in an experience of beauty in the sense that it is not forced by rules of the understanding, as is the agreement among the faculties in acts of cognition. The order and harmony that we experience in the face of the beautiful is subjective, according to Kant; but it is at the same time universal and normative, by virtue of its relation to the conditions of human cognition.

The emphasis Kant places on the role of the activity of the imagination in aesthetic pleasure and discernment typifies a trend in Enlightenment thought. Whereas early in the Enlightenment, in French classicism, and to some extent in Christian Wolff and other figures of German rationalism, the emphasis is on the more-or-less static rational order and proportion and on rigid universal rules or laws of reason, the trend during the development of Enlightenment aesthetics is toward emphasis on the play of the imagination and its fecundity in generating associations.

Denis Diderot is an important and influential author on aesthetics. He wrote the entry “On the Origin and Nature of the Beautiful” for the Encyclopedia (1752). Like Lessing in Germany, Diderot not only philosophized about art and beauty, but also wrote plays and influential art criticism. Diderot is strongly influenced in his writings on aesthetics by the empiricism in England and Scotland, but his writing is not limited to that standpoint. Diderot repeats the classical dictum that art should imitate nature, but, whereas, for French classicists, the nature that art should imitate is ideal nature – a static, universal rational order – for Diderot, nature is dynamic and productive. For Diderot, the nature the artist ought to imitate is the real nature we experience, warts and all (as it were). The particularism and realism of Diderot’s aesthetics is based on a critique of the standpoint of French classicism (see Cassirer 1935, p. 295f.). This critique exposes the artistic rules represented by French classicists as universal rules of reason as nothing more than conventions marking what is considered proper within a certain tradition. In other words, the prescriptions within the French classical tradition are artificial, not natural, and constitute fetters to artistic genius. Diderot takes liberation from such fetters to come from turning to the task of observing and imitating actual nature. Diderot’s emphasis on the primeval productive power and abundance of nature in his aesthetic writings contributes to the trend toward focus on artistic creation and expression (as opposed to artistic appreciation and discernment) that is a characteristic of the late Enlightenment and the transition to Romanticism.

Lessing’s aesthetic writings play an important role in elevating the aesthetic category of expressiveness. In his famous Laocoön: An Essay on the Limits of Painting and Poetry (1766), Lessing argues, by comparing the famous Greek statue with the representation of Laocoön’s suffering in Virgil’s poetry, that the aims of poetry and of the visual arts are not identical; he argues that the aim of poetry is not beauty, but expression. In elevating the aesthetic category of expressiveness, Lessing challenges the notion that all art is imitation of nature. His argument also challenges the notion that all the various arts can be deduced from a single principle. Lessing’s argument in Laocoön supports the contrary thesis that the distinct arts have distinct aims and methods, and that each should be understood on its own terms, not in terms of an abstract general principle from which all arts are to be deduced. For some, especially for critics of the Enlightenment, in this point Lessing is already beyond the Enlightenment. Certainly it is true that the emphasis on the individual or particular, over against the universal, which one finds in other late Enlightenment thinkers, is in tension with Enlightenment tenets. Herder (following Hamann to some extent) argues that each individual art object has to be understood in its own terms, as a totality complete unto itself. With Herder’s stark emphasis on individuality in aesthetics, over against universality, the supplanting of the Enlightenment with Romanticism and Historicism is well advanced. But, according to the point of view taken in this entry, the conception of the Enlightenment according to which it is distinguished by its prioritization of the order of abstract, universal laws and principles, over against concrete particulars and the differences amongst them, is too narrow; it fails to account for much of the characteristic richness in the thought of the period. Indeed aesthetics itself, as a discipline, which, as noted, is founded in the Enlightenment by the German rationalist, Alexander Baumgarten, owes its existence to the tendency in the Enlightenment to search for and discover distinct laws for distinct kinds of phenomena (as opposed to insisting that all phenomena be made intelligible through the same set of general laws and principles). Baumgarten founds aesthetics as a ‘science’ through the attempt to establish the sensible domain as cognizable in a way different from that which prevails in metaphysics. Aesthetics in Germany in the eighteenth century, from Wolff to Herder, both typifies many of the trends of the Enlightenment and marks the field where the Enlightenment yields to competing worldviews.

1. Three Models of Temporal Consciousness
1.1 Time and Consciousness
Time and consciousness are interwoven on several levels. From the vantage point of ordinary life and common sense, consciousness plainly seems to exist in time. When we hear the clock strike twelve, our auditory experience of it so doing also occurs at twelve (or at most a few moments later). Watching a 120-minute action movie results in a two hour stream of auditory and visual experiences (along with accompanying thoughts and feelings), and this stream runs concurrently with the playing of the movie. Quite generally, our conscious states, irrespective of their kind or character, seem to occur in the same temporal framework as events in the wider world. But this is by no means the whole story.

There are also ways in which time or temporality might be regarded as manifest within consciousness. We can judge the duration of temporal intervals, particularly short ones, with reasonable accuracy—an ability that psychologists have investigated in considerable detail (see Wearden 2016 for an overview). Our episodic (or autobiographical) memories supply us with access to our own pasts; thanks to such memories our earlier states of consciousness are not altogether lost to us: they can be recreated (or relived), albeit imperfectly, in our present consciousness. And of course there are past-oriented emotions, such as remorse or regret or shame: through these the past can influence our present feelings, often in powerful ways. While there is no future-directed counterpart of memory, we can anticipate future happenings (more or less accurately, more or less eagerly), and experience future-directed emotions: fear, dread, hope—and these too can exert a powerful influence of our present states of consciousness.

The story is still by no means complete, for temporality is manifest in consciousness in a further and more intimate way. In our ordinary experience, over brief intervals, we seem to be directly aware of temporally extended phenomena such as change, persistence and succession. When we see a friend waving goodbye, do we infer that their arm is moving, on the basis of having observed a motionless arm occupying a sequence of adjacent spatial location? We do make such inferences of this kind: if I see that my neighbour’s dustbin is in the middle of the road rather than its usual position on the pavement, I (rightly) infer that it has been moved. But the case in question is not at all like this: what we see is simply an arm in motion. (Is it for nothing that cinema is often called “the moving image”?) The same applies in other sensory modalities. When listening to a melody, we hear each note giving way to its successor; when we hear a sustained violin tone, we hear the tone continuing on, from moment to moment. If temporally extended occurrences such as these can feature in our perceptual experience, it is natural to conclude that our awareness must be capable of embracing a temporal interval.

While this may seem obvious, it can also seem problematic. We can remember the past and anticipate the future, but we are only directly aware of what is present—or so it is natural to suppose. But the present, strictly speaking, is momentary. So, if our awareness is confined to the present, our awareness must itself lack temporal depth. Hence, we are led swiftly to the conclusion that our direct awareness cannot possibly encompass phenomena possessing temporal extension. We are thus confronted with a conundrum: it seems our awareness must extend over time, but it seems it can’t.

In grappling with this “paradox of temporal awareness” as it is sometimes called, different philosophers have proposed quite different accounts (or models) of the structure of this form of temporal consciousness. Simplifying somewhat, the most discussed options fall into three main categories:

Cinematic Model: our experiences lacks any (or any significant) temporal extension—they are akin to static, motion-free “snapshots” or “stills”. Our streams of consciousness are composed of continuous successions of these static conscious states. In this respect they are analogous to movies, which (as displayed) consist of rapid sequences of still images.
Retentional Model: our experiencing of change and succession occurs within episodes of consciousness which do not themselves possess any (or any significant) temporal extension, but whose contents present (or represent) temporally extended intervals and phenomena. These episodes thus have a complex structure, comprising momentary phases of immediate experience, along with representations (or retentions) of the recent past. Our streams of consciousness are composed of successions of states of this kind.
Extensional Model: our episodes of experiencing are themselves temporally extended, and are thus able to incorporate change and persistence in a quite straightforward way. Our streams of consciousness are composed of successions of these extended phases of experience.
link to extended description below
a. Cinematic Model

 link to extended description below
b. Retentional Model

 link to extended description below
c. Extensional Model

Figure 1.1 The Three Main Conceptions of Temporal Consciousness. [An extended description of Figure 1.1 is in the supplement.]

In his influential writings on these matters William James argued that to make sense of our temporal experience we need to distinguish the strict or mathematical present from the experiential or specious present: whereas the first is indeed durationless, the second is experienced as possessing a brief duration, sufficient to accommodate the change and persistence we find in our immediate experience. Proponents of the cinematic model maintain that James was mistaken: to make sense of our temporal experience we don’t need anything resembling an extended specious present. Proponents of the extensional and retentional views maintain that we do need something resembling a specious present, but offer very different accounts of it.[1]

Ascertaining where the truth lies among the differing accounts of temporal consciousness is interesting in itself. Although most forms of experience seemingly feature succession and persistence—even the most primitive forms if James was correct in characterizing infant consciousness as a “blooming, buzzing confusion”—many philosophers have not found it easy to understand how any form of experience can have such features.[2] The interest and importance of the debate does not end here, for each of the accounts of temporal awareness on offer has significant, and very different, implications for our understanding of the general structure of consciousness. In this entry we will be exploring the principal features and motivations of the competing accounts, as well as their strengths and weaknesses.[3]

1.2 Terminology, Problems and Principles
Although proponents of the competing approaches are attempting to make sense of our experience of temporally extended phenomena, there are divergences on the issue of how precisely this experience should be construed and on several related matters.

One significant divide is between those who believe that temporally extended phenomena really do figure in our immediate experience, and those who deny this. To coin some terminology:

Phenomeno-temporal Realism (PT-realism, henceforth further abbreviated to realism): change, succession and persistence can be directly perceived or apprehended.

Phenomeno-temporal Antirealism (PT-antirealism, henceforth further abbreviated to antirealism): change, succession and persistence cannot be directly perceived or apprehended.

The extensional and retentional models are currently the two most influential forms of realism, with both approaches being developed in a variety of different ways. The task facing antirealists is in one respect the easier of the two: unlike their realist counterparts, they are under no obligation to provide an intelligible account of how it is possible for our consciousness to embrace seemingly temporally extended phenomena. But in another respect their task is the more difficult. Antirealists are under an obligation to “save the (temporal) phenomena”: they need to supply a credible explanation as to why so many of us find it so natural to say we perceive movement and change if in fact we don’t. After all, it does seem perfectly natural to hold that we can see clouds move across the sky, feel water flowing through our fingers and hear melodies. This is the task facing those cinematic theorists—e.g., Chuard (2017)—who hold that we do not directly perceive change or succession but who also accept that we seem to.

Realists generally maintain that it is important to distinguish the experience of succession from a mere succession of experiencings. An experience of succession involves a direct experience of change or persistence; there is no guarantee that a sequence of distinct momentary (or very brief) experiences will constitute an experience with this character even if these experiences occur successively and belong to the same person. If the experiencing of a tone C and a tone D are two entirely separate experiential episodes they won’t jointly constitute an experiencing of the succession C-being-followed-by-D. An experience of succession involves a temporal spread of contents being presented together in consciousness, albeit in the form of a perceived succession rather than simultaneously.

In an influential treatment of these topics Izchak Miller (1984) suggests that philosophical thinking on temporal consciousness has been influenced—overtly or only covertly—by two principles. Miller calls the first of these the “Principle of Presentational Concurrence” (PPC), which he formulates thus:

The duration of a content being presented is concurrent with the duration of the act of presenting it. That is, the time interval occupied by a content which is before the mind is the very same time interval which is occupied by the act of presenting that very content before the mind. (I. Miller 1984: 107)

The “act-content” conception of the structure of consciousness that Miller’s formulation presupposes is not one to which everyone will want to subscribe, but the basic thesis encapsulated in PPC looks highly plausible.[4] If we watch a traffic light change from red to green it is natural to think that we see the red light before we see the green light, and that—more generally—our awareness of these events unfolds concurrently with the events. Of the three conceptions of the nature of temporal experience we encountered in §1.1 the extensional model most clearly conforms with PPC—and for that reason has a prima facie plausibility.

Miller’s second principle is less intuitively plausible, at least on first acquaintance. Miller calls it the “Principle of Simultaneous Awareness” (PSA):

No succession of awarenesses—no matter how close together in time they come—can, by itself, account for an awareness of succession; it must be the case that an awareness of succession derives from simultaneous features of the structure of that awareness. For instance, an awareness of the succession of, say, two tones (or tone-qualities) must involve simultaneous awareness of both tones (or tone-qualities). (I. Miller 1984: 109)

Some elements of Miller’s formulation could be clearer. Phillips expresses the basic idea more succinctly and more clearly:

PSA: If one is aware of a succession or duration, one is necessarily aware of it at one moment. (2014b: 140)[5]

If PSA is true our awareness of the traffic light changing from red to green does not run concurrently with the event itself, it occurs at a single moment, and so runs counter to PPC. To the extent that PPC seems intuitively plausible, PSA seems implausible. However despite this—as we shall see in §4—an impressive number of philosophers and psychologists have rejected PPC and subscribed to PSA. Why has the latter principle seemed plausible? In part because it provides an answer to the question raised a moment ago that many realists have found compelling: “How does an experience of succession differ from a succession of experiences?” For further discussion of these principles and their motivations see Dainton (2000: §5.6), Rashbrook (2013a), Hoerl (2009), and Phillips (2010, 2014b).

1.3 Dynamics of Consciousness
There is a further issue which divides realists. In addition to espousing different views as to the structures within consciousness which provide us with temporal experiences, realists also defend a range of different views concerning the character of temporal experience. Think of what it is like to see ripples move across the surface of a pond (or across one’s skin), or an ocean wave crashing on the beach, or the sound of a violin droning on. When we carefully introspect, it becomes apparent that such experiences possess an internal dynamic character, an immanent intrinsic directed flow, of a distinctive kind. Since introspection also reveals that inner experiences such as mental imagery and bodily sensations all possess a flow-like character, there is reason to think this special form of dynamism is a feature of all forms of temporal experience. Or so some realists urge. Other realists are more sceptical in this regard, and deny that experience is distinctively dynamic in this sort of way, even if it is dynamic in other ways. We thus have a further division to note:

Strong dynamism: some or all forms of consciousness are imbued with an intrinsic directional flow-character.

Moderate dynamism: we directly experience change, succession and persistence but our experience does not possess the inherent flow-character posited by strong dynamists.

Bergson held that consciousness (or durée) is strongly dynamic—“continual flow … is the only immediate date of consciousness” (Bergson 1889 [1910: 44]). He took this dynamism to be a primitive or irreducible feature of experience, describing the experience of a shooting star as “a line of fire” that is characterized by an “absolutely indivisible sensation of motion or mobility” (1889 [1910: 111–2])[6] In stressing the process-like character of perceptual experience Soteriou (2013) approvingly cites O’Shaughnessy, whose commitment to strong dynamism is plain:

[characteristically] the contents of experience are in flux, and necessarily experience itself is in flux, being essentially occurrent in nature … [i]t is not the mere existence of flux […] in the case of experience that is distinctive: it is the necessity of flux. (O’Shaughnessy 2000: 43)

In his Stream of Consciousness (2000) Dainton maintains that intrinsic flow and “dynamic patterning” are features of our temporal experience, and he takes these features to be as primitive as synchronic phenomenal unity. Torrengo (2017) is also committed to strong dynamism. He too thinks that all experiences possess a flow-like character, a character that is irreducible to representational properties of any kind.[7]

1.4 Methodological Controversies
Philosophers interested in uncovering the temporal properties of consciousness have often found inspiration in scientific findings. Recent discussions have featured a wide range of perceptual illusions uncovered by psychologists very prominently—in several much-discussed works Daniel Dennett (1991, Dennett & Kinsbourne 1992) drew the attention of philosophers to a number of experiments where (seemingly) what we perceive is affected by stimuli which lie in the future. In his ground-breaking chapter on the experience of time in The Principles of Psychology (1890) William James spends much of his time relating relevant work carried out by German psychologists such as Exner, Helmolz and Wundt in the preceding decades. As a comparatively new science psychology was just getting started in the nineteenth century, but back in 1689 we find Locke appealing to proto-scientific data when discussing our experience of duration in his Essay, where Locke points out that objects cannot be seen if they move fast enough (e.g., cannon balls), and that a glowing piece of coal appears as a circle when spun quickly.

The question of the extent to which philosophical discussions of temporal experience should be influenced by science is itself a source of controversy. Lee recommends a hard-line science-oriented methodological stance:

My view is that the most powerful considerations in this area have to do with the ways in which temporal information is processed in the brain, so that ultimately what is at stake depends on empirical considerations of a quite general kind. […] It is worth noting at the offset that because I adopt this “bottom-up” methodology, my approach contrasts quite strongly with certain other authors such as Dainton (2000) who argues for views in this area more on the basis of phenomenological than empirical considerations. (Lee 2014a: 2)

In the introduction to his Stream of Consciousness Dainton (2000) willingly concedes that in attempting to understand experiential unity and continuity his own approach will be exclusively phenomenological. He argues that his approach is justified because there exist important experiential structures that are in fact accessible to introspection, and we currently have no other way of accessing these features. Neuroscience may one day be in a position to assist but significant advances will need to be made—indeed Dainton suggests in

situations in which the phenomenological data conflict with accepted science may well provide valuable clues as to how the relevant science might be revised and improved. (2000: 23).

Kon and Miller (2015) advocate a middle way between Dainton’s “top-down” phenomenological approach and Lee’s “bottom-up” approach rooted in neuroscience. They suggest that advances in our understanding of temporal experience will require us to successfully integrate armchair analysis and empirical evidence:

we foresee that empirical evidence may significantly modify classic models these models are still of use: they offer a starting point for empirical enquiry by placing key features of our experience into coherent models. Plus, they offer general frameworks in which particular empirical models may be slotted and that potentially have testable consequences. (2015: 215)

If temporal illusions have played a significant role in recent debates but the same cannot be said of the general neuroscientific theories of consciousness—theories which purport to identify the neural basis of consciousness and (more ambitiously) explain how and why neural processes produce experiences in all its forms. It is far from being the case that general theories of this sort do not exist, or are even thin on the ground—see Wu (2018) for an introduction to several. Why have philosophers interested in temporal experience paid comparatively little attention to these theories? Kent and Wittmann (2021) propose an answer: to a surprising extent the main general theories of how consciousness relates to the brain make no attempt to explain or accommodate experienced succession, at most they can explain experienced simultaneity as it features in the briefest of conscious episodes. Northoff and Lamme (2020) review eight leading neuroscientific theories of consciousness: global neuronal workspace theory (GNWT), predictive coding theory (PCT), embodied theory (EB), temporospatial theory of consciousness (TTC), integrated information theory (IIT), recurrent processing theory (RPT), synchrony theory (ST) and higher-order thought theory (HOT). The majority of these, Kent and Wittmann argue, focus exclusively on processes in the sub-300 msec range, the sorts of neural processes that are generally thought to give rise to momentary experiences of simultaneity. These leading theories have nothing to say about neural processes occurring over longer intervals, from 300 msec to 3 seconds or more, that it is plausible to suppose will be underlie experiences of change and succession. Only RPT and Northoff’s own TTC offer anything different: these theories hold that experienced succession depends on oscillatory neural process that extend over significant periods of time.

If Kent and Wittmann are right it’s obvious why general neuroscientific theories have—thus far at least—had so little impact on the philosophical debates. Whereas the latter offer competing accounts of the experience of temporally extended phenomena seemingly stretching over intervals of time, the neuroscientific theories have largely confined themselves to a single experienced moment. If neuroscience starts to move beyond its current very narrow temporal focus its impact will very likely begin to increase.

These considerations do not mean that it is impossible for the philosophical debates to impact on neuroscience. To focus on just one example, the current incarnation of IIT is quite explicit regarding the narrow temporal confines of consciousness:

… my experience flows at a particular speed—each experience encompassing a hundred milliseconds or so—but I am not having an experience that encompasses just a few milliseconds or hours. (Tononi & Koch 2015: 6)

Since these brief episodes are discrete and non-overlapping our consciousness is less continuous than commonly thought:

Accordingly, the seemingly continuous “stream” of consciousness would actually be constituted by a discrete succession of “snapshots” in line with some psychophysical evidence. (2015: 16)

In effect Tononi and Koch are committing IIT to a version of the cinematic model outlined earlier. This model does have its proponents, so this in itself is not problematic. What is more puzzling, as Singhal, Mudumba and Srinivasan (2022) point out is that IIT distinguishes itself from other neuroscientific approaches by taking phenomenology very seriously indeed. Yet the cinematic model is widely taken to be the most phenomenologically implausible of the leading theories of temporal experience—most of its proponents agree that our ordinary consciousness seems to be deeply continuous. IIT is distinctive by virtue of the singular importance it grants to the unity of consciousness, but it makes no attempt to accommodate the fact (as many see it) that the unity of consciousness extends through time as well as existing at a time. To render IIT maximally phenomenologically plausible these same authors recommend this addition to IIT’s current axioms:

experience always occurs to us as a temporal whole, i.e. experience always has an extension, is continuous and has an inherent direction that is asymmetric. (2022: 14)

If future versions of IIT were to include an axiom along these lines it would be an interesting example of phenomenology influencing the development of a neuroscientific theory.

2. Some Historical Episodes
2.1 William James
In the Anglophone philosophical world over the past century or so William James’ “The Perception of Time”, chapter 15 of his classic The Principles of Psychology (1890) has been particularly influential. In the chapter James introduces readers to relevant experimental work as well as more philosophical reflections. It was thanks to James’ discussion that “the specious present” entered the vocabulary of both philosophers and psychologists. James gives E.R. Clay credit both for the term and for recognizing that the “sensible present” has duration; he quotes him thus:

The relation of experience to time has not been profoundly studied. Its objects are given as being of the present, but the part of time referred to by the datum is a very different thing from the conterminous of the past and the future which philosophy denotes by the name Present. The present to which the datum refers is really a part of the past—a recent past—delusively given as being a time that intervenes between the past and the future. Let it be named the specious present, and let the past, that is given as being the past, be known as the obvious past. All the notes of a bar of a song seem to the listener to be contained in the present. All the changes of place of a meteor seem to the beholder to be contained in the present. At the instant of the termination of such series, no part of the time measured by them seems to be a past. (James 1890: 609)[8]

James goes on:

the original paragon and prototype of all conceived times is the specious present, the short duration of which we are immediately and incessantly sensible. (1890: 631)

In another formulation he enters into more detail, and says something about what this short duration contains:

The unit of composition of our perception of time is a duration, with a bow and a stern, as it were—a rearward—and a forward-looking end. It is only as parts of this duration-block that the relation of succession of one end to the other is perceived. We do not first feel one end and then feel the other after it, and from the perception of the succession infer an interval of time between, but we seem to feel the interval of time as a whole, with its two ends embedded in it. (1890: 609–10)

In the same chapter of the Principles James also writes:

Its content is in a constant flux, events dawning into its forward end as fast as they fade out of its rearward one … Meanwhile, the specious present, the intuited duration, stands permanent, like the rainbow on the waterfall, with its own quality unchanged by the events that stream through it. (1890: 630)

James clearly believed that there is an unvarying structure or mechanism underlying our temporal awareness, as did Husserl after him. If this is right, and if (as many believe) consciousness is essentially temporal, then this structure (or mechanism) is an essential component of consciousness itself, in all its forms.

James is well-known for emphasizing the continuity of experience

Consciousness, then, does not appear to itself as chopped up into bits. Such words as “chain” or “train” do not describe it fitly … It is nothing jointed, it flows. A “river” or a “stream” are the metaphors by which it is naturally described (1890: 239)

and James’ stream metaphor strikes many as apt.[9]

2.2 Locke, Hume and Reid
If the nineteenth century saw a surge in interest in time-consciousness due to discoveries in a range of different fields—see Canales (2009) for more of the story—an interest in these questions dates back far earlier. Saint Augustine’s labours in Book XI of the Confessions led him to espouse a position that is at least highly suggestive of a version of the cinematic conception outlined in §1. Augustine subscribed to the doctrine of presentism (as it has latterly become known), i.e., he held that only what is present is real:

What now is clear and plain is, that neither things to come nor past are. Nor is it properly said, “there be three times, past present and to come:” yet perchance it might be properly said, “there be three times: a present of things past, a present of things present, and a present of things future”. For these three do exist in some sort, in the soul, but otherwhere do I not see them; present of things past, memory; present of things present, sight; present of things future, expectation. (Confessions, bk XI, ch XX, sect 26)

Since for Augustine it was also clear that the present must be entirely without duration, and that our perception is restricted to what is present—“that only can be seen, which is” (bk XI, ch XVIII, sect 24)—we are led swiftly to the conclusion that we can perceive or experience only what is contained in a momentary present.

Since we evidently possess concepts of persistence, succession and suchlike, one would expect philosophers who believe that our basic concepts derive their content from the content of our immediate experience—philosophers such as Locke and Hume—would incline in the direction of realism.[10] And generally speaking, albeit with certain complications, this is what we find. In the Essay (1689) Locke writes:

It is evident to anyone who will but observe what passes in his own mind, that there is a train of ideas which constantly succeed one another in his understanding, as long as he is awake. Reflection on these appearances of several ideas one after another in our minds, is that which furnishes us with the idea of succession: and the distance between any parts of that succession, or between the appearance of any two ideas in our minds, is what we call duration. (Chapter XIV, 3)

Like Locke, Hume believed that our conception of time is derived from our experience of the succession of our perceptions. In Book 1, Part II(§3) of his Treatise (1739) Hume writes:

… time cannot make its appearance to the mind, either alone, or attended with a steady unchangeable object, but is always discovered by some perceivable succession of changeable objects. (Treatise bk 1, pt 2, §3 [1888: 35])

… Five notes played on a flute give us the impression and idea of time; though time be not a sixth impression, which presents itself to the hearing or any other of the senses. [the mind] only takes notice of the manner, in which the different sounds make the appearance … ([1888: 36])

… the indivisible moments of time must be filled with some real object or existence, whose succession forms the duration, and makes it conceivable by the mind. ([1888: 39])

Although Hume agrees with Locke over the origin of our concept of succession, what he says about duration sits uneasily with Locke’s contention that we arrive at the latter concept by observing the distances between impressions. For Hume

the idea of duration is always derived from a succession of changeable objects, and can never be conveyed to the mind by any thing steadfast and unchangeable. ([1888: 37])

Since a period of (total) silence between the hearing of two sounds would not itself contain any change or succession—at least of an auditory kind—the concept of duration cannot be derived from this period of silence.

For Hume the fundamental ingredients of our streams of consciousness are momentary (durationless) experiences occupying “invisible moments” of time. If we were conscious of nothing beyond these durationless episodes is not obvious how we could experience succession. But Hume also held that we apprehend the way (“manner”) momentary perceptions are arranged or organized, and to these “compound impressions” there are corresponding “compound ideas”. As Lorne Falkenstein interprets Hume, compound ideas are themselves extended in time:

[Hume] takes ideas to be objects in their own right, that represent something else by resembling it. … An idea of time represents time by being itself extended in time. (Falkenstein 1997: 193)

If ideas of succession are themselves temporally extended, was Hume an early advocate of extensionalism? For Adrian Bardon the answer is clear and in the affirmative: in the Treatise

Hume articulates an extensionalist account of our perception of space and time—an almost entirely disregarded account that really ought to be the locus classicus for extensionalism. (2019: 468)[11]

In his Essays on the Intellectual Powers of Man (1785, henceforth EIP) Thomas Reid questioned some of Locke’s claims. For Locke succession is a more basic concept than duration—since we arrive at the concept of duration by reflecting on the distances between parts of successions—but Reid argues the reverse is the case. For a succession to exist at all, its parts—either particular impressions or the intervals between them—must themselves already have duration: for if these parts were all entirely lacking in duration, we would be dealing with a purely momentary phenomenon, and hence something which could not contain any kind of succession. Hence succession presupposes duration, and not vice-versa. Moreover, Reid held that our direct awareness is incapable of spanning even a brief temporal interval: “Consciousness, and every kind of thought, is transient and momentary, and has no continued existence” (EIP: III.6, p. 336). If our consciousness is instantaneous and transient it is difficult to see how we could ever be conscious of succession, and this is the stance Reid adopts:

It may here be observed that, if we speak strictly and philosophically, no kind of succession can be an object either of the senses or of consciousness; because the operations of both are confined to the present point of time, and there can be no succession in a point of time; and on that account the motion of a body, which is a successive change of place, could not be observed by the senses alone without the aid of memory. (EIP: III.5, pp. 325–326)

Since the claim that we are immediately aware only of what is present can seem common sense of the plainest sort, it is not surprising to find Reid endorsing it. Reid recognizes that it seems equally commonsensical to say that we see bodies move—after all, we often talk in such terms: e.g., “I saw her waving her arm”. In response he argues that such talk is perfectly legitimate, provided it is construed in loose or popular sense, and not taken strictly and literally.[12] See Levanon (2016a) for a more detailed analysis of Reid’s views—and his criticisms of Locke.

2.3 Kant and Bergson
In the course of his elaboration of transcendental idealism in the Critique of Pure Reason (1787) Kant made a number of claims that would influence subsequent debates on temporal experience. These are not always easy to interpret—for useful introductions see Dunlop (2017) and Bardon (2019). For present purpose this passage in “The Synthesis of Reproduction in Imagination” from the first Critique is particularly relevant:

When I seek to draw a line in thought, or to think of the time from one noon to another, or even to represent to myself some particular number, obviously the various manifold representations that are involved must be apprehended by me in thought one after the other. But if I were always to drop out of thought the preceding representations (the first parts of the line, the antecedent parts of the time period, or the units in the order represented), and did not reproduce them while advancing to those which follow, a complete representation would never be obtained: none of the above-mentioned thoughts, not even the purest and most elementary representations of space and time, could arise. …. the reproductive synthesis of the imagination is to be counted as among the transcendental acts of the mind. We shall therefore entitle this faculty the transcendental faculty of imagination. (A102 [1980: 133])

Anyone who holds that our sensory experience consists of nothing more than a succession of momentary snapshots faces the problem of explaining why we seem to be aware of duration and succession. Kant held that our sensory experience does have this snapshot-like character and solves the resulting problem by offering a richer account of the momentary states. In the visual case, momentary episodes of visual experiencing are accompanied by representations of recently experienced visual contents. More generally, these representations allow us to be aware that our presently occurring experience is a part of an ongoing process.

More needs to be said, but Kant supplies at least the beginnings of one plausible-looking account of how it might be possible for us to be aware of change and succession in the way we seem to be, and it is an approach that can be developed independently of Kant’s transcendental idealism—and its commitment to the unreality of time. The “retentional” approach (recalling the terminology of §1.1) soon found advocates, and is comparatively commonplace by the end of the nineteenth century.

If we move onward a century we encounter Henri Bergson, a philosopher who placed a highly dynamic form of temporal experience right at the centre of his philosophy. As Canales (2015) vividly demonstrates, at the beginning of the twentieth century Bergson’s writings on time and consciousness had considerable influence on his contemporaries, both within the philosophical world and beyond. In his Time and Free Will: An Essay on the Immediate Data of Consciousness (1889 [1910]) Bergson began his campaign against the “spatializing” of time, and in this campaign the concept of duration (or durée) plays a key role. At least in his earlier writings, this concept applies to time as it is featured in our immediate experience. For Bergson, durée is a continuous dynamic experiential flow, immeasurable and unquantifiable—the “ceaselessly seething surd at the heart of things”, in Barrett’s words (Gale 1968: 373). As such it is radically unlike the static conception of time as a manifold of mere locations to be found in the scientific conception of the world, whether Newtonian or Einsteinian.

Pure duration is the form which the succession of our conscious states assumes when our ego lets itself live,when it refrains from separating its present state from its former states … We can thus conceive of succession without distinction, and think of it as a mutual penetration, an interconnexion and organization of elements, each one of which represents the whole, and cannot be distinguished or isolated from it except by abstract thought. (Bergson 1889 [1910: 100–101])

Many of Bergson’s characterizations of durée are negative: he tells us a good deal about what it is not, but comparatively little about what it actually is. While this can sometimes be frustrating, there is a rationale for it: Bergson held that any attempt to conceptualize the flux of consciousness could succeed only at the cost of distorting the phenomena—a doctrine which influenced William James in his later years—for more on this see Dainton (2017a, 2022) and Dolev (2022).

In later works, such as Matter and Memory Bergson suggested that primitive forms of durée can be found in all material things, even the simplest particles and fields. If so, temporal experience is ubiquitous, and there is a flowing dynamism at the heart of literally everything. For more on Bergson’s conception of the nature of matter see Čapek (1971) and Sinclair (2019).

Bergson may have been influential during the first decades of the twentieth century but not everyone was convinced of the fundamental correctness of his metaphysical and phenomenological claims—even in the Francophone philosophical world of the period. In his Intuition of the Instant (1932) Gaston Bachelard launched a radical assault on Bergson’s account of the temporality of consciousness and the temporality of the world. For Bergson the static durationless instant of mathematics and physics is an abstraction to which nothing in concrete reality corresponds—reality is essentially extended and flowing. The position Bachelard defends is diametrically opposed to Bergson’s:

Time alone has but one reality: the reality of the instant. Otherwise put, time is a reality confined to the instant and suspended between two voids. Although time will no doubt be reborn, it must first die. It cannot transport its being from one instant to another in order to forge a duration. (Bachelard 1932 [2013: 6])

… time is the instant, and it is the present instant that bears the full weight of temporality. The past is as empty as the future. The future is as dead as the past. The instant holds no duration at its core; it does not thrust a force in one direction or another. It does not have two faces. It is whole and alone. (1932 [2013: 28])

Bergson complained that conceiving of the continuity of experience in mathematical terms reduces experience to a “dust of instants”. Bachelard responds thus:

Time is noticed solely through instants; duration … is felt solely through instants. Duration is a dust cloud of instants or, better yet, a group of points organized more or less coherently by a phenomenon of perspective. (1932 [2013: 19])

While Bergson argued that the cinematic conception of the stream of consciousness is fundamentally wrong, for Bachelard this conception is essentially correct—and as we shall now see, he is not alone in this.

3. Cinematic Approaches
3.1 Streams and Stills
When it comes to explaining the temporal structure of our consciousness the account offered by the cinematic theorist is appealingly straightforward. On a straightforward version of this view, a typical stream of consciousness consists of a close-packed continuum of momentary (or very brief) phases. Although the contents of these phases are themselves momentary—they do not present motion or change, they are akin to static snapshots. But their occurrence in rapid succession succeeds in generating all the change, succession and motion we find in our experience. Or so the cinematic theorist maintains: on their view nothing more is required. The basic features of the model are depicted in Figure 3.1. On the left we see a punctual beam of awareness, the smooth, steady advance of which generates a sequence of momentary snapshot-like contents (of a falling object, in this instance), only a small selection of which is shown on the right.

link to extended description below
Figure 3.1 The Cinematic Model. [An extended description of Figure 3.1 is in the supplement.]

As we saw earlier, this approach can be traced back as far as St. Augustine and was later advocated by Reid, and more recently by Bachelard. Phillipe Chuard (2011, 2017, 2020) is a contemporary defender of the view, calling it the “snapshot theory”:

… the snapshot theorist argues, the phenomenology we seem to introspect while enjoying successive experiential states not only supervenes upon, but reduces to, those features of successions just listed: the experiential properties of snapshots, their temporal arrangement, the gradual transitions in their successive contents, our memories of previous experiences, and inability to detect small gaps and jumps, all contribute to what it’s like to enjoy the sort of phenomenology associated with putative temporal experiences. (Chuard 2017: 125)

In §1.2 a distinction was drawn between realists and anti-realists, with realists holding that change and succession can be directly perceived and anti-realists maintaining that it cannot. Chuard denies that change can be directly apprehended, putting him in the antirealist camp. But he also accepts that we seem to directly experience change—so realism appears to be true, even if it isn’t.

To be clear, the snapshot view isn’t trying to explain how we do, in fact, have temporal experience. We don’t, the snapshot theorist surmises. Rather, the view aims to explain what it is like to go through successions of very short conscious experiential states, to then point out how the phenomenology thus accounted for seems indiscriminable from the phenomenology associated with the temporal experience we allegedly enjoy. Thus, the snapshot view doesn’t reject the phenomenological appearances, quite the contrary. It aims to explain them without liberally assuming that such experiences must be taken entirely at face value, as revealing the metaphysical structure of our streams of consciousness. (Chuard 2017: 126)[13]

Critics of the cinematic theory are generally of the view that James was correct when he drew a sharp distinction between a mere succession of experiences and an experience of succession, and since the cinematic theorist is providing us with no more than the former it cannot deliver an adequate account of the latter. Dainton (2000: §5.5; 2008b: 57) invites us to imagine a group of five people standing in line with their eyes closed, but directed at a nearby tennis game. If each of these people opens their eyes momentarily before closing them again we have a succession of five experiences, each revealing the on-court action at a particular moment. It seems clear that in this case there is nothing resembling an experience of succession: all each person sees is a momentary still image, and these momentary states are completely isolated from one another experientially. There is, Dainton suggests, a huge difference between this sequence of experiences and our own streams of consciousness, but since the cinematic theory fragments consciousness in an analogous way it is deeply implausible phenomenologically.[14]

As for how sequences of momentary static snapshots can give rise to experiences with seemingly dynamic contents Reid and Chuard both hold that memory plays an important role. In Reid’s words:

It is by memory that we have an immediate knowledge of things past: The senses give us information of things only as they exist in the present moment; and this information, if it were not preserved by memory, would vanish instantly, and leave us as ignorant as if it had never been. (EIP: III.1, p. 303)

But is memory enough? Phenomenologically there is an obvious difference between perceptual experience and experiential memories: the latter are far less detailed and far less vibrant than the former. Given this, it is not obvious that combinations of instantaneous perceptual experiences and memories could provide us with the sorts of experiences of change we actually enjoy: successions of experiences, yes; experiences of succession, no. For further discussion of appeals to memory see Dainton (2000: §5.4) and Phillips (2010: §5).

What of the cinematic analogy itself? It is well known that rapid successions of static images can result in experiences of motion. The images shown on a TV or cinema screen are static snapshots, but evidently, they are perceived as dynamic: objects on a cinema screen are seen to move as smoothly and continuously as their real-life counterparts. This phenomenon—known as “illusory motion” or “the phi phenomenon” was first explored in the nineteenth century by Exner, and has been much-studied since then (not surprisingly, since it underpins televisual industries). But while it is real enough, the phi phenomenon is of little assistance to the cinematic theorist. What the latter needs is an account of how successions of momentary conscious states, each possessing entirely static contents, can give rise to the experience of motion. Static images are indeed being displayed on a cinema screen while we view a movie, but not only are these onscreen stills not themselves experiences, they do not register in our visual experience as static images: what we actually seem to see onscreen are objects in motion.

In the scientific literature the hypothesis that perceptual experience comes packaged in discrete sub-second “frames” possessing static contents has been defended on a number of occasions. White (2018) undertakes a detailed survey of the relevant work in psychology and neuroscience. White’s verdict is that the discrete frames hypothesis has not yet been decisively refuted, but it is seriously problematic on a number of fronts.

The available evidence does not provide consistent support for any specific duration for frames, and perceptual processes display a flexibility that is not readily reconcilable with the frame hypothesis. There are also

problems concerning the definition of frames, the need for informational connections between frames, the means by which boundaries between frames are established. (White 2018: 98)

3.2 Dynamic Snapshots
Cinematic theorists would be on stronger ground if they could supply a plausible explanation as to why we believe we perceive motion (and more generally, change) if in fact we do not. Le Poidevin (2007: 88–92) tentatively forwards a promising hypothesis. As Aristotle noted, if you stare at a waterfall for a short period, and then turn your gaze to the bank beside it, you will see part of the bank (seemingly) start to move in an upwards direction. This phenomenon is commonly called “the waterfall illusion” (or motion aftereffect), and the illusory motion is of an intriguing sort: although parts of the bank seem to flow upward, they do so without seeming to change their location with respect to the rest of the bank.

As for an explanation of what is going on in such cases, Le Poidevin (following Richard Gregory) suggests that perhaps we can discern here the workings of two distinct neural mechanisms. One

registers what we might call “pure motion”, i.e., gives rise to the impression of motion without any associated sense of change of position. (2007: 89)

A second system, relying on short-term memory, tracks and compares the alterations in location over time. This second system is not concerned with telling us about presently occurring motions, rather it gives rise to the sense that objects have changed their positions relative to one another. Hence Le Poidevin’s proposal: perhaps our ordinary experience of motion does, after all, consist of nothing but momentary static snapshots but these momentary experiences seem dynamic thanks to the activation of the “pure motion” mechanism in our visual system.

This is a more promising line for the cinematic theorist to take, and it has recently been endorsed by Arstila (2018), and also been taken up by Prosser, where pure motion plays an important role in his dynamic snapshot theory:

… it is a “snapshot” theory because it accounts for the experience of motion without appeal to a specious present, but it is very different from the cinematic or “static snapshot” theory. I agree with those who hold that the latter theory cannot adequately account for the phenomenology of motion experience. (2017: 149, see also Prosser 2016: §5.4)

This supposedly dynamic version of the cinematic view may be more promising than the static alternative, but it has also come under fire from a number of directions. McKenna argues thus:

For the experienced illusory object … to appear static in space, but with motion-like properties, it must exhibit persistence over some length of time. temporality is inescapable; events continue to succeed one another over time, even if the content remains the same. (2021: §6)

Shardlow makes a similar complaint:

Contrary to what Prosser and Arstila suggest, it simply does not follow that the experience of motion is not in and of itself something with a fundamentally temporally extended phenomenology, and that motion/change as it is experienced seems processive…. (2019: 745)

It may well be a mistake to focus exclusively on the case of vision: after all, in addition to being seen, change can be heard, smelt, tasted, felt in bodily sensations, remembered, imagined and thought about. Even if the existence of the envisaged twin-track neural systems could be established in the visual case, critics point out that as things currently stand there is no reason for thinking Arstila is correct when he proposes that there are a range of different encapsulated systems, one for each of the other forms of temporal experience. On the contrary: if, as has seemed plausible to many, all forms of consciousness possess a dynamic temporal character then it is natural to conclude that temporality is closely connected with the neural processes that are responsible for consciousness itself:

Why adopt the encapsulated mechanism approach when it is simpler, more explanatory, and truer to the phenomena to locate temporality as a feature of a general mechanism responsible for consciousness, whatever that may be? A feature of a general mechanism also has the benefit of accounting for why people never seem to go “timeless” the way people go “blind”—temporality is indispensable to consciousness because it is inextricably bound up with the processes responsible for it. (McKenna 2021: §5)

McKenna suggests that the future-oriented predictive processing proposal from Hohwy, Paton, and Palmer (2015) fits the bill. An alternative general neuro-scientific mechanism is proposed by Piper (2019), who points to the merits of the re-entrant oscillatory multiplexing (ROM) neurodynamical model. On the latter view the temporal features of consciousness are the product of interlocking and interdependent waves of neural activity that are extended through time in a manner that is difficult to reconcile with the cinematic view in any of its guises but eminently compatible with rival extensional models. Just as

music is a product of various auditory resonances (in rhythm, pitch and timbre, for example) amongst the parts of the active orchestra. Analogously the ROM model formalizes the idea that coherent mental representations and experience is the product of various resonances (i.e. multiplexing) between the phases, frequencies and amplitude parameters … of reciprocally connected information-processing (i.e. reentrant) brain circuits. (Piper 2019: 9–10)

In a similar general vein Northoff (2016) and Northoff and Huang (2017) argue that the temporal features of consciousness are inextricably bound up with continuous neural oscillations that are extend through time in a continuous manner. These “slow cortical pulses” are low frequency waves of neural activity that allow the brain to unify stimuli that are temporally separated. This position also runs counter to cinematic conceptions but gels neatly with extensionalism.

4. Retentional Approaches
4.1 Motivations
Endorsing the Augustinian doctrine that consciousness is confined to the present point of time does not oblige one to reject the claim that change and succession feature prominently in immediate experience. These theses are quite compatible with one another provided the experience of change occurs within the confines of the momentary present. Indeed, in the eyes of some—but not all—this is a necessary precondition for contents to be experienced together as parts of a unified whole. The obvious way of developing an account along these lines is to hold that momentary episodes of sensory consciousness are accompanied by a simultaneously existing array of representations (or retentions) of immediately preceding conscious states, and our awareness—at a single moment of time—of this combination of ingredients provides us with what we take to be a direct awareness of change and succession. This “retentional” approach—recalling the terminology of §1.1—was comparatively commonplace by the end of the nineteenth century and continues to attract supporters.

Many realists have no doubt found this approach appealing because it offers a simple and intuitively satisfying explanation of how an experience of succession differs from a mere succession of experiences: in the former case, the contents forming the succession are presented together, as an ensemble, to a single momentary awareness. Brentano and Husserl both subscribed to the Principle of Simultaneous Awareness (PSA) that we encountered in §1.2: “If one is aware of a succession or duration, one is necessarily aware of it at one moment”. Indeed, it may well be that some theorists, consciously or unconsciously, have found the retentional approach appealing because of the way it (in effect) reduces the problem of diachronic phenomenal unity to the comparatively straightforward problem of synchronic unity.

4.2 Brentano and Husserl
Brentano recognized that reaching a clear understanding of how it is possible for us to directly experience succession and persistence is a central issue for phenomenology (or “descriptive psychology” as he preferred to call it). He also recognized that a mere succession of experiences does not, in and of itself, add up to an experience of succession. Brentano’s solution: when listening (say) to an extended tone or melody, at each moment you are aware of a momentary sound-phase, but you are also (and simultaneously) aware of a series of representations (or retentions) of the immediately preceding phases. The latter Brentano referred to as proteraesthesis. Brentano’s approach gives rise to several questions. How can contents which are simultaneous, objectively speaking, seem to be successive? What is the precise nature of the representations occurring in proteraestheses? Brentano’s views on these matters underwent several changes—see Chisholm (1981) and Kraus (1930 [1976]) for further details.

The early years of the twentieth century see Husserl developing an account of time-consciousness along retentional lines. Husserl attended Brentano’s lectures between 1884–6; inspired by them, he decided to devote his energies to philosophy rather than mathematics. In elaborating his own position, in lectures in 1904–6, Husserl begins with criticisms of what Brentano (and Meinong) had to say on the topic, but the position he ends up with is along the same general lines. Husserl may not have adopted the term “specious present”, but he did hold that we have a seemingly direct awareness of change and persistence amongst the objects and processes we perceive over short intervals. He also held, plausibly, that as our streams of consciousness flow on, we have an awareness of their so doing. As for how this is possible, he thought it must involve past phases of consciousness somehow being “retained in grasp” in later moments of consciousness.

At the heart of Husserl’s account is a dynamic tri-partite view of the composition of consciousness at any instant. The three components are: primal impressions, retentions (or “primary memories”) and protentions. Primal impressions are the live, actual experiences that occupy the momentary now. No sooner does a primal impression occur than it slips seamlessly into the past. But it does not vanish from consciousness altogether: it survives in the form of a retention, which presents it as past. For Husserl, retentions are a quite distinctive form of consciousness, and differ significantly from ordinary memories. As for protentions, these are the future-oriented counterparts of retentions. In some cases—e.g., when we are perceiving or remembering a familiar sequence of events—they can be quite detailed, but often they consist of nothing more than an openness to the future, an expectation that something will come.

link to extended description below
Figure 4.1 Husserl’s time diagram. [An extended description of Figure 4.1 is in the supplement.]

The basic mechanics of Husserl's theory are depicted in Figure 4.1, where the horizontal axis represents a continuous flow of primal impressions, the vertical axes represent a selection of retentions (and in the case of F) protentions which accompany the primal impressions D, E and F. (Only a “selection” because in reality, according to Husserl, a continuous stretch of consciousness consists of a dense continuum of primal impressions, each of which is accompanied by its “comet’s tail” of retentions and protentions.) As can be seen, individual primal impressions are retained in later specious presents—increased “pastness” is indicated by a greater number of asterisks. What goes for momentary primal impressions also goes for intervals: D-E is retained at F in the form of the retentional continuum E*–D**.

The broad outlines of Husserl’s position may be clear enough, but the details pose more of a challenge. Husserl wrote voluminously on time-consciousness throughout his career but never found a position he was happy with for long—in his lectures from 1907–10 he found fault with the position he elaborated in the 1904–6 lectures—and he never published a definitive statement of his position. For useful introductions to Husserl’s views see Kortooms (2002) and Zahavi (2004, 2007, 2010).

4.3 Temporal Illusions and Neuroscience
In a series of papers Rick Grush has developed a version of retentionalism in the form of the “trajectory estimation model” (TEM) which draws on ideas and analyses from control theory and signal processing—for further details, see Grush (2005a, 2005b). So far as analogies with Husserl’s doctrines are concerned, a key point is that the internal models employed by these systems are not confined to representing instantaneous states of the relevant domain. What is modelled, rather, is the trajectory of the domain over a short interval of time, i.e., the entire succession of states that the system estimates that domain is most likely to have been in during the relevant interval. It is this trajectory which Grush takes to be the information-processing analogue of Husserl’s tri-partite specious presents.

Grush argues that the abilities of his systems to generate different (and incompatible) representations of what is being perceived at a given time is a positive boon, for it allows his theory to accommodate a variety of temporal illusions. In so-called “post-dictive” illusions what is experienced as seemingly occurring at a time t is influenced by stimuli arriving later than t. One such illusion is the cutaneous rabbit described by Geldard & Sherrick (1972). The experiment involved devices capable of delivering controlled brief (2 msec) pulses to the skin being fitted along the arms of subjects. Surprisingly, when the devices were clustered in just three tight configurations—and the wrist, the elbow and in-between—and five pulses were delivered to each location, rather than experiencing three tight clusters of pulses (one at the wrist, one at the elbow and one in-between) subjects report feeling a succession of evenly spaced pulses starting at the wrist and terminating a the elbow. There are several questions that can be asked about this, but perhaps the most puzzling is: what is happening at the time of the second pulse? How is the brain able to adopt the “evenly spaced” interpretation before the second flash even occurs?

Grush’s TEM has no difficulty explaining what is going on in such cases. In the case of the rabbit, the second pulse is initially experienced as occurring at the wrist. But as the brain updates its models in the light of subsequent sensory information and its own expectations as to the likely scenario confronting it, it alters its verdict and the second pulse is experienced as occurring further along the arm, as part of an evenly spaced succession. When subjects are subsequently queried as to what they experienced, it is the later experiences which get reported—the earlier ones are not remembered.

Proponents of competing approaches have defended different ways of interpreting post-dictive illusions. Dainton (2008a: 381) argues that cases of this sort pose no problem for extensionalists:

might it not be that our visual systems take some time … before producing experience in response to a given stimulus? And might they not use this time to work out a single coherent version of events before committing it to experience?

Eagleman and Sejnowski (2000) proposed a “delayed response” construal of the flash-lag illusion along these lines. In response Grush (2016: 5.1.1 [Other Internet Resources]) argues that since this additional delay will have to be incurred in all our perceptual systems all the time, positing it is by no means cost-free. Arstila (2016a) argues that Grush and Dainton’s explanations of post-dictive visual illusions are both problematic, and proposes an alternative.[15]

Geoff Lee (2014a, 2014b) defends what is arguably a retentional model of temporal experience, albeit one possessing some distinctive features. Lee holds that specious presents are housed in experiential states that have a very brief temporal extension—Lee thinks these states are identical with neural states and processes, and the latter always have a non-zero temporal magnitude. Although these experiences possess some temporal extension they do not have any experiences as proper parts, and so Lee aptly calls them “atomic experiences”. Extensionalists view specious presents as temporally extended experiences which do possess other experiences as proper parts, and for Lee this is the defining feature of extensionalism. None of the seemingly-extended contents of Lee’s atomic experiences seem to be past- or memory-like—they are all fully perceptual in character—and so different from Husserlian retentions.[16]

One of Lee’s main arguments for preferring a version of the retentional (atomic) model is his “Trace-Integration Argument”, which has its roots in his preferred science-oriented methodology. Lee points out a basic and widespread assumption in recent cognitive psychology: information concerning what has been recently perceived must be simultaneously present in subsequent representations if it is to play any role in cognition (Lee 2014a: 15). It does seem plausible to suppose that our brains engage in coding of the sort Lee describes. What is more controversial is whether this is the only kind of processing that our brains engage in when generating temporal experience. For a critical assessments of Lee’s argument Viera (2019), and for very different kind of neural models which rely on temporally extended neural processes see Northoff (2016), Northoff and Huang (2017), and Piper (2019).

4.4 Retentions and Representationalism
The retentional model faces a number of challenges. For the doctrine to be plausible we must be able to make clear sense of the idea that experienced duration can be contained in episodes of experiencing that are themselves without discernible duration, and retentionalists also need to be able to provide a plausible account of how retentions can do the job required of them. For a number of recent theorists—e.g., Grush, Kiverstein, Lee and Tye—a currently popular theory of the nature of perceptual experience helps retentionalism solve these and other problems.

In the philosophy of perception representationalism (or intentionalism) is the doctrine that the phenomenal properties we encounter in perception are determined by, or supervene upon, “representational” contents. Needless to say representations come in very different forms, and the variety deployed by recent representationalists is of a distinctive kind. As Siegel usefully notes:

when one speaks of the contents of a newspaper, one is talking about what information the newspaper stories convey. Many contemporary uses of “the contents of perception” take such contents to be analogous to the contents of a newspaper story. (2005 [2021: §2])

The stories we encounter in newspapers often make claims about the world, and can be assessed for their truth or accuracy, and one way of specifying the content of a story is by specifying what would have to be the case if the story is true. Representationalists maintain that the contents carried by perceptual experiences are similar: we can specify their content by specifying the conditions under which they are true (or reliable). Importantly, on this view perceptual experiences can have representational contents even if the story they are telling is false: we do, after all, misperceive things from time to time—a balloon which looks red might turn out to be orange.

Representationalists hold that, quite generally, the properties of a representational vehicle (that which is doing the representing) and the content of that representation (what is represented) need to be sharply distinguished. The word “red” can represent the colour red without itself being red. A copy of a newspaper is very different from the stories it tells. In the case of temporal experience anyone who finds this theory of perception appealing can adopt a quite straightforward position on the nature of retentions: the latter provide us with a direct awareness of the recent past because they are perceptual experiences possessing meaningful contents that represent the recent past. The problem of understanding how the experienced duration and succession can exist in experiences that are durationless (or almost so) now has a straightforward solution. As we have just seen, representational vehicles and their contents typically do have very different properties, and this is a case in point. In the representationalist framework it would be a mistake to expect the temporal properties of an experience, a vehicle, to match those of its content.

Hoerl (2013a) argues that some of Husserl’s otherwise puzzling pronouncements become a good deal less puzzling if we suppose that he changed his stance from something akin to a sense-datum theorist (in his early days) to something akin to contemporary representationalism (in his later days). Husserl tells us that “Memory—and this is equally true of retention—is not image-consciousness, it is something totally different” (Husserl TPZ [1991: 36]). He also says that as a primal impression is transformed into a retention

there is a radical alteration, an alteration that can never be described in the way in which we describe the changes in sensations that lead again to sensations. (Husserl TPZ [1991: 336])

We can see how Husserl might have thought this true is he had (in effect) adopted representationalism.[17]

There is a further doctrine defended by many representationalists that is also relevant to our current concerns: an insistence on the “transparency” of experience. By this they typically mean (in part at least) that in ordinary perceptual experience, we have no awareness whatsoever of our experiences themselves, we are simply aware of the (worldly) objects and properties that are presented in or by our experiences. If our experiences are invisible, there is no need to introduce properties of experience—phenomenal properties, qualia, sense-data and such—in order to explain the content and character of our ordinary perceptual consciousness. Extending this approach to the particular case of temporal consciousness, Michael Tye argues as follows. First of all, if we assume the transparency thesis is true, the traditional assumption that it is experiences that are related by succession or simultaneity is misguided:

Consider again the case in which I have an experience of a red flash followed by a green flash. Here I experience two colored flashes as occurring one after the other. I do not experience my experience of a red flash as succeeding my experience of a green one any more than I experience my experience of a red flash as red. (2003: 96)

Accordingly, Tye holds that anyone seeking to account for our ability to directly apprehend change by appealing to a unifying relationship between experiences is also misguided: there simply aren’t the token experiences there to beunified; a given period or stretch of consciousness is not composed of successive perceptions or experiences (2003: 102). By way of an alternative he offers a one experience view of streams of consciousness:

The simplest hypothesis compatible with what is revealed by introspection is that, for each period of consciousness, there is only a single experience—an experience that represents everything experienced within the period of consciousness as a whole. (2003: 97)

For a recent defence of Tye’s general approach to transparency in the case of temporal experience see Heeney (2021). As Bayne notes, Tye’s one experience proposal does not sit easily with some of his other views. Tye holds that experiences are representational states that have the ability to directly feed into our cognitive systems. Bayne asks:

Is it really plausible to suppose that the contents of an entire stream of consciousness—that is, the period of consciousness between one state of unconsciousness and the next—are poised for direct input in to the reasoning system? … That seems extremely unlikely. (Bayne 2005: 498)

Soteriou (2010: 230) is also puzzled by this aspect of Tye’s position.

For discussion of some further issues relating to retentional specious presents see the supplementary document The Specious Present: Further Issues.

5. Extensional Approaches
5.1 Origins: A Dogma Rejected
Stern observes at the start of his “Mental Presence-Time” (1897 [2005]) that much recent work in psychology makes an assumption about the kind of unities that can exist within experience: only contents that are instantaneous and simultaneous can be apprehended together. Needless to say, this assumption amounts to a commitment to PSA—see §1.2. Stern proposes that we reject this constraint:

That only those contents can belong to a whole of consciousness that exist together and are simultaneously present at any given time … is a dogma, which, in a more or less veiled form, determines numerous psychological reflections. I consider this dogma, at least in this generalized form, to be false. I believe that there are instances when an apprehension first comes into being on the basis of temporally extended content of consciousness, in such a manner that every part of this content exists in an insoluble connection with every other part. (Stern, 1897 [2005: 313])

Rejecting PSA brings a number of advantages. Experienced contents which appear to be successive can really be successive, rather than existing simultaneously (as with retentional models), similarly episodes of consciousness which seem to persist through intervals of ordinary objective time can really do so. Abandoning the dogma means that temporal consciousness need no longer be systematically misleading as to its own nature. Stern was well aware why his contemporaries maintained that it was necessary to distinguish a succession of experiences from an experience of succession. A sequence of musical notes will only be experienced as a succession if they are experienced together, with each being experienced as following on from its predecessor. Stern was simply suggesting that these unified experiential episodes are themselves extended over temporal intervals rather than momentary.

I therefore put forth the following principle: mental events that play themselves out within a stretch of time can under circumstances form a unified and complex act of consciousness regardless of the non-simultaneity of individual parts. That stretch of time over which a mental act can be extended I call its presence-time. (Stern 1897 [2005: 315])

Wundt held that complexes of sensory contents could only be apprehended directly if they exist in a conscious whole simultaneously. Stern rejects this: “As a whole, yes; as simultaneous, no” (1897 [2005: 319]). What of the notion “the present” if we follow Stern and embrace an extensional model of temporal experience? Stern suggests we needn’t reject the idea that experiences can be present. All we need do is define the present “as the totality of temporal and spatial relations that can become the object of a direct perception” (1897 [2005: 325]). Since we directly perceive events spanning brief intervals, the present thus construed is a positive and finite stretch of time.

How do individual presence-times combine to form streams of consciousness? In ordinary life we are, after all, continually conscious for hours at a stretch, whereas individual presence-times are very short. Stern does not address this question in his article so he can offer little assistance—see Dainton (2017b) for a fuller account of Stern's views —however it was not long before a promising proposal emerged. In 1915 Bertrand Russell published his “On the Experience of Time” in The Monist, where the stream-composition question is addressed. Russell begins by introducing some key terms and theses. A sensation involves a subject standing in the acquaintance relation with an object or sense-datum. Russell makes it clear that he believes change can be directly experienced, telling us:

Succession is a relation which may hold between two parts of one sensation, for instance between two parts of a swift movement which is the object of one sensation; it may then, and perhaps also when one or both objects are objects of immediate memory, be immediately experienced, and extended by inference to cases where one or both of the terms are not present. (1915: 213)

How do specious presents combine to form entire streams of consciousness? Here Russell usefully goes beyond Stern and proposes that neighbouring specious presents in the same stream of consciousness are related by overlap or part-sharing. Let’s suppose A, B, C are brief sounds of the same duration that are experienced as a succession in the same continuous stream of consciousness; let’s also suppose that the lengths of these sounds are such that only two of them can be experienced together. Russell suggests that the resulting temporally extended experience will include two specious presents [A-followed-by-B] and [B-followed-by-C], and since the experiencing of the B-sound is numerically identical with the experiencing of the B-sound in the later specious present the B is heard just once, not twice. The resulting stream of auditory consciousness consists of a continuous succession of sounds, each heard as following on from its predecessor, where only two sounds are experienced together as directly successive.

Russell goes on to offer a further important observation:

If A, B and C succeed each other rapidly, A and B may be parts of one sensation, and likewise B and C, while A and C are not parts of one sensation. But A is remembered when C is present in sensation. In such a case, A and B belong to the same present, and likewise B and C, but not A and C; thus the relation “belong to the same present” is not transitive. (Russell 1915: 233)

As Russell clearly appreciates, if the relation of “belonging to the same present” were transitive, then A would necessarily belong to the same (specious) present as C, and more generally, all the partially overlapping phases of a stream of consciousness would have the character of a single unified specious present—and so you would now be directly experiencing what you saw and heard when you first awoke this morning. Since this is manifestly not the case, the “belonging to the same present” relation is clearly not transitive.

5.2 More Recent Defences and Discussions
5.2.1 Awareness, Simplicity and Overlap
John Foster has defended an overlap-version of the extensional view on a number of occasions. Foster has no doubt that temporally extended phenomena are an important feature of our ordinary experience, observing that

duration and change through time seem to be presented to us with the same phenomenal immediacy as homogeneity and variation of colour through space. (Foster 1982: 255)

Foster begins his discussion by assuming an awareness-content model of consciousness. Let’s suppose a musical scale is being sung, and the duration of the notes is such that a listening subject is aware of three notes in succession. As the scale unfolds the subject will have a succession of auditory experiences

E1 = [do-re-mi],
E2 = [re-mi-so],
E3 = [mi-so-fa]
and so on. This sequence of experiences has a puzzling feature: it looks as though the notes are being experienced more than once, with re featuring in E1and E2, mi in E1, E2 and E3, and so in E2 and E3. Experiences like this are not logically impossible, Foster suggests, but our ordinary experience of listening to a series of notes obviously doesn’t include repetitions of this sort.

Foster proposes a solution:

a presentation of a temporal pattern is itself temporally extended, and it overlaps its predecessor and successor in, so to speak, presentational substance to the extent that its pattern overlaps theirs in phenomenal content. It is this double overlap which provides the key to the sensible continuity of sense experience and unifies presentations into a stream of awareness. (Foster 1979: 176)

Each of the two horizontal brackets in Figure 5.1 represents an act of awareness that is temporally extended and unified; each of these extended acts produces a specious present, the first consisting of the experiencing of do-re and the second re-mi. Unrealistic repetitions are avoided by virtue of the fact that the extended acts overlap by sharing a common part.

link to extended description below
Figure 5.1 Foster’s double overlap theory featuring temporally extended awareness and contents. [An extended description of Figure 5.1 is in the supplement.]

In his Stream of Consciousness (2000, second edition 2006) Barry Dainton sets himself the goal of providing a phenomenological account of the sort of unity and continuity we find in our ordinary streams of consciousness. Dainton does not take any stand on the relationship between the experiential and the physical, other than to assume that consciousness is “an irreducible ingredient of reality in its own right” (2000 [2006: xiv]). He also adopts an indirect realist or “projectivist” view of perceptual experience.

Dainton’s initial focus is on the synchronic (at-a-time) unity of consciousness. He argues that the togetherness of the diverse experiences we are having at any one time is itself a feature our experience, and after considering attempts to explain co-consciousness in other terms Dainton concludes that it should be regarded as a primitive relationship. Among the rejected accounts of phenomenal unity is the thesis that experiential objects and contents are unified by virtue of falling under a single act of awareness. The idea that consciousness has an awareness-content structure—as assumed by Foster—is an appealing one in several respects, but on closer examination all forms of this “A-thesis” turn out to be seriously flawed, or so Dainton argues. By way of an alternative Dainton adopts a one-level view of the structure of consciousness he calls the “simple conception”:

The A-theorist tried to keep awareness distinct from content, but since this turned out to be a mistake we must accept that awareness and content are not distinct ingredients within experience. It follows that consciousness is inseparable from phenomenal contents: when a given phenomenal item comes into being it comes into being as a conscious experience … contents are themselves intrinsically conscious, and hence—in a manner of speaking—they are self-revealing or self-intimating. (Dainton 2000: 57)

In the chapters of Stream of Consciousness devoted to temporal experience Dainton argues that a number of existing approaches face serious problems. These include memory theories in various guises, pulse-theories, Broad’s extended content model and Husserl’s version of retentionalism. Dainton concludes that the “overlap” form of the extensional theory defended by Russell and Foster has significant advantages over the alternatives, and is worthy of further development. Amongst its other virtues it offers a plausible explanation of the way consciousness can be experienced as deeply continuous for hours at a stretch, something rival approaches fail to provide.

For Dainton the earlier and later contents of an individual specious present form a single unified experience by virtue of being experienced together. Dainton argues experiences can be unified over time in the same primitive way as experiences at a time, and so the earlier and later contents within a single specious present can be co-conscious, but diachronically rather than synchronically. There are however, differences between the synchronic and diachronic forms of co-consciousness. It is natural to think that synchronic phenomenal unity is transitive, but as Russell and Foster noted, in the diachronic case failures of transitivity are ubiquitous, and can occur whenever two specious presents partially overlap. Dainton (2000 [2006: chapters 8 and 9]) argues that co-consciousness in its synchronic and diachronic forms connects experiences so profoundly that a form of holism ensues, and since specious presents consist of experiential parts connected by co-consciousness this form of holism extends to them.

Dainton’s account of individual specious presents has one further ingredient. Dainton takes consciousness to be dynamic in a strong way: he holds that our experiences typically exhibit a “discernible phenomenal flow … a sense that the same kind of phenomenal quality is being continuously renewed” (2004a: 15). It is difficult to see how this feature of our experience could be explained by the co-consciousness relationship alone, since the latter is a symmetrical relationship: if do is co-conscious with re then re will be co-conscious with do. Given this symmetry, how is it that we do-flowing-into-re? It is at this point that Dainton introduces an additional ingredient: phenomenal contents

which are symmetrically joined by co-consciousness themselves possess an inherent directional dynamism. The C-tone is not a static auditory quality, but a flowing quality, likewise for D and E. This immanent flow is an essential ingredient of any auditory content, just as essential as timbre, pitch or volume. (2004a: 23)

In Figure 5.2 this dynamic flow is represented by horizontal arrows, and the upper and lower brackets represent the span of diachronic co-consciousness.

link to extended description below
Figure 5.2 Dainton's Simple Overlap Model. [An extended description of Figure 5.1 is in the supplement.]

In “Sensing Change” (2008a) Dainton introduces the “extensional model” as the doctrine that individual specious presents consist of “temporally extended episodes of experience that are apprehended as wholes”. Dainton also responds to Grush’s claim that the extensional model is incapable of accommodating temporal illusions such as the phi-phenomenon in a plausible manner: one way of making sense of the illusions is to suppose that our brains take some time before deciding on an interpretation of incoming stimuli. In response Grush (2017) offers several criticisms of this “delayed extensionalism”, and argues that the envisaged processing delay would be more problematic than Dainton realizes. Arstila (2016a) argues that the approaches defended by Grush and Dainton are both problematic, and offers his own alternative account of apparent motion.

On a different theme, Dainton (2014) focuses on various issues related to the temporal structure of consciousness on the smallest of scales, and he defends the view that our streams of consciousness are “essentially extended continua” whose smallest parts have some finite temporal extension. By virtue of not being composed of strictly momentary parts a challenge to extensionalism by Pelczar (2010a, 2010b) can be met, or so Dainton proposes.

Some of Dainton’s criticisms of alternative approaches have themselves come under critical fire. Gallagher (2003) argues that many of Dainton’s criticisms of Husserl are ineffective if Husserl is construed in the right sort of way—Dainton (2003) responds. Dan Zahavi finds that Dainton’s analysis of the structure of streams of consciousness has many virtues (2007: 470) but is also problematic in several respects. Zahavi is also inclined to view experiences as intrinsically conscious, but argues that Dainton’s simple conception of consciousness goes too far and in the end is too simplistic. He is unimpressed by Dainton’s claim that Husserl simply stipulates that retentions have the mysterious features they need in order to make his theory work, pointing out that Dainton himself takes co-consciousness to be a primitive feature, one that cannot be analysed or reduced to anything else “and if he can employ that kind of argument, I fail to see why Husserl can’t as well” (Zahavi 2007: 468).

Prosser finds the notion of co-consciousness that Dainton takes to be primitive phenomenological feature “quite mysterious” (2016: 147) and so unhelpful:

I can only say that in my own case I am not at all certain what it should be like for two of my experiences to be co-conscious and yet not occur at the same time without this simply being a case of the earlier experience being retained in a short-term memory. (2016: 147)

Coming from a similar direction Chuard (2017: 127–8) suggests that since snapshot theorists can accommodate the seemingly flow-like character of experience there is no need for the theoretical apparatus Dainton’s approach requires.

Rashbrook (2013c) finds Dainton’s claim that synchronic and diachronic co-consciousness are different forms of the same kind of basic relation problematic for a different reason. If Dainton is right in claiming that co-consciousness is primitive then “the only features of the relation that we can describe are its logical properties” (2013c: 479), and these differ. Doesn’t the fact that synchronic co-consciousness is transitive and diachronic co-consciousness non-transitive mean we are dealing with two relations here, rather than one? There is a tension in Dainton’s position—as Bayne (2001: 85) also notes—but the situation may not be as clear-cut as Rashbrook suggests. Co-consciousness may be a basic relation but this does not mean that our knowledge of its nature is confined to its logical properties. We are also—or so Dainton claims—acquainted with its phenomenological character: co-consciousness is simply a label for experienced togetherness, a mode of unity which can be found binding simultaneous and also successive contents in our streams of consciousness.[18]

5.2.2 Temporal Structures and Transparency
In a number of provocative contributions Ian Phillips has argued that much of the temporal experience debate has rested on confusions and erroneous assumptions, which leads Phillips to call for a fresh start. The main target of Phillips (2010) is the Principle of Simultaneous Awareness (PSA), the doctrine that “if one experiences succession or temporal structure at all, then one experiences it at a moment” (2010: 177). Phillips suggests that this doctrine underlies both the various memory theories found in the literature, and specious present theories along the lines of Broad’s (see §6.1 below). Phillips argues that PSA is false. If it were true then it would be possible for the structure of our experience and the temporal structure of the objects and events presented to us in our experience to differ. But Phillips argues that this is in fact impossible.

Phillips’ argument for this controversial claim rests on two key claims. One is “Seems implies Is”, experience cannot be systematically misleading as to its own nature, and hence

we cannot make sense of the idea that experience seems to one’s rational introspective reflection to possess a certain temporal ordering, when it is not in fact so ordered. (2010: 183)

The other key claim is that the temporal aspects of our experience are “transparent” in a distinctive way:

one’s only way of making rational judgments about the temporal structure of experience itself, at least through reflection on one’s experience alone, is by taking the temporal structure of the experience to map the temporal structure of the world as it is experienced as being. (2010: 184)

If experience is transparent in this manner then we will judge that an experience of a succession of notes will itself unfold over time in just the way the notes seem to. If the “Seems implies Is” principle is also correct then it is impossible for the temporal properties of experience and its objects to systematically diverge in the way PSA predicts.

In “The Temporal Structure of Experience” (2014c) Phillips sets out to defend what he calls the “naïve view” of the manner in which the temporal structure of experience and the temporal structure of the objects of experience are related.

… when all goes well, your stream of consciousness inherits the temporal structure of the events that are its contents. You “take in” the temporal structure of the events you witness in witnessing them. As a result, the temporal structure of experience matches the temporal structure of its objects. In cases of illusion, it is as if this is so. Thus, in every case, the temporal structure of experience matches the apparent temporal structure of the objects of experience. (Phillips 2014c: §7.1)

Phillips suggests naïveté applies for temporal properties such as simultaneity, successiveness, relative duration and temporal order. Phillips goes on to address an objection. The claim that experience is transparent is also commonly made by proponents of the representationalist view of perception. Representationalists such as Michael Tye maintain that perceptual experience is entirely diaphanous, and hence that we have no introspective access to it, only to the objects in the world that it reveals. If this conception of transparency is correct, Phillips’ claim that we have introspective access to the temporal properties of our experience must be wrong. In response Phillips points out when it comes to experience, time is special. It may well be correct to reject the idea that an experience of redness or squareness is itself red or square. But

our experiential encounter with time is quite unlike color or shape, since our experience is not just of time, but also manifestly in time. (2014c: 144)

For critical assessments of these views see Lee (2014a), Frischhut (2015) and Viera (2019).

Phillips also makes a claim about what the extensional theory of temporal experience really amounts to. Following Soteriou’s lead here, for Phillips the key and defining feature of extensionalism is not simply a claim that an experience of change or succession takes place over an extended period. It is that when it comes to experience “it is significant stretches, not instants, that are explanatorily and metaphysically fundamental” (2014c:149).

A number of theorists have argued that Phillips’ inheritance thesis—that for any temporal property apparently presented in experience our experience itself possesses that temporal property—is undermined by one or other temporal illusions. Phillips disagrees, and in a series of papers devoted to different illusions he finds ways of reconciling his naïveté with the allegedly problematic experimental findings. Several of the latter centre on postdiction, the well-established phenomenon when what we experience as occurring at a time t is influenced by sensory stimuli occurring later than t. Phillips argues (2014c: §7.7–7.8) that provided we recognize that episodes of experience extending over several hundred milliseconds are metaphysically basic postdiction ceases to be deeply puzzling, for there is no reason to assume happenings later than t are irrelevant to what we experience at t. In Phillips (2014a) the focus is on whether the so-called “motion-silencing” illusion poses a threat to naïveté, as some have argued (for example, Suchow & Alvarez 2011; Watzl 2013). The illusion features a ring of coloured dots which are seen to cease to changing colour when they start rotating. Phillips argues that rather it is best construed as a instance of change-blindness, rather than as a failure of inheritance. In “Perceiving and the Passage of Time” (2013) Phillips deals with the challenges posed by the passage of time apparently speeding up reported by the survivors of life-threatening dangers, along with other duration distortions including the “odd-ball effect”. Phillips (2014b) provides a useful overview of his own work on temporal illusions.

Matthew Soteriou’s stance on a number of issues runs parallel to Phillips’. Soteriou also thinks that our perceptual experiences are in certain important respects transparent. In ordinary perceiving we seem to be directly aware not only of external worldly objects but also of events which are extended through time, and we do not seem to be aware of mental items such as sense-data. But he also thinks that in ordinary perception we have an awareness of temporal aspects of our experiences.

Introspectively, it doesn’t seem to one as though one can mark out the temporal location of one’s perceptual experience as distinct from the temporal location of whatever it is that one seems to be perceptually aware of. Furthermore, it seems to one as though the temporal location of one’s experience depends on, and is determined by, the temporal location of whatever it is that one’s experience is an experience of. (Soteriou 2013: 89f.)

If Soteriou is right, introspection can reveal the temporal properties of not only the events we perceive, but also of the perceptual experiences that are revealing these events, and the events and experiences seem to have the same duration. Introspection can thus provide evidence that our temporal experiences are themselves temporally extended, given that we directly experience change and succession—in line with extensionalism. See Hoerl (2018) for some further discussion.

Among writers on temporal experience Soteriou is distinctive in the emphasis he places on ontological issues, with different types of mental states—when their nature is properly understood—having quite different relationships with time. As Soteriou makes clear, his own thinking on these questions has been strongly influenced by Brian O’Shaughnessy. The latter introduces his own position in Consciousness and the World thus:

Yet even when experience is not changing in type or content, it still changes in another respect: it is constantly renewed, a new sector of itself is there and then taking place. … In short, the domain of experience is essentially a domain of occurrences, or processes and events. (O’Shaughnessy 2000: 42–43)

In developing his own position Soteriou draws a distinction between mental states and occurrent mental processes, with a distinguishing feature of the latter being the way they unfold over time whereas states don’t. For Soteriou (2007: 551–55) the basic units of temporal experience are temporally extended rather than momentary:

The answer we give to the question of what state a subject is in at a time is determined by the answer we give to the question of what state the subject is in during an interval of time that includes that instant…. (2007: 554)

Soteriou defends a version of direct realism (or relationalism) in which perceptual states are occurrent processes which are accompanied by representational states which exist in virtue of perceptual processes, and which wouldn’t otherwise exist. Soteriou argues—here following in Geach’s footsteps—that thought-like mental representations do not unfold over time in the way perceptual forms of consciousness do, a fact which seriously undermines the representationalist theories of perception in several of its guises. For more on these themes see Soteriou (2007, 2010, 2013, 2018).

Oliver Rashbrook has put Soteriou’s process-state distinction to useful work, showing that it can help dispel confusions surrounding the idea that consciousness is continuous (Rashbrook 2013b) and also help meet Pelczar’s challenge to extensional approaches (Rashbrook 2013a). In a more critical vein see Rodríguez (2016) and Steward (2018).

5.2.3 Tense, Perception and Unity
In his “Time and Tense in Perceptual Experience” (2009) Christof Hoerl also defends a form of extensionalism, albeit under the guise of “molecularism”. For Hoerl this approach can only hope to be viable if it is formulated in tenseless rather than tensed terms. Although specious present theorists have often assumed that temporal experience is best characterized in tensed terms such as “past”, “present” and “future”, Hoerl argues that in the extensionalist framework it is tenseless notions such as “before” and “after” that are required. When hearing an auditory succession consisting of a whizz-bang we don’t first experience the whizz as present and then (shortly after) as past-seeming:

my experience is rather as of each sound occurring in turn, and my experience’s taking this course is what constitutes my being aware of the whizz being followed by the bang. (Hoerl 2009: 8)

In a later article Hoerl (2013b) suggests here that currently the two most promising approaches to temporal experience are extensionalism on the one hand, and representationalist variants of retentionalism. He also suggests—also see Hoerl (2017)—that the extensionalist view of temporal experience and the direct realist (or “relationalist”) account of perception are natural partners. The representationalist stance on perceptual experience can assist the retentionalist in a number of ways, as we saw in §4.4. Hoerl is also right that anyone who adopts a realist stance with respect to temporal experience and who also inclines to direct realism will find the extensional view a natural and appealing one. If I see a traffic light change colour then for a direct realist an object undergoing change over an interval of time is being directly presented to me, and the resulting perceptual experience will itself extend through time, just as extensionalists claim. However, on the face of it the extensional approach seems compatible with other views concerning the nature of perceptual experience, such as the indirect realism Dainton prefers one, or adverbialism to mention but two—see Crane and French (2015 [2021]) for an overview of the competing theories.

The form of extensionalism defended by Hoerl is distinctive in a further way. As Hoerl notes (2013b: §6), to account for the difference between a succession of experiences and an experience of succession it is commonly argued that the latter possess a distinctive kind of unity that is absent from the former. Dainton, for example, holds that contents occurring at different times are only experienced as successive if they are bound together by his diachronic co-consciousness relationship. Hoerl argues that this assumption is in fact misguided, and that if we embrace extensionalism there is no need to appeal to this or any other unifying relation. In explaining how an experience of succession differs from a succession of experiences the only factor extensionalist needs to appeal to is the limited temporal span of our temporal awareness. Hoerl suggests that Dainton’s appeal to the non-transitivity of co-consciousness amounts to nothing more than

another way of stating the intuition behind the individuation argument that the maximum duration that individual temporal experiences can span is limited. (Hoerl 2013b: 406)

It is not obvious that extensionalists can dispense with the services of a diachronic unity relationship. Let’s consider things from the vantage point of Hoerl’s favoured combination of extensionalism and direct realism. Direct realists hold that (veridical) perception involves two elements: an external mind-independent object and an act or episode of perceptual awareness—a perceptual experience occurs when our awareness acquaints us with an outer object. In the synchronic case: it is widely (if not universally) agreed that phenomenal unity is a real and important phenomenon. My current visual and auditory experiences are unified in a distinctive way, whereas my current visual experiences and your current auditory experiences are not.

Synchronic phenomenal unity can be accounted for in different ways—see Brook and Raymont (2017 [2021]) for further details. One option is to hold that there is a unity relation which joins experiences together. A second option is to say that experiences are unified by virtue of being subsumed in a more encompassing experience. A further option is to hold that experiential contents are unified when they fall under a single act of awareness. The latter option will be a natural one for direct realists, given their view of the role awareness plays in ordinary perception. Direct realists who take this stance on synchronic unity are, in effect, getting an account of synchronic unity for free—it follows from a prior theoretical commitment to a certain view of perception. But it remains the case that the contents at any given time in a typical stream of consciousness are unified in a distinctive way.

The same applies in the diachronic case. Anyone who combines the extensional view with direct realism will presumably hold that our temporal experience relies on acts of awareness which are themselves temporally extended. But as in the synchronic case, the contents that fall under these acts of awareness will be unified in a distinctive way: their successive parts are experienced together rather than separately. When Hoerl talks of “individual experiences” it is presumably unified ensembles of this kind to which he is referring. Phenomenal unity has not departed from the scene, it is merely being explicated in a different way.

Moreover, phenomenal unity is not confined to the contents of experience, it will also exist at the level of acts of awareness. In the synchronic case, if consciousness has an awareness-content structure all contents have to do in order to be phenomenally unified is to fall under a single awareness at a give time. In the diachronic case the situation is not so straightforward. An act of awareness which extends across an interval of time will be composed of different phases, and unless the successive phases of the extended acts of awareness are themselves experienced together—in the manner depicted in Figure 5.1 above—we won’t have experiences of succession.

To make matters more concrete let us focus on a temporally extended episode of awareness A, which has sufficient temporal extension to encompass a traffic light’s changing from red to green, but which does not stretch any further into the past or future. We can represent this state of affairs schematically thus: A[red, green]. Let’s now narrow our focus and consider two briefer sub-phases of this experience: A[red] and A[green] corresponding to the earlier and later phases of the experience we are considering. Unless the earlier and later phases of A are phenomenally unified our subject’s stream of consciousness consists of two entirely discrete experiences: A[red] and A[green] experienced in succession but not as a succession. In order for our subject to have a single experience—an experience of succession rather than a succession of experiences—it has to be the case that the red and green lights are experienced together rather than separately. Adopting a direct realist conception of perception doesn’t eliminate the need for a mental unity relation, it merely gets re-located or re-described. Or so a critic might object.

For discussion of some further issues relating to extensional specious presents see the supplementary document The Specious Present: Further Issues.

6. Hybrid Approaches
6.1 Extended Contents and Momentary Acts
Given that the retentional and extensional approaches continue to have their defenders a not unreasonable conclusion to draw is that both may contain an element of the truth so far as the nature and structure of temporal consciousness is concerned. Given this it is not surprising to find a number of writers proposing hybrid models which—in differing ways—contain elements of both.

In his Scientific Thought (1923) C.D. Broad writes:

There is no doubt that sensible motion and rest are genuine unanalysable properties of visual sensa. I am aware of them as directly as I am aware of the redness of a red patch (1923: 287)

a clear commitment to realism. Later in the same work, in a much-cited passage he elaborates thus:

… it is a notorious fact that we do not merely notice that something has moved or otherwise changed; we also often see something moving or changing. This happens if we look at the second-hand of a watch or look at a flickering flame. These are experiences of a quite unique kind; we could no more describe what we sense in them to a man who had never had such experiences than we could describe a red colour to a man born blind. (1923: 351)

The account of the structure of temporal consciousness Broad went on to develop in Scientific Thought is of a distinctive kind. It is built on acts of awareness that are themselves momentary but which apprehend contents distributed over a short interval of time. For Broad a stream of consciousness consists of dense sequences of momentary acts and extended contents, with the consequence that the contents apprehended by neighbouring acts largely overlap. For anyone who holds that consciousness has an awareness-content structure Broad’s basic approach may well look quite promising—and many direct realists as well as sense-datum theorists fall into this category. The sort of overlap Broad envisages is shown in Figure 6.1, where three momentary acts A1, A2, and A3 apprehend a succession of auditory tones C-D-E-F, with each act able to apprehend two adjoining tones.

link to extended description below
Figure 6.1 C.D. Broad's Theory. [An extended description of Figure 6.1 is in the supplement.]

Broad’s theory has its merits, but it also gives rise to some problems and puzzles. Let’s suppose that during the experiencing of the D-tone a brief flash of light is also experienced—in Figure 6.2 below the flash is represented by the asterisk shape. This flash falls under A1, and so is experienced by that awareness; it also falls under A2, and so is experienced by that awareness. Hence the problem: it looks as though the flash is experienced twice, when in reality it would be experienced only once. In fact the situation is far worse, because in Broad’s model there are many additional momentary apprehensions occurring between A1 and A2, each creating a different experience. As Mabbott puts it:

Nothing in my direct experience confirms this repetition. If it occurred it would obviously make listening to music or to continuous sentences a matter of the greatest complexity and difficulty. (Mabbott 1951: 161)

Dainton (2000 [2006: 141]) also suggests that Broad’s account is afflicted by a problem of “repeated contents”.

link to extended description below
Figure 6.2 Repetitions and Divergences. [An extended description of Figure 6.2 is in the supplement.]

A further problem stems from the fact that on Broad’s account the periods during which we are continuously aware of contents can have a greater temporal extension than the contents themselves. Returning to Figure 6.2 the experience of the flash unfold over the very brief interval e shown in the diagram. The duration d stretches from A1 to A2 and corresponds to the entire period of time the subject was aware of the flash. As can be seen the interval d is considerably longer than e. Since contents that are apprehended by acts of awareness appear to be present, this means that—if Broad’s account is correct—brief events are experienced as present for considerably longer periods than they actually are present. By allowing us to experience an interval in an instant (or something close to it) Broad renders temporal experience incapable of accurately reflecting the temporal properties of the events we perceive. If our experience were misleading in this sort of way it is difficult to believe we would not notice. For further discussion of these aspects of Broad’s model see Dainton (2000 [2006: 6.2]), Tye (2003), Phillips (2010) and Rashbrook (2012, 2017).

6.2 Further Hybrid Variations
One way for extensionalists to embrace (after a fashion) the structures elaborated by retentionalists is to agree that the latter do exist, and do play a role in our cognition, but at an entirely sub- or pre-conscious level. On this view, retentions (and perhaps protentions) exist, but in the guise of neural mechanisms and processes that do not directly feature in consciousness. Carlos Montemayor (2013; Montemayor & Wittmann 2017) has defended this position. Montemayor proposes that we distinguish the “sensorial present” from “the phenomenal present”. The sensorial present represents stimuli as simultaneous, whereas the phenomenal present has a temporal extension of around half a second up to three seconds. Montemayor goes on to argue that it is a mistake to think the cinematic, retentional and extensional models are mutually incompatible. The cinematic and retentional models correspond to his sensorial present, and whereas the (extensional) phenomenal present is phenomenally conscious, the sensorial present is only access-conscious in Ned Block’s sense. Merino-Rajme (2017) is impressed by the ingenuity of this proposal, but raises doubts as to whether it is compatible with Block’s conception of what access-consciousness involves.

Thomas Sattig (2019c) suggested that in his Raum und Zeit (1915) Anton Marty defended a hybrid model in which both retentional and extensional elements figure in temporal experience. Marty’s position is certainly intriguing, but since it confines the experience of change to momentary phases of experience it ultimately seems more retentionalist than extensionalist in character.

In a recent paper Rick Grush (2016 [Other Internet Resources]) distinguishes two sorts of perceptual content: A-ish content is structured in terms of past, present and future whereas B-ish content is structured in terms of earlier than, simultaneous and later than. Grush points out that in discussions of temporal experience it is generally (if tacitly) assumed that the character of temporal experience has the same character at all temporal scales, over short intervals of time, medium intervals and long intervals. But what if this is not the case? What if our experience isn’t scale invariant? Grush proposes that at the larger temporal scales of seconds or minutes it is very plausible to think that our experience is A-ish in character. If you are watching an Olympic sprint, at around the mid-point some of the race still lies in the future, some of it is in the past, and some of it is happening now. But perhaps it is different at smaller sub-second temporal scales, and this is what Grush proposes: our experience is A-ish down to the scale of 200 msec, but beneath that it is B-ish:

No point in this interval is singled out as a now bracketed by a past and future. Rather, within this interval events are represented as standing in relations of earlier than, simultaneous with, and later than. But at scales greater than this, this B-ishly structured interval of 200 msec effectively becomes the bulky now of A-ish experience. (Grush 2016 [OIR]: 8)

Grush argues that holding that contents possess a B-ish character over short intervals helps circumvent an otherwise serious “surplus content” problem that Dainton (2000, 2008a) has directed against retentional models.

Gerardo Viera also argues for a hybrid approach in which extensional and retentional (or atomist) models both have important play, but where neither applies universally, to all forms of temporal experience. The grounds for this claim are scientific:

empirical evidence suggests that temporal experience is fragmented and composed of many dissociable capacities to perceive the temporal structure of our world. (Viera 2019: 33)

Viera’s starting point is the current state of play in neuroscientific investigations into how the brain manages to keep track of time. The long-dominant assumption that the brain relies on the regular beating of a single master-clock has been steadily undermined. If the master-clock existed and its functioning were disrupted by drugs or neural damage we would expect this disruption to have a devastating global impact on an individual’s time-related abilities, but Viera points out that there are no known cases of neural damage which completely eliminate a person’s ability to perceive time. Coming from the other direction the hypothesis that timing and time perception depends on a multiplicity of different neural mechanisms has plenty of empirical support. When rapid transcranial magnetic stimulation (rTMS) is applied to the frontal cortex the result is impaired timing in the second range; when rTMS is applied to the cerebellum timing in the millisecond range is impaired. Ingesting psylocibin has no effect on the ability to perceive at timescales of less than 2 seconds, but severely impairs perception at longer timescales.

If our brains use a multiplicity of very different neural mechanisms when dealing with time then it is possible that the extensional model applies to some forms of temporal experience and the retentional model to other forms, Viera argues that this may well be the case. When it comes to accounting for temporal perception at the sub-second level for individual sensory modalities so-called intrinsic timing models are currently influential, these rely on the dynamics of temporally extended neural processes to encode time, rather than any external clock. By way of an analogy, think of the way a pattern of ripples on a lake carries information about the time that has elapsed since a pebble was dropped. Viera suggests that any experiences this type of extended neural process produces will themselves be temporally extended in an extensionalist manner, with the mirroring constraint will be satisfied: the temporal features of successive phases of the neural process and the successive phases of the experience will correspond exactly. However, extensionalists don’t have it all their own way. In the case of cross-modal perceptual order judgements at the timescale of less than one second Viera points out that there are cases where mirroring conspicuously fails. Experiments show that if a short delay is introduced between a button-pressing and a flash of light the two events seem to be occurring closer together in time than they in fact are—in some cases the ordering of the stimuli seems to be entirely reversed (Viera 2019: 39–40).

Viera draws an ambitious conclusion from these results: since the mirroring constraint is violated

we have a counterexample to extensionalism, and therefore neither atomism nor extensionalism can provide us with a general theory for how the temporal contents of experience relate to the temporal structure of experience. (2019: 41)

It would be more accurate to hold that the cross-modal temporal order judgement case presents a potential problem for extensionalists who are committed to a very strict form of mirroring. Viera’s argument poses no threat to extensionalists who are prepared to acknowledge that mirroring may sometimes fail to hold at shorter time-scales.

On a number of occasions Ian Phillips (2010, 2018) has suggested that a different sort of hybrid theory may well be worth taking seriously. Phillips proposes that the extensional and retentional approaches have more in common than has usually been realized: there are grounds for thinking that both essentially depend on a form of memory. The kind of memory Phillips has in mind is not the sort we can call up hours, days or months after the event we are recollecting—critics of the Reid-type memory theories are right to point out that memories of this kind are too unlike perception to figure in temporal experience. The relevant type of memory is what James called primary or elementary:

an object of primary memory … never was lost; its date was never cut off in consciousness from that of the immediately present moment. In fact it comes to us as belonging to the rearward portion of the present space of time, and not to the genuine past. (James 1890: 646–7)

Phillips argues that primary memory properly understood, is perceptual in character, and so capable of playing a role in role in experiences of succession by providing us with a direct link to the immediate past. Phillips takes his “refined memory theory” to be a memory-based version of extensionalism. But he also proposes that, properly understood, Husserl’s theory is very similar: Husserl’s retentions are also constitutively connected to the past, and by virtue of that could not exist in a momentary episode of consciousness lacking that connection to the past. Adopting this perspective, Phillips argues, sheds valuable light on the entire field. For it suggests that the fundamental division is between those who those who claim

that it is only because our experience is a process which unfolds in time that it can acquaint us with the temporal structure of reality as it does.… (Phillips 2018: 17)

and those who deny this. Phillips proposes that if we view matters thus

… theorists who we might initially conceive of as rivals, namely extensionalists such as Dainton, and retentionalists such as Husserl and O’Shaughnessy, do not obviously disagree on substance. (2018: 21)

By way of further elaboration Phillips suggests the relation of co-consciousness which Dainton invokes to unify earlier and later phases of experience can itself be viewed as involving a form of memory.

The suggestion that Dainton’s co-consciousness relation could amount to a form of memory is an interesting issue for future discussion. That aside, Phillips’ claim that there is a divide of a fundamental kind between those who hold that experiences of succession require a succession of experiences on the one hand, and those who hold that experiences of succession do not require a succession of experiences on the other, is very plausible.

In his discussion of Phillips’ work Wolf (2021) finds much to recommend, but suggests that in its current form it lacks a decisive advantage over the more orthodox extensional and retentional approaches. The solution, Wolf suggests, is to move in a more dynamic—more Bergsonian direction—by finding a way of incorporating Bergson’s seemingly (but not really) paradoxical claim that “duration is essentially a continuation of what no longer exists into what does exist”. Wolf suggests that once this is done the result is a more appealing form of Bergsonian extensionalism that has greater plausibility than the competing versions, Phillips’ included.

7. Anti-Realisms
Perhaps there is a more dramatic discrepancy between the actual characteristics of our experience, on the one hand, and our beliefs about these characteristics on the other, than anything we have considered up to now. True, we do talk as though we see things move (and more generally, perceive change), and doubtless this talk reflects our beliefs, but perhaps our beliefs are simply wrong. Perhaps our immediate experience is in reality entirely motion-free, and our streams of consciousness radically fragmented, but since we do not believe our experience is like this, we do not talk as though it is.

A position along these lines has been advocated by Dennett. If asked whether our typical visual fields are fully continuous, even when one of our eyes is closed, most of us are inclined to answer in the affirmative: when we look at (say) a white wall, we see an uninterrupted expanse of white. In such cases we are unable to detect a beachball-sized fuzzy dark expanse lying just to one side of the central axis of vision. But the physiology of the eye suggests there should be a “blind spot” at that location, corresponding to the region of the retina occupied by the optic nerve which is devoid of light-sensitive cells. As for why we do not detect a blind region in our visual field, the standard—and on the face of it, plausible—answer is that our visual systems engage in some “perceptual interpolation” or filling-in: our brains extrapolate from the stimuli reaching the light-sensitive cells in the region of the retina immediately surrounding the blind-spot, and fabricate experience to fill the relevant region of the visual field accordingly.

Dennett points out that there is alternative to this account. Rather than “making up” experience in this manner, perhaps our brains simply fail to notice that there is a lack of visual information deriving from the hole region: after all, an absence of information is not the same thing as information about an absence. Never having received information from this region, the brain simply works on the assumption that nothing special is going on there:

The brain doesn’t have to “fill in” for the blind spot, since the region in which the blind spot falls is already labelled (e.g., “plaid” … “more of the same”). (1991: 335)

In effect, since we have a belief about what the blind region contains—typically, “more of the same”—why should the brain go to the trouble of generating experience as well? Dennett goes on to suggest that this treatment of spatial holes can plausibly be extended to temporal holes (gaps in the continuity of experience) also. Our visual experience is constantly interrupted by our eyes darting about during saccades. We don’t notice the resulting holes or gaps in our experience, but they don’t need to be filled in because we’re not designed to notice them. More generally:

One of the most striking features of consciousness is its discontinuity—as revealed in the blind spot, and the saccadic gaps, to take the simplest examples. The discontinuity of consciousness is striking because of the apparent continuity of consciousness. (1991: 356)

Although Dennett himself concentrates on explaining why we are inclined to describe our experience as continuous if it is really discontinuous, the approach can be extended to the immediate experience of change, or so Chuard argues (2011: 17) Suppose the “succession of static snapshots” conception of experience as proposed by the cinematic theorist is correct. Provided the contents and temporal arrangement of these static snapshots are enough to convince our brains that we are perceiving motion and change, we will inevitably believe that this is what we are perceiving, and hence describe our experience in such terms. Isn’t this all that we are required to explain? For Dennett and Chuard nothing further is needed.

As noted in §1.3 it is possible to be a realist about the experience of change and succession but an anti-realist about the dynamic features that some realists claim to be a pervasive feature of our experience. Thomas Sattig falls into this camp. Sattig is a realist about the experience of change and succession:

… I do not merely infer that the leave has moved, from memories of previously experienced momentary leaf-states. I just see that motion occurs. (Sattig 2019a: 275)

Sattig doesn’t reject all forms of flow, and has developed an account of it grounded in phenomenal replacement:

… I see that each momentary leaf-state is immediately replaced by another one like water flowing through a river bed, where each portion of water is immediately replaced by a new portion. (Sattig 2019b: §1)

In reducing the experience of motion to successions of momentary perceptions of objects at different locations he appreciates that some realists will find that his account fails to do justice to the dynamic nature of phenomenal flow:

Primitivists about the phenomenal whoosh of flow will not accept this phenomenological analysis, nor will they accept any other … But I have yet to encounter an alternative phenomenological description that reaches substantially beyond the usual, opaque flow-metaphors. (2019b: §4)

Others are still more sceptical, arguing that realists who believe in experiential flow or passage are deluded about the character of their own experience: flow isn’t a real feature of our experience, we merely (and falsely) believe that it is. Hoerl (2014) adopts this line, arguing that it is a mistake to suppose that the experience of seeing a moving object involves anything more than seeing the object at a succession of different locations—also see Braddon-Mitchell (2014). In a similar but more general vein K. Miller, Holcombe, and Latham (2020) suggest that we may well be inclined to attribute dynamic features to our experience which it in fact lacks, and propose two cognitive mechanisms which may underlie this inclination.

8. Temporal Consciousness and the Metaphysics of Time
8.1 Competing Conceptions of Time
If there are very different accounts of the nature of temporal experience, the same applies to time itself—the time which exists in the wider physical universe, rather than time confined to human consciousness. Let us take a brief look at these differing conceptions before considering the complex issue of how universe-time and experienced-time are related.

One central issue concerning universe-time can be encapsulated is this simple question: “Does time pass?” Temporal passage can be characterized in a number of ways, but at the very least passage is associated with the idea that the present is metaphysically privileged and steadily advancing, and this advance entails that future times will become present, that present times and events will become past, and that past times become ever more past with every passing moment. But while few deny that time seems to pass—and indeed, that this passage is (along with dimensionality) the most obvious difference between time and space—there are many who have denied that time really does pass. Of these a few share McTaggart’s view that time cannot pass because time does not exist.

A more popular view, these days at least, is the view that while time certainly exists, it is more akin to space than it superficially seems. Proponents of the four-dimensional “block universe”—also known as eternalism—hold that there is no ontological distinction between past, present and future, and that all times are equally real. They further hold that there is no unique privileged present time, and a fortiori that there is no such thing as a moving present. Block theorists face a significant challenge: Why does time seem to pass if it doesn’t? Part of the explanation lies in the way our memories accumulate, and intentions and decisions translate into actions (see Ismael 2011, 2013, 2016). Another part of the explanation lies in the character of our experience. Time per se may not pass or flow, but there is something akin to passage and flow in our immediate experience—phenomenal passage we can call it—or so many believe.

The block conception of time has its advantages. It has an appealing simplicity, and accords well with Einstein’s relativity theories, to mention but two. But the rejection of objective temporal passage is not to everyone’s taste, and other conceptions of time also have their advocates. The main contenders are depicted in Figure 8.1 below. At the opposite extreme to the 4-D block view is presentism, the doctrine that concrete reality is confined to the momentary present. Presentists deny any reality to the past or future. Coming in between these extremes is the growing block model. According to the latter, the past is real but the future is not, and the sum total of reality is gradually increasing, by a process of moment-by-moment absolute becoming. On this view the present is merely the most recent addition to reality; it is also the interface between being and non-being. The moving spotlight model is in one respect akin to the standard block model: it accords reality to all times and events, including those yet to occur. It differs from the latter by virtue of the fact that it incorporates objective passage into the universe, in the shape of a privileged (and constantly advancing) present—indicated by the blue line.

link to extended description below
Figure 8.1 Four conceptions of the large-scale composition of the universe. [An extended description of figure 8.1 is in the supplement.]

What McTaggart labelled the “A-series” runs from the distant past, up through the recent past to the present, and then on to the future. The “B-series” is the series of positions which runs from earlier to later, and vice-versa. Properties such being past, present, or future are often known as “A-properties”, whereas being earlier than, being later than, and being simultaneous are known as “B-properties” or “B-relations”. The block or eternalist conception of time is also often called “the B-theory”. The opposed dynamic conceptions of time are often called “A-theories”.

How do these different metaphysical conceptions of time accord with our competing realist accounts of temporal consciousness? One point seems more obvious that most. If reality is confined to a momentary present in the way presentists usually maintain, then it is difficult to see how any form of the extensional approach can be true. Our immediate experience cannot extend through time if time itself has no extension; if earlier and later stream-phases are experienced together, in the way extensional models require, then it seems very plausible to suppose that these phases must both exist. Or to put it another way: an experience which no longer figures in the sum total of reality is not in a position to be part of the same unified state of consciousness as an experience which does so figure, any more than a non-existent brick can help hold up a wall. By contrast, since retentional theorists have the option of holding that our experience of time takes no time—objectively speaking—their position looks to be entirely compatible with presentism, and similarly for the cinematic model.[19] As for the 4-D block conception, it looks equally compatible with all the main views of temporal consciousness. The retentional theorists’ momentary specious presents can exist in universes of this sort, as can those of cinematic theorists, but so too can the non-momentary specious presents to be found in extensional models.

8.2 The Argument from Experience
Does the character of temporal experience have any implications for the nature of time per se? Could the dynamism we encounter in our temporal experience be sign of temporal passage or even a product of it? Does it bolster the A-theorist by providing evidence that time really does pass? Claims that the passage of time features in our experience are not difficult to find.

The best reason to believe that time passes is simply that we find passage, that we are immediately and poignantly involved in the jerk and whoosh of process, the felt flow of one moment into the next. (Williams 1951: 466)

I cannot survey all the motivations philosophers have had for the moving spotlight theory. But the motivation that I like best appeals to the nature of our conscious experience. Of all the experiences I will ever have, some of them are special. Those are the ones that I am having NOW. All those others are ghostly and insubstantial. But which experiences have this special feature keeps changing. (Skow 2009: §5)

I find it impossible to relinquish the sensation of a flowing time and a moving present moment. It is something so basic to my experience of the world that I am repelled by the claim that it only an illusion or misperception. (Davies 1995: 275)

There is hardly any experience that seems more persistently, or immediately given to us than the relentless flow of time. (Schlesinger 1991: 427)

Given that there is more than one conception of what temporal passage itself amounts to the relationship between this sort of passage and temporal experience will not be straightforward. However, Le Poidevin has suggested that there is a general argument which connects the two, he calls it “the argument from experience” (Le Poidevin 2007: §5.1) and it can be formulated along these lines:

We have experiences that are seemingly of the passage of time.
The best explanations of this sort of experience all rely on the passage of time being an objective feature of reality
Therefore temporal passage is a real and objective feature of reality.
As Le Poidevin points out, a variety of quite different experiential considerations have been construed as linked to the passage of time—e.g., the perception of change and motion, the (seeming) confinement of the present—so there is a cluster of different issues which need to be investigated. Useful critical appraisals of these ongoing debates include Baron et al. (2015), Deng (2013, 2018), Frischhut (2015), Hoerl (2014), Prosser (2007, 2012, 2013, 2016).

Among B-theorists who want to deny that time really does pass one popular strategy is to focus on the second premise of argument from experience and find alternative explanations for experiences that are suggestive of passage. L.A. Paul has argued there are well-known results from psychology and the cognitive sciences which are potentially of great use to B-theorists seeking such explanations—see Paul (2010) and also Le Poidevin (2007: §5.5). In the case of apparent motion, for example, two stationary flashing spots on a computer screen will be seen to be moving smoothly back and forth, provided the spots are sufficiently close together and the rate of flashing is not too fast or too slow. In a similar fashion, the moving images on a cinema screen are a product of the ways in which our brains process the sequences of static images being projected onto the screen. Paul suggests that there is a more general lesson here: much of the dynamism we are naturally inclined to suppose exists in the world in reality is being fabricated in our brains:

Occam's razor suggests that the flow or animated character that we often refer to as “motion” is just a mistake. Motion is simply the change of location of a persisting object, and the flow or animated character that we notice and identify with motion is merely an effect of the brain. (Paul 2010: 358)[20]

Simon Prosser is a B-theorist who has on a number of occasions—e.g., Prosser (2000, 2007, 2012, 2013, 2016)—urged adopting a quite radical response to the argument from experience. For Prosser the idea that temporal experience could lend support to any form of temporal passage doctrine is radically misconceived: it is in fact quite impossible. A-theories of time are metaphysically incoherent and temporal passage is impossible. A-theoretic properties cannot exist, and cannot even be represented in consciousness.

In arguing against A-theories Prosser develops and deploys “the Detector Argument”. Smoke detectors can reliably detect the presence of smoke, Geiger counters can detect radiation, could there be a physical device capable of detecting temporal passage, one (say) that is equipped with a bulb which lights up when passage is found? Prosser argues that such a device is impossible: “there could be no physical system that would detect the passage of time” (Prosser 2016: 34). The reason for this is simple and straightforward: although defenders of A-theories of time believe that time passes, they don’t usually hold that passage makes a detectable physical difference to objects and events, and given this it is hard to see how any physical device could detect the existence of temporal passage. Prosser points out that the positions on the nature of the relationship between mind and body that are currently taken seriously in contemporary philosophy all posit very close connections between minds and brains: either minds are brains, or the mental causally depends on brain processes down to their last detail. Given the nature of this relationship “if no physical system can detect the passage of time then neither can the human mind” (Prosser 2016: 35) and it is impossible for temporal passage to register in human experience.

Prosser’s claim that passage makes “no physical difference to events” is questionable on a number of counts. Some A-theorists equate temporal passage with the coming-into-being of events—presentists and growing block theorists fall into this category. A-theorist of this kind will not find Prosser’s argument persuasive. They will point out that if time did not pass the physical universe as we know it simply would not exist. Nothing would happen, there would be no physical interactions between events, no event would cause another event—not if causation involves an earlier event bringing a later event into existence. Indeed there wouldn’t even any events, since events are occurrences in time, and time for the A-theorist essentially involves passage. For more on this line of response see Phillips (2016), Skow (2018) and Dolev (2019).[21]

Even if we set aside A-theories of this kind problems remains. Prosser notes:

Arthur Eddington, who was aware, as long ago as 1928, that no physical system could detect the passage of time, drew the conclusion that “consciousness, looking out through a private door, can learn by direct insight an underlying character of the world which physical measurements do not betray” (Eddington 1928: 91) These days, however, I do not think we can regard views of this kind as acceptable. (Prosser 2016: 35)

However, this issue is less straightforward than Prosser suggests. In The Nature of the Physical World Eddington certainly did claim that the material universe is dynamically temporal in a manner which physics does not recognize, and he also held that we know this because our consciousness provides us with some access to the real nature of the physical world. But in making these claims he wasn’t relying on some sort of mystical revelation concerning the true nature of things. Eddington defended a version of panpsychism, a fact which makes him something of a hero for contemporary panpsychists—see Strawson (2006) and Goff (2017).

Eddington, following in Russell’s footsteps, held that physics only reveals the causal and structural properties of physical things, it tells us nothing of their intrinsic nature—about the inner nature of the stuff they are made from. If we assume, as seems plausible to many, that physical things must have some intrinsic nature, then if physics is silent in this regard there is an important consequence: the hypothesis that the physical processes in our brains associated with consciousness have an experiential intrinsic nature will be compatible with everything physics has to say. In the light of this, Eddington suggests that it would be rather bizarre to adopt a different hypotheses and take the intrinsic nature of the relevant brain processes to be non-experiential:

It seems rather silly to prefer to attach it [consciousness] to something of a so-called “concrete” nature inconsistent with thought, and then to wonder where the thought comes from. (Eddington 1928: 259)

Since there is nothing special about the material in our brains—they’re composed of the same sort of basic physical ingredients as mountains, oceans and trees—then it seems plausible to conclude that if brain-stuff has an experiential intrinsic nature then all physical stuff will.[22]

It’s true that Colin McGinn once characterized panpsychism in an utterly dismissive way:

a complete myth, a comforting piece of utter balderdash … isn’t there something vaguely hippyish, i.e. stoned, about the doctrine? (2006: 93)

It’s also true that panpsychism has its share of problems—in common to all the other attempted solutions to problem of how consciousness and the physical world are related. But it’s also the case that in contemporary philosophy of mind circles panpsychism has a respectability it hasn’t had for some time—see Brüntrup & Jaskolla (2016) and Seager (2019).

Returning to the detector argument, if Eddington’s response has to be treated with respect, then Prosser’s conclusion that no physical system can possibly detect any form of temporal passage looks to be premature. If our experiences are revealing the inner intrinsic natures of certain neural processes—as panpsychists maintain—then if these experiences possess dynamic flow-type properties, then these properties will belong to the physical world. Neural processes, are after all, physical processes. In which case there is at least one way in which a physical system can detect one form of temporal passage.

This point also has a more general metaphysical significance. If panpsychism is true then everything in the universe is enjoying some form of consciousness. If (as many suppose) consciousness is essentially temporal, then if panpsychism is true everything in the universe will be enjoying a temporal form of consciousness. In which case the competing accounts of the structure of temporal experience are competing accounts of the nature of reality as a whole—in much the way Bergson suggested, a century or so ago.

1.The Linguistic Transition
Tracing the development of consciousness in the early modern period is complicated by the fact that both Latin and French, the two primary languages in which philosophy was written, have a single term that could mean either (a) moral conscience, or (b) consciousness. For Latin, the term is conscientia; in French it is conscience. (The verb and adjective forms are similarly ambiguous.) These terms were used with both of their major senses (along with other minor senses) in the seventeenth century, and so any interpretation of the important texts will have to be sensitive to this potential ambiguity.

But, more importantly, the underlying reason for this ambiguity is due to the shift in meaning that was taking place during the seventeenth century. Conscientia and conscience, both of which primarily signified a moral conscience prior to the seventeenth century, were now taking on a new, purely psychological, meaning. And the philosophers of this period were among the main figures influencing this shift in meaning.

Things aren’t any easier for philosophy written in English or German, both of which do have a linguistic means of distinguishing the two concepts. The English term “consciousness” first became widely used in the seventeenth century to mark out this new concept; the German term “Bewusstsein” was coined in the early eighteenth century (the German word for conscience is “Gewissen”). But even with a new word to identify the concept, the English and German terms had multiple shades of meaning. By 1727, we find Richard Cumberland defining consciousness as follows (in an English translation by John Maxwell from the original Latin):

(a) “The reflex Act, by which a Man knows his Thoughts to be his own Thoughts,” (b) “the Direct Act of Thinking; or (which is of the same Import;) simple Sensation,” or (c) “the Power of Self-motion, or of beginning of Motion by the Will” (Cumberland 1727, Appendix I, p. 5).

So, when reading English philosophical texts it is a tricky matter assigning a meaning or analysis to the term. But, of course, this is true to the nature of the problem. Philosophers of the seventeenth century were sketching out a concept that remains problematic to this day. In today’s discussions of consciousness, it is fairly common to mark out even further distinctions to identify which aspect of the problem one is addressing (creature consciousness, state consciousness, phenomenal consciousness, access consciousness, etc.). While some have used these later terms to make sense of what seventeenth-century philosophers are attempting to articulate in their theories, these finer-grained concepts will be for the most part left to today’s philosophers. This entry will instead see what sense can be made from the seventeenth-century philosophers’ own attempts at providing a coherent analysis of consciousness.

(For a helpful survey of the history of the Latin term conscientia prior to the seventeenth century, see Hennig 2007, pp. 466–481. For the transition in seventeenth century French, see G. Lewis 1950, pp. 111–114. For an account of the introduction of the philosophical term in English, see Thiel 1991. For a more literary account of the different senses of the terms in Latin and Greek, see C.S. Lewis 1960.)

The Story. It will be helpful to sketch the narrative arc before becoming immersed in the details of individual systems. There are two significant shifts that will emerge in the discussion below. The first is the one I’ve already indicated: the transition from moral conscience to a purely psychological concept of consciousness—a move from shared knowledge to a notion of consciousness as what is privately introspectable. This starts with Descartes and, in England, with the Cambridge Platonists. While this is certainly a major development, the central concept remains largely unanalyzed. The second shift occurs later in the seventeenth century, when philosophers start to see consciousness as itself something to be explained. This latter transition begins with the Cartesian philosophers who say more about the nature of consciousness in their development of Descartes’s system and in order to avoid some of the objections raised against it. But for the most part these Cartesians remained committed to consciousness as a fundamental property of the mind, a “mark of the mental.” Leibniz completes this second transition by arguing that consciousness cannot be a mark of the mental. He develops an account of mental representation and provides an analysis of consciousness in terms of mental representations, arguing that this results in a fully natural explanation for something that was otherwise mysterious. This represents the start of an explanatory project that continues to this day: can consciousness be explained in terms of something more fundamental?

2. Descartes and the Cartesians
A history of consciousness, in its modern sense, properly starts with Descartes. While it is true that some ancient and medieval philosophers prefigured some aspects of the modern concept of consciousness (see Heinämaa, et al. 2007), a significant shift took place in the seventeenth century, and starting with Descartes in particular, that corresponds with the linguistic shift describe above. So, it is worth asking what it is about Descartes’s project that gave rise to a new way of thinking about conscientia.

2.1 Descartes on Consciousness
In the Geometric Exposition following the second set of replies to the Meditations on First Philosophy (1641), Descartes defines thought in the following way:

Thought. I use this term to include everything that is within us in such a way that we are immediately aware [conscii] of it. Thus all the operations of the will, the intellect, the imagination and the senses are thoughts. I say ‘immediately’ so as to exclude the consequences of thoughts; a voluntary movement, for example, originates in a thought. (CSM II 113 / AT VII 160; cf. Principles of Philosophy Part I, §9 / AT VIIIA 7–8)

Here, in 1641, we have Descartes defining thought in terms of consciousness—a thought is something “in us” of which we are conscious.

There are obvious problems from the start. In what way am I conscious of my thoughts? It seems, rather, that I am conscious of what my thoughts represent. Descartes was well aware of the distinction between a thought and the object of thought, and he made use of two technical terms to mark out this distinction. Descartes distinguished between the form of thought, which he calls idea:

Idea. I understand the term to mean the form of any given thought, immediate perception of which makes me aware [conscius] of the thought. (CSM II 113 / AT VII 160)

Notice the similar reflective aspect of this: it is the perception of an idea that makes me conscious of the thought. But the idea is simply the form of the thought itself. The object of thought is whatever is represented by the thought. And so, Descartes defines the “objective reality of an idea” as “the being of the thing which is represented by an idea insofar as it exists in the idea…. For whatever we perceive as being in the objects of our ideas exists objectively [or by representation] in the ideas themselves” (CSM II 113 / AT VII 160).[1]

And so, as a first pass, it seems that consciousness for Descartes entails a perception (that has some content) and a second, reflective act by which I am aware of the first perception. It seems that the reflective aspect of consciousness does remain as a part of Descartes’s account of consciousness, but we’ll see that it’s less clear just what exactly the “second reflective act” is. But it is also the case that Descartes isn’t so interested in an analysis of consciousness as such. We might be looking for an analysis of consciousness; Descartes is not. For Descartes, consciousness is taken as given.

To see the trajectory from earlier theories of mind, it will be helpful simply to see that, in the cogito argument of the First and Second Meditations, Descartes sees reason to doubt all features of his mind other than what is consciously available to him. And even then, his conscious thoughts serve only as evidence of his own existence—they don’t give any further evidence that what they represent about things external to him either exist at all or exist as represented by the idea in his mind. And so consciousness implicitly becomes, for Descartes, the “mark of the mental” and any further development of theories of mind along these lines will have to consider the role of consciousness in the mental economy.

The role of consciousness, for Descartes, is primarily epistemic—it makes certain things available to the mind. Three particular aspects of this come to the fore in the Meditations:

Transparency of the Mental: All of my thoughts are evident to me (I am aware of all of my thoughts), and my thoughts are incorrigible (I can’t be mistaken about whether I have a particular thought).[2]
Reflection: Any thought necessarily involves knowledge of myself.[3]
Intentionality: My thoughts come to me as if representing something.[4]
Each of these emerge as necessary planks of Descartes’s argument in the Meditations. By simply having a thought (e.g., “I am doubting”) I know that I am having a thought and that this necessarily entails that I exist. This inference depends on the transparency of the mental and a reflective act (which Descartes further emphasizes in the Third Meditation, CSM II 34 / AT VII 49). Further, the intentionality of thought is part of what allows the meditator to infer that he is not alone in the world—he has a thought of an infinitely perfect being, and he has other thoughts of material objects. From this material—the thoughts and what they appear to represent—he is able to infer that God and the material world do in fact exist.

Do these three factors provide us with a full analysis of consciousness? Not entirely. But when pressed to defend these three aspects of the mind, he gives us more material from which we may infer an account of consciousness. For example, Antoine Arnauld, in the Fourth Set of Objections, raises the following problem for Descartes:

The author lays it down as certain that there can be nothing in him, in so far as he is a thinking thing, of which he is not aware [conscius], but it seems to me that this is false. For by ‘himself, in so far as he is a thinking thing,’ he means simply his mind, in so far as it is distinct from his body. But all of us can surely see that there may be many things in our mind of which the mind is not aware [conscius]. The mind of an infant in its mother’s womb has the power of thought, but is not aware [conscius] of it. And there are countless similar examples, which I will pass over. (CSM II 150 / AT VII 214)

Arnauld is objecting here to the transparency thesis—there are countless examples, he thinks, of thoughts of which the thinker is not conscious (a very interesting admission!). How does Descartes respond?

As to the fact that there can be nothing in the mind, in so far as it is a thinking thing, of which it is not aware [conscius], this seems to me to be self-evident. For there is nothing that we can understand to be in the mind, regarded in this way, that is not a thought or dependent on a thought. If it were not a thought or dependent on a thought it would not belong to the mind qua thinking thing; and we cannot have any thought of which we are not aware [conscius] at the very moment when it is in us. In view of this I do not doubt that the mind begins to think as soon as it is implanted in the body of an infant, and that it is immediately aware [conscius] of its thoughts, even though it does not remember this afterwards because the impressions of these thoughts do not remain in the memory. (CSM II 171–172 / AT VII 246)

The possible evidence against the transparency thesis, namely, the baby in the womb, does not tell against it, since failing to remember having a conscious thought does not entail that one did not have a conscious thought. But this answer, as a defense of the transparency thesis, raises a problem for reflection. If reflection is necessarily involved in consciousness, for Descartes, then is he here granting that even a fetus can reflect?

Descartes appears to resist this in his later correspondence with Arnauld. Arnauld distinguishes “simple reflection” from “express reflection,” and argues that although “simple reflection” is “intrinsic to all thought,” it is distinct from the sort of reflection necessary for intellectual memory and understanding. Descartes responds with his own distinction:

[W]e make a distinction between direct and reflective thoughts corresponding to the distinction between direct and reflective vision…. I call the first and simple thoughts of infants direct and not reflective…. But when an adult feels [sentio] something, and simultaneously perceives that he has not felt it before [i.e., it involves intellectual memory], I call this second perception reflection, and attribute it to the intellect alone, in spite of its being so linked to sensation that the two occur together and appear to be indistinguishable from each other. (CSM III 357 / AT V 220–221)

Arnauld, however, preserves this distinction in terms of reflection. According to Arnauld,

[O]ur thought or perception is essentially reflective upon itself: or, as it is said rather better in Latin, est sui conscia. For I do not think without knowing that I think. I do not know a square without knowing that I know it. (Arnauld 71)

This reflection that is essential to any thought, however, does not involve a second order perception. Each thought, according to Arnauld, has reflection built into it—a representation of the subject of thought is an essential part of the content of each thought. This is what he calls “simple” or “virtual reflection” to distinguish it from the sort of reflection that is a result of the subject focusing her attention on some other thought, which does require a second-order thought taking the lower-order thought as its object. (See Nadler 1989, 118–22 for discussion of this.)

Although Descartes resists attributing reflection, even simple reflection, to infants, Arnauld’s distinction is in line with Descartes’s response to another of his objectors. Pierre Bourdin attempts to raise problems for Descartes on the supposition that consciousness requires a distinct reflective thought:

By “thinking” you may mean that you understand and will and imagine and have sensations, and that you think in such a way that you can contemplate and consider your thought by a reflexive act. This would mean that when you think, you know and consider that you are thinking (and this is really what it is to be conscious [conscius esse] and to have conscious awareness [conscientia] of some activity). Such consciousness, you claim, is a property of a faculty or thing that is superior to matter and is wholly spiritual, and it is in this sense that you are a mind or a spirit. (CSM II 364 / AT VII 533–534)

Descartes denies this inference:

My critic says that to enable a substance to be superior to matter and wholly spiritual…, it is not sufficient for it to think: it is further required that it should think that it is thinking, by means of a reflexive act, or that it should have awareness [conscientia] of its own thought. This is…deluded…. [T]he initial thought by means of which we become aware [adverto] of something does not differ from the second thought by means of which we become aware that we were aware of it [per quam advertimus nos istud prius advertisse], any more than this second thought differs from the third thought by means of which we become aware that we were aware that we were aware. (CSM II 382 / AT VII 559)

Descartes does not here deny that reflection is necessary for consciousness. Rather, he is denying that reflection requires a distinct thought. (Note, however, the shift in tense, “…we become aware that we were aware…,” which casts doubt on whether these could be identical thoughts. More on this below.)

And so, in response to these objections Descartes gives us some refinements on his account of consciousness. Consciousness, for Descartes, is an intrinsic property of all thoughts (even of the thoughts of infants) by which the subject becomes aware of the thought itself. While this involves reflection, the reflective thought is not distinct from the initial thought itself.

The adjustments Descartes makes in his claims about consciousness have led some scholars to conclude that Descartes doesn’t have a single account of consciousness. Rather, he is working with multiple distinct notions of consciousness (see Radner 1988, Lähteenmäki 2007, and Simmons 2012). Whether or not he would have been aware of this is unclear.

Summary. Descartes provides one of the first purely psychological uses of the concept of consciousness when he defines thought in terms of consciousness. However, he does not provide an analysis of the concept. Rather, he employs the concept in a way that grounds his epistemic claims in the Meditations, for example. But the ways in which he employs the concept is suggestive of an analysis: a conscious thought is a mental state that is somehow self-intimating. And all thoughts, according to Descartes, have this basic property.

This sketch of an analysis was bequeathed to Descartes’s disciples, who argued over how best to understand consciousness. It is clear that Descartes’s project gives a central role to consciousness, but Descartes nowhere gives us an analysis of this basic concept. Is there anything about consciousness as such that allows it to play this central role?

(For more on the topic of consciousness and the related topics of transparency of the mental, representation, and reflection in Descartes, see Alanen 2003, Broughton 2008, Hennig 2007, Lähteenmäki 2007, McRae 1972, Radner 1988, Rozemond 2006, Simmons 2012, and Wilson 1978. Interpretations of Descartes’s account of consciousness differ significantly. Hennig, for example, argues that Descartes is not in fact using the term conscientia in a new way. Simmons, on the other hand, argues that Descartes has the resources for a nuanced account of consciousness, allowing for a wide variety of psychological phenomena. For criticisms of these types of interpretations of Descartes, see Christofidou 2023.)

2.2 In the Aftermath of Descartes
Three main threads of a psychological sense of conscience emerge from this sketch of Descartes’s views, and they immediately generate philosophical controversy.

Consciousness makes thoughts transparent to the mind: Are we aware of all our thoughts? When we are aware of having a thought, can we doubt that we are having that thought?
Consciousness involves reflection. Is consciousness essentially constituted by a perception distinct from the original perception? Does consciousness necessarily involve memory or reflection? Is all consciousness a form of self-consciousness?
Conscious thought is intentional. Are all thoughts representational? What is the nature of intentionality and what is its relation to consciousness?
Each of these three sets of questions were taken up and developed in different directions by the philosophers that followed Descartes most closely. The Cartesians, as they are called, were divided on each of these issues, and these sets of questions continue with us in one form or another to this day.

2.2.1 Transparency
Many Cartesians followed Descartes in defining thought in terms of consciousness. Louis de la Forge, who systematized Descartes’s account of the mind, defined thought in this way:

Thought [is] that perception, consciousness [conscience], or inner knowledge which each one of us experiences directly in ourselves when we are aware of [s’aperçevoir de] what we do or of what takes place in ourselves. (La Forge 39)

And later,

[T]he nature of thought consists [in] that consciousness [conscience], testimony [témoignage] and inner sensation [sentiment interieur] by which the mind is aware [averti] of everything it does or suffers and, in general, of everything which takes place immediately in itself at the same time as it acts or is acted on. (La Forge 57, translation altered)

Note that here La Forge elaborates on Descartes’s definition. He treats these terms as equivalent: perception, consciousness, testimony, inner sensation. Descartes does not describe consciousness in terms of sentiment, and this addition raises important questions—is consciousness simply a kind of sensation? Is it to interior perception what our senses of sight, sound, taste, etc. are to the perception of external things? Or is it different in kind?

Malebranche follows La Forge in this identification. In The Search after Truth, Malebranche uses “consciousness” (conscience) and “inner sensation” (sentiment interieur) interchangeably. (See, for example, Book III, Part 2, Chapter 7, Search 236–239.) Later, he defines thought in a way that closely models La Forge’s definition:

[B]y the words thought, mode of thinking, or modification of the soul, I generally understand all those things that cannot be in the soul without the soul being aware of them through the inner sensation it has of itself. (Search 218)

(Schmaltz argues that Malebranche was strongly influenced by La Forge in his argument here. See Schmaltz 1996, 16ff.)

Thus, La Forge and Malebranche continue Descartes’s commitment to transparency. However, the shift to “interior sense” is an important shift, since it marks a shift in the content of what is transparent to the mind, especially concerning the mind’s own nature. Malebranche famously denied Descartes’s claim that the mind is better known than the body. This is due to the fact that, although we know body confusedly through our sensations of the external world, we nevertheless have knowledge of the nature of body. (I’ll leave aside Malebranche’s complicated story of how we come to have that knowledge.) But, in the case of the mind, all we have is the internal sense of the mind—we do not know the nature of the mind since we have no such concept. Malebranche says:

It is true that we know well enough through our consciousness, or the inner sensation that we have of ourselves, that our soul is something of importance. But what we know of it might be almost nothing compared to what it is in itself. (Search 238)

He later gives an explanation of why we have knowledge of bodies through the ideas of bodies, but not so for the soul:

The knowledge that we have of our soul through consciousness is imperfect, granted; but it is not false. On the other hand, that knowledge that we have of bodies through sensation or consciousness, if the confused sensation we have of what takes place in our body can be called consciousness, is not only imperfect, but also false. We therefore need an idea of the body to correct our sensations of it—but we need no idea of our soul, since our consciousness of it does not involve us in error…. (Search 239)

Thus, consciousness, as internal sensation, gives us imperfect knowledge of the soul, but it is knowledge that is sufficient for all practical (and, importantly for Malebranche, theological) purposes.

So, the subtle shift in the meaning of consciousness to “internal sensation” places some limits on what can be known about the mind by means of consciousness. One can be aware that one is thinking, but this does not give us a clear idea of the soul. It is not self-knowledge of the same sort. But note also the other shift that this entails—marked by Malebranche’s qualification in the passage above. The sensation of external objects may not be (properly speaking) consciousness. Consciousness is an interior phenomenon, a sensation of what is going on in us, and so the visual perception of a red ball can be called consciousness only in a derivative way. This leads us to questions about reflection, taken up in the next thread.

2.2.2 Reflection
As discussed above, already in the Seventh Objections to the Meditations, the objection was raised that consciousness appears to require a distinct reflective thought. Descartes denied the inference, saying that

[T]he initial thought by means of which we become aware of something does not differ from the second thought by means of which we become aware that we were aware of it, any more than this second thought differs from the third thought by means of which we become aware that we were aware that we were aware. (CSM II 382 / AT VII 559)

Again, as noted above, Descartes’s response here is not a denial that reflection is necessary for consciousness—he denies that reflection requires a distinct thought. La Forge and Malebranche both follow Descartes in this denial (see Schmaltz 1996, 18).

But this passage is somewhat ambiguous. Here Descartes distinguishes (1) becoming aware of something, which apparently requires only a single thought, from (2) becoming aware that we were aware of something. Apparently, first-order awareness does not require a reflective act. And, while becoming aware that we were aware of something does require a reflective act, it does not require a distinct thought (and so the threatening regress is not problematic). But it’s not at all clear from this passage how the reflection could be built in to the original thought, especially since there appears to be a shift in tenses (the second awareness is temporally posterior to the initial awareness).

Antoine Arnauld develops an account of reflection that incorporates this distinction. The reflection that is essential to any thought does not involve a second order perception. As noted above, Arnauld argued that each thought has reflection built into it, although this does not entail a second-order thought. Only explicit reflection, where an individual focuses their attention on their own thoughts, requires a second-order perception. (For more on Arnauld’s account, see Nadler 1989, 118–22. For the Scholastic background of “virtual reflection” as used by Arnauld, see Schmal 2020.)

As Geneviève Lewis shows, this issue became a critical source of debate in the later seventeenth century. She notes that Pierre-Silvain Régis, in his defense of Cartesianism, commits himself to some sort of reflective knowledge as a constitutive part of consciousness. Régis, like Arnauld, reaches all the way back to Augustine as a source for this doctrine, quoting Augustine’s claim that “it is necessary that [an animal] perceives (sentio) that it does see when it sees” (Augustine 37, quoted by Régis, Système I, 150) When conscious of something, one “perceives that one perceives it.” This way of putting it was actually quite common as a way of describing the psychological sense of consciousness—one not only sees a red ball, but one also perceives that one perceives the red ball. This sounds for all the world like a reflective act.

On the basis of this, one of the chief opponents to Cartesianism, Pierre Daniel Huet, argues that the Cartesians are begging the question. He argues,

Every thought involves three things: the thinking mind, the thing placed before the thinking mind [i.e., the object of thought], and the action of the thinking mind on the thing placed before it. (Huet 82)

Descartes, Huet contends, fails to distinguish these three things in the cogito argument. When Descartes says ego cogito, I am thinking, what is the object of thought? His own thought itself. But, and here is the objection, this cannot be the same thought as the original thought, “for if it were, the action would be turned back upon itself, which is absurd and contrary to the natural light so often invoked by Descartes” (83). Nevertheless, this is the very response Descartes gives in his response to Bourdin. Why does Huet think this is “absurd and contrary”?

Huet goes on:

[I]n order for me to think that I am thinking, two thoughts are needed, with one reflecting on the other—the later, current one on the previous, earlier one—so that in order for the first thought, by which the mind is aware, to be placed before the mind, the second thought, by which the mind is aware, is of the first thought. Or, in short, the first thought will be the end or object of the second; the second will be the action of the mind whereby it is directed to the first thought. But it is a contradiction that both should occur by a single action… (84)

In his reply, Régis argues that this is precisely what is going on. He argues that we have no need for distinct reflective ideas; Descartes “perceives that he thinks by a single and simple idea, which is known through itself” (Réponse 35; cf. Système I, 150). And then he argues that if a second act were necessary then an infinite regress would threaten, since in order to be aware of the second thought one would need a third, and so on.[5] Huet sidesteps this objection with a response drawn from Aquinas: “he [Aquinas] admits that thoughts will be multiplied ad infinitum and that the mind is infinite—not in act, but in potency” (Huet 86).

But underlying all of this is a further, important, difference between Huet and the Cartesians. Huet argues that

This expression [i.e., “ego cogito”] is defective, for it should be taken to mean, and to be worth as much as if I were to say, ‘I am thinking that I was thinking.’ For like the eyes, the human mind can attend to only one thing at a time. Thus, in order for me to think that I am thinking, two thoughts are needed…. (84)

If Huet’s phrase “the human mind can attend to only one thing at a time” means that a we can think of only one thing at a time, then the Cartesians will reject this premise. Indeed, Descartes explicitly does so (see CSM III 335 / AT V 149). But Régis responds by rejecting the premise that the eye sees only one thing at a time, reinforcing the analogy between the mind and the eye. He argues that if thought is to the mind as light is to the eye, then when we see something, there are three distinct aspects of the event: “the eye that sees, the action by which it sees, and the object seen” (Réponse 35). Suppose now that we say, “I see the light.” Must we suppose that there must be a second light illuminating first? No; we see the light by itself. Similarly for thought—if Huet grants the analogy, he “must conclude that [a thought] is known through itself” (Réponse 36).

The result is that, for the Cartesians, a thought can “turn back upon itself,” which is what Huet finds absurd. Huet’s objection is that the Cartesians are illicitly smuggling in the subject as an object of all thoughts. If so, he argues, then this requires a second thought, which undermines the cogito argument.

And so one of the crucial points of clarification for a theory of consciousness is getting straight on whether consciousness involves reflection, and, if so, whether that requires a distinct reflective thought.

2.2.3 Intentionality
These considerations of incorrigibility and reflection have implications for the intentionality of thought. Antoine Dilly, another Cartesian philosopher of the seventeenth century, will bring out some of these points. In response to an argument by Ignace Gaston Pardies in which Pardies defends a certain kind of knowledge in animals, Dilly defends the Cartesian position. He writes (in 1676):

To avoid falling into an equivocation concerning the word reflection, it is good to recognize that [a] we can sometimes reflect on what we do and [b] sometimes the first thought that we have is not only perceived, but when a second thought takes the first for its object it happens that we know its nature much better by this repeated inspection. This is even more so since the first thought principally renders its object present to the soul and by being sensed informs us of its [i.e., the thought’s] presence. But this second thought has as its object only the first; it shows it to us as lively as the first shows us its object. Thus it should not be believed that each thought is followed by a second that makes it known, because the latter would have to have a third, and so on to infinity. But we are assured, being convinced by our own experience, that all thought is made sensible to the soul, not by any veritable return on itself, but directly and immediately merely by its presence: thus when I see, my vision makes sensible what is, without having need for any other thing. Each person can be much better convinced of this by consulting themselves…. (Dilly 116–118)

There are two noteworthy elements here. First, Dilly repeats the arguments we saw in Régis, advancing the view that thoughts are known through themselves rather than requiring a distinct reflective thought. Second, Dilly nevertheless characterizes our perception in terms of reflection in order to preserve a sense in which the original perception “informs us” of its presence (i.e., the presence of the idea), by means of which we are aware of the object of thought. This is the sort of awareness that Descartes and the Cartesians have been working to preserve.

Dilly is developing this thought with an eye to dismissing what Pardies describes as “corporeal knowledge.” As Dilly understands this, Pardies is saying that an animal can perceive something without perceiving that it perceives, contrary to the Augustinian slogan mentioned above. That is to say, there may be a representation of the object in the animal, but the animal is unaware of the object. Dilly responds:

Is it conceivable that [a dog] is led to run to his master by a genuine knowledge that he has of him, without knowing that he perceives his master…? How could he identify this man from a hundred others that resemble him without perceiving that he sees him and is assured, from the inside, that it is him and not some other that he needs to go to for petting? And how does he do all of this without knowing that he does it? (122)

Underlying Dilly’s rhetorical questions about the dog in need of a good petting is a thesis about intentionality. According to Dilly, any attempt to demonstrate that animals have thought must consider how the thought would enter into the passions and actions that the animal is experiencing. It is not enough simply to develop an account of perception by which the things around the animal are impressed upon it.

The implicit argument here is that there is no genuine representation if there is no awareness of the representation. Whatever a dog qua machine is acting on when running to his master, it is not an internal representation of his master that the dog acts on with purpose. The “corporeal knowledge” would be nothing but connections or impressions of one body on another—without an awareness of these impressions and what they represent, they won’t serve the purposes of knowledge, sensation, action, or volition.

Dilly argues that intentionality requires awareness—a thought does not represent an object unless there is a subject that is aware of the representation. And so the consciousness of a thought is conceptually prior to its intentionality, which is to say that intentionality is simply a kind of consciousness.[6] But, as we will see, others will argue in the reverse direction. Indeed, if a conscious thought is a representation of something plus a reflective act, then it seems that the representation is conceptually prior to consciousness. What is being worked out during this period is what, exactly, the relation of consciousness, representation, and thought really is. And this is something of enduring interest.[7]

3. Spinoza
While many philosophers after Descartes took up the issues related to consciousness left by Descartes, one possible exception is Spinoza. On some interpretations, he doesn’t have much to say at all about consciousness.[8] This is somewhat striking, given how much Spinoza had to say about ideas and the mind. However, this may be a reflection of just how thin Spinoza’s attribute of thought really is, bringing together what in Descartes were distinct concepts: will and intellect, judgment and perception, and the like, developing a fully naturalized account of the mind. And so it seems that, insofar as Spinoza has a theory of consciousness, it will be explained in terms of some other more fundamental feature of the mind.

Spinoza’s theory of mind is a thoroughly representational theory of mind. The mental consists simply in representational content, for Spinoza. In Ethics 2p7, he argues that “the order and connection of ideas is the same as the order and connection of things,”[9] which is to say that for each extended object, there is a parallel idea. This is called mind-body parallelism. From this Spinoza is able to develop his theory of mind: “The first thing that constitutes the actual being of a human mind is nothing but the idea of a singular thing which actually exists” (2p11). Each mind is itself an idea with a particular object—in the case of humans, the mind is the idea of its body, and whatever happens in the body will be represented in the mind (as he argues in 2p12 and 2p13). The mind is a particular idea that represents a singular object, namely, the body that it is parallel to. This is a fully representational theory of mind, and anything else that can be inferred from the mind will have its parallel in the body that it represents. (For more on Spinoza’s representational theory of mind, see Della Rocca 1996.)

So, of the three main threads discussed above, it seems that the intentionality of thought is the primary pivot on which everything else turns for Spinoza’s theory of mind. There are suggestions in Spinoza’s Ethics that he thinks there are some representations of which we are unaware. At the end of the Ethics, Spinoza describes the “wise man” as the one who is “conscious of himself, and of God, and of things” (5p42s), the clear implication being that those who aren’t wise fail to be conscious of themselves, God, or things, even if these things are present to mind through a mental representation. And so, it seems that Spinoza needs an account of consciousness that does not extend to every mental representation (or, at the very least, not to the same degree). Below are presented some of the main interpretations of Spinoza’s account of consciousness, although Daniel Garber has recently argued that Spinoza does not have any such worked out theory, “nor did he need one” (Garber 2021).

3.1 Moral Consciousness
As the reference to the “wise man” above suggests, Spinoza’s primary use of the term “consciousness” is moral, but he is making a significant departure from the older sense of the term as “moral conscience.” There is no inner testimony that Spinoza thinks we should heed. Rather, he is focusing our attention on how we think of ourselves as a part of the natural order. He uses this concept to draw together his moral, epistemological, and metaphysical projects.

It is significant that Spinoza rarely used the term conscientia (in its various forms) in the Ethics, and when he does it is almost exclusively in parts 3 through 5, where Spinoza is considering the nature of specifically human affects and bondage or freedom with respect to them. Indeed, the few times Spinoza uses conscientia in Parts 1 and 2, he does so in a way that points forward to its use in the later part of the Ethics.[10]

The proposition in which the term conscientia gets the widest use is 3p9:

P9: Both insofar as the Mind has clear and distinct ideas, and insofar as it has confused ideas, it strives, for an indefinite duration, to persevere in its being and it is conscious of this striving it has.

Dem.: …since the Mind (by IIp23) is conscious of itself through ideas of the Body’s affections, the Mind (by p7) is conscious of its striving.

Schol.: When this striving is related only to the Mind, it is called Will; but when it is related to the Mind and Body together, it is called Appetite. This Appetite, therefore, is nothing but the very essence of man, from whose nature there necessarily follow those things that promote his preservation. And so man is determined to do those things.

Between appetite and desire there is no difference, except that desire is generally related to men insofar as they are conscious of their appetite. So desire can be defined as appetite together with consciousness of the appetite.

The “content” of consciousness—what it is we are conscious of when we have a mental state with the form articulated in 3p9, is best expressed by the following quotation from the appendix to Part 1:

[A]ll men are born ignorant of the causes of things, and…they all want to seek their own advantage, and are conscious of this appetite.

From these [assumptions] it follows, first, that men think themselves free, because they are conscious of their volitions and their appetite, and do not think, even in their dreams, of the causes by which they are disposed to wanting and willing, because they are ignorant of [those causes]. It follows, secondly, that men act always on account of an end, viz. on account of their advantage, which they want.

The transition Spinoza is attempting to effect in his readers is a transition from this sort of consciousness—where we falsely regard ourselves as free, we think of the world as having a rich and extensive teleology, and we think of ourselves as agents freely acting on purposes and ends—to another sort of consciousness in which we know ourselves to be part of an “eternal necessity” (5p42s). As Spinoza puts it:

Therefore, the more each of us is able to achieve this kind of knowledge [i.e., the third kind of knowledge], the more he is conscious of himself and of God, i.e., the more perfect and blessed he is. (5p31s)

And so the role of consciousness for Spinoza is primarily moral—the moral transition is a transition in the content of our consciousness. But, as already noted, this appears to require some variation between what is strictly represented by the mind and the way it appears to the mind in consciousness. To get at this difference, we’ll need to look more closely at the form of consciousness for Spinoza.[11]

3.2 Ideae Idearum
At the beginning of the previous section, we noted that Spinoza rarely uses the term conscientia, and when he does it is primarily in parts 3 through 5. This claim, while true, is somewhat misleading. Note that the quotation above from 3p9 refers us back to 2p23 for his claims about consciousness. And again in 3p30d, 3def.aff1, and 4p8d Spinoza refers us back to 2p23, 19, or 21. It seems clear that he intends 2p19 through 23 to have some consequence for his theory of consciousness, and so many commentators have tried to develop an account of consciousness from what Spinoza says in that section of the Ethics.

2p23 does not say anything about consciousness as such. Instead, it describes the way the mind knows itself and the limits on the mind’s knowledge of itself. Here is what Spinoza says:

P23: The Mind does not know itself, except insofar as it perceives the ideas of the affections of the Body.

Dem.: The idea, or knowledge of the mind (by P20) follows in God in the same way, and is related to God in the same way as the idea, or knowledge, of the body. But since (by P19) the human Mind does not know the human Body itself, i.e. (by P11C), since the knowledge of the human Body is not related to God insofar as he constitutes the nature of the human Mind, the knowledge of the Mind is also not related to God insofar as he constitutes the essence of the human Mind. And so (again by P11C) to that extent the human Mind does not know itself.

Next, the ideas of the affections by which the Body is affected involve the nature of the human Body itself (by P16), i.e. (by P13), agree with the nature of the Mind. So knowledge of these ideas will necessarily involve knowledge of the Mind. But (by P22) knowledge of these ideas is in the Mind itself. Therefore, the human Mind, to that extent only, knows itself, q.e.d.

Many of the crucial phrases are ambiguous here, but as a first attempt, we might say that Spinoza is arguing for the following thesis:

A mind has a conscious thought of P iff

the mind has an idea that represents its body being affected by P; and
the mind has a second idea representing the first to itself.
This is one way to make sense of “perceiv[ing] the ideas of the affections of the Body.” Edwin Curley presents such an interpretation of this passage (Curley 1969, 128). The benefit of this theory of consciousness is that it is thoroughly representational, and so it is consistent with Spinoza’s general project of developing a representational theory of mind. Further, this theory would seem to entail that not all minds are conscious (or that not all thoughts are conscious)—Spinoza suggests that infants are not conscious in 5p6s and 5p35s

Despite these advantages, this initial understanding of this passage has fallen under heavy fire. Margaret Wilson has objected to this reading by arguing that it does not provide a satisfactory way of distinguishing between conscious and non-conscious minds or conscious and non-conscious thoughts. Since, in God, there must be ideas of all ideas, any given idea (and any given mind) will have the necessary second idea (or even infinitely many—see 2p21s) that would render it conscious. (See Wilson, 134–138 for further objections.) Jonathan Bennett puts forward similar objections, concluding that if this is Spinoza’s account of consciousness, it is “absurdly excessive” (Bennett 188). Curley concedes the point (see Curley 1988, 71–72).

Others have tried to rehabilitate this interpretation and respond to the potential objections. Lee C. Rice (1990) and Christopher Martin (2007) both offer responses to the objections and attempt to defend this interpretation of Spinoza’s theory of consciousness. Their efforts at making sense of 2p19–23 are interesting, but it is not easy from this section of the text to avoid the “absurdly excessive” conclusions. Of course, one could simply bite the bullet here and say that Spinoza is in fact “absurdly excessive”! He is committed to panpsychism, why not take the short step to a similarly extensive account of consciousness? Indeed, the next set of interpretations are prepared to go that far.

3.3 Complexity and Power
Despite the explicit reference to the “ideas of ideas” passages in later discussions of consciousness, Stephen Nadler (2008) and Don Garrett (2008) think this is the wrong place to look for Spinoza’s theory of consciousness. Instead, they develop their interpretations from the thesis of mind-body parallelism.

While Nadler is inclined to think that Spinoza does not have a full-blown account of consciousness, what Spinoza does offer is “very suggestive…for a particular kind of project, one that represents a naturalistic account of consciousness that is precocious in so far as it points the way to just the kind of empirical, scientific inquiry into consciousness that characterizes contemporary neuroscience and (some) recent philosophy of mind” (586). Quoting 2p13s and 5p39s, Nadler argues that the feature that is being tracked by the mind in consciousness is the structural complexity of the body. 5p39s reads as follows:

[H]e who, like an infant or child, has a Body capable of very few things, and very heavily dependent on external causes, has a Mind which considered solely in itself is conscious of almost nothing of itself, or of God, or of things. On the other hand, he who has a Body capable of a great many things, has a Mind which considered only in itself is very much conscious of itself, and of God, and of things.

In this life, then, we strive especially that the infant’s Body may change (as much as its nature allows and assists) into another, capable of a great many things and related to a Mind very much conscious of itself, of God, and of things.

From these passages, Nadler concludes that “human or higher consciousness for Spinoza is nothing but the mental correlate of the superlative complexity of the human body” (587). The result is that consciousness, for Spinoza, is a matter of degree (as is suggested in the passage above). Nadler also suggests the possibility that this could be a threshold concept—that there is a minimum degree of complexity that must be satisfied before a mind could be conscious. But, citing Garrett’s appeal to Spinoza’s naturalism, he dismisses the threshold view. And so, consciousness comes in degrees, and all minds have it (contrary to the worries in the ideae idearum section).[12]

Don Garrett draws from the same texts as Nadler, but what he emphasizes in these passages is the difference in ability. Note in the above passage that Spinoza talks of the infant body as one “capable of very few things.” And so the underlying feature that consciousness tracks, according to Garrett, is the relative power of the body (23–24). The more power a body has, the greater the degree of consciousness in the mind.

The problem with this view, according to Nadler, is that “all that Garrett is warranted in concluding from his argument and the central passages in question is that degrees of consciousness and degrees of power of thinking in a mind vary proportionately, but not that consciousness is itself identical to power of thinking” (592–93). However, given Spinoza’s representational account of mind, the only two features that stand out as candidates for explaining consciousness are some features of the representations themselves (their complexity) or the causal efficacy of the ideas (their power). (Cf. Della Rocca 2008 108–118.)

Michael LeBuffe has argued that the central passages on which most scholars have developed their interpretations should not be read as proposing a theory of consciousness; rather, these passages are focused on “the epistemological status of certain elements of conscious experience.” Nevertheless, he does recognize that Spinoza requires a theory of consciousness and raises a particular problem for Garrett’s interpretation. On Garrett’s interpretation, the power of a mind and the power of its constituent ideas could diverge. That is, there could be a very powerful mind (which is conscious to a high degree) whose ideas are relatively less powerful (of which the mind is conscious to a very low degree). That is, on Garrett’s view, it is possible for a more powerful mind (as a whole) to have ideas all of which are less conscious than the ideas in a less powerful mind, in which case it would be odd to describe the more powerful mind as having a higher degree of consciousness (LeBuffe 2010, 557). LeBuffe argues to the contrary that Spinoza does not characterize the power of a mind (as a whole) in terms of its level of consciousness.

Eugene Marshall has proposed a development of Garrett’s interpretation, which reduces consciousness to “affectivity” (see Marshall 2014, chapter 4). “Affectivity” is the property an idea has when it increases, decreases, or fixes the power of the mind’s striving (its “conatus”) or when it moves the mind to act. Emotions such as joy or fear would be affective in this way, but so would certain rational judgments. Marshall argues that this provides a more developed account of how power is centrally involved in consciousness for Spinoza while avoiding some of the problems of Garrett’s proposal.

4. Developments in England
So far the discussion has centered on continental Europe. But there were similar developments towards a theory of consciousness in England.

4.1 Hobbes
At the beginning of the seventeenth century, we find Hobbes giving the traditional definition of consciousness:

When two, or more men, know of one and the same fact, they are said to be CONSCIOUS of it one to another; which is as much as to know it together. And because such are fittest witnesses of the facts of one another, or of a third; it was, and ever will be reputed a very evil act, for any man to speak against his conscience; or to corrupt or force another to do so…. Afterwards, men made use of the same word metaphorically, for the knowledge of their own secret facts, and secret thoughts; and therefore it is rhetorically said, that the conscience is a thousand witnesses. (Leviathan 7.4)

The etymological sense of consciousness of shared knowledge is preserved here and connected with the function of conscience as a witness. Indeed, it is important to Hobbes to preserve this public sense of consciousness/conscience, since he viewed the private judgments of conscience to be “repugnant to civil society” (Leviathan 29.7).

And yet, quite apart from the term ‘consciousness’, it seems that Hobbes has an account of phenomenal awareness:

[I]f the appearances be the principles by which we know all other things, we must needs acknowledge sense to be the principle by which we know those principles, and that all the knowledge we have is derived from it. And as for the causes of sense, we cannot begin our search of them from any other phenomenon than that of sense itself. But you will say, by what sense shall we take notice of sense? I answer, by sense itself, namely, by the memory which for some time remains in us of things sensible, though they themselves pass away. For he that perceives that he hath perceived, remembers. (De Corpore 25.1, p. 389; for some discussion of this text, see Frost 2005)

We must be cautious about attributing a theory of consciousness (in the modern day sense) to Hobbes here. In particular, we should be cautious of what is meant by sensing that we have sensed, since sensation is itself an appearance, which, presumably, one would be aware of. But these appearances are connected together into a single experience by memory. As Hobbes says in Leviathan, “much memory, or memory of many things, is called experience” (2.4). But phenomenal awareness seems to be a property of sensation itself, for Hobbes. Hobbes resists the implication of a higher-order account of consciousness in his objections to Descartes’s Mediations (cf. CSM II, 122–123 / AT VII 173; for discussion of the relation of Hobbes and Descartes on the topic of consciousness, see Ross 1988).

4.2 The Cambridge Platonists
The shifting use of conscientia has here been traced through the Cartesian line. However, a largely independent line developed through the Cambridge Platonists (as is argued in Thiel 1991), and in particular in the writings of Ralph Cudworth.

Cudworth developed his theory by reflecting on Plotinus’s Enneads, where Plotinus makes use of the Greek term synaisthesis (literally: “sensed with”) to distinguish lower natures from higher. Cudworth translates this into English as “con-sense” or “consciousness” (True Intellectual System 159). It is by working out a particularly Platonic metaphysical theory that Cudworth develops his account of consciousness.

Cudworth, along with other Cambridge Platonists, argued for “plastic natures,” which are immaterial sources of action in the world. These plastic natures are similar to minds or souls, but, pace Descartes, Cudworth allowed that there are non-conscious thoughts and non-conscious plastic natures. Against Descartes’s argument that all mental states are conscious, Cudworth argues as follows (True Intellectual System 160):

Suppose, for reductio, that “cogitation” (or thought) is the essence of the soul.
The essence of thought is consciousness (granted by both Cudworth and Descartes).
The souls of men are sometimes in a deep, dreamless sleep (i.e., without consciousness).
So, by (1) through (3), the souls of men sometimes cease to exist.
But (4) is absurd.
And so, (1) should be rejected: the essence of the soul is not thought.
And so there is much in the soul (and especially in other principles of life) that we know nothing about and cannot account for mechanically (ibid). Unlike Spinoza and Leibniz (below), Cudworth does not have the same interest in articulating a “natural” account of consciousness or mental activity, since the plastic natures themselves are sources of divine activity and providence.

Nevertheless, the role consciousness plays in Cudworth’s system is a similar awareness of one’s own thought that is distinct from the moral conscience. While consciousness does contain a reference to the subject of thought, for Cudworth, it does not do so immediately or explicitly. It takes a distinct act of reflection in order to provide the sort of self-reference necessary for making moral judgments about one’s own actions (Thiel 1991 92–24). (For more on Cudworth’s account of consciousness, see Thiel 1991 and Lähteenmäki 2010.)

4.3 Locke
John Locke famously makes use of consciousness in his theory of personal identity, separating personal identity from identity of substance or identity of matter. This is a purely psychological account of identity, which has implications for judgments of moral responsibility (which Locke does develop), but consciousness itself is not to be equated with the moral sensibility.

Locke’s definition of “person” contains in it a definition of consciousness:

[A person] is a thinking intelligent Being, that has reason and reflection, and can consider it self as it self, the same thinking thing in different times and places; which it does only by that consciousness, which is inseparable from thinking, and as it seems to me essential to it: It being impossible for any one to perceive, without perceiving, that he does perceive. (Essay 2.27.9)

Here again we find commitments to the transparency of the mental and connections between consciousness and reflection. The identification of consciousness with “perceiving that [one] does perceive” raises again the specter of the higher-order interpretation.[13] But there are good reasons to think that a higher-order theory won’t work for Locke (see Coventry and Kriegel 2008 and Weinberg 2008). In just about every section of this entry, we have encountered someone as interpreting the relevant philosopher as a higher-order theorist. But repeatedly this suggestion is countered explicitly by the philosopher himself or implicitly by an obvious incoherence with other basic principles. One might hope that the frequent objections in the literature will put an end to such speculations.[14] While expressions of accounts of consciousness in the seventeenth century might sound a lot like today’s higher-order theories of consciousness, there are almost always alternative ways of construing the accounts that are more faithful to what’s going on at the time.

Rather, in Locke’s case, it seems that the analysis of consciousness allows only the inference that thoughts are self-intimating. “When we see, hear, smell, taste, feel, meditate, or will any thing, we know that we do so” (2.27.9). And yet there has been a long history arguing that Locke equates consciousness and reflection (for this history of this interpretation, see Kulstad 84–85). Of course, even if Locke’s account of consciousness necessarily involves reflection, we have seen that this doesn’t immediately entail a higher-order theory. But, as Mark Kulstad argues, there is good reason to think that Locke distinguishes consciousness from reflection. One can be conscious of something (namely, a sensible quality) without thereby reflecting on it (Kulstad 87–91).[15]

Further, like Descartes, Locke argues that this is the essence of thought—one can’t have a thought without “being conscious of it” (2.1.19). However, he will extend this idea only as far as experience will allow—it is not at all clear to him that “the soul always thinks,” since we often fail to have conscious experience while asleep. And so, as Locke says, “every drowsy nod shakes their doctrine, who teach that the soul is always thinking” (2.1.13; see 2.1.10–20 for the full argument). This argument resembles that offered by Cudworth, and, like Cudworth, Locke will conclude that thinking is not the essence of the soul. The soul can persist through a state in which there is no thinking—this is the beginning of his separation of the underlying substance from its psychological states. The consciousness of an individual bears no necessary relation to the substance it inheres in, and so the substance contributes nothing to the identity of the individual.

Shelley Weinberg has argued for an interpretation of Locke’s theory of consciousness that she thinks solves many of the most pressing problems of interpretation. According to Weinberg, for Locke,

Consciousness is self-consciousness. It is a non-evaluative self-referential form of awareness internal to all perceptions of ideas. It is the perception that I am perceiving an idea, or the perception of myself as perceiving an idea. (xi)

She takes Locke’s account to entail that every act of perception is a complex state involving “at the very least, an act of perception, an idea perceived, and consciousness (that I am perceiving)” (xi). Her defense of this view shows how such an account of consciousness helps make sense of Locke’s claims about the knowledge of one’s own existence, the knowledge of external objects, personal identity, and moral agency (Weinberg 2016).

5. Leibniz
Returning to the Continent, we find that Leibniz may be the first philosopher we’ll encounter that can properly be said to have a theory of consciousness. Leibniz is one of the first philosophers to make it very explicit that he is trying to work out an analysis for this new psychological account of consciousness. He even invents a new word for the concept: apperception, a nominalization of the French verb s’apercevoir de, to perceive. And along with this new term, he develops a theory of consciousness that he intends to be fully naturalized, which, in part, means that there are no unexplained gaps in the analysis that require recourse to brute explanation or miracle.

Further, Leibniz is one of the first to provide a theoretical grounding for non-conscious mental states, in contrast to the Cartesians we discussed above who defined thought in terms of consciousness. As Leibniz says,

[I]t is good to distinguish between perception, which is the internal state of the monad [i.e., simple substance] representing external things, and apperception, which is consciousness, or the reflective knowledge of this internal state, something not given to all souls, nor at all times to a given soul. Moreover, it is because they lack this distinction that the Cartesians have failed, disregarding the perceptions that we do not apperceive, in the same way that people disregard imperceptible bodies. This is also what leads the same Cartesians to believe that only minds are monads, that there are no souls in beasts, still less other principles of life. (“Principles of Nature and Grace” §4, AG 208)

Thus, Leibniz thinks he has diagnosed a significant error in the Cartesian philosophical system, and he has the solution in his account of consciousness. A couple of things stand out immediately from this passage, which connect to our discussion above:

Leibniz’s theory of mind is a representational theory of mind. Perception is not understood in terms of awareness, but rather in terms of the substance’s “representing external things.”
Some, but not all, “souls” are conscious.
And those souls that are conscious can transition between conscious and non-conscious states. Indeed, as he argues elsewhere, there must be infinitely many petites perceptions in each mind of which they are unaware, even while they are conscious of some things. (See the preface to the New Essays.)
Minds or mind-like substances are found throughout nature (in humans, animals, and other “principles of life”). But their fundamental properties are the same: they are by nature representational.
So, like Spinoza, Leibniz will have to provide a theory of consciousness in terms of representations, and, perhaps unlike Spinoza, he will have to demonstrate how this theory allows for transitions from conscious to non-conscious states. If he can do this, then, he thinks, his theory of mind will avoid many of the problems plaguing the Cartesian theory of mind. Further, he thinks it will be a fully natural theory, one that will open up a new science of the mind, which he calls pneumatology (cf. RB 56; the name pneumatology obviously didn’t catch on, but the science Leibniz envisioned would probably overlap significantly with today’s cognitive sciences).[16]

So, then, what was the account of consciousness Leibniz had to offer? Some have picked up on what Leibniz says in the quotation above (“…apperception, which is consciousness, or the reflective knowledge of this internal state”) and argue that consciousness, for Leibniz, is a matter of reflection. And, as we have seen, this is a popular option during the seventeenth century, but it is also an option for which it is not always clear what the underlying structure would be. Does reflection require a distinct second-order perception that takes the first-order perception as its object? Or is it rather like Arnauld’s suggestion of a virtual reflection (in contrast to an explicit reflection)? Many scholars believe that Leibniz is arguing for higher-order theory of consciousness, where consciousness is constituted by a first-order perception and a distinct higher-order perception. (For this sort of an interpretation of Leibniz’s theory of consciousness, see Kulstad 1990, Gennaro 1999, and Simmons 2001.)

In fact, Leibniz’s purported analysis of consciousness in terms of reflection isn’t entirely clear. If Leibniz is arguing that a perception becomes a conscious perception when it is accompanied by a second-order perception, then Leibniz has a philosophical problem. Margaret Wilson’s argument against Curley’s similar analysis of Spinoza’s theory of consciousness above applies even better to Leibniz. Leibniz’s theory of mind entails that every mind represents the universe (the “universal expression” thesis), which would always necessarily include a self-expression. All minds would have higher-order perceptions of themselves and their mental states, undermining Leibniz’s ability to distinguish among conscious/non-conscious substances or conscious/non-conscious perceptions within a single substance. All substances would be conscious, and all mental states would be conscious mental states. (For a development of these criticisms as well as an argument that a higher-order theory of consciousness would violate one of Leibniz’s basic metaphysical theses, see Jorgensen 2009. For a possible response (but not decisive) to some of these objections, see Jorgensen 2011a.)

Of course, it may be that Leibniz simply didn’t see this implication and so he held an incoherent theory of consciousness. But there is another candidate theory in the near neighborhood. Consider what Leibniz says about simple substances (or, as he calls them, “monads”) in the following passage:

[S]ince the nature of the monad is representative, nothing can limit it to represent only a part of things. However, it is true that this representation is only confused as to the detail of the whole universe, and can only be distinct for a small portion of things, that is, either for those that are closest, or for those that are greatest with respect to each monad, otherwise each monad would be a divinity. Monads are limited, not as to their objects, but with respect to the modifications of their knowledge of them. Monads all go confusedly to infinity, to the whole; but they are limited and differentiated by the degrees of their distinct perceptions. (“Monadology,” §60, AG 220–221)

Leibniz here starts by articulating the universal expression thesis—all simple substances represent “the whole.” What distinguishes them from one another is the relative “degrees of their distinct perceptions,” which track the things that “are closest, or…greatest with respect to each monad.” Combining what Leibniz says here with other similar texts, we see Leibniz articulating a broadly functional account of consciousness. Consciousness is a function of perceptual distinctness, which itself is a function of how things are represented in the individual monad.

To see how perceptual distinctness arises from a variety of representations, Leibniz provides his famous example of the sound of the ocean:

To give a clearer idea of these minute perceptions which we are unable to pick out from the crowd, I like to use the example of the roaring noise of the sea which impresses itself on us when we are standing on the shore. To hear this noise as we do, we must hear the parts which make up this whole, that is the noise of each wave, although each of these little noises makes itself known only when combined confusedly with all the others, and would not be noticed if the wave which made it were by itself. (RB 54)

Each tiny wave sound impresses itself on our sensory organs and are then combined into a more noticeable sound, one that will stand out from the rest of the background representations of the world. “Noticeable perceptions,” Leibniz says, “arise by degrees from ones which are too minute to be noticed” (RB 57).

The way in which distinct perceptions arise depends on the functional organization of the body. In the “Principles of Nature and Grace,” Leibniz says that when a simple substance has a body with “organs that are adjusted in such a way that, through them, there is contrast and distinction among the impressions they receive, and consequently contrast and distinction in the perceptions that represent them…then this may amount to sensation…” (AG 208). The contrast in noticeable perceptions arises because of the function of the body “confusing” (that is, fusing together) the representations of the external world in such a way that they become more distinctive. So, although they are confused, these perceptions stand out against the perceptual background—they are confused and distinct. When and how this occurs will depend on a variety of factors, including the ability and sophistication of the sense organs, the disposition of the individual, etc. Additionally, this will be a matter of degree—certain representations will stand out more than others. And so, for Leibniz, consciousness itself will be a matter of degree.[17]

However, in order for Leibniz to account for transitions in consciousness (whether it’s a mind becoming conscious or whether it is a transition in a mind becoming conscious of a particular object) it cannot be the case that just any degree of perceptual distinctness results in consciousness. Rather, Leibniz’s theory of consciousness appears to entail that there is a certain minimal threshold at which consciousness arises. And this threshold might itself be sensitive to context and the status of the mind—things that I’ll notice when I’m wide awake will go unnoticed when I’m in a sound sleep. Here is one example that Leibniz provides, along with his explanation:

[T]here are hundreds of indications leading us to conclude that at every moment there is in us an infinity of perceptions, unaccompanied by awareness [apperception] or reflection; that is, of alterations in the soul itself, of which we are unaware because these impressions are either too minute and too numerous, or else too unvarying, so that they are not sufficiently distinctive on their own. But when they are combined with others they do nevertheless have their effect and make themselves felt, at least confusedly, within the whole. This is how we become so accustomed to the motion of a mill or a waterfall, after living beside it for awhile, that we pay not heed to it. Not that this motion ceases to strike on our sense-organs, or that something corresponding to it does not still occur in the soul because of the harmony between the soul and the body; but these impressions in the soul and the body, lacking the appeal of novelty, are not forceful enough to attract our attention and our memory, which are applied only to more compelling objects. (RB 53–54)

Note that Leibniz here reaffirms that we are aware only of the perceptions that are “sufficiently distinctive” or are “forceful enough.” This suggests a certain level of perceptual distinctness or force that will “make themselves felt.” As in the case of the mill—you move in next door to the mill and can’t sleep because of the noise. But, over time, you become accustomed to the sound of the mill and no longer notice it. It is this sort of phenomenological fact, which we can all recognize, that Leibniz thinks he can explain in terms of the variations in perceptual distinctness. It’s not, as he says, that the noise no longer affects our sensory organs—the noise continues to be registered internally, but there is something about the lack of novelty that results in a transition in consciousness. We no longer notice the noise (or, at the very least, we don’t notice it nearly as much). What explains this? Leibniz thinks he can give a natural explanation of this in terms of the forcefulness of the impression. Somehow it becomes less forceful over time. (How does it do this? Leibniz doesn’t give us a full account here. This is where he thinks we will see the promise of his theory and then investigate the causes.)[18]

Thus, Leibniz may be seen as providing a fully naturalized philosophy of mind in which he advocates for a threshold theory of consciousness. This is a same-order theory of consciousness—for Leibniz, a conscious perception is a distinct perception. That is, at some level of distinctness, the perception stands out sufficiently to be noticed. All perceiving substances have perceptions that have some degree of distinctness, but not all perceiving substances have distinct perceptions. Rather, it requires some threshold degree of distinctness (relative to context) for a perception to be distinct. (For a full account of this position, see ch. 7 of Jorgensen 2019.)

Leibniz never uses the term “threshold” when discussing consciousness, but his examples all appeal to thresholds in one way or another. He says later in the New Essays:

I…prefer to distinguish between perception and being aware [apperception]. For instance, a perception of light or color of which we are aware is made up of many minute perceptions of which we are unaware; and a noise which we perceive but do not attend to is brought within reach of our awareness by a tiny increase or addition. (134)

Thus, at some level the noise will be noticed. Leibniz is silent on precisely how this threshold is determined. Although he frequently claims that differences in kind (although continuous with other kinds) arise at the infinite or the infinitesimal, this is in tension with many of the phenomena of consciousness which apparently arise at some mid-level degree of perceptual distinctness (as with the description of the difference between a conscious perception of light and an unconscious perception of light above). Here is another area where Leibniz is offering a theory and is optimistic that the relevant natural factors determining the threshold will be discovered in the science of pneumatology (and, indeed, cognitive science has made some progress in this direction).

But the overall transition has been made. The initial transition from a morally-laden concept to a fully psychological concept was made with Descartes and the Cambridge Platonists. And here, through the Cartesians and in Leibniz, we see an attempt to clarify the concept and to provide a coherent analysis of the concept. Leibniz’s account (and Spinoza’s account, insofar as he has one) treats consciousness as a natural phenomenon to be explained in natural ways, and so he endeavors to explain consciousness in terms of the underlying mental representations. This has obvious connections to representational and functional accounts of consciousness that continue to this day.

(For more on the topic of consciousness in Leibniz, see Barth 2011; Bolton 2011; de Gaudemar 2004; Furth 1967; Jorgensen 2009, 2011a, and 2011b; Kulstad 1990; Thiel 2011 (section 3 of chapter 9); and Simmons 2001 and 2011.)

1. Historical Background
It is unsurprising that early western feminists should have regarded embodiment with suspicion, choosing instead to stress the rational powers of the female mind; for as François Poullain de la Barre famously claimed in 1673, “the mind has no sex” (1673 [1990: 87]). For some early feminists, this meant enthusiastically endorsing a dualism between mind and body, with bodily features regarded as contingent characteristics of the self, and the potentially rational mind as its core. For them, as indeed for later feminists, it was essential to break any suggested deterministic link between corporeal characteristics, mental faculties and social role. Reason, they mostly claimed, was a universal human capacity independent of corporeal differences (Wollstonecraft, Mill and Taylor Mill). There were additional reasons for early feminists such as Wollstonecraft in the eighteenth century and Taylor Mill in the nineteenth, to regard their bodies with suspicion. In the context in which they lived as middle class women, their bodies were commodities to be preened and maintained, to enable them to entice men into matrimony so that they would have the material means to live. Women’s attention to their bodies therefore took the form of producing them as objects for others’ appraisal, and the dangers which Wollstonecraft saw in this have been echoed in feminist work up to the present day. Wollstonecraft’s 1792 text, A Vindication of the Rights of Woman, provides, as Bordo (1993) notes, a clear example of the disciplining of the female body as we, post-Foucault, would now describe it.

To preserve personal beauty, woman’s glory! The limbs and faculties are cramped with worse than Chinese bands, and the sedentary life which they are condemned to live, whilst boys frolic in the open air, weakens the muscles … artificial notions of beauty, and false descriptions of sensibility have been early entangled with her motives of action. (Wollstonecraft 1792 [1988: 55])

The body was also a source of vulnerability. Mill and Taylor Mill were preoccupied with the way their susceptibility to illness interrupted their ability to produce philosophical work and cast the shadow of early death over their life plans. Moreover, any celebration of the female body as source of sensual pleasure was constrained by a risk of pregnancy.

The body also came to prominence in nineteenth century feminism in Britain through the campaign led by Josephine Butler against the Contagious Diseases Act (Jordan 2001). This act permitted women to be forcibly examined for venereal disease. Butler extended ideas of individual rights, prominent within liberal political philosophy, to rights over one’s body. The campaign of inspection was viewed as a particularly outrageous violation of such rights and the women were perceived as victims of male and medical appropriation of their bodies. Here we find the beginnings of arguments picked up later in campaigns against rape and sexual violence, as well as in campaigns for access to birth control and abortion, and in the feminist health movement – all of which stress women’s rights to control what happens to their bodies. This absence of control found its most extreme example in the case of the bodies of slave women, where the body became literally the property of another, disciplined in a way that bore a marked contrast to that articulated by Wollstonecraft.

Her back and her muscle … pressed into field labour where she was forced to … work like men. Her hands were demanded to nurse and nurture the white man and his family … . Her vagina used for his sexual pleasure … the womb … the place of capital investment … the resulting child the … surplus worth money on the slave market. (Omolade 1983: 354)

In the nineteenth and early twentieth century the campaign for women’s suffrage dominated feminist activity in the west. The Seneca Falls Convention Statement does not mention the body, but Sojourner Truth’s famous speech to the Ohio Women’s Convention drew attention to the body as a marker of race and class differences within the feminist movement:

I have as much muscle as any man, and can do as much work as any man. I have ploughed, and planted, and gathered into barns, and no man could head me! And ain’t I a woman? I could work as much and eat as much as a man—when I could get it—and bear de lash a well! And ain’t I a woman? (Truth 1851 [1881: 116]).

Moreover, in the writings of Cady Stanton we find a recognition of the way bodily markers are used to perpetuate both racial and sexual oppression:

The prejudice against color, of which we hear so much, is no stronger than that against sex. It is produced by the same cause, and manifested very much in the same way. The negro’s skin and the woman’s sex are both prima facie evidence that they were intended to be in subjection to the white Saxon man. (Stanton 1860 [1881: 681])

Following the first world war and the granting of suffrage in many countries, women continued to campaign on issues of sexual equality, and control over their bodies. The issue of reproduction came to the fore in political philosophies of the right and left. On the political right, following the loss of life in the war, motherhood became a concern of the state and a public duty. Moreover, increasing concerns with eugenics and racial purity led to a desire to control the reproduction of certain groups within society. At the same time, within United Kingdom feminist circles, the Abortion Reform Association was formed and echoed both earlier and later feminist demands for the right of every woman to decide what should happen to her body. But an implicit dualism remained. The body was seen as something owned by, and thereby separate from, the self, something over which the self had rights.

Nonetheless, in the early twentieth century, with the emergence of psychoanalysis, came a different model of our relationship to our body, which was to become crucial to later feminist philosophers. For Freud the ego, the conscious sense of self, was a bodily ego: “the ego is first and foremost a bodily ego” (Freud 1923 [1962: 26]). This means that our sense of self is a sense of a body, and involves an awareness of that body as having a certain shape or form. Significantly, the shape or form we experience our body as having is not dictated simply by anatomy, but by the affective and sensory significance with which different parts are invested (Freud 1923). Certain aspects of the body have a salience, and other anatomical parts do not show up, unless painful, in the sense of our body which constitutes our sense of self (the insides of the body, perhaps the back of the knees). Some parts are more significant than others, linked to experiences of pleasure and pain, for example, or to the possibility of effective agency (the hands), to relations with others (the face). This insight of Freud and others (Schilder), informed much of the critical theorizing around the body which followed.

2. The Second Sex
It was, however, with the publication of The Second Sex by Simone De Beauvoir, that feminist theorizing about the relation between the body and the self took center stage. Along with other phenomenologists, particularly Merleau-Ponty, and Sartre, Beauvoir recognizes that “to be present in the world implies strictly that there exists a body which is at once a material thing in the world and a point of view towards the world” (Beauvoir 1949 [1982: 39]). The self, for phenomenologists, as for Freud, is necessarily corporeal, the body constitutes the self. It is not a separate entity to which the self stands in relation. This body, however, is not simply what biology offers us an account of. The body which gained their attention was the body as lived, as yielding the sensory experiences and lived intentionality of a subject negotiating its world. It is also a body which is encountered by others whose response to it mediates our own sense of being. What is central to Beauvoir’s account is that such bodily existence, the point of view it provides, and the response it garners, is different for men and women. Her account provides a complex and non-reductive picture of the intertwining of the material and the cultural in the formation of our embodied selves (see the entry on Simone de Beauvoir, Kruks 2010, Sandford 2006, Moi 1999).

2.1 The Data of Biology
In the first chapter of The Second Sex Beauvoir reviews the data of biology. But she does so with a warning. Such data are not to be thought of as determining individual characteristics or social life. With that warning she goes on to describe what are claimed as biological characteristics of the female qua animal or organism which, in addition to differences in reproductive role, includes claims that “woman is weaker than man, she has less muscular strength, … can lift less heavy weights” (1949 [1982: 66]). She rehearses these “facts” while also declaring that “in themselves [such facts] have no significance” (1949 [1982: 66]). This is because “it is only in a human perspective that we can compare the female and the male of the human species”, and from this human perspective “the physiological facts … take on meaning, this meaning … dependent on a whole context” (1949 [1982: 66]). So, for example, in relation to “the burden imposed on women by her reproductive function … society alone is the arbiter” (1949 [1982: 67]).

Such remarks have led to Beauvoir being regarded as an originator of the sex/gender dichotomy, which became pivotal to feminist theorizing in the 1970s (see the entry: feminist perspectives on sex and gender). Standardly sex was seen as fixed by biology, and gender, as the social meanings attached to such biology, seen as historically and socially variable, and open to change. It is in this context that Beauvoir’s famous claim that “One is not born, but rather becomes, a woman”, is consistently quoted (1949 [1982: 295]). Nonetheless Beauvoir’s own position does not map onto this sex/gender distinction in a straightforward way (Sandford 2006, Lennon and Alsop 2019, cp 4). For her the data of biology, offered as facts, lack the fixity which later accounts sometimes took for granted. She shows herself aware of the way in which cultural myths and metaphors influence the telling of the biological story, even as she herself offers it to us. In pointing out the ideological influence on the descriptions of the active sperm and the passive egg (1949 [1982: 44]) she anticipates the work of later writers (Martin 1987). Moreover, she shows herself consistently aware of the possibilities which the biological data leave open to us, stressing alternatives to heterosexual reproduction throughout the biological realm, the incidence of hermaphrodism in human and other animals, and drawing attention, in the animal kingdom, to cases where care of the eggs and the young is done by both male and female animals. The consequence is that not even the biology of sexual difference is determined.

It is only through existence that the facts are manifest … and nothing requires that this body have this or that particular structure … the perpetuation of the species does not necessitate sexual differentiation … [while] it remains true that both a mind without a body and an immortal man are strictly inconceivable … we can imagine a parthenogenetic or hermaphroditic society. (1949 [1982: 390], my emphasis)

On the other hand, the meanings and significance which we attach to our materiality do not float free of that materiality. The way the body is lived by us has to accommodate the data which biology variably tries to capture, including facts of reproduction, menstruation and menopause. “Sex” for Beauvoir was not, then, a biological category. It is, as Sandford (2006) points out, an existential one. And in exploring what constituted existing as a woman, biological data was just one of the constituents.

2.2 Living the Female Body
In later chapters Beauvoir provides a phenomenology of the body as lived throughout the different stages of a woman’s life. Here she is explicitly offering her narrative as an account of lived experience, the body in situation. In childhood the young girl’s body is experienced in a different way from that of the young boy. She is trained into a different way of inhabiting it. He is encouraged to climb trees and play rough games. She is encouraged to treat her whole person as a doll, “a passive object … an inert given object” (1949 [1982: 306–307]). The consequence is an inhibited intentionality, her spontaneous movements inhibited, “the exuberance of life … restrained” (1949 [1982: 323]), “lack of physical power” leading to a “general timidity” (1949 [1982: 355]). The account which Beauvoir is offering here is one in which girls undergo something like a training in bodily habits which structure the possibilities for interaction with their world.

As the girl enters puberty, Beauvoir notes, her body becomes to her a source of horror and shame. “This new growth in her armpits transforms her into a kind of animal or algae” (1949 [1982: 333]), her menstrual blood a source of disgust. These negative descriptions are continued for sexual initiation, marriage, and motherhood. Her phenomenology of the maternal body has been especially controversial:

ensnared by nature the pregnant women is plant and animal … an incubator, a conscious and free individual who has become life’s passive instrument … not so much mothers … as fertile organisms, like fowls with high egg production. (1949 [1982: 513])

These accounts have been a source of criticism, particularly when later feminists sought to celebrate the female body as a source of pleasure, fertility, and empowerment (see below). However, it is important to recognize that what she was offering was a descriptive phenomenology of female bodies as lived in specific situations. She was describing a particular set of experiences at a specific social and historical point. As she explicitly says:

if the biological condition of women does constitute a handicap, it is because of her general situation …. It is in a total situation which leaves her few outlets that her peculiarities take on their importance. (1949 [1982: 356–357])

It is this situation which her writings aimed to highlight and change.

2.3 The Body and Others
The way in which the young girl and then the woman experiences her body is, for Beauvoir, a consequence of a process of internalizing the view of it under the gaze of others.

Through compliments and admonishments, through images and words, she discovers the meaning of the words pretty and ugly; she soon knows that to be pleased is to be pretty as a picture; she tries to resemble an image, she disguises herself, she looks at herself in the mirror, she compares herself to princesses and fairies from tales. (1949 [2010: 304])

Here is the beginning of the way in which women live their bodies as objects for another’s gaze, something which has its origin not in anatomy but in “education and surroundings” (1949 [2010: 304]). Beauvoir’s account of the way in which women live their bodies in such an objectified way, internalizing the gaze and producing their bodies as objects for others, has been one of her most important contributions to a phenomenology of female embodiment, anticipating and influencing the work of later feminists such as Bartky and Young (see below sections 5.1 and 7.1) .

Beauvoir’s phenomenology of women’s experience was also, itself, influential on, and in conversation with, philosophers theorizing raced embodiment. The phenomenological writer Franz Fanon (Black Skins White Masks, 1952 [1968]) describes how, on his arrival in France, he discovers his blackness:

I discovered myself as an object among other objects…the other fixes me, just like a dye is used to fix a chemical solution….It is not a question of the Black being black anymore, but rather of his being Black opposite the White…we came to have to confront the white gaze …. I was all at once responsible for my body, responsible for my race, for my ancestors. I ran an objective gaze over myself, discovering my blackness, my ethnic characteristics and then I was deafened by cannibalism, intellectual deficiency fetishism, racial defects, slave ships, and above all, above all else, “Sho good Banana”. (1952 [1968: 185–186])

Later theorists have, however, pointed out that in offering her own account, Beauvoir herself failed to recognize the way in which both race and gender intersect in providing a phenomenology of lived corporeality (Gines 2017; see the discussion of intersectionality in section 4 below).

3. Sexual Difference
The descriptions which Beauvoir offers us of the female body as lived, are in marked contrast to the valorization of that body we find in the writings of sexual difference theorists: “What is at stake in the debate … is the positive project of turning difference into a strength, of affirming its positivity” (Braidotti 1994: 187). Engagement with female embodiment, the goal of which is to give positive accounts thereof, are found in two different strands of feminist thought: Anglo-American radical feminism (particularly in the late 1970s and 80s) and psychoanalytic feminism, drawing on the work of Freud and Lacan. Sexual difference theorists, whether working from a radical feminist tradition or from a psychoanalytic feminist tradition, insist on the specificity of female embodiment, a horizon which becomes invisible when the male is taken as the norm of the human. For many of these theorists sexual difference is fundamental and immutable. Braidotti claims “being a woman is always already there as the ontological precondition for my existential becoming as a subject” (1994: 187).

3.1 Radical Feminism
There are some controversies over exactly what is to be termed radical feminism. As used here the term refers to feminists who stress essential or very deep rooted differences between men and women, and who celebrate the distinctive modes of embodiment and experiential capacities that women have. Radical feminists were/are centrally involved in highlighting sexual violence against women globally, which they sometimes see as rooted in male nature, or deep processes of socialization. Despite Shulamith Firestone’s (1970 [1979]; Merck and Sandford 2010) early visions of liberating women from reproductive tasks, within most Anglo-American radical feminism, both female sexuality and the female capacity to give birth are seen as grounds for affirming the power and the value of the female body. Female sexuality is celebrated for its power and its supposed capacity to escape from structures of dominance and submission (Rich 1979). Women’s maternal bodies are seen as a source of positive values to set against male norms, stressing care and inter-subjectivity, as opposed to autonomy and duty (Rich 1979, Ruddick 1989). Women’s engagement with the reproductive process is also regarded as anchoring both anti-militarism and a respect for the natural world, which puts them at the forefront of peace and ecological movements (Griffin 1978). Reproduction and women’s caring roles also set them against the widespread violence of men. These approaches are very significant for giving women’s bodies a positive value which induces pride rather than shame. However, such approaches also suffer from the dangers of homogenizing what are very variable experiences, both of sexuality and maternity. As Grimshaw points out, for women, childbearing has been seen “both as the source of … greatest joy and as the root of their worst suffering” (1986: 73). Moreover, women themselves engage in military professions, and can themselves be violent in private and public space. Claims celebrating female embodiment therefore need to heed Beauvoir’s insistence that the experience of embodiment is a product of situation.

3.2 This Sex Which is Not One
In the work of Irigaray, (1975, 1977, 1993), we find a sustained critique of the masculinist presuppositions embedded in philosophy and psychoanalysis. Irigaray points out that in these bodies of work “man” is presented as the universal norm, and sexual difference is not recognized, or is recognized in such a way that woman is conceptualized as the “maternal-feminine”, which has been left behind in the move to abstract thought. Such a critique insists on the recognition of sexual difference and the difference that female corporeality can make to the shape thought can take. She makes here what may seem like a rather startling claim: namely that the morphology of the body is reflected in the morphology of certain thought processes. So, for example, western rationality is marked by principles of identity, non-contradiction, binarism, atomism and determinate individuation. She sees this as: “the one of form, of the individual, of the (male) sex organ”. In contrast: “the contact of at least two (lips) keeps woman in touch with herself” (1977 [1985: 79]), and suggests an ambiguity of individuation, a fluidity and mobility, a rejection of stable forms.

Such claims have been interpreted by some as suggesting that Irigaray is a biological essentialist, that she sees the biology of male and female bodies as yielding (potentially) different patterns of thought, and that she is insisting that the thinking and writing which is expressive of women’s bodies should be made visible. In contrast to such a reading however, is Irigaray’s own insistence on the impossibility of returning to a body outside of its representation within culture. This makes evident that the bodily features which she invokes in her writings are not brute materialities, but (as is perhaps made clearest in Whitford 1991) bodies as they feature in the interconnected symbolic and imaginary of western culture (1991: chapter 3). When Irigaray refers to male and female bodily characteristics she is, according to Whitford, capturing the way she finds these features both represented and imagined, that is, affectively experienced, in the personal and social domain. She argues for the need to reconstruct an inter-connected imaginary and symbolic of the female body which is liveable and positive for women. Whitford suggests this is not an essentialist task of providing an accurate description of women’s bodies as they really are. It is a creative one in which the female body is lovingly re-imagined and rearticulated to enable women to both feel and think differently about their embodied form. Irigaray’s attention to the imaginary body is, however, informed by a respect for a materiality, a nature, which although open to multiple modes of disclosure, offers us two kinds of sexed bodies, to which our imaginary significations remain answerable.

Irigaray herself considers how philosophical and psychoanalytic thinking would be different if we took a re-imagined female or maternal body as its starting point instead of the male body, imagined in phallic terms. Such work has been continued in the writings of, for example, Battersby (1998), Cavarero (1995) and Alison Stone (2011). Battersby explores “what happens to the notion of identity if we treat the embodied female as the norm for models of the self” (1998: 38). Natality challenges a fixed conception of identity, makes evident that self and non-self are not in opposition, and that identity “erupts from the flesh” (1998: 39). For Cavarero the lack of attention paid to the fact that we are born from woman has given western metaphysics a preoccupation with death rather than birth. Stone (2011) explores the maternal body to suggest models of subjectivity of a new kind, immersed in relations of intimacy and dependence. Stone “analyses this form of subjectivity in terms of how the mother typically reproduces with her child her history of bodily relations with her own mother, leading to a distinctive maternal and cyclical form of lived time” (2011: Jacket).

4. Intersectionality
Both the foundational status and the inevitability of sexual difference have become key points of contention between sexual difference theorists and intersectional theorists whose work is anchored particularly in black feminist thought (Crenshaw 2019, Hill Collins and Bilge 2016), but also in contributions from theorists of bodily abilities and trans theorists (Garland-Thomson 2002, Bettcher and Garry 2009, Koyama 2006). These theorists challenge the priority of sexual difference in accounts of embodied subjectivity, and interrogate the possibility of providing generic accounts of what such difference consists in. What counts as being a man or a woman, what life opportunities result from gendered positionality, and how these factors are internalized to form our lived experience of being gendered, is mediated by the other categories which intersect with gendered ones. Being a “black man/woman”, or “gay man/woman”, or “trans man/woman” (themselves categories which also mediate each other and are mediated further by, for example, nationality, religion, age, class and our positioning on the ability/disability axis), each has a different content from being a “white, straight, middleclass, cis gendered, able bodied woman or man”. The normative ideals attached to the concepts are different, though also overlapping. These positionalities have consequences for our life opportunities both economically and in the wider social realm, which the structural data make evident. And all of this has consequences for our lived subjectivity, how we experience our bodies, our sense of ourselves as male or female, amongst other identifiers.

Black feminist critiques challenge the racism of mainstream white feminist thought for theorizing womanhood from the perspective of white women thereby rendering the particular experiences of black and other groups of marginalized women invisible. Audre Lorde writes:

As a Black lesbian feminist comfortable with the many ingredients of my identity, and a woman committed to racial and sexual freedom of expression, I find I am constantly being encouraged to pluck out some aspect of myself and present this as a meaningful whole, eclipsing or denying the other parts of self. But this is a destructive and fragmenting way to live. (Lorde 1984)

Two centuries earlier Sojourner Truth, in her famous “Ain’t I a Woman” speech at Seneca Falls (see above) signalled the very different modes of embodiment for black slave women and white bourgeois women. The coining of the term intersectionality is often accredited to African-American civil rights advocate and feminist and critical race scholar, Kimberle Crenshaw (2019). As black women we do not experience racism AND sexism as separate discrete strands of oppression, Crenshaw argues, but instead racism and sexism intersect and combine to shape the lives, including the experiences of embodiment, of black women, in very specific ways. This is not a matter of adding on experiences of being raced to a foundational sexed identity. What constitutes being a woman is inter-articulated with being black, in ways that challenge the universalism of sexual difference theory.

Disability theorists from the 1990s onwards explored how disability affected the gendering process and gender the experiences and outcomes of differing bodily abilities (Mairs 1990, Thomas 1999). Feminist theory, as Garland-Thomson argues:

interrogates how subjects are multiply interpellated; in other words, how the representational systems of gender, race, ethnicity, ability, sexuality and class mutually construct, inflect and contradict one another. (2002: 3)

The status of the lived body, the politics of appearance, the medicalisation of the body, the privilege of normalcy (2002: 4)

all look different from the perspective of women regarded as disabled. And the relative privileges of normative femininity are often denied to these women. Such work by intersectional feminists challenges any foundational role, or universal articulation of, sexed difference itself.

5. Bodily Practices
5.1 Disciplining the Body
Feminist writers from Wollstonecraft onwards have drawn attention to the way in which society prescribes norms in relation to which subjects regulate their own bodies and those of others. Beauvoir’s account of this has been highlighted above. “Our bodies are trained, shaped and impressed with the prevailing historical forms of … masculinity and femininity” (Bordo 1993: 91). By regimes of dieting, makeup, exercise, dress, and cosmetic surgery, women, and increasingly men, try to sculpt their bodies into shapes which reflect the dominant societal norms. Such disciplinary practices attach not only to the production of appropriately gendered bodies, but to other aspects of bodily identity subject to social normalization. Hair straightening, blue tinted contact lenses, surgical reconstruction of noses and lips, are practices in which the material shapes of our bodies are disciplined to correspond to a social ideal, reflecting the privileged position which certain kinds of, usually, white, always able, always young, bodies occupy.

This became a major theme in 1970s feminist writing. Dworkin writes:

In our culture not one part of a woman’s body is left untouched, unaltered. … From head to toe, every feature of a woman’s face, every section of her body, is subject to modification. (1974: 113–114)

From the 1990s, feminist attention to the power relations working through such disciplinary practices has made extensive use of the work of Foucault (Foucault 1975, Bartky 1990, Bordo 1993). Foucauldian insights regarding disciplinary practices of the body are applied to the disciplining of the gendered, and most insistently the female, body. Such accounts stress the way in which women actively discipline their own bodies not only to avoid social punishments, but also to derive certain kinds of pleasure. There are two key features of such accounts. One stresses the way in which the material shape of bodies is modified by such practices. The second that such modifications are a consequence of bodies carrying social meanings, signalling within specific contexts, sexual desirability, or availability, or respectability, or participation in social groupings. With attention to the work of Foucault and other poststructuralist writers, also came the recognition that practices of bodily modification could have multiple meanings, with disagreements over responses to cosmetics, fashion and cosmetic surgery (Davis 1995, Alsop and Lennon 2018). It was against this background that Bordo (1993) developed her complex and influential reading of the anorexic body:

female slenderness … has a wide range of sometimes contradictory meanings … suggesting powerlessness … in one context, autonomy and freedom in the next. (1993: 26; see the Ethics of Embodiment, section 8, below)

5.2 Performativity
In the work of Butler (1990, 1993, 2004), the subjection of our bodies to such normalizing practices becomes viewed not only as a way in which already sexed bodies seek to approximate an ideal, but as the process whereby sexed subjects come into existence at all. Here Butler is following Beauvoir’s claim that we become differentiated as women and men, rather than being born as such. Since 1990 with the appearance of Gender Trouble, her performative account of gendered subjectivity has dominated feminist theory. Butler rejects the view that gender differences, with their accompanying presumptions of heterosexuality, have their origin in biological or natural differences. She explores, instead, how such a “naturalising trick” is pulled off; asking by what means a unity of biology, gendered identification, and heterosexuality comes to appear natural. Butler, like Foucault, views discourses as productive of the identities they appear to be describing. When a baby is born and the midwife says “it’s a girl” she is not reporting an already determinate state of affairs, but taking part in a practice which constitutes that state of affairs. The effect of repetition of acts of this kind is to make it appear that there are two distinct natures, male and female. These gendered performances are ones which we act out ourselves and which others act out in relation to us. They are acted out in accordance with social scripts prescribing ideals which are unrealizable, but which none the less provide the framework for our activities. These dominant ideals reinforce the power of certain groups; e.g., men and heterosexuals, over others. These others – women, gay people, trans and gender non-conforming people, those with differently abled bodies, or bodies differently shaped from the dominant ideal – are treated socially as outsiders, “the abject”, and subject to social punishments.

The performances by means of which our bodies become gendered vary in different contexts, and can change over time. Constituting myself as a caring mother, my performance would differ from that of a sexy pop star. Moreover, these practices are not independent of those which produce other aspects of our identity. Butler has stressed the way in which gendered performances incorporate a presumptive heterosexuality; but, as intersectional theorists have made clear, they also are co-constituted with class, race and national and cultural positioning, as well as age and a variety of forms of abilities and disabilities. In bodily acts manifesting gendered positionality, other social positions are carried along in such a way that it becomes impossible to disentangle a universally present strand of gender.

If gender becomes a matter of bodily style and performance, as this model suggests, then there is no necessary link between gender and any particular bodily shape. The alignment between anatomical shape and gendered performance is itself just a norm. Furthermore, this norm, along with others governing gendered performance, is open to destabilization and change. For Butler, same sex practices are one way of destabilizing the normative links of gender and heterosexuality. Various trans performances, in a parallel way, challenge the link of anatomical shape and gender. The trans community, problematised by sexual difference theory, therefore comes to occupy a central position for Butler. They are pivotal to the process of “queering” by means of which gender binaries, established by normalizing practices, are to be undermined and unravelled. So, for example, the television documentary, Pregnant Man by McDonald (2008), featuring a pregnant man who is referred to as a man and presented as a regular guy, works to undermine our binaries. What remains problematic about this, however, is that the effect of performance is unpredictable. Drag, for example, can support or dislodge gendered stereotypes and we cannot always sort out which any instance will produce. This make possibilities for reflective agency difficult to negotiate (McNay 2000).

5.3 Materialisation
For some commentators such a performative account of the formation of sexed bodies, fails to capture how the materiality of the body enters into our sense of self. In the preface to Bodies that Matter, Butler reports a common response to her work:

What about the materiality of the body, Judy? … an effort … to recall me to a bodily life that could not be theorized away … for surely bodies live and eat; eat and sleep; feel pain and pleasure; endure illness and violence; and these facts … cannot be dismissed as mere construction. (1993: ix)

Butler answers such questions by giving an account of the materiality of the body in terms of a process of materialisation. Here she is “calling into question the model of construction whereby the social unilaterally acts on the natural and invests it … with … meaning” (1993: 4). Instead she offers us a picture in which what we count as the material, as nature, as the given, is not something to which we have unmediated access. It is itself a product of particular modes of conceptualizing, modes which do not escape the workings of power. “Sex posited as prior to construction will, by virtue of being posited, become the effect of that very positing” (1993: 5). She concurs with the position of Spivak:

If one thinks of the body as such, there is no possible outline of the body as such. There are thinkings of the systematicity of the body, there are value codings of the body. The body, as such, cannot be thought, and I certainly cannot approach it. (Spivak 1989)

For Butler, we have to think of matter in terms of “a process of materialisation that stabilises over time to produce the effect of boundary, fixity … we call matter” (1993: 9). We cannot, then, ask questions about what limits are set by something outside of what we conceptualize. We can, however, explore the possibilities of conceptualizing otherwise. This does not mean that there is nothing outside of discourse. Butler makes clear that the body exceeds any attempt to capture it in discourse. It is just such excessiveness which allows the possibility of alternative formations of it, for the body outruns any of the ways we might have of thinking about it. But we cannot approach the extra-discursive except by exploring discursive possibilities.

6. Biology and the New Materialisms
Butler’s (1993) thinking together of the material and the discursive has, however, been criticized for not allowing the body more of a drag on signification (Alaimo and Hekman 2008; Lennon and Alsop 2019). Such a “flight from the material”, according to Alaimo and Hekman, has foreclosed attention to “lived material bodies and evolving corporeal practices” (2008: 3). To correct such a deficit, in the framework of what is termed the new materialism, what is stressed instead is that, although “language structures how we apprehend the ontological, it doesn’t constitute it” (2008: 98). The insight of the new materialist discussions has been to ensure that matter, the material, is accorded an active role in this relation.

For Grosz, there is:

an elision of the question of nature and of matter in Butler’s work. Mattering becomes more important than matter! Being “important”, having significance, having a place, mattering, is more important than matter, substance or materiality (interview with Ausch, Doane, and Perez 2000).

In Grosz’s own work such materiality is conceived of in terms of “active forces”. The body is involved in a process of active “becoming” which outruns any account which might be offered of it within culture. In the same interview she claims: “Nature is … is openness, resource, productivity”. Here the body is not simply a materiality which outruns any attempt to conceptualize it; it is actively involved in processes of change and transformation. Grosz’s recent work (1999 [2008]), exploring biology and its relationship to culture, shows an increasing interest in unravelling the nature/culture opposition by a stress on “the virtualities, the potentialities, within biological existence that enable cultural, social, and historical forces to work with and transform that existence” (1999 [2008: 24]). Returning to Darwin, she sees in his work “the genesis of the new from the play of repetition and difference within the old” (2008: 28). Nonetheless, she draws some problematic conclusions which are not endorsed by current feminist biologists (Fausto-Sterling 2000; Fine 2012, 2017). In embracing natural selection she appears to give it a foundational explanatory role so that

language, culture, intelligence, reason, imagination memory – terms commonly claimed as defining characteristics of the human and the cultural – are all equally effects of the same rigorous criteria of natural selection (Grosz 1999 [2008: 44]).

Moreover, within this process a binary sexual difference is required as “one of the ontological characteristics of life itself” (1999 [2008: 44]). And this sexual differentiation and the sexual selection with which, for her, it is interwoven, is then invoked to ground racial and other forms of bodily differences.

Grosz’s endorsement of a biology which renders the sexual binary unassailable, has been criticized for going beyond recognizing the importance of the material, to privilege a particular biological account of matter (Jagger 2015). The history of sex difference research shows that the biological theories giving an account of sex differences, are the products of particular historical and culturally specific moments of production. Such a recognition has allowed biological accounts of sex differences to be revisited with an eye as to where cultural assumptions about gender have influenced them. Of key importance in this regard has been the assumption that there are simply two sexes, male and female, a model which has come increasingly under challenge. Fausto-Sterling points out the range of inter-sex bodies that are forced into a binary classificatory system (1992, 2000). She explains that “the varieties are so diverse … that no classificatory scheme could do more than suggest the variety of sexual anatomy encountered in clinical practice” (1993: 22). Oudshoorn (1994), in a genealogy of the emergence of the theory of sex hormones, shows how a model of binary sex differences prevailed, in a context in which dualistic notions of male and female could have been abandoned (see entry feminist philosophies of biology and also Fausto-Sterling 1992, 2000; Fine 2012, 2017). Lane argues that

mobilizing a reading of biology as open-ended and creative, supports a perspective that sees sex and gender diversity as a continuum, rather than a dichotomy—put simply, “nature” throws up all this diversity and society needs to accept it. (2009: 137)

Lane, as a trans theorist, is confronting what is seen as an anti-biologism within performative gender theory, and exploring the complex interpellation of biological and cultural factors in the aetiology of trans subjectivity, without treating Grosz’s biological account as authoritative (see entry on feminist perspectives on trans issues).

This is not to deny that there is something independent of our conceptualizations which sets constraints on what can be said about it. What we cannot do is disentangle the bit which is given from our ways of thinking about it. What needs addressing, according to Barad, is “the entanglement of matter and meaning” (Barad 2007), the inter-implication of the discursive and the material in which no priority is given to either side. Barad explores this entanglement with particular reference to the work of physicist Niels Bohr. Viewing matter as an active “agent” ensures that matter and meaning are mutually articulated. Importantly, however, although the empirical world of matter takes an active part, this does not involve according it some sort of immediate givenness, or a straight-forwardly determining role. In her approach, Barad is following in the footsteps of Haraway. In 1985, prior to Butler’s Gender Trouble, Haraway had published her “Cyborg Manifesto” (1985 [1991]). Haraway’s project had some overlap with that later articulated by Butler. She wished to overcome the binary between nature and culture, replacing the two terms with nature/culture, in which different elements cannot be disentangled. She was also concerned to draw attention to the complex factors which go into constituting what is to count as nature for us. Most crucially, she was concerned to undermine the supposed naturalness of certain binaries, insisting on a breaching of boundaries between human and animal and between animal and machine. So came her invocation of the cyborg: a creature “simultaneously animal and machine” populating a world “ambiguously natural and crafted” (1985 [1991: 149]). In pointing to the cyborg as the figure which captures our “bodily reality”, Haraway is resisting any appeal to a pure nature which is supposed to constitute our bodily being. There is no clear boundary between what is natural and what is constructed. In Haraway’s picture, however, the body, along with the rest of the natural world, has what she calls “a trickster quality that resists categories and projects of all kinds” (1997: 128). In this and her later work (Haraway 2003, 2008), her account of the quirkiness and agency which, in Butler, is primarily discussed as a feature of discursive practices, is as much a feature of nature. Nature is viewed as an agent, actively contributing to the indivisible nature/culture with which we are faced. “We must find another relationship to nature besides reification, possession, appropriation and nostalgia” (2008: 158). This other relation is to view nature as “a partner in the potent conversation” (2008: 158), in which we attempt to constitute it. What is so notable about her work is the careful respect shown to the concreteness of bodily existence and to the biological narratives, alongside narratives of historical and cultural kinds.

7. Pragmatism
The preoccupation with a “rebalancing” of nature and culture, the material and the discursive, can also be found in feminist-pragmatist work. Drawing on the philosophical resources provided by the classical pragmatists, especially by John Dewey, William James, and Jane Addams, such work positions feminist concerns with gendered embodiment within the wider philosophical frameworks developed by pragmatists – including their naturalist ontology, social and political meliorism, and fallibilist epistemology. For example, taking John Dewey’s naturalism as a starting point, Shannon Sullivan utilises Dewey’s idea of the habituated organism that exists in constant adaptation to its environment to redress what she views as Butler’s neglect of “the concrete aspects of bodily existence” (2001, 8). Dewey eschewed philosophical dualisms, such as mind-body, and thought-practice, in his work, and feminist-pragmatists have drawn on his anti-dualistic theorising to (re-)define the relationship between nature and culture, mind and body, self and other (see e.g. Seigfried 1996, McKenna 2001, Fischer 2014, and the Hypatia special issue on Feminism and Pragmatism by Seigfried 1993). Explicating Dewey’s concepts of “transaction”, “body-mind” (2008, 211) and “habit”, Sullivan explains that “the human organism is characterized by activity, which has physical and mental aspects to it”, with “organisms’ bodying generally occur[ring] in patterned, rather than random ways” and being “constituted by habits, which are an organism’s acquired styles of activity” (2001, 30). Sullivan goes on to develop a reading of habit in light of Butler’s notion of performativity, thereby acknowledging “both...the discursivity of bodies and attending to lived bodily experience” (2001, 8) that is deeply structured by gender, race, (dis)ability, and other markers of “difference”.

Like Barad and other new materialists, feminist-pragmatists, following Dewey, view nature and matter as deeply agentic. Thus, in her recent work on the physiology of gendered and racialised oppression, Sullivan notes:

In the case of both physiological functions and habit, their transactional relationship with the world means not only that the environment helps constitute the function or habit, but also the function or habit helps constitute, and possibly change, the world. The relationship between both physiological function and habit and their environments is non-viciously circular (2015, 12).

Sullivan proposes a closer look at the biological and medical sciences, arguing that this need not result in the enshrining of only two sexes/genders, or in the reification of a “pre-critical sense of an unchanging bodily given”. Instead, she argues that “in a sexist, male-privileged world, what makes sex/gender biologically real is neither reproduction nor a sex binary, but the physiological incorporation of sexist oppression, which often is also heterosexist” (2015, 27).

In a contribution on the confluences between pragmatism and the new materialisms, Fischer (2018) points out that the “return” to biology and the material proposed by new materialists is well served by pragmatist work, with Dewey, in particular, being heavily influenced by Darwin. Moreover, as Seigfried’s (1996) seminal work on pragmatism and feminism highlights, pragmatism uses experience as its central category of analysis, rather than language, which, so Fischer asserts, can allow for a re-evaluation of the relationship between the material and the discursive (and the role of the gendered body therein) within a different philosophical frame (Fischer, 2018).

8. A Return to Phenomenology
A return to an interest in feminist phenomenology, in the footsteps of Beauvoir, started with the work of Bartky and Young in the late 1970s, but became widespread only in the 1990s. At the center of phenomenological accounts of embodiment is the lived experience of the body (which pragmatists similarly foreground). For such writers, embodiment is our mode of being-in-the-world (Young 2005: 9). The notion of experience is treated with great suspicion in the poststructuralist framework within which Butler is primarily positioned. The suspicion is a consequence of empiricist uses of the term, in which experience is tied to a “myth of the given” whereby body and world are offered to us in an unmediated way. The experiences to which phenomenological writers draw attention are not, however, of such a pure kind. For they are experiences of bodies in situations, in which it is impossible to disentangle so called “natural” and “social” elements. For as Merleau-Ponty points out,

everything is both manufactured and natural in man, as it were, in the sense that there is not a word, not a form of behaviour which does not owe something to purely biological being—and which at the same time does not elude the simplicity of animal life (1945 [1962: 189]).

Here there is an entanglement of nature/culture, matter and meaning, which parallels that insisted on by Haraway and Barad discussed above. But the phenomenological accounts foreground lived experience of the body in a way that is often absent from what are now termed the new materialist writings (although it is foregrounded in the writings of some trans theorists, see Salamon 2010).

Interest in the phenomenology of embodiment is an attempt to further articulate Freud’s claim that “the ego is a bodily ego” (Freud 1923 [1962]), to capture the way corporeal characteristics surface in our experiences of ourselves and others. Feminist writers such as Bartky, Young, Alcoff, Heinämaa, and Weiss are carrying on the project started by Beauvoir; but a major influence for many of them is also the work of Merleau-Ponty. They put such resources to work to make visible the variable experiences of gendered, raced, classed, differently abled and differently aged bodies, to reflect on the way such experiences mediate social positionality and constitute our sense of self.

8.1 Throwing Like a Girl
In a series of essays written early in her career, Young (reprinted 2005) captured everyday experiences of women’s embodiment. Such accounts were not simply descriptive, but were aimed, initially, to make evident the way in which the social norms governing female “bodily comportment” yielded an inhibited intentionality, an interruption in the pre-reflexive engagement with our environment to which Merleau-Ponty had drawn our attention (1945 [1962]). So, for example, in “Throwing Like A Girl” (1980) she points to studies which suggest that girls and boys throw in different ways and that women, when attempting physical tasks, frequently fail to use the physical possibilities of their bodies. Here she is echoing the descriptions offered by Beauvoir. Also following Beauvoir, Young suggests that the inhibited intentionality characteristic of female embodiment derives from the fact that women often experience their bodies as things/objects, “looked at and acted upon” (1980 [2005: 39]), as well as the source of capacities. “She often lives her body as a burden, which must be dragged and prodded along, and at the same time protected” (1980 [2005: 36]). For Young, as for Beauvoir, such experiences of embodiment are not a consequence of anatomy, but rather of the situation of women in contemporary society, but they point to significant ways in which female lived embodiment can be an obstacle to intentional engagement with the world.

Other essays written by Young, for example, “Pregnant Embodiment” (1984), “Breasted Experience” (2005, but a shorter version in 1992) and “Menstrual Meditations” (2005a), focus on distinctive aspects of female embodiment that yield distinct ways of being in the world. Here the stress is not only on inhibited intentionality. There is also recognition that such experiences can offer alternative possibilities for embodied engagement that can be positive as well as negative. In her accounts, Young stresses that it is such everyday ordinary experiences of embodiment, variable as they are, that constitute women’s sense of their identity as women. Young develops this insight in a discussion of Moi’s suggestion that we should replace categories of both sex and gender with the category of the lived body. Moi (1999) suggests that the category of the lived body can capture the way material features of our bodies play a role in our subjective sense of self, without giving a reductionist, biological account of such embodiment.

8.2 Visible Identities
Alcoff points out that such phenomenological accounts “require a cross-indexing by cultural and ethnic specificity” (Alcoff 2006: 107). In her work, a phenomenological account is employed to give an account of those identity categories which are anchored in material bodily features – what she terms visible identities. Alcoff is offering an account which integrates social identity categories with people’s experiences of the bodies of themselves and others. Focusing primarily on raced and gendered identities, she makes clear the way in which bodily features (color, hair, nose, breasts, genitals) are invested with a significance which becomes a part of our immediate perceptual experience of them:

Both race and sex … are most definitely physical, marked on and through the body, lived as a material experience, visible as surface phenomena and determinant of economic and political status. (2006: 102)

Because of the material reality of the features and the immediacy of our perceptual response, the meanings attached to such features become naturalized. The fact that they are the product of learned modes of perception is not evident to us, for such perceptual practices have become habitual and are resistant to change. She points out how “race and gender consciousness produce habitual bodily mannerisms that feel natural and become unconscious after long use” (2006: 108).

The significance, therefore, of certain bodily shapes, informs our sense of our own body and of the bodies of others. The sense of our own body reflects, as was articulated by Sartre, Fanon, and Beauvoir, the way it is perceived by others. The very shape of the body carries its position in patterns of social interaction. In a striking example regarding raced physiognomies, Alcoff quotes from Rodriguez’s book Days of Obligation (1992):

I used to stare at the Indian in the mirror. The wide nostrils … the thick lips …. Such a long face—such a long nose—sculpted by indifferent, blunt thumbs, and of such common clay. No one in my family had a face as dark or as Indian as mine. My face could not portray the ambition I brought to it. (Alcoff 2006: 189; my emphasis)

Ambition is something expressible in a body of a different kind, and the face he looks at points to a positioning at odds with what he desires. Although Alcoff restricts her analysis to race and sex, it is clear that it also has relevance to other bodily identities. The body in the wheelchair has similar difficulty expressing physical prowess that Rodriguez’s has of expressing ambition. Lennon and Alsop (2019, Ch. 7) point out that such a framework makes sense of the desires of some trans people for corporeal transformation. For, experiences of material features of the body are foundational to our sense of our sexed identity and used by others to position us in patterns of social interaction. Despite the polarising and often damaging consequences of the perceptual practices which Alcoff draws our attention to, she remains optimistic about the possibilities for change, though stressing the difficulties of even bringing these practices into view. Such changes require that people are brought to experience their own bodies and the bodies of others in a different way: “perceptual practices are dynamic even when congealed into habit … people are capable of change” (Alcoff 2006: 189).

8.3 Bodily Imaginaries
Alcoff is drawing attention to the salience which particular bodily features have in our experiencing of our own bodies and the bodies of others. This links her work to that of other theorists who explore this relation with reference to the notions of both “body image” and “bodily imaginaries”. Weiss (1999) begins her exploration of body images with the work of Merleau-Ponty (1945 [1962]) and Schilder (1935 [1950]), though castigating both for ignoring the difference that sexed and raced positionality make. For Merleau-Ponty our body image or body schema is the awareness we have of the shape or form of our body: “my posture in the inter-sensory world, a form” (Weiss, 10). Such an awareness is not of an objective anatomical body, but of the body in the face of its tasks, a body in which some aspects stand out and others are invisible. It is by means of such body schemas that we are able to act intentionally in the world, and, although they most commonly operate at a pre-reflective level, they constitute our sense of ourselves as corporeal beings. In the work of Schilder, the multiple nature of such body images and their dynamic nature is stressed. For him, the phenomenological account is interwoven with a psychoanalytic one. Our corporeal or postural schema is formed, in part, by the emotional and imaginative significance which is given to parts of the body by our personal relations with others, and by the significance attached to corporeal features in the social domain: “the touches of others, the interest others take in the different parts of our body, will be of enormous importance in the postural model of the body” (Weiss 1999: 16). This ensures that our body image is formed by the way the body is experienced and emotionally invested rather than cognitively represented. This is what, for many writers, is captured by the notion of the bodily imaginary (Gatens 1996, Lennon 2015). Feminists employing the concept of the bodily imaginary (influenced by the work of Irigaray discussed above) therefore stress that the way we have of experiencing our bodies, invests particular contours with emotional and affective salience. Gatens (1996), in exploring the notion of bodily imaginaries, also draws on the work of Spinoza. For her, the imaginary body is

the social and personal significance of the body as “lived”, socially and historically specific in that it is constructed by a shared language … and common institutional practices (1996: 11–12).

Many of the emotional saliencies which are attached, socially or only individually, to specific bodily features are damaging and destructive. There are many damaging imaginaries of women’s bodies, gay bodies, black bodies, or those imagined as disabled. It therefore seems imperative that such ways of thinking/feeling specific corporeal features can be subject to change. The matter becomes complex once we recognize that the affective salience which our bodies bear may not be available to reflective scrutiny, but nonetheless reveals itself in the habitual perceptual practices to which Alcoff drew our attention. To effect change, we need to offer alternative pictures which make emotional (imaginative) and not only cognitive sense. This is a crucial issue for all writers who want to provide an account of corporeal identities in terms of affectively laden body images, or bodily imaginaries. We can see this process at work in the rewriting of the female body offered by Irigaray, and in the re-imagining of the black body which we find in writers such as hooks, where the skin of the man lying next to her, “soot black like my grand-daddy’s skin” can return her to “a world where we had a history … a world where … something wonderful might be a ripe tomato, found as we walked through the rows of Daddy Jerry’s garden” (hooks 1990: 33; see also Tate 2009). Feminist theorists of the body, working with the notion of the bodily imaginary, therefore see creative acts directed at alterations in our mode of perceiving bodies, as central to the process of political and social transformation (Lennon 2015).

9. The Ethics of Embodiment
The work on bodily imaginaries from within the phenomenological framework, makes explicit the extent to which our embodied identities are dependent on the responses of others. They are negotiated intersubjectively, linked to the possible pattern of social interactions within which we can recognizably be placed. It is also clear that the imaginaries which are normatively attached to certain bodily morphologies can be restricting and damaging. Both Beauvoir and Fanon described the damaging consequences of encountering the myths and images carried by female and black bodies, which become internalized to mediate our embodied sense of self. The work of many theorists of bodily abilities point to the norms surrounding bodily shape and form in relation to which non-normative bodies are seen as freaks and monsters (Garland-Thomson 1997). Mairs admits experiencing shame of her body:

it is a crippled body. Thus it is doubly other, not merely by the … standards of patriarchal culture but by the standards of physical desirability erected for everybody in our world …. My belly sags from loss of muscle tone, which also creates all kind of intestinal disruptions, hopelessly humiliating in a society in which excretory functions remain strictly unspeakable (Mairs 1990 [1997: 299, 301]).

The way Mairs experiences her body is formed in relation to normalizing discourses in which the “crippled” body, in particular the “desiring crippled body”, is banished to the realm of the rejected, often unthinkable, other. The blossoming of the aesthetic surgery industry amongst women, and increasingly men, is a consequence of an increasingly narrow set of bodily morphologies being accepted as attractive and desirable. Moreover, these morphologies are usually of young bodies. This fuels the demand for body modification of aging bodies (Alsop and Lennon 2018; Dolezal 2015; Gilman 1999; Heyes and Jones 2009).

As a consequence of these insights, there is increasing work amongst feminist philosophers concerning the ethics of embodiment. Weiss (2015) points to

specific feminist philosophers, critical race scholars, and disability theorists who … illustrate, and ultimately combat, the insidious ways in which sexism, racism, and “compulsory able-bodiedness” (McRuer 2006), impoverish the lived experience of both oppressors and the oppressed, largely by predetermining the meaning of their bodily interactions in accordance with institutionalized cultural expectations and norms. (2015: 77)

There are two special issues of the feminist journal Hypatia (Bergoffen and Weiss 2011, 2012) devoted to the ethics of embodiment, dealing with the implications of situating bodies at the center of ethical theory. This requires looking at the operation of bodily norms, and at which bodies and modes of comportment are valued and which are not. It also requires engaging with bodily vulnerability in relation to the normative human and ethical ideals of autonomy and subjecthood. Garland-Thomson discusses what she terms “misfitting”, a lack of fit between body and world and between our bodies and other peoples (2011, also Bergoffen and Weiss 2011). When we fit harmoniously and properly into the world, we forget the contingency of this, because the world sustains us.

When we experience misfitting and recognize that disjuncture for its political potential, we expose the relational component and the fragility of fitting. Any of us can fit here today and misfit there tomorrow (Garland-Thomson 2011: 597).

Our bodily vulnerability, and consequently our vulnerability to others, is also central to the later work of Butler. It is through the body that we become vulnerable to our material environment and to the violence which may be inflicted on us by others: “living in a world of beings who are …physically dependent on one another, physically vulnerable to one another” (2004: 22). The vulnerability to social punishments and the threats of violence attach particularly to those who fail to conform to social norms. But Butler stresses the vulnerability and precariousness of everyone’s subjectivity, formed as it is by public systems of meaning which are themselves precarious and crisscrossed by differences. We are affected by the outside, the social and familial bonds, which enable us to assume subjectivity and agency, but are also injurious to us in closing down possibilities for our ways of being.

I am affected not just by this one other or set of others, but by a world in which humans, institutions and organic and inorganic processes all impress themselves upon this me, who is, at the onset, susceptible in ways that are radically involuntary (2015: 6/7).

Such susceptibility is, for her, the mode of being of embodied sensibility (see Gonzalez-Arnal, Jagger and Lennon (eds.) 2012, for papers highlighting the distinctiveness of different modes of embodiment and the vulnerability of the body to pain and assault. Also see Widdows 2018 for a discussion of Beauty as an Ethical Ideal and the entry on feminist perspectives on disability).

10. Conclusion
Feminist theorists of embodiment have made a central contribution to philosophy of embodiment and ensured, along with critical race theorists and theorists of (dis)ability, that attention to the body plays a central role in metaphysical, ethical, social and political thought. The theories which emerge are not simply of gendered embodiment. They provide a general account of the relations between bodies and selves. What is stressed within the feminist literature is the range of philosophical theories which are required to make sense of the embodied self. Naturalising frameworks need supplementing with phenomenological, poststructuralist, psychoanalytic, and pragmatist ones, in just the ways that feminist theorists have exemplified, if embodied subjectivity is to become intelligible.

1. Plato’s reading audience
For whom did Plato write? Who was his readership? A very good survey of this topic is Yunis 2007 from which I would like to quote the following illuminating passage: “before Plato, philosophers treated arcane subjects in technical treatises that had no appeal outside small circles of experts. These writings, ‘on nature’, ‘on truth’, ‘on being’ and so on, mostly in prose, some in verse, were demonstrative, not protreptic. Plato, on the other hand, broke away from the experts and sought to treat ethical problems of universal relevance and to make philosophy accessible to the public” (13). Other scholars, such as Morgan (2003), have also argued that Plato addressed in his writings both philosophical and non-philosophical audiences.

It is true that in the Republic Plato has the following advice for philosophers: “like someone who takes refuge under a little wall from a storm of dust or hail driven by the wind, the philosopher—seeing others filled with lawlessness—is satisfied if he can somehow lead his present life free from injustice and impious acts and depart from it with good hope, blameless and content” (496d–e) (unless otherwise noted, all quotations from Plato are from the translations included in Plato (1997)). He was certainly very bitter about Socrates’ fate. In his controversial interpretation Strauss (1964) argues that in Plato’s view the philosopher should stay disconnected from society. This interpretation is too extreme. Plato did not abandon Socrates’ credo, that the philosopher has a duty towards his fellow-citizens who do not devote their lives to philosophy. For him philosophy has a civic dimension. The one who makes it outside the cave should not forget about those who are still down there and believe that the shadows they see there are real beings. The philosopher should try to transmit his knowledge and his wisdom to the others, and he knows that he has a difficult mission. But Plato was not willing to go as far as Socrates did. He preferred to address the public at large through his written dialogues rather than conducting dialogues in the agora. He did not write abstruse philosophical treatises but engaging philosophical dialogues meant to appeal to a less philosophically inclined audience. The dialogues are, most of the time, prefaced by a sort of mise en scène in which the reader learns who the participants to the dialogue are, when, where and how they presently met, and what made them start their dialogue. The participants are historical and fictional characters. Whether historical or fictional, they meet in historical or plausible settings, and the prefatory mises en scène contain only some incidental anachronisms. Plato wanted his dialogues to look like genuine, spontaneous dialogues accurately preserved. How much of these stories and dialogues is fictional? It is hard to tell, but he surely invented a great deal of them. References to traditional myths and mythical characters occur throughout the dialogues. However, starting with the Protagoras and Gorgias, which are usually regarded as the last of his early writings, Plato begins to season his dialogues with self-contained, fantastical narratives that we usually label his ‘myths’. His myths are meant, among other things, to make philosophy more accessible.

2. Plato’s myths
There are in Plato identifiable traditional myths, such as the story of Gyges (Republic 359d–360b), the myth of Phaethon (Timaeus 22c7) or that of the Amazons (Laws 804e4). Sometimes he modifies them, to a greater or lesser extent, while other times he combines them—this is the case, for instance, of the Noble Lie (Republic 414b–415d), which is a combination of the Cadmeian myth of autochthony and the Hesiodic myth of ages. There are also in Plato myths that are his own, such as the myth of Er (Republic 621b8) or the myth of Atlantis (Timaeus 26e4). Many of the myths Plato invented feature characters and motifs taken from traditional mythology (such as the Isles of the Blessed or the judgment after death), and sometimes it is difficult to distinguish his own mythological motifs from the traditional ones. The majority of the myths he invents preface or follow a philosophical argument: the Gorgias myth (523a–527a), the myth of the androgyne (Symposium 189d–193d), the Phaedo myth (107c–115a), the myth of Er (Republic 614a–621d), the myth of the winged soul (Phaedrus 246a–249d), the myth of Theuth (Phaedrus 274c–275e), the cosmological myth of the Statesman (268–274e), the Atlantis myth (Timaeus 21e–26d, Critias), the Laws myth (903b–905b).

Plato refers sometimes to the myths he uses, whether traditional or his own, as muthoi (for an overview of all the loci where the word muthos occurs in Plato see Brisson 1998 (141ff.)). However, muthos is not an exclusive label. For instance: the myth of Theuth in the Phaedrus (274c1) is called an akoē (a “thing heard”, “report”, “story”); the myth of Cronus is called a phēmē (“oracle”, “tradition”, “rumour”) in the Laws (713c2) and a muthos in the Statesman (272d5, 274e1, 275b1); and the myth of Boreas at the beginning of the Phaedrus is called both muthologēma (229c5) and logos (d2).

The myths Plato invents, as well as the traditional myths he uses, are narratives that are non-falsifiable, for they depict particular beings, deeds, places or events that are beyond our experience: the gods, the daemons, the heroes, the life of soul after death, the distant past, etc. Myths are also fantastical, but they are not inherently irrational and they are not targeted at the irrational parts of the soul. Kahn (1996, 66–7) argues that between Plato’s “otherworldly vision” and “the values of Greek society in the fifth and fourth centuries BC” was a “radical discrepancy”. In that society, Plato’s metaphysical vision seemed “almost grotesquely out of place”. This discrepancy, claims Kahn, “is one explanation for Plato’s use of myth: myth provides the necessary literary distancing that permits Plato to articulate his out–of–place vision of meaning and truth.”

The discussion of the Symposium ends with Aristophanes and Agathon falling asleep while Socrates is trying to prove that “the skilful tragic dramatist should also be a comic poet” (223d). Plato himself seems to be such an author, as some of his dialogues read like tragedies (e.g. the Phaedo), while others mix arguments with irony and humour (e.g. the Euthydemus, Lesser Hippias, or Ion). For the link between drama and philosophy in Plato’s dialogues see Puchner (2010), Folch (2015), Zimmermann (2018), and Fossheim, Songe-Møller and Ågotnes (2019); for the importance of comedy and laughter in the dialogues see Tanner (2017) and Naas (2018b); and for the theory and practice of narrative in Plato see Halliwell (2009). And now to go back to Kahn’s claim (see the above paragraph) that in Plato “myth provides the necessary literary distancing that permits Plato to articulate his out–of–place vision of meaning and truth.” This may well be the case. But we have to keep in mind that Plato’s dialogues are a mix of various literary genres (philosophy, comedy, tragedy, poetry, mythology, rhetoric), and that this mix is also (to use Kahn’s expression) out-of-place. In other words, both the content and the form of Plato’s dialogues were, and still are, rather extraordinary—and that, I reckon, was meant to free his readers from conventions and encourage them to think for themselves about the issues that, he, Plato, discusses in his dialogues.

The Cave, the narrative that occurs in the Republic (514a–517a), is a fantastical story, but it does not deal explicitly with the beyond (the distant past, life after death etc.), and is thus different from the traditional myths Plato uses and the myths he invents. Strictly speaking, the Cave is an analogy, not a myth. Also in the Republic, Socrates says that until philosophers take control of a city “the politeia whose story we are telling in words (muthologein) will not achieve its fulfillment in practice” (501e2–5; translated by Rowe (1999, 268)). The construction of the ideal city may be called a “myth” in the sense that it depicts an imaginary polis (cf. 420c2: “We imagine the happy state”). In the Phaedrus (237a9, 241e8) the word muthos is used to name “the rhetorical exercise which Socrates carries out” (Brisson 1998, 144), but this seems to be a loose usage of the word.

Most (2012) argues that there are eight main features of the Platonic myth. (a) Myths are a monologue, which those listening do not interrupt; (b) they are told by an older speaker to younger listeners; (c) they “go back to older, explicitly indicated or implied, real or fictional oral sources” (17); (d) they cannot be empirically verified; (e) their authority derive from tradition, and “for this reason they are not subject to rational examination by the audience” (18); (f) they have a psychologic effect: pleasure, or a motivating impulse to perform an action “capable of surpassing any form of rational persuasion” (18); (g) they are descriptive or narrative; (h) they precede or follow a dialectical exposition. Most acknowledges that these eight features are not completely uncontroversial, and that there are occasional exceptions; but applied flexibly, they allow us to establish a corpus of at least fourteen Platonic myths in the Phaedo, Gorgias, Protagoras, Meno, Phaedrus, Symposium, Republic X, Statesman, Timaeus, Critias and Laws IV. The first seven features “are thoroughly typical of the traditional myths which were found in the oral culture of ancient Greece and which Plato himself often describes and indeed vigorously criticizes” (19).

Dorion (2012) argues that the Oracle story in Plato’s Apology has all these eight features of the Platonic myth discussed by Most (2012). Dorion concludes that the Oracle story is not only a Platonic fiction, but also a Platonic myth, more specifically: a myth of origin. Who invented the examination of the opinions of others by the means of elenchus? Aristotle (see Sophistical Refutations 172a30–35 and Rhetoric 1354a3–7) thought that the practice of refutation is, as Dorion puts it, “lost in the mists of time and that it is hence vain to seek an exact origin of it” (433). Plato, however, attempts to convince us that the dialectical elenchus “were a form of argumentation that Socrates began to practice spontaneously as soon as he learned of the Oracle” (433); thus, Plato confers to it a divine origin; in the Charmides he does the same when he makes Socrates say that he learned an incantation (a metaphor for the elenchus) from Zalmoxis; see also the Philebus 16c (on Socrates mythologikos see also Miller (2011)).

We have a comprehensive book about the people of Plato: Nails (2002); now we also have one about the animals of Plato: Bell and Naas (2015). Anyone interested in myth, metaphor, and on how people and animals are intertwined in Plato would be rewarded by consulting it. Here is a quotation from the editors’ introduction, “Plato’s Menagerie”:

Animal images, examples, analogies, myths, or fables are used in almost every one of Plato’s dialogues to help characterize, delimit, and define many of the dialogues’ most important figures and themes. They are used to portray not just Socrates [compared to a gadfly, horse, swan, snake, stork, fawn, and torpedo ray] but many other characters in the dialogues, from the wolfish Thrasymachus of the Republic to the venerable racehorse Parmenides of the Parmenides. Even more, animals are used throughout the dialogues to develop some of Plato’s most important political or philosophical ideas. […] By our reckoning, there is but a single dialogue (the Crito) that does not contain any obvious reference to animals, while most dialogues have many. What is more, throughout Plato’s dialogues the activity or enterprise of philosophy itself is often compared to a hunt, where the interlocutors are the hunters and the object of the dialogue’s search—ideas of justice, beauty, courage, piety, or friendship—their elusive animal prey. (Bell and Naas 2015, 1–2)
3. Myth as a means of persuasion
For Plato we should live according to what reason is able to deduce from what we regard as reliable evidence. This is what real philosophers, like Socrates, do. But the non-philosophers are reluctant to ground their lives on logic and arguments. They have to be persuaded. One means of persuasion is myth. Myth inculcates beliefs. It is efficient in making the less philosophically inclined, as well as children (cf. Republic 377a ff.), believe noble things.

In the Republic the Noble Lie is supposed to make the citizens of Callipolis care more for their city. Schofield (2009) argues that the guards, having to do philosophy from their youth, may eventually find philosophizing “more attractive than doing their patriotic duty” (115). Philosophy, claims Schofield, provides the guards with knowledge, not with love and devotion for their city. The Noble Lie is supposed to engender in them devotion for their city and instill in them the belief that they should “invest their best energies into promoting what they judge to be the city’s best interests” (113). The preambles to a number of laws in the Laws that are meant to be taken as exhortations to the laws in question and that contain elements of traditional mythology (see 790c3, 812a2, 841c6) may also be taken as “noble lies”.

The following myths are eschatological: Gorgias 523a–527a, Meno 81a–d, Phaedo 107c–115a, Phaedrus 246a–257a, Republic 614b–621d, and Laws 903b–905d. The stories they tell differ—to a greater or lesser extent—although some themes occur in more than one of them: the judgement of souls for their earthly life, their subsequent punishment or reward, the contemplation of forms in the other world, and reincarnation (which, in the Phaedo 81d–e, is part of the soul’s punishment or reward; see also the Timaeus 42c–e and 90e–92c). These are Plato’s myths, but they feature many elements and deities of classical mythology (such as Zeus, Prometheus, Hestia, Necessity and the Fates). For good surveys of Plato’s eschatological myths see Annas (1982) and Inwood (2009); see also the entries on myth and eschatology in Press and Duque (2022). For the relationship between philosophy and religion in Plato see Nightingale (2021). O’Meara (2017, 114) argues that the Timaeus and the Statesman are “reformed Panathenaic” festivals—in which Zeus (Timaeus) and Athena (Statesman) are “reformed”—while the Laws is a “reformed Dionysian festival” (in which Dionysus is “reformed”).

Plato’s eschatological myths are not complete lies. There is some truth in them. In the Phaedo the statement “The soul is immortal” is presented as following logically from various premises Socrates and his interlocutors consider acceptable (cf. 106b–107a). After the final argument for immortality (102a–107b), Cebes admits that he has no further objections to, nor doubts about, Socrates’ arguments. But Simmias confesses that he still retains some doubt (107a–b), and then Socrates tells them an eschatological myth. The myth does not provide evidence that the soul is immortal. It assumes that the soul is immortal and so it may be said that it is not entirely false. The myth also claims that there is justice in the afterlife and Socrates hopes that the myth will convince one to believe that the soul is immortal and that there is justice in the afterlife. “I think”, says Socrates, that “it is fitting for a man to risk the belief—for the risk is a noble one—that this, or something like this, is true about our souls and their dwelling places” (114d–e). (Edmonds (2004) offers a interesting analysis of the final myth of Phaedo, Aristophanes’ Frogs and the funerary gold leaves, or “tablets”, that have been found in Greek tombs). At the end of the myth of Er (the eschatological myth of the Republic) Socrates says that the myth “would save us, if we were persuaded by it” (621b). Myth represents a sort of back-up: if one fails to be persuaded by arguments to change one’s life, one may still be persuaded by a good myth. Myth, as it is claimed in the Laws, may be needed to “charm” one “into agreement” (903b) when philosophy fails to do so.

Sedley (2009) argues that the eschatological myth of the Gorgias is best taken as an allegory of “moral malaise and reform in our present life” (68) and Halliwell (2007) that the myth of Er may be read as an allegory of life in this world. Gonzales (2012) claims that the myth of Er offers a “spectacle [that] is, in the words of the myth itself, pitiful, comic and bewildering” (259). Thus, he argues, “what generally characterizes human life according to the myth is a fundamental opacity” (272); which means that the myth is not actually a dramatization of the philosophical reasoning that unfolds in the Republic, as one might have expected, but of everything that “such reasoning cannot penetrate and master, everything that stubbornly remains dark and irrational: embodiment, chance, character, carelessness, and forgetfulness, as well as the inherent complexity and diversity of the factors that define a life and that must be balanced in order to achieve a good life” (272). The myth blurs the boundary between this world and the other. To believe that soul is immortal and that we should practice justice in all circumstances, Gonzales argues, we have to be persuaded by what Socrates says, not by the myth of Er. Unlike the eschatological myths of the Gorgias and Phaedo, the final myth of the Republic illustrates rather “everything in this world that opposes the realization of the philosophical ideal. If the other myths offer the philosopher a form of escapism, the myth of Er is his nightmare” (277, n. 36).

4. Myth as a teaching tool
The philosopher should share his philosophy with others. But since others may sometimes not follow his arguments, Plato is ready to provide whatever it takes—an image, a simile, or a myth—that will help them grasp what the argument failed to tell them. The myth—just like an image, or analogy—may be a good teaching tool. Myth can embody in its narrative an abstract philosophical doctrine. In the Phaedo, Plato develops the so-called theory of recollection (72e–78b). The theory is there expounded in rather abstract terms. The eschatological myth of the Phaedo depicts the fate of souls in the other world, but it does not “dramatize” the theory of recollection. The Phaedrus myth of the winged soul, however, does. In it we are told how the soul travels in the heavens before reincarnation, attempts to gaze on true reality, forgets what it saw in the heavens once reincarnated, and then recalls the eternal forms it saw in the heavens when looking at their perceptible embodiments. The Phaedrus myth does not provide any proofs or evidence to support the theory of recollection. It simply assumes this theory to be true and provides (among other things) an “adaptation” of it. Since this theory the myth embodies is, for Plato, true, the myth has (pace Plato) a measure of truth in it, although its many fantastical details may lead one astray if taken literally. Among other things, the fantastical narrative of the myth helps the less philosophically inclined grasp the main point of Plato’s theory of recollection, namely that “knowledge is recollection”.

5. Myth in the Timaeus
The cosmology of the Timaeus is a complex and ample construction, involving a divine maker (assisted by a group of less powerful gods), who creates the cosmos out of a given material (dominated by an inner impulse towards disorder) and according to an intelligible model. The cosmology as a whole is called both an eikōs muthos (29d, 59c, 68d) and an eikōs logos (30b, 48d, 53d, 55d, 56a, 57d, 90e). The expression eikōs muthos has been translated as ‘probable tale’ (Jowett), ‘likely story’ (Cornford), ‘likely tale’ (Zeyl). The standard interpretation is promoted by, among others, Cornford (1937, 31ff.). The Timaeus cosmology, Cornford argues, is a muthos because it is cast in the form of a narration, not as a piece-by-piece analysis. But also, and mainly, because its object, namely the universe, is always in a process of becoming and cannot be really known. Brisson (1998, ch. 13) offers a different solution, but along the same lines. The cosmology, Brisson argues, is a non-verifiable discourse about the perceptible universe before and during its creation. In other words: the cosmology is an eikōs muthos because it is about what happens to an eikōn before, and during, its creation, when everything is so fluid that it cannot be really known. The standard alternative is to say that the problem lies in the cosmologist, not in the object of his cosmology. It is not that the universe is so unstable so that it cannot be really known. It is that we fail to provide an exact and consistent description of it. A proponent of this view is Taylor (1928, 59). Rowe (2003) has argued that the emphasis at 29d2 is on the word eikōs, not muthos, and that here muthos is used primarily as a substitute for logos without its typical opposition to that term (a view also held by Vlastos (1939, 380–3)). Burnyeat (2009) argues that this cosmology is an attempt to disclose the rationality of the cosmos, namely the Demiurge’s reasons for making it thus and so. The word eikōs (a participial form of the verb eoika, “to be like”) is, argues Burnyeat, usually translated as “probable”; but—as textual evidence from Homer to Plato proves—it also means “appropriate”, “fitting”, “fair”, “natural”, “reasonable”. Since the cosmology reveals what is reasonable in the eikōn made by the Demiurge, it may rightly be called eikōs, “reasonable”. The Demiurge’s reasoning, however, is practical, not theoretical. The Demiurge, Burnyeat claims, works with given materials, and when he creates the cosmos, he does not have a free choice, but has to adjust his plans to them. Although we know that the Demiurge is supremely benevolent towards his creation, none of us could be certain of his practical reasons for framing the cosmos the way he did. That is why anyone aiming at disclosing them cannot but come up with “probable” answers. Plato’s cosmology is then eikōs in the two senses of the word, for it is both “reasonable” and “probable”. But why does Plato call it a muthos? Because, Burnyeat argues, the Timaeus cosmology is also a theogony (for the created cosmos is for Plato a god), and this shows Plato’s intention to overcome the traditional opposition between muthos and logos.

Timaeus speaks about the Demiurge’s practical reasoning for creating the cosmos as he did. No cosmologist can deduce these reasons from various premises commonly accepted. He has to imagine them, but they are neither fantastical, nor sophistic. The cosmologist exercises his imagination under some constraints. He has to come up with reasonable and coherent conjectures. And in good Socratic and Platonic tradition, he has to test them with others. This is what Timaeus does. He expounds his cosmology in front of other philosophers, whom he calls kritai, “judges” (29d1). They are highly skilled and experienced philosophers: Socrates, Critias and Hermocrates and at the beginning of the Critias, the sequel to the Timaeus, they express their admiration for Timaeus’ cosmological account (107a). One may say that Timaeus’ account has been peer-reviewed. The judges, however, says Plato, have to be tolerant, for in this field one cannot provide more than conjectures. Timaeus’ cosmological discourse is not aimed at persuading a less philosophically inclined audience to change their lives. It may be argued that its creationist scenario was meant to make the difficult topic of the genesis of the realm of becoming more accessible. In the Philebus, in a tight dialectical conversation, the genesis of the realm of becoming is explained in abstract terms (the unlimited, limit, being that is mixed and generated out of those two; and the cause of this mixture and generation, 27b–c). But the Timaeus aims at encompassing more than the Philebus. It aims not only at revealing the ultimate ontological principles (accessible to human reason, cf. 53d), and at explaining how their interaction brings forth the world of becoming, but also at disclosing, within a teleological framework, the reasons for which the cosmos was created the way it is. These reasons are to be imagined because imagination has to fill in the gaps that reason leaves in this attempt to disclose the reasons for which the cosmos was created the way it is.

6. Myth and philosophy
In the Protagoras (324d) a distinction is made between muthos and logos, where muthos appears to refer to a story and logos to an argument. This distinction seems to be echoed in the Theaetetus and the Sophist. In the Theaetetus Socrates discusses Protagoras’ main doctrine and refers to it as “the muthos of Protagoras” (164d9) (in the same line Socrates also calls Theaetetus’ defence of the identity of knowledge and perception a muthos). And later on, at 156c4, Socrates calls a muthos the teaching according to which active and passive motions generate perception and perceived objects. In the Sophist, the Visitor from Elea tells his interlocutors that Xenophanes, Parmenides and other Eleatic, Ionian (Heraclitus included) and Sicilian philosophers “appear to me to tell us a myth, as if we were children” (242c8; see also c–e). By calling all those philosophical doctrines muthoi Plato does not claim that they are myths proper, but that they are, or appear to be, non-argumentative. In the Republic Plato is fairly hostile to particular traditional myths (but he claims that there are two kinds of logoi, one true and the other false, and that the muthoi we tell children “are false, on the whole, though they have some truth in them”, 377a; for a discussion of allegory and myth in Plato’s Republic see Lear (2006)). Halliwell (2011) claims that Book X of the Republic “offers not a simple repudiation of the best poets but a complicated counterpoint in which resistance and attraction to their work are intertwined, a counterpoint which (among other things) explores the problem of whether, and in what sense, it might be possible to be a ‘philosophical lover’ of poetry” (244). For an illuminating article on the Republic and the Odyssey see Segal (1978); see also Howland (2006).

In many dialogues he condemns the use of images in knowing things and claims that true philosophical knowledge should avoid images. He would have had strong reasons for avoiding the use of myths: they are not argumentative and they are extremely visual (especially those he invented, which contain so many visual details as if he would have given instructions to an illustrator). But he didn’t. He wanted to persuade and/or teach a wider audience, so he had to make a compromise. Sometimes, however, he seems to interweave philosophy with myth to a degree that was not required by persuading and/or teaching a non-philosophical audience. The eschatological myths of the Gorgias, Phaedo and Republic, for instance, are tightly bound with the philosophical arguments of those dialogues (cf. Annas 1982); and the eschatological myth of the Phaedo “picks one by one the programmatic remarks about teleological science from earlier on in the dialogue, and sketches ways in which their proposals can be fulfilled” (Sedley 1990, 381). Some other times he uses myth as a supplement to philosophical discourse (cf. Kahn (2009) who argues that in the myth of the Statesman Plato makes a doctrinal contribution to his political philosophy; Naas (2018a, Chapter 2) offers an interesting interpretation of this myth, and (Chapter 3) discusses Michel Foucault’s reading of it. A number of chapters in Sallis (2017) and in Bossi and Robinson (2018) reassess the myth of the Statesman. One time, in the Timaeus, Plato appears to overcome the opposition between muthos and logos: human reason has limits, and when it reaches them it has to rely on myth (arguably, that also happen in the Symposium; for a very close reading of how Diotima’s speech interacts with Aristophanes’ myth of the androgyne see Hyland (2015).

“On the less radical version, the idea will be that the telling of stories is a necessary adjunct to, or extension of, philosophical argument, one which recognizes our human limitations, and—perhaps—the fact that our natures combine irrational elements with the rational” (Rowe 1999, 265). On a more radical interpretation, “the distinction between ‘the philosophical’ and ‘the mythical’ will—at one level—virtually disappear” (265). If we take into account that Plato chose to express his thoughts through a narrative form, namely that of the dialogue (further enveloped in fictional mises en scène), we may say that the “use of a fictional narrative form (the dialogue) will mean that any conclusions reached, by whatever method (including ‘rational argument’), may themselves be treated as having the status of a kind of ‘myth’” (265). If so, “a sense of the ‘fictionality’ of human utterance, as provisional, inadequate, and at best approximating to the truth, will infect Platonic writing at its deepest level, below other and more ordinary applications of the distinction between mythical and nonmythical forms of discourse” (265); if so, it is not only “that ‘myth’ will fill in the gaps that reason leaves (though it might do that too, as well as serving special purposes for particular audiences), but that human reason itself ineradicably displays some of the features we characteristically associate with story-telling” (265–6) (cf. also Fowler (2011, 64): “Just as the immortal, purely rational soul is tainted by the irrational body, so logos is tainted by mythos”). It is difficult to say which one of these two readings is a better approximation of what Plato thought about the interplay between myth and philosophy. The interpreter seems bound to furnish only probable accounts about this matter.

Fowler (2011) surveys the muthos–logos dichotomy from Herodotus and the pre–Socratic philosophers to Plato, the Sophists, and the Hellenistic and Imperial writers, and provides many valuable references to works dealing with the notion of muthos, the Archaic uses of myth– words, and ancient Greek mythology; see also Wians (2009). For the muthos–logos dichotomy in Plato see also Miller (2011, 76–77).

7. Plato’s myths in the Platonist tradition
Aristotle admits that the lover of myths is in a sense a lover of wisdom (Metaphysics 982b18; cf. also 995a4 and 1074b1–10). He might have used a myth or two in his early dialogues, now lost. But in general he seems to have distanced himself from myth (cf. Metaphysics 1000a18–9).

On the philosophical use of myth before Plato there are a number of good studies, notably Morgan 2000. There is, however, little on the philosophical use of myth in the Platonist tradition. Of Plato’s immediate successors in the Academy, Speusippus, Xenocrates and Heraclides of Pontus composed both dialogues and philosophical treatises. But, with one exception, none of these seems to have used myths as Plato did. The exception is Heraclides, who wrote various dialogues—such as On the Things in Hades, Zoroastres and Abaris—involving mythical stories and mythical, or semi-mythical, figures. In the later Platonist tradition—with the exception of Cicero and Plutarch—there is not much evidence that Plato’s philosophical use of myths was an accepted practice. In the Neoplatonic tradition various Platonic myths became the subject of elaborate allegorization. Porphyry, Proclus, Damascius and Olympiodorus gave allegorical interpretations of a number of Platonic myths, such as the Phaedo and Gorgias eschatological myths, or the myth of Atlantis.

For the influence of Plato’s myths on various thinkers (Bacon, Leibniz, the German Idealists, Cassirer and others) see Keum (2020).

8. Renaissance illustrations of Plato’s myths
Plato was a celebrated figure in the Renaissance but only a few illustrations of Platonic mythical motifs can be found. Perhaps Plato’s attitude to visual representation—claiming so often that the highest philosophical knowledge is devoid of it, and attacking poets and artists in general more than once—inhibited and discouraged attempts to capture in painting, sculpture or prints, the mythical scenes Plato himself depicted so vividly in words. Perhaps artists simply felt themselves unequal to the task. McGrath (2009) reviews and analyzes the rare illustrations of Platonic mythical figures and landscapes in Renaissance iconography: the androgyne of the Symposium, the charioteer of the Phaedrus, the Cave, and the spindle of the universe handled by Necessity and the Fates of the Republic.

1. Metaphysical foundations of existentialist aesthetics
The term “aesthetics” as it first emerged in modern philosophy (in A. G. Baumgarten’s 1750 Aesthetica) encompassed the theory of perception, the theory of beauty and the theory of art. This remained true of all philosophical aesthetics in the late 18th and 19th centuries. In this brand of aesthetics, the aesthetic moment is but one aspect of the general theory of how humans perceive, know, and act in the world; the theories of beauty and of artistic practice depend on the theories of perception, knowledge and judgement, and those in turn are premised upon more fundamental considerations regarding the nature of reality and our relationship to it. Existentialist aesthetics is a continuation of this tradition. It is intimately connected to certain metaphysical views, and it owes its richness and consistency to the fact that it is part of a complex and coherent philosophical system. Therefore we should begin by delineating the most salient features of this metaphysical outlook.

The key insight that defines and unites existentialism as a philosophical position, despite all the divergences between the authors included under that denomination, is the emphasis on the radical nature of human freedom, and the metaphysical and ontological imports of that freedom. The metaphysical and ontological significance of freedom precedes its moral, ethical, and political aspects, since the ways in which human beings “hook up” to the world should be considered before issues of duty or justice. For existentialism, human freedom grounds the very possibility of knowledge in its deepest form, i.e., the capacity of human beings to reveal something about reality. A Christian existentialist like Gabriel Marcel interprets the metaphysical reach of human freedom in terms of the capacity and responsibility of individuals to make themselves “available” to the mystery of their participation in creation, in particular by responding to the appeal of the great “Thou” (Marcel 1960b). Atheistic existentialists (Camus, Sartre, de Beauvoir, Merleau-Ponty), on the contrary, do not ground freedom in faith and the hope of accessing the transcendent; instead they emphasise the difficulty of embracing that freedom, since nothing can ensure that our attempts at finding meaning in the world will actually yield something objectively present in it. But in all cases freedom is the ultimate ground of human beings’ capacity to relate to the world.

2. The phenomenological core of existentialist aesthetics
For the 20th century existentialists, a decisive philosophical inspiration was phenomenology, the philosophical method devised by the German philosopher, Edmund Husserl, during the late 19th and early 20th centuries. To a lesser extent, they were also influenced by Martin Heidegger’s extension of Husserl’s method, which combined existential analysis and deep ontology. Even Camus, who does not define himself as a phenomenologist, and indeed sometimes rejects the tag of “existentialist” (1945), appropriates the notion of intentionality, central to Husserl’s phenomenology, in his most famous work, The Myth of Sisyphus (Camus 1942b, 44–50). It follows that existentialist aesthetics and the phenomenological approach to aesthetic perception and judgement (Ingarden 1962, 1965) are two closely related areas. Mikel Dufrenne situates his work precisely at this intersection (see especially Dufrenne 1973). However, the existentialists’ approach to phenomenology is highly original, and has significant and distinctive implications for aesthetics.

What does intentionality mean, and why is it such a central notion in existentialist thinking about art? Husserl shows that when any type of meaning is articulated (in cognitive, moral, affective, aesthetic attitudes, etc.), a specific act of consciousness occurs. The specificity of the meaning in question depends on the particular way in which consciousness “intends” its content in each case, i.e., the specific way in which it relates to a given (e.g., an object to know, judge, perceive, enjoy, and so on). In other words, different types of meaning depend on the specific structure of the acts of consciousness that carry them; in particular, they depend on the specific temporality of these mental acts. To give an example that made its way into some of the most famous existentialist literary works (e.g., in the famous descriptions in Nausea, Sartre’s first novel): there is a specific temporality involved in perceiving an object in space. The object is not given in an instant, and every perception points to a potential new perception which will confirm or revise the previous ones. This temporality of perception implies recourse to memory and a unification of past moments of perception. This emphasis on the way human consciousness “intends” the world in different ways accounts not just for the content of human knowledge, but also, more radically, for the relationship of the human being to reality. It is not just an epistemological but a metaphysical position.

This approach to the basic problem of metaphysics is highly significant because it circumvents the dualisms of prior European philosophy: subject vs. object, impressions vs. a priori principles as the basis of knowledge, freedom vs. determinism, and so on. The emphasis on intentionality avoids these dualisms because it entails, on the one hand, that all meanings are constituted through acts of human consciousness, thus insisting on the active role of the subject in the formulation of any meaningful aspect of the world. On the other hand, however, the theory of intentionality also implies that the world already contains the meanings that consciousness reveals, either because these meanings are potentialities from the point of view of human action (this is Sartre’s view), or simply because these meanings are already in the world (Merleau-Ponty’s view, but also that of Marcel, for whom true knowledge arises from the openness to the fullness of Being).

The existentialists explicitly embraced the philosophical solutions that phenomenology provided. For example, Sartre’s What is Literature?, the key text of existentialist aesthetics, starts off by reformulating the fundamental lesson of Husserlian phenomenology:

Each of our perceptions is accompanied by the consciousness that human reality is a “revealer”, that is, it is through human reality that “there is” being, or, to put it differently, that man is the means by which things are manifested. It is our presence in the world which multiplies relations. It is we who set up this relationship between this tree and a bit of sky. Thanks to us, that star which has been dead for millennia, that quarter moon, and that dark river are associated in the unity of a landscape. It is the speed of our car and our aeroplane which organises the great mass of the earth. With each of our acts, the world reveals to us a new face. But, if we know that we are directors of being, we also know that we are not its producers. If we turn away from this landscape, it will sink back into its dark permanence. At least, it will sink back; there is no one mad enough to think that it is going to be annihilated (Sartre 1948a, 26).
3. Art as revelation of the world
Sartre draws a basic aesthetic implication from the thesis that meaning in the world depends on acts of consciousness: the fundamental aim of the work of art is to deliberately and consistently exert this uniquely human quality to introduce meaningful order and regularities into the world. Whereas in the “natural attitude” this happens without the agent’s awareness (in the form of natural perception, folk and scientific knowledge), in artistic practice the order, regularities, perspectives, and meaningful relationships are formalised, emphasised, systematised, and wilfully arranged. The simultaneous effect is to “reveal” significant features of the world and to gain a reflexive sense of being revealers of the world and ‘manifesting’ it. Thus, our sense of freedom is tremendously increased:

One of the chief motives of artistic creation is certainly the need of feeling that we are essential in relationship to the world. If I fix on canvas or in writing a certain aspect of the fields or the sea or a look on someone’s face which I have disclosed, I am conscious of having produced them by condensing relationships, by introducing order where there was none, by imposing the unity of mind on the diversity of things (Sartre 1948a, 27).
Thus the first aspect of aesthetic pleasure is this double “joy” (Sartre 1948a, 41) of “disclosing” the world and fully appropriating the unique power to do so, becoming aware of and exercising our radical freedom. This first aspect of aesthetic pleasure can be called “metaphysical”, since it arises from the fundamental relation between humans and the world (Howells 1988).

Indeed, such is the metaphysical reach of human freedom that every attempt to disclose a portion of the world tends to aim for the disclosure of the “totality” of beings. This is because (as Husserl already insisted) the most partial or minute act of perception entails a reference to a broader horizon of future potential perceptions. Many existentialist writers stress this primordial, metaphysical function of the work of art as a partial revealing that aims to uncover the totality of Being. This idea is found, most notably, in Simone de Beauvoir’s defence of the metaphysical novel (de Beauvoir 1946, 1965, 73; see also, Merleau-Ponty’s reflections in his review of de Beauvoir’s first novel, 1945c).

Such an intimate link between metaphysics and art explains why existentialists often place certain artists on a level equal or superior to the philosophers: Camus with Dostoievski, Marcel with Bach, Merleau-Ponty with Cézanne, Sartre and de Beauvoir with Faulkner and Kafka. It also partly explains why most existentialist philosophers were equally, or in fact more, active as creative writers. According to them, metaphysical inquiry and artistic practice share a fundamental aim: both are ways of revealing to human beings their own freedom and responsibility.

4. Art as expression of human freedom
The metaphysical and ethical dimensions of human freedom are intimately related. This is the most significant difference between the existentialists and Husserlian phenomenology: the existentialists link the power to disclose the world to the obligation for human beings to decide who they should be, in terms of the fundamental values directing a person’s life. The concept of “existence” designates precisely this ethical dimension of human life. The existentialists argue that, of all the beings existing in the world, the human being is the only one that can decide what it should be; indeed, it is forced to do so since it has no fixed nature. As the existentialist motto goes, “man is condemned to be free.” Here, freedom is not just independence in the sense of independence from, but in the sense of being able to decide who and what one should be. This ethical dimension of freedom as the power of self-determination (which also entails the duty to use it) explains the central place of the notion of “engagement (commitment).” Before it designates any necessity to choose in particular situations, “engagement” refers to the fundamental position of the human individual, whose very being consists in having to make use of its freedom. On the existentialists’ outlook, the only positive feature of “human reality,” strictly speaking, is responsibility towards others and towards oneself (and, for the Christian existentialists, towards God). Many human beings refuse this burden and flee from their ontological responsibility by accepting pre-given roles. This refusal is what Sartre’s “bad faith” and Marcel’s “functional man” designate.

What is the link between the metaphysical and the ethical dimensions of human freedom, and how does this latter concern aesthetics?

Let us begin with the first part of the question. We will first approach it by using a mode of argument typical of phenomenology. Many existentialists insist that the ways in which a human consciousness “intends” the world (that is, imposes a certain order and regularity in external phenomena) is intrinsically dependent on the values the person has set for herself. A mountain climber views a mountain in a way radically different from an intellectual who has devoted his or her life to books. The difference in their perspectives relates to the deep projects of selves that distinguish these two persons. In other words, behind every perception there is a value influencing the perception in advance and thus ultimately determining its precise content. On a deeper level, the experience that there is something at all, the experience of being, cannot be conceived if there is not a desire for it (an “ontological exigency” says Marcel). The very capacity of human beings to conceive something in the world at all is premised on their capacity to posit values (Sartre 1943a; Marcel 1960a, for the religious perspective).

If that is true, however, then every “revelation” of the world in the first, metaphysical sense also entails a revelation of the fundamental ethical (or, as the existentialists preferred, existential) project underpinning this perception. This answers, then, the second part of the question regarding the relation between the work of art and the ethical aspect of freedom. For the existentialists, as we saw, the work of art brings to a higher level of reflexivity and consistency the innate capacity of human beings to disclose the world. However, since this capacity is itself rooted in the ethical or religious nature of human beings, the work of art plays a central role in conveying a more acute sense of ethical responsibility. It follows that there is an intimate link between art and engagement: every aesthetic ordering of the world brings with it a conception of human freedom and suggests ways to use it.

Hence, Sartre’s definition of the literary work, which applies broadly to all works of art: “… an imaginary presentation of the world inasmuch as it requires human freedom” (1948a, 45). In other words, the artwork serves the purpose of “making us feel essential in relation to the world.” The work of art presents the world not just in the sense that it reveals aspects of it, but also in the sense that it calls for human involvement, notably in collective action (or, for Marcel, ‘communion’) (Goldthorpe 1992).

This definition of the artwork remains ambiguous inasmuch as it does not specify whose freedom is required. A number of features can be delineated as a result, depending on whose freedom is emphasised in each case.

The freedom required by the world is first of all that of the artist. Every artwork reveals a fundamental, existential attitude towards the world, and is the expression of an existential choice. We will return to the fundamental notion of expression below, but we can already note that putting existential weight on every act of disclosure leads directly to the conclusion that artistic practice is intimately linked to ethical and political choices.

However, the ‘expressive’ aspect of the artwork, the fact that it is the manifestation of a unique subjectivity, is not the most interesting one for the existentialists; from this perspective, existentialist aesthetics is quite distant from romanticism. This is because existence, freedom and self-determination are, for the existentialists, essentially active and practical notions. The existential choice is not simply a choice of who one should be, in the sense of a choice of personality or character; the theory of existence does not translate into a theory of genius. Rather, the emphasis is on the active relationship within the world, and especially with others. Accordingly, one defines who one is by what one does with one’s freedom in the world, through the ways in which one proposes to change the world, notably in relation to other human agents. When the artist presents the world, whether he or she likes it or not this presentation also proposes to others ways to live in the world and possibly (at least for the most politically minded authors, such as Sartre, de Beauvoir and Merleau-Ponty) ways to change it. In Sartre’s words, every “imaginary presentation of the world” is an act of “a” freedom speaking to “other” freedoms about possible ways of engaging freedom in the world. Extending Sartre’s definition of the novel, then, we could say that every artwork is an “appeal” (Sartre 1948a, 32).

Therefore the artwork involves a freedom that is not just that of the artist, but also that of the audience. In existentialist language, it is freedom considered as ‘engaged,’ that is, irreducibly caught up in engagement and forced to do something about it. Hence, Sartre offers another definition of the artwork that identifies the different poles of the metaphysical power of art: “… the writer has chosen to reveal the world and particularly to reveal man to other men so that the latter may assume full responsibility before the object which has thus been laid bare” (Sartre 1948a, 14).

In their own artistic practice and their work as critics, the existentialists tended to interpret this conception of art’s mission (as revelation and appeal) as an argument in favour of representational approaches, and against formalistic and puristic approaches. They were generally sceptical of ‘autotelic’ conceptions of the artwork that view it as a self-contained object answerable only to its own formal rules. In this respect, again, they differ from major modernist views. However, while their insistence on the representative dimension of art and its ethical and political significance sets them at odds with many 20th century avant-gardes and aesthetic theories, the renewed emphasis on political commentary and the artist’s responsibility in recent decades suggests that their approach is less outdated than it might once have seemed.

5. Art and the absurd
So far we have only considered the subjective side of the link between human revelation of the world and the world itself. Existentialism, however, also emphasizes the objective side of the link; that is, the world itself as object of perception and knowledge, and as the context in which human action takes place. Here, there are some notable differences between ‘optimistic’ and ‘tragic’ conceptions of the world in terms of our human endeavours.

The ‘optimistic’ ontologies, like those of Marcel or Merleau-Ponty, see the world as being on the whole a welcoming place for human knowledge and action. Marcel, despite his critical analyses of what he sees as the ills of modern society, is the most optimistic of all, mainly owing to the theological grounding of his ontology. Ultimately there is no gap for him between the yearning for full participation in the world (including in God) and the world itself, since we owe our very existence and capacity for participation to the ultimate origin of this world. As he writes in his diary: “Knowledge is within being, enfolded by it” (1935, 115). Although Merleau-Ponty does not share this theological conviction, he agrees with Marcel on a crucial point: our incarnation in the world through our bodies is the fundamental beginning of our learning to inhabit the world meaningfully. As a result of our being both in and of the world through our bodies, Merleau-Ponty believes that on the whole our presentations of the world reveal objective features of it.

The ‘tragic’ ontologies of Sartre, de Beauvoir and Camus, on the other hand, insist on the inhospitality of the world towards human endeavours insofar as the world is mostly reticent to our attempts at introducing meaning and unity into it. For Camus, the ‘absurd’ mainly designates this resistance of the world to our endeavours. Whilst we crave for sense and harmony, the world has nothing to offer but chaos and a random play of blind forces. All our efforts to impose order and sense upon a world that can ultimately accommodate neither are therefore doomed to fail. The absurd, then, denominates both the most fundamental state of the world and the absurdity of human attempts at overcoming this basic fact.

However, whilst Camus’ ‘absurd’ names the essentially tragic state of humanity, it is counterbalanced by his awe towards the indifferent majesty of Nature. For Camus, one of the ways of liberating oneself from the illusion of meaning and unity is to open up to the beauty of Nature and partake in it, abandoning oneself in privileged moments of hedonistic communion with wild environments, such as the rugged Algerian landscape or the Mediterranean, or in eroticism (1938a; see the moments of happiness in The Outsider, for example, 1942a, 23–24, 116–117).

Sartre, on the other hand, insists on the “disgusting”, “nauseating” aspects of a world resistant to meaning, order and beauty. His first novel, Nausea, painstakingly chronicles this ontological disgust towards the strangeness of the world. A proffered hand becomes “a big white worm,” a glass of beer a hostile partner whose “gaze” the hero attempts to avoid for half an hour; a pebble on the beach reveals the “nausea” that is communicated from the world “through the hands.” Even here, however, aesthetic experiences trigger some exceptional moments in which the hero manages to escape ontological ‘nausea’. This occurs, for example, when the novel’s main character suddenly hears a jazz song in a café, which, like a “band of steel,” points to a different time beyond the drudgery of the everyday (Sartre 1938, 21–23).

Many of the existentialists’ literary creations attempt to describe the entanglements of human freedom in these fundamental ontological features of the world. Admittedly, this applies to some existentialist authors more than others. For instance, Marcel’s plays explore the difficulties that modern individuals encounter in responding to the appeal of transcendence, and in giving in to faith and hope. But these obstacles arise mainly from social institutions (notably around marriage) and historical events (the tragic circumstances of the 20th century and what Marcel sees as the dangerous objectivism of modern society). Similarly, de Beauvoir’s novels tend to portray individuals seeking their true selves beyond the strictures of social morality. In contrast, a great part of Camus’ and Sartre’s literary work is dedicated to describing the difficulties that people face when trying to find their place, not just in their social, but also in their natural and material environments. As we have noted, some of the best-known passages in their literary writings also describe moments in which the obtrusiveness of the world is overcome, yielding fleeting yet sublime experiences of sensuous communion with nature and others.

6. Ontology of the artwork
Sartre drew some particularly interesting conclusions from the definition of the functions of art on the basis of an existentialist metaphysics. These conclusions relate to what, in contemporary discussions, is called the ‘ontology’ of the artwork: the type of reality of the artwork’s different elements and their internal relations. Mikel Dufrenne has most thoroughly pursued this ontological approach.

Sartre’s early texts on the imagination already provided significant insights in that regard (in particular, see Dufrenne’s lengthy discussions of them in his The Phenomenology of Aesthetic Experience, 1973). The freedom that characterises human subjectivity is manifested most vividly in a specific type of intentionality: the imagining of an object. Imagination exemplifies the power of human consciousness because it is a type of intentionality that posits in the same act both the existence of the object and its inexistence, since it “intends” it precisely as a virtual object. In imagination, the object is indeed intended by consciousness, but “as absent”, as “containing a certain part of nothingness” inasmuch as it is posited as not existing here and now (Sartre 1940). This distinguishes it from the type of intentionality involved in perception, one of the key aspects of which is precisely the positing of its object as existent.

This emphasis on the ‘derealising’ aspect of the consciousness of an image has important implications for the ontological status of the artwork. The real, material elements of the artwork are, properly speaking, not the actual elements on which the aesthetic judgement is fixed. These are fixed instead on a virtual object, i.e., the work’s ideal qualities, wherein the work’s meaning, power and beauty are manifested (Sartre 1940, 213; see also Dufrenne 1973, 3). On this account, the material aspects of the artwork are “occasions” for the manifestation of the ideal aspects. Sartre insists that one should reject any suspicion of dualism here: “There is no realisation of the imaginary, nor can we speak of its objectification,” (ibid.) as though a prior mental representation had been “objectified” and realised in the actual artwork. Rather, the “real” artwork has two sides: a real and an “unreal” (irréel, virtual, or ideal) side. These two are, however, indistinguishable. “The painting should then be conceived as a material thing visited from time to time by an unreal which is precisely the painted object” (ibid; see Dufrenne 1973, 3–18). The real, says Sartre, is the analogue of the ideal. Merleau-Ponty puts it in similar terms, at first in terms of sense and non-sense, and later on in terms of the visible and the invisible: the ideal content of the artwork is “in transparency behind the sensible or in the heart of the sensible.” It “doubles up the lights and sounds from beneath, is their other side or their depth” (Merleau-Ponty 1964a, 150–151, but already in 1945a, 182–183).

This general “negative” dimension of the artwork (the fact that as an ideal object it is not reducible to the materiality that carries it) applies also to each of the artwork’s elements and their relations (the colours and shapes in a painting, the words and sentences in a novel, and so on). Existentialist aesthetics generally insists on the unity that artistic expression brings to the world. As a consequence of this emphasis on organic unity, it seems to propound a rather conventional image of the aesthetic qualities of the artwork (see, for example, from a theologically informed perspective, Marcel’s discussion of the symphony and the fugue as examples of self-enclosed “perfection” [1960b, 53–54]).

However, Sartre’s analyses of the relationship between the artwork’s elements shows that the insistence on unity as a criterion of artistic beauty is perhaps not as banal as it might sound. Sartre’s pre-war texts on the imagination are especially informative on this topic. In them, Sartre shows the substantial relationship between the power of human consciousness to “nihilate” the world (to overlook some of its aspects and emphasise others on the basis of an existential set of values) and the internal coherence of the artwork:

… each stroke of the brush (is) not for itself, (…) it (is) given together with an unreal (irréel) synthetic whole and the aim of the artist is to construct a whole of real colours which enable this unreal to manifest itself. (…) It is the configuration of these unreal objects that I designate as beautiful (Sartre 1940, 216).
This implies that the artist’s existential project, which defines the perspective from which the world is revealed in a special way, lends its consistency to the formal features of the artwork. But the quote above also indicates the relation between the different elements that make up the overall composition: in the end, every particular material element that contributes to the general composition is related to the others through a relation of negativity.

The theory of meaning that underpins this view of the artwork’s structure thus seems to anticipate a Saussurean definition of language. Famously, Saussure analysed the functioning of language as a ‘diacritical’ system in which each sign owes its signification not to a substantial, one-to-one relation between word and referent, but rather to its place within the overall linguistic system. Basically, a sign means what it means on the basis of ‘not being’ any of the other signs. ‘Dog’ means what it does because the signifier (the material sound) and the signified (the intended meaning) differs from all others, and especially the proximate ones: ‘log’, ‘fog’, ‘god’, and so on; ‘wolf’, ‘cat’, and so on.

In the same manner, the existentialist philosophers who dedicated the most attention to the articulation of meaning (Sartre and Merleau-Ponty) insist on the essentially diacritical essence of the aesthetic element in a given composition: an element has aesthetic significance on the basis of its relation to the other elements, rather than owing to any substantial meaning of its own. It follows that, for example, in a painting the pleasure derived from a particular colour in isolation from the rest of the work is not ‘aesthetic’ in the strong sense but only in a lower sense: as a pleasure for the senses only. This also implies that often the meaning and aesthetic power of a composition (a text, a painting and so on) rests just as much on what is not said or not shown; what lies in-between the elements of the composition, rather than on the elements explicitly shown. The existentialists all insist that meaning is largely to be found in a certain form of silence. In the case of a novel:

… the literary object, though realised through language, is never realised in language. On the contrary, it is by nature a silence and a contestation of speech. The hundred thousand words aligned in a book can be read one by one without the meaning of the work emerging; meaning is not the sum of the words, but its organic totality (Sartre 1948a, 30).
This means that the different elements of the artwork should not be approached separately or in their immediate reality, but in terms of how they function organically, systematically and negatively. The colours in a painting, and the choice of words and the rhythm of sentences in a novel are all but traces, ellipses, elisions, and caesuras that suggest in the negative, just as much as the elements positively indicate the contours of a certain perspective onto the world.

7. Theory of expression
The emphasis on the capacity of human consciousness to “derealise” the world amounts to a defence of the creative freedom of the artist. The artwork is the most striking example of the power of human consciousness to turn towards the world in such a way that it takes in from it certain elements and blanks out others, in accordance to a fundamental existential project. Artistic practice is one of the most eminent demonstrations of human freedom because it shows how human practice can recreate (Camus, Sartre, de Beauvoir, Merleau-Ponty) or recover (Marcel) a new, more ordered world out of the given world. Camus offers a concise formulation for a central principle of existentialist aesthetics: “To write is already to choose” (Camus 1951, 271).

The existentialist philosophers did not refrain from formulating internal (aesthetic) and external (ethical and political) constraints to artistic practice, but their aesthetics fundamentally proclaims the radical freedom of the artist, also seeing in it the privileged exemplar of human freedom in general. Camus, for example, makes artistic activity, the choice of becoming an artist, one of the privileged modes for humans to deal with the absurd (Camus 1942b, 86–88). Many existentialist texts dedicated to aesthetic matters emphasise the “mystery” of creativity, the amazing “solution” that an artwork represents, the “miracle of expression” that elicits admiration from the audience and philosophers.

However, a central, shared assumption of existentialists, beyond the stark religious and political differences between them, is the essential ambiguity of human freedom (de Beauvoir 1947a): I am radically free as consciousness, yet wholly determined by my “facticity”, the physical, social and other circumstances in which my consciousness comes to the world. On this particular point Heidegger’s existential analytic is a shared reference that brings together these otherwise diverse (or, indeed, antagonistic) thinkers. In the case of the artist, the ambiguity resides already in the decision and the passion to become an artist. Although a set of genetic and social preconditions influences that choice, it is equally the product of an individual decision in that specific situation.

The work of art is caught up in the same ambiguity. On the one hand, it is the free creation of an unconstrained person, a purely idiosyncratic expression of an individuality. On the other, it is constrained by various factors that exert influence on its very structure: the audience, the historical period that will receive the work, the material elements that make up the artwork, and in particular, the already signifying elements that the artist reuses and recomposes to create a new work.

Merleau-Ponty’s writings of the 1950s (1953a, 1953b, 1953c) advance an original existentialist theory of expression that addresses this latter dimension in particular. It can be argued that this theory of expression captures and makes explicit thoughts that a number of other existentialist writers shared on these questions.

In The Prose of the World (1969), Merleau-Ponty explores the emergence and logic of meaning and meaning-giving activity, of signification and expression, using the example of literary works (particularly the novel). Stendhal provides him with a paradigmatic case study. Such an attempt to draw deep philosophical conclusions from artworks is typical of existentialist practice.

Firstly, the literary work can help us understand the phenomenon of meaning and meaning-giving by seeing the writer as creating new meanings, indeed a new language (a Joycean version of English, a Flaubertian French, and so on) by recomposing a language he or she shares with an entire historical community. This is a truly ambiguous aspect that can be taken (on one hand) as the proof of the mystery of expression, evidence of a creative power required to make possible the emergence of the new out of the old, while (on the other hand) this new is possible only on the basis of the already-instituted. But this initial remark points to a much deeper level; here, it is painting that offers the most precious indications. In discussing André Malraux’s seminal essays on the history of painting (Malraux 1953), Merleau-Ponty articulated a detailed existentialist theory of meaning where the artwork plays the central role. The Husserlian metaphor of ‘perspective’ is appropriated and transformed into a general formula for both the power of perception and the metaphysical condition of the human being.

Intentionality can be said to coincide with the establishment of a perspective in a world where there is, prior to human presence, none. For reality to appear in all its different qualities and structures, human consciousness is required. What distinguishes the artist from other language-users is the consistency and coherence of a specific outlook onto the world. Such coherent perspective introduces an element of regularity and structure in the chaos of the world. It introduces directions: a high and a low, a right and a left. That is, it introduces sense.

This link between artistic expression and meaning leads to a major re-evaluation of the notion of style. Rather than a superficial way of formulating meanings that remain unchanged by their expression, style in this context now indicates a fundamental perspective from which the world can be approached; it indicates a perspective that would not have existed prior to the expressive act. It designates an “irreplaceable deviation” that is possible only from a specific way of being-in-the-world, and which is subsequently recaptured in symbolic language, whether the linguistic form of literature, or the “indirect language” of painting. Style is a coherent perspective, a “coherent deformation,” a way of being-in-the-world and of approaching the world from a certain angle. On this model, style does not express pre-existing meaning, but creates it. Camus, in the pages of The Rebel devoted to the aesthetic dimensions of rebellion, developed a concomitant conception of artistic expression:

… unity in art appears at the limit of the transformation which the artist imposes on reality. This correction, which the artist imposes by his language and by a redistribution of the elements extracted from reality, is called style and gives the recreated universe its unity and its boundaries (Camus 1951, 270).
This in turn gives a more specific meaning to the relation of the new and the old in expression. True expression (whether the first genuine self-expression of the learning speaker, a new scientific meaning, or true artistic achievement) is both totally idiosyncratic, and a re-composition of shared elements; it transforms the old. For true expression to occur, two forms of speech are thus required: “speaking speech” and “spoken speech” (Merleau-Ponty, 1945a, 197). This explains the puzzling fact that a true expression must be at once a true creation, something unheard of, and yet can be understood only if the language it uses (natural, scientific or artistic) is known. In other words, expression is always also a form of communication between one “speaker” and the community of speakers. Assuming that Merleau-Ponty’s analyses are representative of views that were shared by the other existentialist writers (see Sartre, 1948a, 56, in which the germane concept of “mediation” is used; “communication” is the central notion in Marcel’s philosophy of theatre), we can note that once again existentialist aesthetics seems at odds with many modern artistic currents, which have insisted on drawing a radical distinction between the functions and uses of artistic and everyday languages. For example, a major poet and theorist of literature like Paul Valéry was inspired by Mallarmé’s famous characterisation of poetry as “giving a purer sense to the words of the tribe.” We can also mention surrealist and expressionist painters and film directors who sought to break through everyday imagery in order to transfigure reality.

Merleau-Ponty (1959, 1969) also argues that artistic communication has a certain capacity to transcend the ages and cut across languages. Beyond the historical situatedness of artistic communication (the fact that an artistic language re-uses the language of its contemporaries), the task of giving sense on the basis of being-in-the-world is part of the metaphysical condition of being human, and so applicable to all humans throughout history. As a result, considering that art is a ‘higher degree’ of communication, the work of art is not just a striking example of genuine expression, but also exemplifies the fact that every act of meaning is open to the past and the future of other human acts of expression.

At this point, we can note a tension within the aesthetics of many existentialist writers (a tension that is quite acute in Sartre’s work) between the relative trans-historical meaningfulness of artworks and their utter situatedness: artworks offer an image of engaged freedom in particular situations that are truly accessible only to its contemporaries (Sartre 1948a, 50–52). Merleau-Ponty, for his part, insists on the underlying unity of the history of painting, which allows us to find traces and echoes of past painters in modern ones. The history of painting is a microcosmic image of history, and a testament to the capacity of present generations to understand the actions and passions of the past (Merleau-Ponty 1969, 72). Merleau-Ponty’s vision of the possibility of empathy across the ages does not deny the historical relativity of sense formations. It shows how, despite the spatiotemporal distance that separates historical contexts, humans can still understand each other, historians can understand previous times, anthropologists other peoples, and we can somehow access some of the meanings of past artistic practices. The expressive achievements of other peoples are both radically alien, and yet the result of expressive gestures that are commensurable to ours, inasmuch as they are the product of a common human capacity, viz., the capacity to transcend the natural world and recreate it as a meaningful and ordered universe.

8. The artist
As discussed above, a key assumption of existentialist aesthetics is the essential ambiguity of human freedom, as it must assert itself within a facticity, viz., a set of given factors (physical, social and so on) that it has not created An important implication of this emphasis on facticity is that it forges a vital link between philosophy and the arts, which from this perspective similarly aim to explore the metaphysical ambiguity of the human condition.

This grants the artist a special status from at least two standpoints:

Artistic activity as an existential choice is a privileged mode of taking up and realising the paradoxical nature of being human. In Camus’ words, artistic activity is one of the key attitudes to face the absurd. Camus’ celebration of art in The Myth of Sysiphus (1942b, 127), which crowns artistic expression as the ultimate form of “joy,” would ring true for the other existentialists despite their noted differences on the question of the absurd. Indeed, many existentialist writers made similar statements reflecting their own life choices, in particular their decision to pursue a philosophical and literary career. The personal dimension that can be found in many existentialist writings grants these texts a special status in the history of philosophy, since it blurs a boundary that has been essential to the definition of the genre of philosophical writing, viz., the boundary between the theoretical and the biographical, the personal and the general. Marcel’s “metaphysical diary” is a good case in point. More than just an original form of philosophical analysis, the diary illustrates Marcel’s own conception of the true self as a gradual awakening to the “appeal” of being through the combined practices of ontological inquiry, artistic creation and personal engagement. Sartre also wrote an autobiographical account of his discovery of the world of words, Les Mots, without doubt one of his masterpieces. The same can be said of Camus’ last narrative text, La Chute, which mixes autobiography with an ironical account of his philosophy.

Beyond their own personal practice, the existentialists also find philosophical significance in the lives of great artists, and are interested in the moment they chose to become artists and how this primordial choice unfolded over the course of their lives. Artists provide paradigmatic case studies for the paradoxes of “existence” and “expression” (Sartre 1947b, 1971). Indeed, this is true not just of writers and painters but also of actors. For Camus, in fact, actors are those “who draw the best conclusion” from the metaphysical truth of human existence (1942b, 107).

The artist’s activity is also deeply significant in terms of its power of articulating a coherent world. Every person has to make existential choices and has a need for expression, but artists present particularly pure and powerful exemplars of these facets of human existence. Their achievements are worthy of admiration because they involve the creation of virtual worlds. Every consciousness, every being-in-the-world is expressive, but only rarely is this expression truly new. Most of the time, human expression is only the repetition of instituted meanings, as in the quasi-automatic use of spoken language. Only the great artists show the power of expression in its purity, its newness and coherence. To recreate a virtual world that can do justice to the complexity of the real world is an almost “miraculous” fact, as Merleau-Ponty says of Cézanne. As we can see, the existentialists are no longer that far from the romantics with respect to their emphasis on genius.

Since the expressive world of a genuine artist is a new perspective onto the world that is identical with the artist’s whole idiosyncratic mode of being-in-the-world, there will be a deep, underlying continuity in his or her work. The communication that the work of art establishes across time and space operates, first and foremost, within the oeuvre itself, with themes and stylistic traits echoing each other throughout it (Camus 1942b, 102–103; Merleau-Ponty 1969, 67). But there is an inherent fatalism in artistic activity. Expressive activity can only ever be an attempt at expression, and it is structurally doomed to fail because there is too much to reveal in the world. The means of expression are finite, and they operate in a twisted manner, just as much through direct designation as through ellipsis and allusion. This leads Camus to conclude that creative activity, like all free activities, is in the end only another absurd attempt at dealing with the absurdity of human life (1942b, 130).

9. The audience
An essential ambiguity characterises also the experience of the audience. On the one hand, the genuine artist creates a new virtual world that expresses a coherent, idiosyncratic perspective on the world shared by all. When the audience meets the artwork successfully, the spectators suddenly change their own mode of perception and have to adopt a new perspective. To use a linguistic metaphor, the tired, instituted language of everyday communication (‘spoken’ or sedimented language) is rejuvenated by a ‘speaking’ language, a true expression that imposes itself on the audience (be it the reader or the spectator). Therefore, the artwork, in a sense, creates its own audience (Merleau-Ponty 1969, 86, and also 12–13; see also Dufrenne, 1973, 63–71).

Nevertheless there is also an active side to artistic enjoyment, as in reading, for example. Without the spectator’s contemplation, or the reader’s reading, the artwork’s expression remains purely subjective. It becomes objective, manifesting its sense in actuality, only through the symbolic consumption of the audience. This act, however, is not passive: it mobilises the audience’s own power of expression and imagination. Reading, watching, or listening are, as Sartre puts it, “directed creations”: “To write is to make an appeal to the readers that they lead into objective existence the revelation which I (the artist) have undertaken by means of language” (Sartre 1948a, 32; Dufrenne 1973, 47–60). Marcel’s conception of the theatre as an experience of ‘communion’ also implies this active participation of the audience.

The ambiguity of aesthetic experience is linked directly to the above mentioned theory of the negativity of the expressive means. The work of art functions when it is able to define a coherent perspective onto the world, yet the consistency of this perspective is typically only implicit within its objective expressive features. The spectator’s work of interpretation is indispensable to translate the traces, caesuras and elisions that negatively express the new world of expression into positive traits: “… the imagination of the spectator has not only a regulative function but a constitutive one. It does not play: it is called upon to recompose the beautiful object beyond the traces left by the artist” (Sartre 1948a, 33).

A metaphor Sartre and Merleau-Ponty employ frequently is that of the two sides of the artwork, comparable to the two sides of a mirror. The artist only sees his or her own work from the inside; he or she lives the artwork in a sense, since the expressive power is rooted in an idiosyncratic form of being-in-the-world. For the work to become an objective entity with a manifest meaning, the understanding and imagination of the audience needs to reconstruct the meaningful silence in between the traces. And this understanding cannot be passive, since the truly expressive meaning involves a new form of being-in-the-world. The spectator or reader is called upon to effectuate the same original mode of being-in-the-world: “If he is a writer, that is, if he knows how to find the ellipses, elisions and caesuras of conduct, the reader will respond to his appeal and meet him at the centre of the imaginary world he animates and rules” (Merleau-Ponty 1969, 89). Once again, a key feature of aesthetic experience is communication, the ‘echo’ that a subjective attitude to the world finds in others.

10. The existentialist “system of the arts”
This vision of the artwork as a privileged medium of expression and communication (in the substantive, metaphysical senses given to these words in existentialist philosophy) leads to a relatively coherent approach to the different art forms, something like a loose existentialist ‘system of the arts.’ A system of the arts explains not just what art is in essence, seeking a definition of art and determining its social, political or philosophical functions. It also ranks the arts in a hierarchy, giving an account of how each form uses specific material and expressive means to fulfil those functions. In the end, one art-form in particular is usually regarded as privileged, exemplary of the mode of fulfilling the mission of art. All classical philosophical aesthetics, from Kant and his immediate followers to Alain, have presented their own, more or less developed “système des beaux-arts” (Alain 1920, Natanson 1968).

10.1 Theatre
For most of the existentialists, theatre is the prime art form, i.e., the one that best allows the artist to use his or her freedom to create a virtual world that simultaneously appeals to the audience’s own freedom (regardless of how we define that freedom, theologically or politically). For Camus, de Beauvoir, Marcel and Sartre, philosophical activity and recognition as playwrights were intimately linked (Goldthorpe 1986). Marcel, who wrote thirty plays in total, defined himself as “philosophe-dramaturge” (philosopher-dramatist, see Lazaron 1978), to insist on what was, for him, an indissoluble unity between philosophical meditation and playwriting. Indeed, it is well worth noting that, apart from de Beauvoir (whose single attempt at writing for the theatre was not very successful [see de Beauvoir 1945b and 1962, 672–673]), they were all equally famous as playwrights and as philosophers in their time.

Arguably, Sartre’s theoretical reflections on the theatre of his time have remained the most widely read today. In describing what were for him the defining features of existentialist theatre, Sartre also aimed to identify some of the main aspects of theatre itself. As these features are grounded in his theory of freedom, theatre is, for Sartre, the art par excellence.

The identification of art in general with the theatre is already evident in the fact that the same word – ‘situation’ – simultaneously encapsulates the metaphysical position of the human being-in-the-world and summarises one of theatre’s core aesthetic elements (Sartre 1976, 35). The two ‘enemies’ in French existentialism, Sartre and Marcel, agree on the centrality of the concept of ‘situation.’ What is literature? defines the mission of literature as the attempt “to reveal the world and particularly to reveal man to other men so that the latter may assume full responsibility before the object which has been thus laid bare” (Sartre 1948a, 14). Centred as it is on the praxis of real human beings confronted with the contradictions of concrete situations, theatre is the best medium to present in purified form the tragic responsibility of human freedom, the fact that “we are condemned to be free” in a world inhospitable to our projects.

This emphasis on action and situation leads to a series of highly prescriptive rules, as we see in the criteria that Sartre used in his critical reviews of contemporary theatre writing and production. To rise to the task of achieving a “theatre of situations,” writing and production must resist the temptation of focusing on the characters; they need to present archetypical situations in which human freedom is most radically at stake, notably through different types of universal ‘conflicts of rights.’ Theatre needs to avoid psychology and concentrate on action (in clear contrast to Marcel’s theatre, which is mainly concerned with staging conflicts of inner conscience); it must be wary of a realistic approach that might take the focus away from the violence of the conflicts. For the same reason, the duration of the play and the number of the characters must be reduced. The stage must be empty and the language must be direct but non-realistic, compressing the acuteness of the situation as powerfully as possible. In short, existentialist theatre explicitly intends to return to a Greek conception, attempting to present contemporary “myths” in a world without gods (Sartre 1976).

But the situations, precisely, are situated: they always take place in specific social and political contexts. The myths that the theatre presents, therefore, have two temporal dimensions: 1) Because they are about distinguishing features of human ‘being,’ they have, like Greek and Corneillian tragedy, a transhistorical appeal; they are plays about human freedom in general. This explains the classical bent of many existentialist plays. Thus, it makes perfect sense to stage the conundrums of modern, absurd freedom through the figure of Caligula, as Camus does in one of his most famous plays. 2) The situation is always a specific one, particularly a specific social and political circumstance, with its specific conflict of rights. In the years following the Second World War, the conflict of rights is widely understood as the conflict between liberal rights and the socialist ideal. All the existentialists agreed on this, with the notable exception of Marcel. The ‘communist question’ (of whether to embrace the proposed communist solution to the problems facing the world in 1948 – the date of publication of What is Literature?) was one of the most urgent political questions for them. More generally, we can mention the question of the value of individual engagement as opposed to engagement in a collective movement (a question at the centre of Malraux’s novels, notably his Human Condition, which approaches the existentialist aesthetic), and the place of individual freedom in an age of conflict between global forces. These questions were at the forefront of existentialist concerns when they devised their aesthetics, and wrote their plays and novels.

We have noted the similarity between Sartre and Marcel regarding their emphasis on “situations”. Although Sartre noted other features of existentialist theatre that formally apply to Marcel’s plays, there are stark differences in their approach to playwriting. Whereas for Sartre the ultimate justification of theatre is political, for Marcel it is metaphysical: it is a question of finding salvation and hope, and safeguarding the possibility of faith. Yet, like Sartre’s, Marcel’s plays staged the specific problems of the age as he saw them: e.g., the rise of technology and instrumental thinking, which bring about a reductive attitude to the world and especially to other human beings; the atrocities of the century, and the moral disorientation of modern individuals. Despite his metaphysical optimism, Marcel’s theatre shares with other existentialist plays a patently sombre mood. He wants to depict “the drama of the soul in exile, of the soul that suffers from its lack of communion with itself and with others” (Preface to Troisfontaines 1953, 35). Marcel’s plays consistently portray a creeping feeling of absurdity that befalls the main characters.

10.2 The novel
The novel comes very close to theatre as the art-form of choice for the existentialists. For most existentialists, the ultimate models were not philosophers, but contemporary novelists, two of whom were especially paradigmatic, viz., Dostoievsky and Kafka. Sartre, de Beauvoir and Camus saw themselves in equal measure as writers of fiction and as philosophers. They engaged with each other’s fictional work at least as much as with their theoretical writings, if not more (Camus 1938b, 1939, Sartre 1943b, Merleau-Ponty 1945c). Indeed, as already noted, fiction and autobiographical writings were direct applications of their philosophical visions. “To think is to create a world,” writes Camus, showing the deep identity between philosophical and fictional creation (Camus 1942b, 87–91). The reason is the same as with theatre: narrative fiction, focused on a series of ‘situations’ in which the fundamental existential choices facing human beings can be carefully staged, is a powerful mode of engaging the free imagination of the reader, and thus of calling him or her to action: “What in fact is a novel but a universe in which action is endowed with form?” (Camus 1951, 263). The novel is a revelation of the world, notably in its social and political urgency, by a freedom for other freedoms. As Merleau-Ponty writes in “Metaphysics and the Novel”: “Intellectual works had always been concerned with establishing a certain attitude toward the world, of which literature and philosophy, like politics, are just different expressions; but only now [thanks to existentialist philosophy] has this concern become explicit” (Merleau-Ponty 1945c, 27; see also Camus 1942b, 92 and 1951, 258–267).

In existentialist aesthetics, artistic activity and its products have external aims: to reveal the world to others, both in a metaphysical and political sense. As noted, this aesthetic theory therefore conflicts with the notion that the artwork is an end in itself, or that style and form are self-justified. Thus, the existentialists were deeply suspicious of some of the main artistic movements of the time, particularly Surrealism, even if some of them admired its rebellious spirit (Camus 1951, 88–100); or, later on, the Nouveau Roman (Alain Robbe-Grillet, Nathalie Sarraute and Claude Simon) and the literature that was developed around the post-structuralist journal Tel Quel (see de Beauvoir’s critical appraisal in Francis and Gontier 1979, 226, 233–234). Compared with Dadaism, Surrealism, and the literary avant-gardes that immediately followed the existentialist era, existentialist aesthetics has an outdated, almost conservative air to it. It unabashedly calls for a new classicism somewhere between formalism and realism (either in its naturalist or socialist versions), and beyond romanticism (Camus 1944 and 1951, 268–271), on the grounds that the moral and political dimensions of literature consist not just in a rebellion against everyday language and the social-political order of the day, but also in the more demanding (yet modest) task of properly naming the world in order to unveil the immense injustice reigning in it, while also retrieving its fleeting and inhuman beauty (Camus 1951, 272–279). In his prolific work as literary critic, Sartre consistently rejected formalism and “art for art’s sake,” even in the case of illustrious French writers such as Mallarmé or Flaubert. As noted already, the existentialist demand that art maintain a strong connection to everyday reality (so as to fulfill its moral and political roles) made it seem outdated in the context of modernist projects but aligns with 21st-century concerns about the political significance and impact of art.

The condemnation of “art for art’s sake” applies to all the arts and has important repercussions for aesthetic critique and the conception of style. The existentialists take great pains to note that their rejection of formalism, purism and autotelism in the arts does not amount to advocating a crude version of realism (Camus 1951, 268–270; Sartre 1948a, 44). As we have noted already in the case of theatre, the classical aspect of existentialist aesthetics impacts on the choice of stylistic means: “One is not a writer for having chosen to say certain things, but for having chosen to say them in a certain way. And to be sure, the style makes the value of the prose. But it should pass unnoticed” (Sartre 1948a, 15).

Furthermore, the existentialist definitions of meaning as negativity, and of expression as ‘coherent distortion’, mean that stylistic achievement (the ability to let new sense be revealed) relies as much on the choice of words and syntax as on the ‘silences’ and omissions that define an expressive gesture.

10.3 Poetry
With their emphasis on action in situations, the existentialists have an uneasy relationship to poetry. Only Camus, following the example of Nietzsche, wrote a number of poems (Camus 1933, 1935–1941). In many passages in Camus, poetry has a positive connotation. This connotation, however, refers to a specific quality of language, viz., the use of vivid images that manage to convey some truth about the human condition, rather than to the merits of poetry as a specific literary form.

For Sartre, the stance of 19th century novelists who engaged in ‘art for art’s sake’ is not too dissimilar to the problematic way modern poets approach language. In fact, Sartre’s studies on two of the major French poets of the 19th century, Baudelaire and Mallarmé, are tinged with the same disapprobation as his immense study of Flaubert (Sartre 1947b, 1952b, 1971–72). Modern poetry for Sartre is, in the final analysis, a misguided use of language. It uses language as an end in itself, a thing, the same way that a painter uses colour. This ignores the fact that in language the relationship between materiality and signification is opposite to that of other artistic media. Language is, for the existentialists, the favoured artistic medium because, as the mode of expression that is most directly a medium of signification, it is the one that best reveals a situation as situation in the strong sense, viz., as a part of the world where human freedom is directly engaged metaphysically, ethically and politically. Poets, on the other hand, “are men who refuse to utilise language. Now, since the quest for truth takes place in and by language conceived as a kind of instrument, it is unnecessary to imagine that they aim to discern or expound the true. Nor do they dream of naming the world” (Sartre 1948a, 5). In their use of language, modern poets seem to ignore and oppose the main qualities that the existentialists grant it, namely, its representative and communicative powers. This explains why poetry remains at the margins of the existentialist system of the arts, at least inasmuch as it is viewed as not being as eminently philosophical and political as the theatre and the novel. In this case again, the existentialists are squarely at odds with the surrealists, who condemned the novel and saw in poetry the real artistic medium.

However, this critical stance towards poetry was far from consistent and universally applied by the existentialist philosophers. Marcel wrote two long studies on Rilke (1945). Camus published a vibrant review of the work of René Char (Camus 1935–1936), and saw in the work of Francis Ponge an eminent illustration of the task of literature in the absurd situation of post-war France (Camus 1943). Sartre also dedicated a long and largely positive review to the work of Francis Ponge, interpreting his poetic work as a kind of profane phenomenology (Sartre 1944 in 1947a). This positive assessment might well have rested on a misunderstanding, since Ponge had the exact opposite view of language to that of Sartre regarding poetry, seeing it precisely as the form that would best be able to “name the world” and make human freedom face its responsibility. In “Black Orpheus” (1948c), a preface to a collection featuring the main representatives of the “Négritude” movement, Sartre explained why it was precisely through poetry that the Black poets who lived under French colonial rule would best account for their experiences and their struggles. In later writings (1972), he softened the hard distinction he had established in What is Literature? between poetic and prosaic uses of language.

10.4 Non-linguistic arts: painting and music
The existentialists’ relative lack of interest in poetry was based on the view that poets tend to use of language in misguided ways. For the same reason, the other non-discursive arts attract almost as little interest as poetry (however, see Camus 1951, 257). Yet, when they are discussed, they are treated more favourably than poetry, since they do not have language as their medium, and this means that the accusation against poetry becomes irrelevant. The emphasis on language as the eminent medium for the representation of human freedom reproduces a classical argument that is already at the heart of Hegel’s aesthetics (a fact of which the existentialists are fully aware [Sartre 1948a, 5]). The implication for the other arts is that they are able to produce and convey ideal contents, meaning and beauty, but that these are never as transparently accessed as in linguistic expression. Rather, the ideal content in non-linguistic art-forms remains trapped, glued, as it were, in the materiality of the artwork:

… it is one thing to work with colour and sound, and another to express oneself by means of words. Notes, colours, and forms are not signs. They refer to nothing exterior to themselves. (…) As Merleau-Ponty has pointed out in The Phenomenology of Perception, there is no quality of sensation so bare that it is not penetrated with significance. But the dim little meaning which dwells within it, a light joy, a timid sadness, remains immanent or trembles about like a heat mist; it is colour or sound. (Sartre 1948a, 1)
This seems to introduce some important differences amongst the existentialists, since Merleau-Ponty, for instance, claimed that all art forms function like language. But Merleau-Ponty agrees with Sartre on the important differences between art forms. In The Prose of the World, he argues that there is a single source behind all acts of expression, which makes them commensurable to language, only to acknowledge the specificity of language in a manner similar to Sartre’s. For example, the “voices” in painting – a metaphor for the ideal content of painting – are ‘voices of silence’ that speak only an ‘indirect language’ (the titles of Malraux’s famous studies on the history of painting). That is to say, they remain attached to their specific materiality, making the work a self-enclosed world. In Merleau-Ponty’s repeated metaphor, every painter starts the history of painting afresh (1960, 309–311) because the same visible world calls for an infinite number of expressive variations, each singular in its determinate coherence. The history of painting, therefore, is indeed made up of constant echoes and criss-crosses, with each generation revisiting the visual themes and techniques of the past generations, but the communication amongst the works are haphazard, indirect, and cannot be accumulated. There is no progress in the history of painting. In language, on the other hand, meanings acquired from the past are sedimented in current meanings and allow for the dialectic of spoken and speaking speech discussed earlier (Merleau-Ponty 1969, 97–113). This means that the material of literature carries with it the sedimented historical experiences of the lifeworlds it speaks about. There is no progress in literature either, not in a sense comparable to scientific progress, but the novel, simply by using the language of the lifeworld it arises from, is a direct witness of the broader historical narrative in which it is embedded. As a result, it can portray ethical and political situations very powerfully.

Precisely, the poet’s sin is to treat language as though it were a sound or a note; it is to treat language as a thing and to revere its materiality. This ignores the nature of linguistic expression, in which the signs must be traversed towards their signification. The reverse error is that of Paul Klee, who, according to Sartre, uses colour both as sign and as object (1948a, 23). The existentialist system of the arts is ordered according to the Hegelian principle where arts that involve language rule over the others, because they best express human freedom.

In Sartre’s What is Literature? this apparent disdain for the materiality of painting seems at odds with another aesthetic principle of the existentialists, namely, the capacity of art to witness the obtrusiveness of the world, and, in exceptional moments of aesthetic communion, its inhuman beauty. Indeed, in a few smaller texts, Sartre (1963) seems to return to this aspect of the artwork, which he himself had so powerfully illustrated in his first novel. However, it is true that the existentialists are more interested in the ways in which human beings sort out the entanglements of their freedom in the absurd world, than in the depiction of the materiality of that world. Merleau-Ponty’s texts on the ontological grandeur of Cézanne’s painting are not representative of existential aesthetics generally, but reflect that author’s unique perspective on art and ontology.

Music, which in some classical systems of the arts (in Schopenhauer and Nietzsche, for example) is the highest and most metaphysical art form, also receives an ambiguous treatment in existentialist aesthetics. In The Myth of Sisyphus, for example, Camus seems to be saying that it is the absurd art par excellence because it realises in the purest form what all art conscious of the absurd should be about, namely, the “triumph of the flesh” in the absence of any ultimate meaning:

… that game the mind plays with itself according to set and measured laws takes place in the sonorous compass that belongs to us and beyond which the vibrations nevertheless meet in an inhuman universe. There is no purer sensation. (…) The absurd man recognises as his own these harmonies and these forms (Camus 1942b, 91).
Marcel often emphasised the extent to which music had played a significant role in his philosophical inspiration. He was famous for his improvisations on classical 19th century poems, which his wife noted after the Second World War. We saw earlier that Sartre in a famous passage of Nausea had described an encounter with jazz music in a café as a sublime experience in which the beautiful inner coherence of the musical flow transcended for a moment the nauseating meaninglessness of the material world. And note also de Beauvoir’s late enthusiasm for music (in Francis and Gontier 1979, 67).

Despite these descriptions of music as a privileged meaningful experience in an absurd world, none of the existentialists provides any sustained analysis on the relationship between music, philosophy and the existential condition. Camus interprets positively the formality of music, its lack of discursivity and the abstraction of its relation to the world of flesh (see also his early essay in Camus 1935–1936), features that the latter Merleau-Ponty interprets negatively; but, in the end, the existentialist writers do not give music any detailed consideration.

10.5 Cinema
The most puzzling aspect about the existentialists’ systems of the arts is their relative lack of interest, in their most famous writings at least, in cinema, the privileged art form of the 20th century. Of all the arts, this would have been the one that would appear to have truly been able to present ‘situations.’

In the case of Sartre, this is all the more surprising given his intimate association with cinema at many points in his life. Several passages in de Beauvoir’s and Sartre’s autobiographical writings attest to their shared enthusiasm for the new art (Sartre 1964). The profound influence of film on the young Sartre is well documented in his early writings, where he demonstrates great sensitivity towards the formal and political potentialities of the new medium, in contrast to most of the French intelligentsia of the time (Sartre 1924, 1931). Indeed, these early texts credit cinema with precisely the same capacities of expression that are later granted to theatre, such as the capacity to present action, the necessary yet ambiguous necessity of engagement and the capacity of artistic expression to represent the masses to the masses. Literary criticism has established to what extent Sartre attempted to reproduce in literary form the techniques employed by cinema in the representation of time, space and internal states of consciousness, and specifically how such an influence was crucial in his first major work, Nausea (Johnson 1984).

During the war, Sartre was employed as a script writer by a production company for whom he wrote eight scripts. Two of these were published after the war (Sartre 1947c, 1948b), and two of them were filmed. Most of these scripts provided the material for Sartre’s plays and novels when their realisation failed. In 1958, he also wrote two scripts for films on Freud and Joseph Le Bon. Sartre also wrote twelve articles on film in total, notably a critique of Citizen Kane in 1945, which inspired a response by André Bazin that was to become one of his most famous essays (Bazin 1947). De Beauvoir also recounts the deep impact that the cinematic experience had on Sartre’s ontological views. According to her, the cinematic representation of human actions hostage to the world’s power of resistance was a crucial source of inspiration for his mature ontology, notably for his vision of the absurdity inherent in the world’s contingency (de Beauvoir 1960).

Despite this connection with cinema, the enthusiasm apparent in the early texts receded into the background after his discovery of phenomenology in 1933, following his study year in Germany (de Beauvoir 1962, 231). After that date, cinema no longer features as an important art form in his aesthetic writings. Indeed, in a 1958 conference, Sartre explicitly ranks theatre above cinema because it “has more freedom,” as “a film depicts men who are in the world and are conditioned by it,” whereas “theatre presents action by a man on the stage to men in the audience, and, through this action, both the world he lives in and the performer of the action” (Sartre 1976, 60–61). In other words, theatre is the true art of freedom in situations. Similarly, in later years, de Beauvoir explicitly ranked the novel over cinema for its capacity to “materialise the presence of human beings to human beings” (de Beauvoir quoted in Francis and Gontier 1979, 200). As with the Nouveau Roman, Sartre and de Beauvoir were quite reserved towards the Nouvelle Vague, the new French cinema of the 1960s (ibid.).

Rather than Sartre, it is Merleau-Ponty who gave the most lucid exposition of the evident link between cinema and existentialist philosophy in a conference at the National School of Cinema in Paris (1947b). Despite this insightful text, however, compared with the eminent philosophical status that is bestowed upon theatre, the novel, and painting for the late Merleau-Ponty, as the truly “metaphysical” art forms, cinema is remarkably absent from the most important existentialist writings in aesthetics.


